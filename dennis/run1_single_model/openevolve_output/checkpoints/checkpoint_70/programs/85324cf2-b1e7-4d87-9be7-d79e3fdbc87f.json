{"id": "85324cf2-b1e7-4d87-9be7-d79e3fdbc87f", "code": "import numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes c^T * x, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Total constraints: num_pairs + 4 * n (boundary constraints)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Vectorized assignment of pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n    \n    # Vectorized assignment of boundary constraints\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    base = num_pairs\n    A_ub[base : base + n, np.arange(n)] = 1\n    b_ub[base : base + n] = x - 1e-11\n    \n    A_ub[base + n : base + 2*n, np.arange(n)] = 1\n    b_ub[base + n : base + 2*n] = 1.0 - x - 1e-11\n    \n    A_ub[base + 2*n : base + 3*n, np.arange(n)] = 1\n    b_ub[base + 2*n : base + 3*n] = y - 1e-11\n    \n    A_ub[base + 3*n : base + 4*n, np.arange(n)] = 1\n    b_ub[base + 3*n : base + 4*n] = 1.0 - y - 1e-11\n    \n    try:\n        # Using HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1. Perturbed 5x5 Grid with one extra circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # 2. Staggered layers (5, 4, 5, 4, 5, 3)\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # 3. Phyllotaxis Spiral\n    phi = (1 + np.sqrt(5)) / 2\n    indices = np.arange(n) + 0.5\n    r_spiral = np.sqrt(indices / n) * 0.47\n    theta = 2 * np.pi * indices / (phi**2)\n    c3 = np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(c3)\n    \n    # 4. Concentric Rings (1, 8, 17)\n    c4 = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c4.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c4))\n    \n    # 5. Concentric Rings (1, 7, 18)\n    c5 = [[0.5, 0.5]]\n    for radius, count in [(0.22, 7), (0.43, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c5))\n\n    # Optimization Loop\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.009\n        \n        for step in range(350):\n            if time.time() - start_time > 580:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient from dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii, jj = i_idx[active_mask], j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Move centers apart to allow for larger radii\n                g_vals = lams * diffs / (ds + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity\n            # Indices correlate with the vectorized order in solve_max_radii\n            mu0 = np.abs(duals[num_pairs : num_pairs + n])\n            mu1 = np.abs(duals[num_pairs + n : num_pairs + 2*n])\n            mu2 = np.abs(duals[num_pairs + 2*n : num_pairs + 3*n])\n            mu3 = np.abs(duals[num_pairs + 3*n : num_pairs + 4*n])\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Update step with normalization for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Boundary enforcement and learning rate decay\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final check and cleanup to ensure absolute validity\n    final_radii, _, i_idx, j_idx, _ = solve_max_radii(best_centers)\n    \n    # Geometric validity enforcement pass (eliminating floating point creep)\n    for _ in range(30):\n        for i in range(n):\n            final_radii[i] = min(final_radii[i], best_centers[i, 0], 1.0 - best_centers[i, 0],\n                                 best_centers[i, 1], 1.0 - best_centers[i, 1])\n        for i, j in zip(i_idx, j_idx):\n            d = np.linalg.norm(best_centers[i] - best_centers[j])\n            if final_radii[i] + final_radii[j] > d:\n                overlap = (final_radii[i] + final_radii[j]) - d\n                final_radii[i] -= overlap * 0.5\n                final_radii[j] -= overlap * 0.5\n                \n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Interface to match the evaluation expectations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")", "changes_description": null, "language": "python", "parent_id": "97d33656-3427-4516-b89a-076027f959dc", "generation": 4, "timestamp": 1771869994.3264241, "iteration_found": 55, "metrics": {"validity": 1.0, "sum_radii": 0.2351731952468359, "target_ratio": 0.0892497894674899, "combined_score": 0.0892497894674899, "radius_variance": 0.015119971662549768, "spatial_spread": 0.10074616125486412}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.4797382079429555, "target_ratio": 0.9410771187639301, "combined_score": 0.9410771187639301, "radius_variance": 0.0033994973812845213, "spatial_spread": 0.19275911129667, "eval_time": 1.2359836101531982}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician specializing in circle packing problems and computational geometry. \nYour task is to improve a constructor function that directly produces a specific arrangement of 26 circles in a unit square, maximizing the sum of their radii. \nTry to improve the results reported in the AlphaEvolve paper which achieved a sum of 2.635 for n=26.\n\nKey insights:\n- The optimization routine is critically important - simple physics-based models with carefully tuned parameters\n- Consider strategic placement of circles at square corners and edges\n- Adjusting the pattern to place larger circles at the center and smaller at the edges\n- Similar radius circles often form regular patterns, while varied radii allow better space utilization\n- Perfect symmetry may not yield the optimal packing due to edge effects\n\nMake sure that your codecod is syntactically perfect, strictly adheres to PEP 8 indentation, and contains no ellipses, comments-as-placeholders, or unclosed structures.\n", "user": "# Current Program Information\n- Fitness: 0.9411\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.9411\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n1.24s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.479738/2.635 = 0.9411\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.4797, target_ratio: 0.9411, combined_score: 0.9411, radius_variance: 0.0034, spatial_spread: 0.1928, eval_time: 1.2360\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5002, target_ratio: 0.9489, combined_score: 0.9489, radius_variance: 0.0047, spatial_spread: 0.1955, eval_time: 6.4416\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5422, target_ratio: 0.9648, combined_score: 0.9648, radius_variance: 0.0078, spatial_spread: 0.1638, eval_time: 4.1488\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9648)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    for k, (i, j) in enumerate(zip(i_idx, j_idx)):\n        A_ub[k, i] = 1\n        A_ub[k, j] = 1\n        b_ub[k] = dists[k] - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        A_ub[base, i], b_ub[base] = 1, x[i] - 1e-11\n        A_ub[base + 1, i], b_ub[base + 1] = 1, 1.0 - x[i] - 1e-11\n        A_ub[base + 2, i], b_ub[base + 2] = 1, y[i] - 1e-11\n        A_ub[base + 3, i], b_ub[base + 3] = 1, 1.0 - y[i] - 1e-11\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # Layout 1: 5x5 Grid with one circle near the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # Layout 2: Staggered layers (5, 4, 5, 4, 5, 3) to fill the square\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # Layout 3: Ring distribution (1 center, 8 middle, 17 outer)\n    c3 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c3.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c3))\n\n    # Layout 4: Another staggered layout (4, 5, 4, 5, 4, 4)\n    c4 = []\n    layers4 = [4, 5, 4, 5, 4, 4]\n    for r_idx, n_row in enumerate(layers4):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers4)])\n    inits.append(np.array(c4))\n    \n    # Layout 5: Random distribution\n    np.random.seed(42)\n    inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.008  # Initial learning rate\n        \n        for step in range(350):\n            # Periodically check time limit\n            if time.time() - start_time > 560:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            # Duals tell us how the sum of radii changes with center positions\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Direction of movement to increase the distance\n                g_vals = (lams[:, np.newaxis] * diffs / (ds + 1e-12))\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints\n            # Sensitivity to moving away from the four walls\n            mu0 = np.abs(duals[num_pairs + 4 * np.arange(n)])      # r_i <= x_i\n            mu1 = np.abs(duals[num_pairs + 4 * np.arange(n) + 1])  # r_i <= 1-x_i\n            mu2 = np.abs(duals[num_pairs + 4 * np.arange(n) + 2])  # r_i <= y_i\n            mu3 = np.abs(duals[num_pairs + 4 * np.arange(n) + 3])  # r_i <= 1-y_i\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final cleanup to ensure radii are optimal for the best centers found\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Entry point for evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5422), Performs well on target_ratio (0.9648), Performs well on combined_score (0.9648), Performs well on radius_variance (0.0078), Performs well on spatial_spread (0.1638), Performs well on eval_time (4.1488)\n\n### Program 2 (Score: 0.9489)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles in a unit square.\nThis program uses a dual-gradient optimization approach to find circle centers\nthat maximize the sum of radii. For any set of fixed centers, the optimal radii\nare computed using Linear Programming. The gradients for the centers are then\nderived from the dual variables of this LP.\n\"\"\"\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # We combine pairwise and boundary constraints into one A_ub matrix\n    # to obtain dual variables for both simultaneously.\n    # Total constraints: num_pairs + 4 * n\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    for k, (i, j) in enumerate(zip(i_idx, j_idx)):\n        A_ub[k, i] = 1\n        A_ub[k, j] = 1\n        # Subtract a tiny epsilon to ensure strict validity against float errors\n        b_ub[k] = max(0, dists[k] - 1e-11)\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        A_ub[base, i] = 1\n        b_ub[base] = max(0, x[i] - 1e-11)\n        A_ub[base + 1, i] = 1\n        b_ub[base + 1] = max(0, 1.0 - x[i] - 1e-11)\n        A_ub[base + 2, i] = 1\n        b_ub[base + 2] = max(0, y[i] - 1e-11)\n        A_ub[base + 3, i] = 1\n        b_ub[base + 3] = max(0, 1.0 - y[i] - 1e-11)\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n    except Exception:\n        # Fallback for environments with older scipy versions\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None))\n        \n    if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n        return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    return np.zeros(n), None, i_idx, j_idx, dists\n\n\ndef run_packing():\n    \"\"\"\n    Core function to optimize the arrangement of 26 circles.\n    Utilizes multiple starting configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Define diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # Layout 1: 5x5 Grid with one extra circle at center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]])\n    inits.append(c1)\n    \n    # Layout 2: Staggered layers (5, 4, 5, 4, 5, 3) to fill the square\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2)[:n])\n    \n    # Layout 3: Concentric circles (1 center, 7 middle, 18 outer)\n    c3 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 7), (0.42, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c3.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c3)[:n])\n    \n    # Layout 4: Random distribution\n    np.random.seed(42)\n    inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.006  # Initial learning rate\n        \n        for step in range(400):\n            # Periodically check time limit (600s total)\n            if time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            # Duals tell us how the sum of radii changes with center positions\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            # Scipy returns negative duals for minimization; we use absolute values\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-7\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                g_vals = (lams[:, np.newaxis] * diffs / (ds + 1e-12))\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints\n            mu0 = np.abs(duals[num_pairs + 4 * np.arange(n)])\n            mu1 = np.abs(duals[num_pairs + 4 * np.arange(n) + 1])\n            mu2 = np.abs(duals[num_pairs + 4 * np.arange(n) + 2])\n            mu3 = np.abs(duals[num_pairs + 4 * np.arange(n) + 3])\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers strictly within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.994\n            \n    return best_centers, best_radii, best_sum\n\n\ndef construct_packing():\n    \"\"\"Wrapper to meet the standard constructor signature.\"\"\"\n    return run_packing()\n\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n# EVOLVE-BLOCK-END\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5002), Performs well on target_ratio (0.9489), Performs well on combined_score (0.9489), Performs well on radius_variance (0.0047), Performs well on spatial_spread (0.1955), Performs well on eval_time (6.4416)\n\n### Program 3 (Score: 0.9411)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii. \nThe dual variables of this LP provide the sensitivity of the sum of radii to the \ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and the tightest boundary constraints.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: minimize -sum(radii) to maximize sum(radii)\n    c_obj = -np.ones(n)\n\n    # Inequality constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    b_left = x\n    b_right = 1.0 - x\n    b_bottom = y\n    b_top = 1.0 - y\n\n    # Find which boundary is tightest for each circle\n    max_r_boundary = np.minimum.reduce([b_left, b_right, b_bottom, b_top])\n    bounds_lp = [(0, r) for r in max_r_boundary]\n\n    try:\n        # Highs is efficient and provides marginals (duals)\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, max_r_boundary\n\n\ndef run_packing():\n    \"\"\"\n    Runs the circle packing optimization and returns the best found configuration.\n    \"\"\"\n    n_circles = 26\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Define several starting configurations\n    initial_configs = []\n\n    # Init 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx.ravel(), gy.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # Init 2: Hexagonal-like staggered layers (5, 4, 5, 4, 5, 3) = 26 circles\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # Init 3: 6x4 Grid plus 2 extra circles\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx2.ravel(), gy2.ravel()])\n    c3 = np.vstack([c3, [[0.2, 0.5], [0.8, 0.5]]])\n    initial_configs.append(c3)\n\n    # Optimize each initial configuration\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        # Dual-gradient optimization iterations\n        for step in range(150):\n            res, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Update gradient based on pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        if d > 1e-8:\n                            grad[ii] += lam * diff / d\n                            grad[jj] -= lam * diff / d\n\n                # Update gradient based on boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0: grad[i, 0] += mu\n                        elif tightest == 1: grad[i, 0] -= mu\n                        elif tightest == 2: grad[i, 1] += mu\n                        elif tightest == 3: grad[i, 1] -= mu\n\n                # Normalize step for stability and apply update\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    # Decay the step size over time\n                    step_size = 0.006 * (0.99 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Keep centers within the unit square\n                cur_c = np.clip(cur_c, 1e-7, 1.0 - 1e-7)\n            else:\n                break\n\n    # Perform a final rigorous LP solve and validity correction\n    if best_c is None:\n        best_c = initial_configs[1]\n\n    res_final, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(best_c)\n    final_r = res_final.x\n    final_c = best_c\n\n    # Strict geometry enforcement (multi-pass) to ensure zero overlap or boundary violation\n    for _ in range(50):\n        for i in range(n_circles):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n\n    return final_c, final_r, np.sum(final_r)\n\n\ndef construct_packing():\n    \"\"\"Alias for run_packing to match expected constructor interface.\"\"\"\n    return run_packing()\n# EVOLVE-BLOCK-END\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.4797), Performs well on target_ratio (0.9411), Performs well on combined_score (0.9411), Performs well on radius_variance (0.0034), Performs well on spatial_spread (0.1928), Performs well on eval_time (1.2360)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles in a unit square.\nThis program uses a multi-start repulsion-based optimization for circle centers\nfollowed by a Linear Programming step to maximize the total sum of radii.\n\"\"\"\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= dist(c_i, c_j) and boundary constraints.\n    \"\"\"\n    n = centers.shape[0]\n    # Minimize -sum(r_i) which is equivalent to maximizing sum(r_i)\n    c_obj = -np.ones(n)\n    \n    # Overlap constraints: r_i + r_j <= distance between centers\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(centers[i_idx] - centers[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    A_ub = np.zeros((num_pairs, n))\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Use a tiny safety margin to ensure strict compliance with float precision\n    b_ub = dists - 1e-12\n    \n    # Boundary constraints: each circle i must stay within [0, 1] x [0, 1]\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = centers[:, 0], centers[:, 1]\n    max_r_possible = np.minimum.reduce([x, 1 - x, y, 1 - y])\n    bounds = [(0, max(0, r_limit - 1e-12)) for r_limit in max_r_possible]\n    \n    try:\n        # Use the modern HiGHS solver if available\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n    except Exception:\n        # Fallback to the default solver for older scipy versions\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        \n    if res.success and res.x is not None:\n        return res.x\n    return np.zeros(n)\n\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the placement of 26 circles to maximize the sum of their radii.\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Try different topological initializations for multi-start optimization\n    for attempt in range(4):\n        if attempt == 0:\n            # 5x5 Grid initialization with one extra circle\n            xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.0000)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii.\nThe dual variables of this LP provide the sensitivity of the sum of radii to the\ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and pairwise distances.\n    \"\"\"\n    n = 26\n    # Objective: maximize sum(radii) => minimize -sum(radii)\n    c_obj = -np.ones(n)\n\n    # Pairwise constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1.0 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    max_r_boundary = np.minimum.reduce([x, 1.0 - x, y, 1.0 - y])\n    bounds_lp = list(zip(np.zeros(n), np.maximum(max_r_boundary, 1e-10)))\n\n    try:\n        # Use HiGHS solver for efficiency and access to dual variables\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists\n\n\ndef construct_packing():\n    \"\"\"\n    Runs the circle packing optimization using dual-gradient ascent on center positions.\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Initial configurations to explore different topologies\n    initial_configs = []\n\n    # 1. Staggered layers (5, 5, 5, 5, 5, 1)\n    c1 = []\n    for r_idx in range(6):\n        num_row = 5 if r_idx < 5 else 1\n        for i_idx in range(num_row):\n            offset = 0.2 if r_idx % 2 == 1 else 0.0\n            x_coord = (i_idx + 0.5 + offset) / 5.5\n            y_coord = (r_idx + 0.5) / 6.0\n            c1.append([x_coord, y_coord])\n    initial_configs.append(np.array(c1)[:n])\n\n    # 2. Concentric rings (1 center, 8 middle, 17 outer)\n    c2 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 8), (0.43, 17)]:\n        for i in range(count):\n            angle = 2 * np.pi * i / count\n            c2.append([0.5 + rad * np.cos(angle), 0.5 + rad * np.sin(angle)])\n    initial_configs.append(np.array(c2)[:n])\n\n    # 3. Standard 5x5 grid plus one circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c3 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]])\n    initial_configs.append(c3)\n\n    # Optimization Loop\n    for start_pts in initial_configs:\n        curr_pts = np.clip(start_pts, 0.01, 0.99)\n        \n        for step in range(160):\n            res, i_idx, j_idx, d_vals = solve_lp(curr_pts)\n            if not res or not res.success:\n                break\n\n            current_sum = -res.fun\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_c = curr_pts.copy()\n                best_r = res.x\n\n            try:\n                # Extract dual variables (marginals) to compute gradients\n                lambdas = getattr(res.ineqlin, 'marginals', None)\n                mus = getattr(res.upper, 'marginals', None)\n                if lambdas is None or mus is None:\n                    break\n                \n                grad = np.zeros((n, 2))\n                diffs = curr_pts[i_idx] - curr_pts[j_idx]\n                \n                # Pairwise sensitivity\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-8:\n                        ii, jj = i_idx[k], j_idx[k]\n                        vec = lam * diffs[k] / (d_vals[k] + 1e-10)\n                        grad[ii] += vec\n                        grad[jj] -= vec\n\n                # Boundary sensitivity\n                for k in range(n):\n                    mu = abs(mus[k])\n                    if mu > 1e-8:\n                        xk, yk = curr_pts[k]\n                        b_opts = [xk, 1.0 - xk, yk, 1.0 - yk]\n                        tightest = np.argmin(b_opts)\n                        if tightest == 0: grad[k, 0] += mu\n                        elif tightest == 1: grad[k, 0] -= mu\n                        elif tightest == 2: grad[k, 1] += mu\n                        elif tightest == 3: grad[k, 1] -= mu\n\n                # Normalize gradient step for stability\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-10:\n                    step_size = 0.009 * (0.99 ** step)\n                    curr_pts += step_size * grad / gnorm\n                    curr_pts = np.clip(curr_pts, 1e-8, 1.0 - 1e-8)\n                else:\n                    break\n            except Exception:\n                break\n\n    # Final geometric polish and LP solve to ensure perfect validity\n    res_final, _, _, _ = solve_lp(best_c)\n    final_c, final_r = best_c, res_final.x\n\n    # Strict multi-pass enforcement for zero overlap or boundary violations\n    for _ in range(100):\n        for i in range(n):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(final_c[i] - final_c[j])\n                if final_r[i] + final_r[j] > dist:\n                    overlap = (final_r[i] + final_r[j]) - dist\n                    final_r[i] -= overlap * 0.5\n                    final_r[j] -= overlap * 0.5\n\n    return final_c, final_r, np.sum(final_r)\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef solve_max_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Falls back to a robust projected gradient descent method if scipy is unavailable.\n    \"\"\"\n    n = len(centers)\n    radii = None\n    \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = []\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            bounds.append((0, max_r))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            radii = res.x\n    except Exception:\n        pass\n        \n    if radii is None:\n        # Fallback to projected gradient descent on constraints\n        radii = np.zeros(n)\n        max_bounds = np.array([min(x, y, 1 - x, 1 - y) for x, y in centers])\n        \n        dist_matrix = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(centers[i] - centers[j])\n                dist_matrix[i, j] = d\n                dist_matrix[j, i] = d\n        np.fill_diagonal(dist_matrix, np.inf)\n        \n        lr_fallback = 0.005\n        for _ in range(3000):\n            overlap = np.maximum(0, radii[:, None] + radii[None, :] - dist_matrix)\n            grad = np.ones(n) - 200.0 * np.sum(overlap, axis=1)\n            radii += lr_fallback * grad\n            radii = np.clip(radii, 0, max_bounds)\n            \n    # Strictly enforce constraints to eliminate any floating-point inaccuracies\n    for i in range(n):\n        x, y = centers[i]\n        radii[i] = min(radii[i], x, y, 1 - x, 1 - y)\n        \n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii\n\n\ndef optimize_packing(n=26, steps=2500):\n    \"\"\"\n    Optimizes the\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef get_exact_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Falls back to a robust geometric projected gradient descent method if scipy is unavailable.\n    \"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c_obj = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = []\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            bounds.append((0, max(0, max_r)))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n        \n    # Fallback to optimization if linprog fails or is unavailable\n    r = np.full(n, 0.05)\n    for _ in range(1000):\n        grad = -np.ones(n)\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if r[i] > max_r:\n                grad[i] += 100 * (r[i] - max_r)\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                overlap = r[i] + r[j] - dist\n                if overlap > 0:\n                    grad[i] += 100 * overlap\n                    grad[j] += 100 * overlap\n                    \n        r -= 0.01 * grad\n        r = np.maximum(r, 0)\n    return r\n\ndef construct_packing():\n    \"\"\"\n    Construct a specific arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    B = 50 # Number of parallel batches for optimization\n    \n    # Initialize batch of centers and radii for parallel optimization\n    c = np.random.uniform(0.1, 0.9, (B, n, 2))\n    r = np.full((B, n), 0.05)\n    \n    # Structured initialization to seed optimal topologies\n    # Batch 0: Ring layout 1, 8, 17\n    c[0, 0] = [0.5, 0.5]\n    for i in range(8):\n        a = 2 * np.pi * i / 8\n        c[0, i+1] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n    for i in range(17):\n        a = 2 * np.pi * i / 17\n        c[0, i+9] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n\n    # Batch 1: Grid-like 5x5 + 1\n    gx, gy = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 5))\n    c[1, :25] = np.column_stack([gx.flatten(), gy.flatten()])\n    c[1, 25] = [0.5, 0.5]\n\n    # Batch 2: Another ring layout 1, 6, 19\n    c[2, 0] = [0.5, 0.5]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        c[2, i+1] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n    for i in range(19):\n        a = 2 * np.pi * i / 19\n        c[2, i+7] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n        \n    # Batch 3: Hexagonalish\n    hex_c = []\n    for i in range(6):\n        for j in range(6):\n            if len(hex_c) < 26:\n                hex_c.append([0.15 + 0.14 * i + (j % 2) * 0.07, 0.15 + 0.14 * j])\n    c[3] = np.array(hex_c)\n\n    # Batch 4: Concentric 4, 9, 13\n    for i in range(4):\n        a = 2 * np.pi * i / 4\n        c[4, i] = [0.5 + 0.1 * np.cos(a), 0.5 + 0.1 * np.sin(a)]\n    for i in range(9):\n        a = 2 * np.pi * i / 9\n        c[4, i+4] = [0.5 + 0.25 * np.cos(a), 0.5 + 0.25 * np.sin(a)]\n    for i in range(13):\n        a = 2 * np.pi * i / 13\n        c[4, i+13] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    lr_c = 0.005\n    lr_r = 0.005\n    \n    idx_i, idx_j = np.triu_indices(n, k=1)\n    \n    # Main optimization loop\n    for step in range(8000):\n        grad_c = np.zeros_like(c)\n        grad_r = -np.ones_like(r)\n        \n        # Penalties for boundary violations\n        viol_left = np.maximum(0, r - c[:, :, 0])\n        grad_r += 100 * viol_left\n        grad_c[:, :, 0] -= 100 * viol_left\n        \n        viol_right = np.maximum(0, r + c[:, :, 0] - 1)\n        grad_r += 100 * viol_right\n        grad_c[:, :, 0] += 100 * viol_right\n        \n        viol_bottom = np.maximum(0, r - c[:, :, 1])\n        grad_r += 100 * viol_bottom\n        grad_c[:, :, 1] -= 100 * viol_bottom\n        \n        viol_top = np.maximum(0, r + c[:, :, 1] - 1)\n        grad_r += 100 * viol_top\n        grad_c[:, :, 1] += 100 * viol_top\n        \n        # Pairwise overlap penalties\n        c_i = c[:, idx_i, :] \n        c_j = c[:, idx_j, :] \n        r_i = r[:, idx_i]    \n        r_j = r[:, idx_j]    \n        \n        diff = c_i - c_j\n        dist = np.linalg.norm(diff, axis=2) + 1e-10 \n        \n        overlap = np.maximum(0, r_i + r_j - dist) \n        penalty = 200 * overlap \n        \n        dir_ij = diff / dist[:, :, None] \n        force = penalty[:, :, None] * dir_ij \n        \n        for p in range(len(idx_i)):\n            i = idx_i[p]\n            j = idx_j[p]\n            grad_r[:, i] += penalty[:, p]\n            grad_r[:, j] += penalty[:, p]\n            grad_c[:, i, :] -= force[:, p, :]\n            grad_c[:, j, :] += force[:, p, :]\n            \n        # Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** (step + 1))\n        v_c_hat = v_c / (1 - beta2 ** (step + 1))\n        c -= lr_c * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** (step + 1))\n        v_r_hat = v_r / (1 - beta2 ** (step + 1))\n        r -= lr_r * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        c = np.clip(c, 0, 1)\n        r = np.maximum(r, 0)\n        \n        # Learning rate decay\n        if step % 2000 == 1999:\n            lr_c *= 0.5\n            lr_r *= 0.5\n\n    best_sum = 0\n    best_c = None\n    best_r = None\n    \n    # Evaluate configurations exactingly to ensure 100% validity\n    for b in range(B):\n        cb = c[b]\n        rb = get_exact_radii(cb)\n        \n        # Strict geometry enforcement multiple passes\n        for _ in range(3):\n            for i in range(n):\n                x, y = cb[i]\n                rb[i] = min(rb[i], x, y, 1 - x, 1 - y)\n                rb[i] = max(0, rb[i])\n                \n            for i in range(n):\n                for j in range(i + 1, n):\n                    dist = np.linalg.norm(cb[i] - cb[j])\n                    if rb[i] + rb[j] > dist:\n                        scale = (dist - 1e-12) / (rb[i] + rb[j])\n                        rb[i] *= scale\n                        rb[j] *= scale\n                        \n        s = np.sum(rb)\n        if s > best_sum:\n            best_sum = s\n            best_c = cb\n            best_r = rb\n            \n    return best_c, best_r, best_sum\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles maximizing sum of radii.\"\"\"\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\nimport time\n\ncenters = None\nradii = None\nsum_radii = 0.0\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes exact optimal valid radii for fixed circle centers using Highs Linear Programming,\n    guaranteeing strict constraints satisfaction to avoid any floating-point violations.\n    \"\"\"\n    n = len(pts)\n    c = -np.ones(n)\n    \n    # Vectorized computation of pairwise distances\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dx = pts[i_idx, 0] - pts[j_idx, 0]\n    dy = pts[i_idx, 1] - pts[j_idx, 1]\n    dist = np.hypot(dx, dy)\n    \n    # A_ub limits r_i + r_j <= distance_ij\n    A_ub = np.zeros((len(i_idx), n))\n    A_ub[np.arange(len(i_idx)), i_idx] = 1\n    A_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dist\n    \n    # Bounds restrict each circle fully within the unit square\n    x = pts[:, 0]\n    y = pts[:, 1]\n    max_r = np.clip(np.minimum.reduce([x, y, 1 - x, 1 - y]), 0, None)\n    bounds = [(0, r) for r in max_r]\n    \n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n    if res.success:\n        r_opt = res.x\n    else:\n        r_opt = np.zeros(n)\n        \n    r_opt = np.clip(r_opt, 0, max_r)\n    \n    # Strict correction pass handling any marginal numerical overlaps safely\n    for _ in range(10):\n        violations = 0\n        for k in range(len(i_idx)):\n            i = i_idx[k]\n            j = j_idx[k]\n            d = dist[k]\n            if r_opt[i] + r_opt[j] > d + 1e-11:\n                scale = (d / (r_opt[i] + r_opt[j])) * 0.999999\n                r_opt[i] *= scale\n                r_opt[j] *= scale\n                violations += 1\n        if violations == 0:\n            break\n            \n    return r_opt\n\ndef _compute():\n    \"\"\"\n    Runs an accelerated multi-start SLSQP search to rapidly explore configurations.\n    Optimizes both coordinates and radii concurrently using precise vectorized Jacobians.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    max_time = 580.0  # Limits computation below 600s strict timeout\n    \n    best_sum_r = -1\n    best_centers = None\n    best_radii = None\n    \n    def obj(p):\n        return -np.sum(p[2*n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii. \nThe dual variables of this LP provide the sensitivity of the sum of radii to the \ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and the tightest boundary constraints.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: minimize -sum(radii) to maximize sum(radii)\n    c_obj = -np.ones(n)\n\n    # Inequality constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    b_left = x\n    b_right = 1.0 - x\n    b_bottom = y\n    b_top = 1.0 - y\n\n    # Find which boundary is tightest for each circle\n    max_r_boundary = np.minimum.reduce([b_left, b_right, b_bottom, b_top])\n    bounds_lp = [(0, r) for r in max_r_boundary]\n\n    try:\n        # Highs is efficient and provides marginals (duals)\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, max_r_boundary\n\n\ndef run_packing():\n    \"\"\"\n    Runs the circle packing optimization and returns the best found configuration.\n    \"\"\"\n    n_circles = 26\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Define several starting configurations\n    initial_configs = []\n\n    # Init 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx.ravel(), gy.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # Init 2: Hexagonal-like staggered layers (5, 4, 5, 4, 5, 3) = 26 circles\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # Init 3: 6x4 Grid plus 2 extra circles\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx2.ravel(), gy2.ravel()])\n    c3 = np.vstack([c3, [[0.2, 0.5], [0.8, 0.5]]])\n    initial_configs.append(c3)\n\n    # Optimize each initial configuration\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        # Dual-gradient optimization iterations\n        for step in range(150):\n            res, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Update gradient based on pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        if d > 1e-8:\n                            grad[ii] += lam * diff / d\n                            grad[jj] -= lam * diff / d\n\n                # Update gradient based on boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0: grad[i, 0] += mu\n                        elif tightest == 1: grad[i, 0] -= mu\n                        elif tightest == 2: grad[i, 1] += mu\n                        elif tightest == 3: grad[i, 1] -= mu\n\n                # Normalize step for stability and apply update\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    # Decay the step size over time\n                    step_size = 0.006 * (0.99 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Keep centers within the unit square\n                cur_c = np.clip(cur_c, 1e-7, 1.0 - 1e-7)\n            else:\n                break\n\n    # Perform a final rigorous LP solve and validity correction\n    if best_c is None:\n        best_c = initial_configs[1]\n\n    res_final, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(best_c)\n    final_r = res_final.x\n    final_c = best_c\n\n    # Strict geometry enforcement (multi-pass) to ensure zero overlap or boundary violation\n    for _ in range(50):\n        for i in range(n_circles):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n\n    return final_c, final_r, np.sum(final_r)\n\n\ndef construct_packing():\n    \"\"\"Alias for run_packing to match expected constructor interface.\"\"\"\n    return run_packing()\n# EVOLVE-BLOCK-END\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes c^T * x, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Total constraints: num_pairs + 4 * n (boundary constraints)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Vectorized assignment of pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n    \n    # Vectorized assignment of boundary constraints\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    base = num_pairs\n    A_ub[base : base + n, np.arange(n)] = 1\n    b_ub[base : base + n] = x - 1e-11\n    \n    A_ub[base + n : base + 2*n, np.arange(n)] = 1\n    b_ub[base + n : base + 2*n] = 1.0 - x - 1e-11\n    \n    A_ub[base + 2*n : base + 3*n, np.arange(n)] = 1\n    b_ub[base + 2*n : base + 3*n] = y - 1e-11\n    \n    A_ub[base + 3*n : base + 4*n, np.arange(n)] = 1\n    b_ub[base + 3*n : base + 4*n] = 1.0 - y - 1e-11\n    \n    try:\n        # Using HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1. Perturbed 5x5 Grid with one extra circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # 2. Staggered layers (5, 4, 5, 4, 5, 3)\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # 3. Phyllotaxis Spiral\n    phi = (1 + np.sqrt(5)) / 2\n    indices = np.arange(n) + 0.5\n    r_spiral = np.sqrt(indices / n) * 0.47\n    theta = 2 * np.pi * indices / (phi**2)\n    c3 = np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(c3)\n    \n    # 4. Concentric Rings (1, 8, 17)\n    c4 = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c4.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c4))\n    \n    # 5. Concentric Rings (1, 7, 18)\n    c5 = [[0.5, 0.5]]\n    for radius, count in [(0.22, 7), (0.43, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c5))\n\n    # Optimization Loop\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.009\n        \n        for step in range(350):\n            if time.time() - start_time > 580:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient from dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii, jj = i_idx[active_mask], j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Move centers apart to allow for larger radii\n                g_vals = lams * diffs / (ds + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity\n            # Indices correlate with the vectorized order in solve_max_radii\n            mu0 = np.abs(duals[num_pairs : num_pairs + n])\n            mu1 = np.abs(duals[num_pairs + n : num_pairs + 2*n])\n            mu2 = np.abs(duals[num_pairs + 2*n : num_pairs + 3*n])\n            mu3 = np.abs(duals[num_pairs + 3*n : num_pairs + 4*n])\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Update step with normalization for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Boundary enforcement and learning rate decay\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final check and cleanup to ensure absolute validity\n    final_radii, _, i_idx, j_idx, _ = solve_max_radii(best_centers)\n    \n    # Geometric validity enforcement pass (eliminating floating point creep)\n    for _ in range(30):\n        for i in range(n):\n            final_radii[i] = min(final_radii[i], best_centers[i, 0], 1.0 - best_centers[i, 0],\n                                 best_centers[i, 1], 1.0 - best_centers[i, 1])\n        for i, j in zip(i_idx, j_idx):\n            d = np.linalg.norm(best_centers[i] - best_centers[j])\n            if final_radii[i] + final_radii[j] > d:\n                overlap = (final_radii[i] + final_radii[j]) - d\n                final_radii[i] -= overlap * 0.5\n                final_radii[j] -= overlap * 0.5\n                \n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Interface to match the evaluation expectations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")\n\n```"]}}, "artifacts_json": "{\"execution_time\": \"5.48s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum: 0.235173, Ratio: 0.0892\"}", "artifact_dir": null, "embedding": null}