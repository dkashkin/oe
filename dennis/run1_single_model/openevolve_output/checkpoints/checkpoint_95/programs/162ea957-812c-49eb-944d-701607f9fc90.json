{"id": "162ea957-812c-49eb-944d-701607f9fc90", "code": "import numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= distance to wall.\n    \n    Returns:\n        radii: Optimal radii for each center.\n        duals: Dual variables (marginals) providing sensitivity to center movement.\n        i_idx, j_idx: Indices of circle pairs used for constraints.\n        dists: Euclidean distances between centers.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes the objective function, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combine pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Small epsilon to ensure strict validity within floating point precision\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Correct any negative bounds caused by centers being slightly out of square\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use the HiGHS solver for efficiency and access to marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return None, None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent derived from LP.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts to explore different packing topologies\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # 3: Staggered layers (5, 4, 5, 4, 5, 3) = 26\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # 4: Staggered layers (4, 5, 4, 5, 4, 4) = 26\n    c4 = []\n    for r_idx, n_row in enumerate([4, 5, 4, 5, 4, 4]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c4))\n\n    # 5: Ring distribution (1 center, 8 middle, 17 outer)\n    c5 = [[0.5, 0.5]]\n    for rad, count in [(0.24, 8), (0.46, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c5))\n    \n    # 6: Fibonacci / Spiral layout\n    c6 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt((i + 0.5) / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c6.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c6))\n\n    # 7: Concentric layers (1, 7, 18)\n    c7 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 7), (0.44, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c7.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c7))\n    \n    # 8: Grid 6x4 with 2 extras\n    gx8, gy8 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx8.ravel(), gy8.ravel()]), [[0.2, 0.5], [0.8, 0.5]]]))\n\n    # Optimization loop for each initialization\n    for c_start in inits:\n        if time.time() - start_time > 550:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.015  # Starting learning rate\n        \n        for step in range(300):\n            # Check for early exit based on time\n            if step % 20 == 0 and time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on sensitivity from dual variables\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            # Dual variables indicate the rate of change of the sum w.r.t the constraint bounds\n            # For maximize sum(r_i), we move the centers in directions that increase b_ub\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distances: push centers apart\n            lams_p = lambdas[:num_pairs]\n            active_p = lams_p > 1e-9\n            if np.any(active_p):\n                ii, jj = i_idx[active_p], j_idx[active_p]\n                diffs = curr_c[ii] - curr_c[jj]\n                # Normalized direction vectors scaled by dual sensitivity\n                g_vals = lams_p[active_p, np.newaxis] * diffs / (dists[active_p, np.newaxis] + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints: move centers inward to make room\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]  # Sensitivity for x and 1-x\n            grad[:, 1] += mus[:, 2] - mus[:, 3]  # Sensitivity for y and 1-y\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within the unit square and apply decay to step size\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.99\n            \n    # Final cleanup: ensure radii are strictly optimal for the best centers found\n    if best_centers is not None:\n        final_radii, _, _, _, _ = solve_max_radii(best_centers)\n        return best_centers, final_radii, np.sum(final_radii)\n    else:\n        # Fallback in case of failure\n        random_c = np.random.uniform(0.1, 0.9, (n, 2))\n        random_r, _, _, _, _ = solve_max_radii(random_c)\n        return random_c, random_r, np.sum(random_r)\n\ndef run_packing():\n    \"\"\"Main execution function to be called by evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")", "changes_description": null, "language": "python", "parent_id": "85256b23-7ee8-4b54-a4e1-bfa033f1673d", "generation": 3, "timestamp": 1771870476.0284407, "iteration_found": 71, "metrics": {"validity": 1.0, "sum_radii": 2.5484641429049923, "target_ratio": 0.9671590675161262, "combined_score": 0.9671590675161262, "radius_variance": 0.007950843135816166, "spatial_spread": 0.16441368764744677, "eval_time": 5.291803359985352}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician specializing in circle packing problems and computational geometry. \nYour task is to improve a constructor function that directly produces a specific arrangement of 26 circles in a unit square, maximizing the sum of their radii. \nTry to improve the results reported in the AlphaEvolve paper which achieved a sum of 2.635 for n=26.\n\nKey insights:\n- The optimization routine is critically important - simple physics-based models with carefully tuned parameters\n- Consider strategic placement of circles at square corners and edges\n- Adjusting the pattern to place larger circles at the center and smaller at the edges\n- Similar radius circles often form regular patterns, while varied radii allow better space utilization\n- Perfect symmetry may not yield the optimal packing due to edge effects\n\nMake sure that your codecod is syntactically perfect, strictly adheres to PEP 8 indentation, and contains no ellipses, comments-as-placeholders, or unclosed structures.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.9648 \u2192 0.0000. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: module 'program' has no attribute 'run_packing'\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/cp_1model_1phase/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/cp_1model_1phase/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: module 'program' has no attribute 'run_packing'\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5422, target_ratio: 0.9648, combined_score: 0.9648, radius_variance: 0.0078, spatial_spread: 0.1638, eval_time: 4.1488\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5591, target_ratio: 0.9712, combined_score: 0.9712, radius_variance: 0.0086, spatial_spread: 0.1660, eval_time: 7.7775\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5778, target_ratio: 0.9783, combined_score: 0.9783, radius_variance: 0.0044, spatial_spread: 0.2088, eval_time: 9.6580\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9783)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    x, y = pts[:, 0], pts[:, 1]\n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Ensure bounds are strictly non-negative\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent derived from LP.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # 3: Staggered layers (5, 4, 5, 4, 5, 3) = 26\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # 4: Another staggered layout (6, 7, 6, 7) = 26\n    c4 = []\n    for r_idx, n_row in enumerate([6, 7, 6, 7]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 4])\n    inits.append(np.array(c4))\n    \n    # 5: Staggered (5, 5, 5, 5, 6) = 26\n    c5 = []\n    for r_idx, n_row in enumerate([5, 5, 5, 5, 6]):\n        for i_idx in range(n_row):\n            c5.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 5])\n    inits.append(np.array(c5))\n\n    # 6: Ring distribution (1 center, 8 middle, 17 outer)\n    c6 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c6.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c6))\n    \n    # 7: Fibonacci / Spiral layout\n    c7 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt(i / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c7.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c7))\n\n    # 8: Randomly perturbed grid\n    np.random.seed(42)\n    inits.append(np.clip(inits[0] + np.random.normal(0, 0.02, (n, 2)), 0.05, 0.95))\n    \n    # 9: 6x4 Grid plus 2 extra circles\n    gx9, gy9 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx9.ravel(), gy9.ravel()]), [[0.5, 0.4], [0.5, 0.6]]]))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.01  # Initial learning rate\n        \n        for step in range(450):\n            # Check time limit periodically\n            if time.time() - start_time > 560:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distances\n            lams_p = lambdas[:num_pairs]\n            diffs = curr_c[i_idx] - curr_c[j_idx]\n            g_vals = lams_p[:, np.newaxis] * diffs / (dists[:, np.newaxis] + 1e-15)\n            np.add.at(grad, i_idx, g_vals)\n            np.add.at(grad, j_idx, -g_vals)\n            \n            # Gradients from boundary constraints\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]\n            grad[:, 1] += mus[:, 2] - mus[:, 3]\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final optimize and validity check for the best centers found\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Standard entry point for circle packing evaluations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5778), Performs well on target_ratio (0.9783), Performs well on combined_score (0.9783), Performs well on radius_variance (0.0044), Performs well on spatial_spread (0.2088), Performs well on eval_time (9.6580)\n\n### Program 2 (Score: 0.9712)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    \n    Returns:\n        radii: Optimal radii for each center\n        duals: Dual variables (marginals) from the LP\n        i_idx, j_idx: Indices of circle pairs\n        dists: Euclidean distances between centers\n    \"\"\"\n    n = pts.shape[0]\n    # Minimize -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.sqrt(np.sum(diffs**2, axis=1))\n    num_pairs = len(i_idx)\n    \n    # Constraints: pairwise (r_i + r_j <= d_ij) and boundary (r_i <= d_wall)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = np.maximum(0, dists - 1e-12)\n    \n    # Boundary constraints: x_i, 1-x_i, y_i, 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        # r_i <= x[i]\n        A_ub[base, i], b_ub[base] = 1, np.maximum(0, x[i] - 1e-12)\n        # r_i <= 1.0 - x[i]\n        A_ub[base + 1, i], b_ub[base + 1] = 1, np.maximum(0, 1.0 - x[i] - 1e-12)\n        # r_i <= y[i]\n        A_ub[base + 2, i], b_ub[base + 2] = 1, np.maximum(0, y[i] - 1e-12)\n        # r_i <= 1.0 - y[i]\n        A_ub[base + 3, i], b_ub[base + 3] = 1, np.maximum(0, 1.0 - y[i] - 1e-12)\n        \n    try:\n        # Use HiGHS solver for efficiency and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent. The gradients\n    are derived from the sensitivity of the LP objective to changes in center\n    coordinates (pairwise distances and boundary distances).\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = np.random.uniform(0.1, 0.9, (n, 2))\n    best_radii = np.zeros(n)\n    start_time = time.time()\n    \n    # Diverse initial layouts to explore potential optimal topologies\n    inits = []\n    \n    # 1. Perturbed Grid 5x5 plus one extra circle near center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.505, 0.495]]))\n    \n    # 2. Various staggered/hexagonal layers\n    # Layouts: 5-4-5-4-5-3, 4-5-4-5-4-4, and 6-5-6-5-4\n    for layout in [[5, 4, 5, 4, 5, 3], [4, 5, 4, 5, 4, 4], [6, 5, 6, 5, 4]]:\n        c = []\n        for r_idx, n_row in enumerate(layout):\n            for i_idx in range(n_row):\n                c.append([(i_idx + 0.5) / (n_row + 0.1), (r_idx + 0.5) / (len(layout) + 0.1)])\n        inits.append(np.array(c)[:n])\n        \n    # 3. Phyllotaxis Spiral (efficient natural packing)\n    phi = (1 + 5**0.5) / 2\n    idx_arr = np.arange(n) + 0.5\n    r_spiral = 0.47 * np.sqrt(idx_arr / n)\n    theta = 2 * np.pi * idx_arr / (phi**2)\n    inits.append(np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)]))\n    \n    # 4. Concentric Rings (1 center, 8 middle, 17 outer)\n    c_rings = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c_rings.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c_rings)[:n])\n    \n    # 5. Random starts with different seeds\n    np.random.seed(1337)\n    for _ in range(4):\n        inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n        \n    # Multi-start optimization loop\n    for c_start in inits:\n        # Respect a 540-second execution limit for the whole construction process\n        if time.time() - start_time > 540:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.015  # Initial learning rate\n        \n        for step in range(350):\n            # Frequent time check within the iteration loop\n            if step % 25 == 0 and time.time() - start_time > 540:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            curr_sum = np.sum(radii)\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n                \n            # Compute gradients from dual variables (marginal sensitivities)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Pairwise distance sensitivity: pushes centers apart to enlarge sum(radii)\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                d = dists[active_mask][:, np.newaxis]\n                # Normalized direction vectors scaled by dual importance\n                g_vectors = lams * diffs / (d + 1e-15)\n                np.add.at(grad, ii, g_vectors)\n                np.add.at(grad, jj, -g_vectors)\n                \n            # Boundary sensitivity: pushes centers away from walls\n            mus = np.abs(duals[num_pairs:]).reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]  # x_i and 1-x_i\n            grad[:, 1] += mus[:, 2] - mus[:, 3]  # y_i and 1-y_i\n            \n            # Apply normalized gradient update for numerical stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n                \n            # Keep centers strictly within the unit square square\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            # Gradual learning rate decay to fine-tune final position\n            lr *= 0.995\n            \n    # Re-calculate optimal radii for the best centers found across all starts\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Evaluate the packing arrangement for the target number of circles.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5591), Performs well on target_ratio (0.9712), Performs well on combined_score (0.9712), Performs well on radius_variance (0.0086), Performs well on spatial_spread (0.1660), Performs well on eval_time (7.7775)\n\n### Program 3 (Score: 0.9648)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    for k, (i, j) in enumerate(zip(i_idx, j_idx)):\n        A_ub[k, i] = 1\n        A_ub[k, j] = 1\n        b_ub[k] = dists[k] - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        A_ub[base, i], b_ub[base] = 1, x[i] - 1e-11\n        A_ub[base + 1, i], b_ub[base + 1] = 1, 1.0 - x[i] - 1e-11\n        A_ub[base + 2, i], b_ub[base + 2] = 1, y[i] - 1e-11\n        A_ub[base + 3, i], b_ub[base + 3] = 1, 1.0 - y[i] - 1e-11\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # Layout 1: 5x5 Grid with one circle near the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # Layout 2: Staggered layers (5, 4, 5, 4, 5, 3) to fill the square\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # Layout 3: Ring distribution (1 center, 8 middle, 17 outer)\n    c3 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c3.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c3))\n\n    # Layout 4: Another staggered layout (4, 5, 4, 5, 4, 4)\n    c4 = []\n    layers4 = [4, 5, 4, 5, 4, 4]\n    for r_idx, n_row in enumerate(layers4):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers4)])\n    inits.append(np.array(c4))\n    \n    # Layout 5: Random distribution\n    np.random.seed(42)\n    inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.008  # Initial learning rate\n        \n        for step in range(350):\n            # Periodically check time limit\n            if time.time() - start_time > 560:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            # Duals tell us how the sum of radii changes with center positions\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Direction of movement to increase the distance\n                g_vals = (lams[:, np.newaxis] * diffs / (ds + 1e-12))\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints\n            # Sensitivity to moving away from the four walls\n            mu0 = np.abs(duals[num_pairs + 4 * np.arange(n)])      # r_i <= x_i\n            mu1 = np.abs(duals[num_pairs + 4 * np.arange(n) + 1])  # r_i <= 1-x_i\n            mu2 = np.abs(duals[num_pairs + 4 * np.arange(n) + 2])  # r_i <= y_i\n            mu3 = np.abs(duals[num_pairs + 4 * np.arange(n) + 3])  # r_i <= 1-y_i\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final cleanup to ensure radii are optimal for the best centers found\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Entry point for evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5422), Performs well on target_ratio (0.9648), Performs well on combined_score (0.9648), Performs well on radius_variance (0.0078), Performs well on spatial_spread (0.1638), Performs well on eval_time (4.1488)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0892)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes c^T * x, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Total constraints: num_pairs + 4 * n (boundary constraints)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Vectorized assignment of pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n    \n    # Vectorized assignment of boundary constraints\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    base = num_pairs\n    A_ub[base : base + n, np.arange(n)] = 1\n    b_ub[base : base + n] = x - 1e-11\n    \n    A_ub[base + n : base + 2*n, np.arange(n)] = 1\n    b_ub[base + n : base + 2*n] = 1.0 - x - 1e-11\n    \n    A_ub[base + 2*n : base + 3*n, np.arange(n)] = 1\n    b_ub[base + 2*n : base + 3*n] = y - 1e-11\n    \n    A_ub[base + 3*n : base + 4*n, np.arange(n)] = 1\n    b_ub[base + 3*n : base + 4*n] = 1.0 - y - 1e-11\n    \n    try:\n        # Using HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1. Perturbed 5x5 Grid with one extra circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # 2. Staggered layers (5, 4, 5, 4, 5, 3)\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # 3. Phyllotaxis Spiral\n    phi = (1 + np.sqrt(5)) / 2\n    indices = np.arange(n) + 0.5\n    r_spiral = np.sqrt(indices / n) * 0.47\n    theta = 2 * np.pi * indices / (phi**2)\n    c3 = np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(c3)\n    \n    # 4. Concentric Rings (1, 8, 17)\n    c4 = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c4.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c4))\n    \n    # 5. Concentric Rings (1, 7, 18)\n    c5 = [[0.5, 0.5]]\n    for radius, count in [(0.22, 7), (0.43, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c5))\n\n    # Optimization Loop\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.009\n        \n        for step in range(350):\n            if time.time() - start_time > 580:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient from dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii, jj = i_idx[active_mask], j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Move centers apart to allow for larger radii\n                g_vals = lams * diffs / (ds + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity\n            # Indices correlate with the vectorized order in solve_max_radii\n            mu0 = np.abs(duals[num_pairs : num_pairs + n])\n            mu1 = np.abs(duals[num_pairs + n : num_pairs + 2*n])\n            mu2 = np.abs(duals[num_pairs + 2*n : num_pairs + 3*n])\n            mu3 = np.abs(duals[num_pairs + 3*n : num_pairs + 4*n])\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Update step with normalization for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Boundary enforcement and learning rate decay\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final check and cleanup to ensure absolute validity\n    final_radii, _, i_idx, j_idx, _ = solve_max_radii(best_centers)\n    \n    # Geometric validity enforcement pass (eliminating floating point creep)\n    for _ in range(30):\n        for i in range(n):\n            final_radii[i] = min(final_radii[i], best_centers[i, 0], 1.0 - best_centers[i, 0],\n                                 best_centers[i, 1], 1.0 - best_centers[i, 1])\n        for i, j in zip(i_idx, j_idx):\n            d = np.linalg.norm(best_centers[i] - best_centers[j])\n            if final_radii[i] + final_radii[j] > d:\n                overlap = (final_radii[i] + final_radii[j]) - d\n                final_radii[i] -= overlap * 0.5\n                final_radii[j] -= overlap * 0.5\n                \n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Interface to match the evaluation expectations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n### Program D2 (Score: 0.9411)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii. \nThe dual variables of this LP provide the sensitivity of the sum of radii to the \ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and the tightest boundary constraints.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: minimize -sum(radii) to maximize sum(radii)\n    c_obj = -np.ones(n)\n\n    # Inequality constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    b_left = x\n    b_right = 1.0 - x\n    b_bottom = y\n    b_top = 1.0 - y\n\n    # Find which boundary is tightest for each circle\n    max_r_boundary = np.minimum.reduce([b_left, b_right, b_bottom, b_top])\n    bounds_lp = [(0, r) for r in max_r_boundary]\n\n    try:\n        # Highs is efficient and provides marginals (duals)\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, max_r_boundary\n\n\ndef run_packing():\n    \"\"\"\n    Runs the circle packing optimization and returns the best found configuration.\n    \"\"\"\n    n_circles = 26\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Define several starting configurations\n    initial_configs = []\n\n    # Init 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx.ravel(), gy.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # Init 2: Hexagonal-like staggered layers (5, 4, 5, 4, 5, 3) = 26 circles\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # Init 3: 6x4 Grid plus 2 extra circles\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx2.ravel(), gy2.ravel()])\n    c3 = np.vstack([c3, [[0.2, 0.5], [0.8, 0.5]]])\n    initial_configs.append(c3)\n\n    # Optimize each initial configuration\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        # Dual-gradient optimization iterations\n        for step in range(150):\n            res, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Update gradient based on pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        if d > 1e-8:\n                            grad[ii] += lam * diff / d\n                            grad[jj] -= lam * diff / d\n\n                # Update gradient based on boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0: grad[i, 0] += mu\n                        elif tightest == 1: grad[i, 0] -= mu\n                        elif tightest == 2: grad[i, 1] += mu\n                        elif tightest == 3: grad[i, 1] -= mu\n\n                # Normalize step for stability and apply update\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    # Decay the step size over time\n                    step_size = 0.006 * (0.99 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Keep centers within the unit square\n                cur_c = np.clip(cur_c, 1e-7, 1.0 - 1e-7)\n            else:\n                break\n\n    # Perform a final rigorous LP solve and validity correction\n    if best_c is None:\n        best_c = initial_configs[1]\n\n    res_final, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(best_c)\n    final_r = res_final.x\n    final_c = best_c\n\n    # Strict geometry enforcement (multi-pass) to ensure zero overlap or boundary violation\n    for _ in range(50):\n        for i in range(n_circles):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n\n    return final_c, final_r, np.sum(final_r)\n\n\ndef construct_packing():\n    \"\"\"Alias for run_packing to match expected constructor interface.\"\"\"\n    return run_packing()\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef solve_max_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Falls back to a robust projected gradient descent method if scipy is unavailable.\n    \"\"\"\n    n = len(centers)\n    radii = None\n    \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = []\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            bounds.append((0, max_r))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            radii = res.x\n    except Exception:\n        pass\n        \n    if radii is None:\n        # Fallback to projected gradient descent on constraints\n        radii = np.zeros(n)\n        max_bounds = np.array([min(x, y, 1 - x, 1 - y) for x, y in centers])\n        \n        dist_matrix = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(centers[i] - centers[j])\n                dist_matrix[i, j] = d\n                dist_matrix[j, i] = d\n        np.fill_diagonal(dist_matrix, np.inf)\n        \n        lr_fallback = 0.005\n        for _ in range(3000):\n            overlap = np.maximum(0, radii[:, None] + radii[None, :] - dist_matrix)\n            grad = np.ones(n) - 200.0 * np.sum(overlap, axis=1)\n            radii += lr_fallback * grad\n            radii = np.clip(radii, 0, max_bounds)\n            \n    # Strictly enforce constraints to eliminate any floating-point inaccuracies\n    for i in range(n):\n        x, y = centers[i]\n        radii[i] = min(radii[i], x, y, 1 - x, 1 - y)\n        \n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii\n\n\ndef optimize_packing(n=26, steps=2500):\n    \"\"\"\n    Optimizes the\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii.\nThe dual variables of this LP provide the sensitivity of the sum of radii to the\ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, distances, and boundary limits.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: maximize sum(radii) => minimize -sum(radii)\n    c_obj = -np.ones(n)\n\n    # Pairwise constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n    dists = np.maximum(dists, 1e-9)  # Avoid division by zero\n\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x_i, 1-x_i, y_i, 1-y_i)\n    # clip to ensure points are strictly inside [0, 1]\n    pts_c = np.clip(pts, 1e-9, 1.0 - 1e-9)\n    x, y = pts_c[:, 0], pts_c[:, 1]\n    b_max = np.minimum.reduce([x, 1.0 - x, y, 1.0 - y])\n    bounds_lp = [(0, b) for b in b_max]\n\n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, b_max\n\n\ndef construct_packing():\n    \"\"\"\n    Optimizes circle centers using dual-gradient feedback from LP solutions.\n    \"\"\"\n    n_circles = 26\n    np.random.seed(42)\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Generate diverse initial configurations\n    initial_configs = []\n\n    # 1: 5x5 Grid plus one center circle\n    gx1, gy1 = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx1.ravel(), gy1.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # 2: Hexagonal staggered layers (4, 5, 4, 5, 4, 4) = 26 circles\n    c2 = []\n    layers = [4, 5, 4, 5, 4, 4]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # 3: 6x4 Grid plus 2 random circles\n    gx3, gy3 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx3.ravel(), gy3.ravel()])\n    c3 = np.vstack([c3, [[0.25, 0.5], [0.75, 0.5]]])\n    initial_configs.append(c3)\n\n    # 4: Random configurations to explore different topologies\n    for _ in range(4):\n        initial_configs.append(np.random.uniform(0.1, 0.9, (n_circles, 2)))\n\n    # Optimization Loop\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        for step in range(200):\n            res, i_idx, j_idx, dists, b_max = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            # lambdas: pairwise constraint duals; mus: boundary constraint duals\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Gradient component from pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        grad[ii] += lam * diff / d\n                        grad[jj] -= lam * diff / d\n\n                # Gradient component from boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        # Move centers to increase the limiting boundary distance\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0:\n                            grad[i, 0] += mu\n                        elif tightest == 1:\n                            grad[i, 0] -= mu\n                        elif tightest == 2:\n                            grad[i, 1] += mu\n                        elif tightest == 3:\n                            grad[i, 1] -= mu\n\n                # Stability: Normalize gradient and apply decaying step size\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    step_size = 0.012 * (0.992 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Ensure centers stay strictly within the unit square\n                cur_c = np.clip(cur_c, 1e-8, 1.0 - 1e-8)\n            else:\n                break\n\n    # Final solve with safety margin to ensure zero overlap or boundary violation\n    if best_c is None:\n        best_c = initial_configs[0]\n\n    final_res, i_idx, j_idx, dists, b_max = solve_max_radii_lp(best_c)\n    final_r = final_res.x\n    final_c = best_c\n\n    # Strict multi-pass geometric enforcement for final validity\n    for _ in range(100):\n        # Enforce boundary constraints\n        for i in range(n_circles):\n            x, y = final_c[i]\n            final_r[i] = min(final_r[i], x, 1.0 - x, y, 1.0 - y)\n            final_r[i] = max(0, final_r[i])\n        # Enforce pairwise non-overlap constraints\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n                else:\n                    final_r[ii] = final_r[jj] = 0\n\n    return final_c, final_r, np.sum(final_r)\n# EVOLVE-BLOCK-END\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles in a unit square.\nThis program uses a multi-start repulsion-based optimization for circle centers\nfollowed by a Linear Programming step to maximize the total sum of radii.\n\"\"\"\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= dist(c_i, c_j) and boundary constraints.\n    \"\"\"\n    n = centers.shape[0]\n    # Minimize -sum(r_i) which is equivalent to maximizing sum(r_i)\n    c_obj = -np.ones(n)\n    \n    # Overlap constraints: r_i + r_j <= distance between centers\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(centers[i_idx] - centers[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    A_ub = np.zeros((num_pairs, n))\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Use a tiny safety margin to ensure strict compliance with float precision\n    b_ub = dists - 1e-12\n    \n    # Boundary constraints: each circle i must stay within [0, 1] x [0, 1]\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = centers[:, 0], centers[:, 1]\n    max_r_possible = np.minimum.reduce([x, 1 - x, y, 1 - y])\n    bounds = [(0, max(0, r_limit - 1e-12)) for r_limit in max_r_possible]\n    \n    try:\n        # Use the modern HiGHS solver if available\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n    except Exception:\n        # Fallback to the default solver for older scipy versions\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        \n    if res.success and res.x is not None:\n        return res.x\n    return np.zeros(n)\n\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the placement of 26 circles to maximize the sum of their radii.\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Try different topological initializations for multi-start optimization\n    for attempt in range(4):\n        if attempt == 0:\n            # 5x5 Grid initialization with one extra circle\n            xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef get_exact_radii(centers):\n    \"\"\"\n    Computes the exact maximum valid radii for a given set of centers using Linear Programming.\n    Falls back to a robust geometric projected gradient descent method if scipy is unavailable.\n    \"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c_obj = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = []\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            bounds.append((0, max(0, max_r)))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n        \n    # Fallback to optimization if linprog fails or is unavailable\n    r = np.full(n, 0.05)\n    for _ in range(1000):\n        grad = -np.ones(n)\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if r[i] > max_r:\n                grad[i] += 100 * (r[i] - max_r)\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                overlap = r[i] + r[j] - dist\n                if overlap > 0:\n                    grad[i] += 100 * overlap\n                    grad[j] += 100 * overlap\n                    \n        r -= 0.01 * grad\n        r = np.maximum(r, 0)\n    return r\n\ndef construct_packing():\n    \"\"\"\n    Construct a specific arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    B = 50 # Number of parallel batches for optimization\n    \n    # Initialize batch of centers and radii for parallel optimization\n    c = np.random.uniform(0.1, 0.9, (B, n, 2))\n    r = np.full((B, n), 0.05)\n    \n    # Structured initialization to seed optimal topologies\n    # Batch 0: Ring layout 1, 8, 17\n    c[0, 0] = [0.5, 0.5]\n    for i in range(8):\n        a = 2 * np.pi * i / 8\n        c[0, i+1] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n    for i in range(17):\n        a = 2 * np.pi * i / 17\n        c[0, i+9] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n\n    # Batch 1: Grid-like 5x5 + 1\n    gx, gy = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 5))\n    c[1, :25] = np.column_stack([gx.flatten(), gy.flatten()])\n    c[1, 25] = [0.5, 0.5]\n\n    # Batch 2: Another ring layout 1, 6, 19\n    c[2, 0] = [0.5, 0.5]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        c[2, i+1] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n    for i in range(19):\n        a = 2 * np.pi * i / 19\n        c[2, i+7] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n        \n    # Batch 3: Hexagonalish\n    hex_c = []\n    for i in range(6):\n        for j in range(6):\n            if len(hex_c) < 26:\n                hex_c.append([0.15 + 0.14 * i + (j % 2) * 0.07, 0.15 + 0.14 * j])\n    c[3] = np.array(hex_c)\n\n    # Batch 4: Concentric 4, 9, 13\n    for i in range(4):\n        a = 2 * np.pi * i / 4\n        c[4, i] = [0.5 + 0.1 * np.cos(a), 0.5 + 0.1 * np.sin(a)]\n    for i in range(9):\n        a = 2 * np.pi * i / 9\n        c[4, i+4] = [0.5 + 0.25 * np.cos(a), 0.5 + 0.25 * np.sin(a)]\n    for i in range(13):\n        a = 2 * np.pi * i / 13\n        c[4, i+13] = [0.5 + 0.4 * np.cos(a), 0.5 + 0.4 * np.sin(a)]\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    lr_c = 0.005\n    lr_r = 0.005\n    \n    idx_i, idx_j = np.triu_indices(n, k=1)\n    \n    # Main optimization loop\n    for step in range(8000):\n        grad_c = np.zeros_like(c)\n        grad_r = -np.ones_like(r)\n        \n        # Penalties for boundary violations\n        viol_left = np.maximum(0, r - c[:, :, 0])\n        grad_r += 100 * viol_left\n        grad_c[:, :, 0] -= 100 * viol_left\n        \n        viol_right = np.maximum(0, r + c[:, :, 0] - 1)\n        grad_r += 100 * viol_right\n        grad_c[:, :, 0] += 100 * viol_right\n        \n        viol_bottom = np.maximum(0, r - c[:, :, 1])\n        grad_r += 100 * viol_bottom\n        grad_c[:, :, 1] -= 100 * viol_bottom\n        \n        viol_top = np.maximum(0, r + c[:, :, 1] - 1)\n        grad_r += 100 * viol_top\n        grad_c[:, :, 1] += 100 * viol_top\n        \n        # Pairwise overlap penalties\n        c_i = c[:, idx_i, :] \n        c_j = c[:, idx_j, :] \n        r_i = r[:, idx_i]    \n        r_j = r[:, idx_j]    \n        \n        diff = c_i - c_j\n        dist = np.linalg.norm(diff, axis=2) + 1e-10 \n        \n        overlap = np.maximum(0, r_i + r_j - dist) \n        penalty = 200 * overlap \n        \n        dir_ij = diff / dist[:, :, None] \n        force = penalty[:, :, None] * dir_ij \n        \n        for p in range(len(idx_i)):\n            i = idx_i[p]\n            j = idx_j[p]\n            grad_r[:, i] += penalty[:, p]\n            grad_r[:, j] += penalty[:, p]\n            grad_c[:, i, :] -= force[:, p, :]\n            grad_c[:, j, :] += force[:, p, :]\n            \n        # Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** (step + 1))\n        v_c_hat = v_c / (1 - beta2 ** (step + 1))\n        c -= lr_c * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** (step + 1))\n        v_r_hat = v_r / (1 - beta2 ** (step + 1))\n        r -= lr_r * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        c = np.clip(c, 0, 1)\n        r = np.maximum(r, 0)\n        \n        # Learning rate decay\n        if step % 2000 == 1999:\n            lr_c *= 0.5\n            lr_r *= 0.5\n\n    best_sum = 0\n    best_c = None\n    best_r = None\n    \n    # Evaluate configurations exactingly to ensure 100% validity\n    for b in range(B):\n        cb = c[b]\n        rb = get_exact_radii(cb)\n        \n        # Strict geometry enforcement multiple passes\n        for _ in range(3):\n            for i in range(n):\n                x, y = cb[i]\n                rb[i] = min(rb[i], x, y, 1 - x, 1 - y)\n                rb[i] = max(0, rb[i])\n                \n            for i in range(n):\n                for j in range(i + 1, n):\n                    dist = np.linalg.norm(cb[i] - cb[j])\n                    if rb[i] + rb[j] > dist:\n                        scale = (dist - 1e-12) / (rb[i] + rb[j])\n                        rb[i] *= scale\n                        rb[j] *= scale\n                        \n        s = np.sum(rb)\n        if s > best_sum:\n            best_sum = s\n            best_c = cb\n            best_r = rb\n            \n    return best_c, best_r, best_sum\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= distance to wall.\n    \n    Returns:\n        radii: Optimal radii for each center.\n        duals: Dual variables (marginals) providing sensitivity to center movement.\n        i_idx, j_idx: Indices of circle pairs used for constraints.\n        dists: Euclidean distances between centers.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes the objective function, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combine pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Small epsilon to ensure strict validity within floating point precision\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Correct any negative bounds caused by centers being slightly out of square\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use the HiGHS solver for efficiency and access to marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return None, None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent derived from LP.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts to explore different packing topologies\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # 3: Staggered layers (5, 4, 5, 4, 5, 3) = 26\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # 4: Staggered layers (4, 5, 4, 5, 4, 4) = 26\n    c4 = []\n    for r_idx, n_row in enumerate([4, 5, 4, 5, 4, 4]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c4))\n\n    # 5: Ring distribution (1 center, 8 middle, 17 outer)\n    c5 = [[0.5, 0.5]]\n    for rad, count in [(0.24, 8), (0.46, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c5))\n    \n    # 6: Fibonacci / Spiral layout\n    c6 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt((i + 0.5) / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c6.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c6))\n\n    # 7: Concentric layers (1, 7, 18)\n    c7 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 7), (0.44, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c7.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c7))\n    \n    # 8: Grid 6x4 with 2 extras\n    gx8, gy8 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx8.ravel(), gy8.ravel()]), [[0.2, 0.5], [0.8, 0.5]]]))\n\n    # Optimization loop for each initialization\n    for c_start in inits:\n        if time.time() - start_time > 550:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.015  # Starting learning rate\n        \n        for step in range(300):\n            # Check for early exit based on time\n            if step % 20 == 0 and time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on sensitivity from dual variables\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            # Dual variables indicate the rate of change of the sum w.r.t the constraint bounds\n            # For maximize sum(r_i), we move the centers in directions that increase b_ub\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distances: push centers apart\n            lams_p = lambdas[:num_pairs]\n            active_p = lams_p > 1e-9\n            if np.any(active_p):\n                ii, jj = i_idx[active_p], j_idx[active_p]\n                diffs = curr_c[ii] - curr_c[jj]\n                # Normalized direction vectors scaled by dual sensitivity\n                g_vals = lams_p[active_p, np.newaxis] * diffs / (dists[active_p, np.newaxis] + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints: move centers inward to make room\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]  # Sensitivity for x and 1-x\n            grad[:, 1] += mus[:, 2] - mus[:, 3]  # Sensitivity for y and 1-y\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within the unit square and apply decay to step size\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.99\n            \n    # Final cleanup: ensure radii are strictly optimal for the best centers found\n    if best_centers is not None:\n        final_radii, _, _, _, _ = solve_max_radii(best_centers)\n        return best_centers, final_radii, np.sum(final_radii)\n    else:\n        # Fallback in case of failure\n        random_c = np.random.uniform(0.1, 0.9, (n, 2))\n        random_r, _, _, _, _ = solve_max_radii(random_c)\n        return random_c, random_r, np.sum(random_r)\n\ndef run_packing():\n    \"\"\"Main execution function to be called by evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")\n```"]}}, "artifacts_json": "{\"execution_time\": \"5.29s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.548464/2.635 = 0.9672\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 96.7% of target value\", \"radius_stats\": \"Min: 0.059481, Max: 0.173416, Avg: 0.098018\"}", "artifact_dir": null, "embedding": null}