{"id": "365c43b3-f3e8-4b9c-9198-e64e376ac490", "code": "An elegant and systematic way to advance this optimization further is by introducing a **Hybrid Multi-Stage Pipeline** that heavily relies on purely vectorized operations. \n\nIn this upgraded algorithm, we employ three complementary layers of optimization:\n1. **Adam Momentum Physics (Global Search):** We start with Adam gradient descent employing an exponential penalty parameter alongside micro-vibrations to jump out of early local minima and settle onto the most promising general layouts.\n2. **SLSQP Vectorized Polishing (Local Precision):** Following Adam, SciPy\u2019s Sequential Least Squares Programming engine steps in. Powered by an explicitly defined analytical Jacobian, this stage snaps both the radii AND the centers into perfectly tight local configurations, solving hundreds of complex geometric pair restrictions per second.\n3. **Highs LP Finalization (Mathematical Strictness):** We conclude with a pristine Linear Programming stage that meticulously squeezes out the absolute limits of the radii around the settled centers, resolving 1e-12 scale numerical floating-point bounds.\n\nBy ensuring purely vectorized evaluation metrics, the optimization speed enables up to 100+ completely distinct topological seeded layout attempts within the allowed execution window.\n\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0", "changes_description": null, "language": "python", "parent_id": "9c62ee83-cbc1-400d-adc3-a70e6e3f70c7", "generation": 3, "timestamp": 1771884669.585278, "iteration_found": 99, "metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6289024020226384, "target_ratio": 0.9976859210712101, "combined_score": 0.9976859210712101, "radius_variance": 0.004950301792583467, "spatial_spread": 0.18579813382497223, "eval_time": 45.39852690696716}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following best practices:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n* You MUST think creatively, identify multiple alternative options of the algorithm design, analyze their pros and cons, and select the most promising algorithm.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: You MUST respond in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9977\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.9859 \u2192 0.9977\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n45.40s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.628902/2.635 = 0.9977\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.8% of target value\n```\n\n### radius_stats\n```\nMin: 0.061584, Max: 0.136665, Avg: 0.101112\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5978, target_ratio: 0.9859, combined_score: 0.9859, radius_variance: 0.0048, spatial_spread: 0.1899, eval_time: 36.1525\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6289, target_ratio: 0.9977, combined_score: 0.9977, radius_variance: 0.0050, spatial_spread: 0.1858, eval_time: 45.3985\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6300, target_ratio: 0.9981, combined_score: 0.9981, radius_variance: 0.0049, spatial_spread: 0.1857, eval_time: 45.5303\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9981)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(P.shape[0], P.shape[1]) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 150 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 8\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            sizes = [5, 5, 6, 5, 5]\n            idx = 0\n            for r, cols in enumerate(sizes):\n                for c in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * c / max(1, cols - 1), 0.1 + 0.8 * r / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            # Purely randomized seeding\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n        elif mode == 7:\n            # Random perturb of 5x5 grid\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x + np.random.uniform(-0.02, 0.02), y + np.random.uniform(-0.02, 0.02)]\n                        idx += 1\n            P[25] = np.random.rand(2) * 0.8 + 0.1\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6300), Performs well on target_ratio (0.9981), Performs well on combined_score (0.9981), Performs well on radius_variance (0.0049), Performs well on spatial_spread (0.1857), Performs well on eval_time (45.5303)\n\n### Program 2 (Score: 0.9977)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(*P.shape) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 100 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 7\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6289), Performs well on target_ratio (0.9977), Performs well on combined_score (0.9977), Performs well on radius_variance (0.0050), Performs well on spatial_spread (0.1858), Performs well on eval_time (45.3985)\n\n### Program 3 (Score: 0.9859)\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 100 and (time.time() - start_time) < 40.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 6\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(12):\n                angle = 2 * np.pi * i / 12\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[12 + i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[20] = [0.5, 0.5]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1:\n                    P[i, 0] += 0.8\n                elif i % 4 == 2:\n                    P[i, 1] += 0.8\n                elif i % 4 == 3:\n                    P[i] += 0.8\n        elif mode == 4:\n            # Hexagonal-like bias\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n                \n        # Initialize radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.07 - 0.035 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.02\n        C = 1.0\n        steps = 3000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Final safety check\n        scale_final = compute_valid_scale(P, R_final)\n        if scale_final < 1.0:\n            R_final *= scale_final * 0.9999999\n            \n        current_sum = float(np.sum(R_final))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), best_sum\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5978), Performs well on target_ratio (0.9859), Performs well on combined_score (0.9859), Performs well on radius_variance (0.0048), Performs well on spatial_spread (0.1899), Performs well on eval_time (36.1525)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef compute_valid_scale_batch(P, R):\n    \"\"\"\n    Vectorized version of compute_valid_scale for processing batches of environments.\n    \"\"\"\n    B, N, _ = P.shape\n    diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    idx = np.arange(N)\n    dist[:, idx, idx] = np.inf\n    \n    R_sum = R[:, :, np.newaxis] + R[:, np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12), axis=(1, 2))\n        scale_left = np.min(P[:, :, 0] / (R + 1e-12), axis=1)\n        scale_right = np.min((1 - P[:, :, 0]) / (R + 1e-12), axis=1)\n        scale_bottom = np.min(P[:, :, 1] / (R + 1e-12), axis=1)\n        scale_top = np.min((1 - P[:, :, 1]) / (R + 1e-12), axis=1)\n        \n    scales = np.minimum.reduce([scale_pairs, scale_left, scale_right, scale_bottom, scale_top])\n    scales = np.clip(scales, 0.0, 1.0)\n    return scales\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Calculates the mathematically strict maximum possible radii using a Linear \n    Programming solver for a single configuration.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        \n        num_pairs = N * (N - 1) // 2\n        A_\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.3333)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver (SciPy required).\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef run_packing():\n    \"\"\"\n    Main entry point for finding the optimal configuration.\n    Uses continuous optimization (Adam-based physics penalty method) combined\n    with simulated annealing and topological seeding.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    \n    # Run heavily randomized topological restarts within given time bounds\n    while attempt < 150 and (time.time() - start_time) < 180.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializing schemes\n        mode = attempt % 6\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n            P[9:] = np.random.rand(17, 2) * 0.8 + 0.1\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        lr = 0.02\n        C = 1.0  # Constraint weight starts gentle and anneals to strict\n        steps = 3500\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Iterative physics layout model via Adam optimization\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients calculation enforcing penalty violations + sum of R scaling\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            P = np.clip(P, 1e-5, 1 - 1e-5)\n            \n            C *= 1.0015\n            lr *= 0.9995\n            \n            # Injection of symmetry breaking noise\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        # Log successful improved iteration configurations\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Alternative approach to stage1_passed, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Highly optimized vector-based Adam gradient descent applying penalty constraints.\n    Memory allocation is minimized for maximum search iteration throughput.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1 = 0.\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correctly handling floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to strictly maximize their sum without overlapping.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist[i, j])\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef final_polish_slsqp(P, R):\n    \"\"\"\n    Applies a non-linear co-optimization polishing phase to both the Centers\n    and Radii simultaneously using SLSQP. This helps squeeze the final decimal \n    points out of highly optimized configurations.\n    \"\"\"\n    try:\n        from scipy.optimize import minimize\n        N = len(P)\n        \n        def objective(x):\n            return -np.sum(x[2*N:])\n            \n        def obj_jac(x):\n            grad = np.zeros(3*N)\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nAn excellent way to improve this score and systematically achieve a dense and valid circle packing is to implement a robust **Hybrid Optimization Pipeline**. \n\nThe improved algorithm breaks the optimization into three powerful stages:\n1. **Physics-based Relaxation (Simulated Annealing):** An initial phase using momentum gradients (Adam) with a decaying learning rate and an exponentially increasing constraint weight (`C`). This effectively acts as simulated annealing, allowing circles to fluidly push each other into optimal configurations before solidifying.\n2. **SLSQP Local Polishing:** With the topology established, we use SciPy\u2019s Sequential Least Squares Programming. A purely vectorized analytical Jacobian executes hundreds of iterations per second to rigorously snap the centers to their optimal coordinates.\n3. **Linear Programming Finalizer:** An exact mathematical fallback shrinks or strictly maximizes the final radii around the finalized centers to guarantee 0.0000 constraint violations and secure the final score.\n\nFurther improvements include symmetry breaking, genetic mutation pooling, and initial size/position biasing strictly as requested.\n\n```python\nimport time\nimport warnings\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\n\nclass AdamOptimizer:\n    \"\"\"Standard Adam Optimizer implemented in pure NumPy for physics relaxation.\"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"Computes penalty-based overlap violations and exact gradients for physics relaxation.\"\"\"\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, 1e-10)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P =\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(*P.shape) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 100 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 7\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["An elegant and systematic way to advance this optimization further is by introducing a **Hybrid Multi-Stage Pipeline** that heavily relies on purely vectorized operations. \n\nIn this upgraded algorithm, we employ three complementary layers of optimization:\n1. **Adam Momentum Physics (Global Search):** We start with Adam gradient descent employing an exponential penalty parameter alongside micro-vibrations to jump out of early local minima and settle onto the most promising general layouts.\n2. **SLSQP Vectorized Polishing (Local Precision):** Following Adam, SciPy\u2019s Sequential Least Squares Programming engine steps in. Powered by an explicitly defined analytical Jacobian, this stage snaps both the radii AND the centers into perfectly tight local configurations, solving hundreds of complex geometric pair restrictions per second.\n3. **Highs LP Finalization (Mathematical Strictness):** We conclude with a pristine Linear Programming stage that meticulously squeezes out the absolute limits of the radii around the settled centers, resolving 1e-12 scale numerical floating-point bounds.\n\nBy ensuring purely vectorized evaluation metrics, the optimization speed enables up to 100+ completely distinct topological seeded layout attempts within the allowed execution window.\n\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0"]}}, "artifacts_json": "{\"stderr\": \"Stage 1 evaluation failed: Program execution failed: invalid character '\\u2019' (U+2019) (tmpn8b4m9yk.py, line 5)\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\\\", line 384, in evaluate_stage1\\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\\n  File \\\"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\\\", line 172, in run_with_timeout\\n    raise RuntimeError(f\\\"Program execution failed: {results['error']}\\\")\\nRuntimeError: Program execution failed: invalid character '\\u2019' (U+2019) (tmpn8b4m9yk.py, line 5)\\n\", \"failure_stage\": \"stage1_execution\", \"suggestion\": \"Check basic syntax and imports before attempting full evaluation\"}", "artifact_dir": null, "embedding": null}