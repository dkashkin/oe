{"id": "def079be-f237-41af-94b4-2cc2a81c222c", "code": "import time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 100 and (time.time() - start_time) < 40.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 6\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(12):\n                angle = 2 * np.pi * i / 12\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[12 + i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[20] = [0.5, 0.5]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1:\n                    P[i, 0] += 0.8\n                elif i % 4 == 2:\n                    P[i, 1] += 0.8\n                elif i % 4 == 3:\n                    P[i] += 0.8\n        elif mode == 4:\n            # Hexagonal-like bias\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n                \n        # Initialize radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.07 - 0.035 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.02\n        C = 1.0\n        steps = 3000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Final safety check\n        scale_final = compute_valid_scale(P, R_final)\n        if scale_final < 1.0:\n            R_final *= scale_final * 0.9999999\n            \n        current_sum = float(np.sum(R_final))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), best_sum", "changes_description": null, "language": "python", "parent_id": "27a4085a-fe61-4a5b-9242-cef5fe1d9081", "generation": 4, "timestamp": 1771882393.8942964, "iteration_found": 57, "metrics": {"validity": 1.0, "sum_radii": 2.5977796595393166, "target_ratio": 0.9858746336012587, "combined_score": 0.9858746336012587, "radius_variance": 0.004834541844247796, "spatial_spread": 0.1899387993343908, "eval_time": 36.15251922607422}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following best practices:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n* You MUST think creatively, identify multiple alternative options of the algorithm design, analyze their pros and cons, and select the most promising algorithm.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: You MUST respond in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0000\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: invalid character '\u2019' (U+2019) (tmpl8dkx6v7.py, line 5)\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: invalid character '\u2019' (U+2019) (tmpl8dkx6v7.py, line 5)\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5854, target_ratio: 0.9812, combined_score: 0.9812, radius_variance: 0.0050, spatial_spread: 0.1900, eval_time: 18.6987\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9812)\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    scale_pairs = np.min(dist / (R_sum + 1e-10))\n    \n    scale_left = np.min(P[:, 0] / (R + 1e-10))\n    scale_right = np.min((1 - P[:, 0]) / (R + 1e-10))\n    scale_bottom = np.min(P[:, 1] / (R + 1e-10))\n    scale_top = np.min((1 - P[:, 1]) / (R + 1e-10))\n    \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x * 0.9999999  # Slightly scale to ensure strict bound compliance\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 40 and (time.time() - start_time) < 25.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 5\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[i] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n                \n        # Initialize initial radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.06 - 0.03 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.015\n        C = 1.0\n        steps = 4000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 800 == 0 and step < 2500:\n                P += np.random.randn(*P.shape) * 0.001\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5854), Performs well on target_ratio (0.9812), Performs well on combined_score (0.9812), Performs well on radius_variance (0.0050), Performs well on spatial_spread (0.1900), Performs well on eval_time (18.6987)\n\n### Program 2 (Score: 0.3333)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver (SciPy required).\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef run_packing():\n    \"\"\"\n    Main entry point for finding the optimal configuration.\n    Uses continuous optimization (Adam-based physics penalty method) combined\n    with simulated annealing and topological seeding.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    \n    # Run heavily randomized topological restarts within given time bounds\n    while attempt < 150 and (time.time() - start_time) < 180.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializing schemes\n        mode = attempt % 6\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n            P[9:] = np.random.rand(17, 2) * 0.8 + 0.1\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        lr = 0.02\n        C = 1.0  # Constraint weight starts gentle and anneals to strict\n        steps = 3500\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Iterative physics layout model via Adam optimization\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients calculation enforcing penalty violations + sum of R scaling\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            P = np.clip(P, 1e-5, 1 - 1e-5)\n            \n            C *= 1.0015\n            lr *= 0.9995\n            \n            # Injection of symmetry breaking noise\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        # Log successful improved iteration configurations\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n### Program 3 (Score: 0.0000)\n```python\n```python\nimport numpy as np\nimport time\n\ntry:\n    from scipy.optimize import minimize, linprog\n    HAS_SCIPY = True\nexcept ImportError:\n    HAS_SCIPY = False\n\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in pure NumPy.\n    Used for smooth, momentum-based gradient descent if SciPy is unavailable.\n    \"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"\n    Computes penalty-based overlap violations and mathematically exact gradients.\n    Penalty weight 'C' smoothly pushes bounds to solidify the packing.\n    \"\"\"\n    N = len(R)\n    \n    left = R - P[:, 0]\n    right = R - (1 - P[:, 0])\n    bottom = R - P[:, 1]\n    top = R - (1 - P[:, 1])\n    \n    v_left = np.maximum(0, left)\n    v_right = np.maximum(0, right)\n    v_bottom = np.maximum(0, bottom)\n    v_top = np.maximum(0, top)\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    v_overlap = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(v_left**2 + v_right**2 + v_bottom**2 + v_top**2)\n    loss += C * np.sum(np.triu(v_overlap)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (v_left + v_right + v_bottom + v_top)\n    \n    grad_P[:, 0] += 2 * C * (-v_left + v_right)\n    grad_P[:, 1] += 2 * C * (-v_bottom + v_top)\n    \n    grad_R += 2 * C * np.sum(v_overlap, axis=1)\n    \n    safe_dist = np.maximum(dist, 1e-10)\n\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n```python\nimport time\nimport numpy as np\n\ntry:\n    from scipy.optimize import minimize, linprog\n    SCIPY_AVAILABLE = True\nexcept ImportError:\n    SCIPY_AVAILABLE = False\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes the maximum scale factor (up to 1.0) to ensure that no circles overlap\n    and all circles are strictly bounded within the unit square [0, 1].\n    \"\"\"\n    if np.all(R <= 1e-10):\n        return 0.0\n        \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = np.maximum(R[:, np.newaxis] + R[np.newaxis, :], 1e-10)\n    scale_pairs = np.min(dist / R_sum)\n    \n    R_safe = np.maximum(R, 1e-10)\n    scale_left = np.min(P[:, 0] / R_safe)\n    scale_right = np.min((1 - P[:, 0]) / R_safe)\n    scale_bottom = np.min(P[:, 1] / R_safe)\n    scale_top = np.min((1 - P[:, 1]) / R_safe)\n    \n    return max(0.0, float(min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top)))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given an optimal arrangement of fixed centers, utilizes Linear Programming \n    to extract the mathematical maximum possible sum of radii.\n    \"\"\"\n    N = len(P)\n    try:\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef adam_optimize(P_init, R_init, steps=4000):\n    \"\"\"\n    Simulated physics-based gradient descent optimization using Adam.\n    Repels overlapping circles and pushes them towards boundary compliance \n    while continuously expanding their radii to maximize space utilization.\n    \"\"\"\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    lr = 0.015\n    \n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.0000)\n```python\nimport time\nimport numpy as np\n\ntry:\n    from scipy.optimize import linprog\n    SCIPY_AVAILABLE = True\nexcept ImportError:\n    SCIPY_AVAILABLE = False\n\n\nclass AdamOptimizer:\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    dist[dist < 1e-10] = 1e-10\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (left + right + bottom + top)\n    grad_P[:, 0] += 2 * C * (-left + right)\n    grad_P[:, 1] += 2 * C * (-bottom + top)\n    \n    grad_R += 2 * C * np.sum(overlap_masked, axis=1)\n    \n    weight = 2 * C * overlap_masked / dist\n    grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n    \n    return loss, grad_P, grad_R\n\n\ndef get_initial_state(attempt, N):\n    np.random.seed(attempt)\n    P = np.random.rand(N, 2) * 0.8 + 0.1\n    \n    mode = attempt % \n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\nimport numpy as np\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in NumPy for fully vectorized operations.\n    Provides smooth, momentum-based gradient descent robust to gradient scaling.\n    \"\"\"\n    def __init__(self, shape):\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, lr):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params = params - lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes the maximum scaling factor for radii such that no overlaps occur\n    and all circles remain strictly within the [0, 1] bounds.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    safe_R_sum = np.where(R_sum > 0, R_sum, 1.0)\n    scale_pairs = np.where(R_sum > 0, dist / safe_R_sum, np.inf)\n    min_scale_pairs = np.min(scale_pairs)\n    \n    safe_R = np.where(R > 0, R, 1.0)\n    scale_left = np.where(R > 0, P[:, 0] / safe_R, np.inf)\n    scale_right = np.where(R > 0, (1 - P[:, 0]) / safe_R, np.inf)\n    scale_bottom = np.where(R > 0, P[:, 1] / safe_R, np.inf)\n    scale_top = np.where(R > 0, (1 - P[:, 1]) / safe_R, np.inf)\n    \n    min_scale_bounds = np.min([scale_left, scale_right, scale_bottom, scale_top])\n    \n    return max(0.0, min(min_scale_pairs, min_scale_bounds))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, find the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n    except ImportError:\n        return None, None\n        \n    c = -np.ones(N)\n    A_ub = []\n    b_ub = []\n    \n    for i in range(N):\n        for j in range(i + 1, N):\n            dist = np.linalg.norm(P[i] - P[j])\n            row = np.zeros(N)\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n```python\nimport numpy as np\nimport time\n\ntry:\n    from scipy.optimize import minimize, linprog\n    HAS_SCIPY = True\nexcept ImportError:\n    HAS_SCIPY = False\n\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in pure NumPy.\n    Used for smooth, momentum-based gradient descent if SciPy is unavailable.\n    \"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"\n    Computes penalty-based overlap violations and mathematically exact gradients.\n    Penalty weight 'C' smoothly pushes bounds to solidify the packing.\n    \"\"\"\n    N = len(R)\n    \n    left = R - P[:, 0]\n    right = R - (1 - P[:, 0])\n    bottom = R - P[:, 1]\n    top = R - (1 - P[:, 1])\n    \n    v_left = np.maximum(0, left)\n    v_right = np.maximum(0, right)\n    v_bottom = np.maximum(0, bottom)\n    v_top = np.maximum(0, top)\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    v_overlap = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(v_left**2 + v_right**2 + v_bottom**2 + v_top**2)\n    loss += C * np.sum(np.triu(v_overlap)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (v_left + v_right + v_bottom + v_top)\n    \n    grad_P[:, 0] += 2 * C * (-v_left + v_right)\n    grad_P[:, 1] += 2 * C * (-v_bottom + v_top)\n    \n    grad_R += 2 * C * np.sum(v_overlap, axis=1)\n    \n    safe_dist = np.maximum(dist, 1e-10)\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n```python\nimport time\nimport numpy as np\n\ntry:\n    from scipy.optimize import minimize, linprog\n    SCIPY_AVAILABLE = True\nexcept ImportError:\n    SCIPY_AVAILABLE = False\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes the maximum scale factor (up to 1.0) to ensure that no circles overlap\n    and all circles are strictly bounded within the unit square [0, 1].\n    \"\"\"\n    if np.all(R <= 1e-10):\n        return 0.0\n        \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = np.maximum(R[:, np.newaxis] + R[np.newaxis, :], 1e-10)\n    scale_pairs = np.min(dist / R_sum)\n    \n    R_safe = np.maximum(R, 1e-10)\n    scale_left = np.min(P[:, 0] / R_safe)\n    scale_right = np.min((1 - P[:, 0]) / R_safe)\n    scale_bottom = np.min(P[:, 1] / R_safe)\n    scale_top = np.min((1 - P[:, 1]) / R_safe)\n    \n    return max(0.0, float(min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top)))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given an optimal arrangement of fixed centers, utilizes Linear Programming \n    to extract the mathematical maximum possible sum of radii.\n    \"\"\"\n    N = len(P)\n    try:\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef adam_optimize(P_init, R_init, steps=4000):\n    \"\"\"\n    Simulated physics-based gradient descent optimization using Adam.\n    Repels overlapping circles and pushes them towards boundary compliance \n    while continuously expanding their radii to maximize space utilization.\n    \"\"\"\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    lr = 0.015\n    \n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nAn excellent way to improve this score and systematically achieve a dense and valid circle packing is to implement a robust **Hybrid Optimization Pipeline**. \n\nThe improved algorithm breaks the optimization into three powerful stages:\n1. **Physics-based Relaxation (Simulated Annealing):** An initial phase using momentum gradients (Adam) with a decaying learning rate and an exponentially increasing constraint weight (`C`). This effectively acts as simulated annealing, allowing circles to fluidly push each other into optimal configurations before solidifying.\n2. **SLSQP Local Polishing:** With the topology established, we use SciPy\u2019s Sequential Least Squares Programming. A purely vectorized analytical Jacobian executes hundreds of iterations per second to rigorously snap the centers to their optimal coordinates.\n3. **Linear Programming Finalizer:** An exact mathematical fallback shrinks or strictly maximizes the final radii around the finalized centers to guarantee 0.0000 constraint violations and secure the final score.\n\nFurther improvements include symmetry breaking, genetic mutation pooling, and initial size/position biasing strictly as requested.\n\n```python\nimport time\nimport warnings\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\n\nclass AdamOptimizer:\n    \"\"\"Standard Adam Optimizer implemented in pure NumPy for physics relaxation.\"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"Computes penalty-based overlap violations and exact gradients for physics relaxation.\"\"\"\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, 1e-10)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P =\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["import time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 100 and (time.time() - start_time) < 40.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 6\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(12):\n                angle = 2 * np.pi * i / 12\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[12 + i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[20] = [0.5, 0.5]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1:\n                    P[i, 0] += 0.8\n                elif i % 4 == 2:\n                    P[i, 1] += 0.8\n                elif i % 4 == 3:\n                    P[i] += 0.8\n        elif mode == 4:\n            # Hexagonal-like bias\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n                \n        # Initialize radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.07 - 0.035 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.02\n        C = 1.0\n        steps = 3000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Final safety check\n        scale_final = compute_valid_scale(P, R_final)\n        if scale_final < 1.0:\n            R_final *= scale_final * 0.9999999\n            \n        current_sum = float(np.sum(R_final))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), best_sum"]}}, "artifacts_json": "{\"execution_time\": \"36.15s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.597780/2.635 = 0.9859\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 98.6% of target value\", \"radius_stats\": \"Min: 0.069520, Max: 0.134986, Avg: 0.099915\"}", "artifact_dir": null, "embedding": null}