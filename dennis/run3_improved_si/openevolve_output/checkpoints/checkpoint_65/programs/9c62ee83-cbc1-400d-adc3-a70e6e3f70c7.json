{"id": "9c62ee83-cbc1-400d-adc3-a70e6e3f70c7", "code": "import time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(*P.shape) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 100 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 7\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)", "changes_description": null, "language": "python", "parent_id": "1f0d0e03-cbec-483f-bc29-0314f7765daa", "generation": 2, "timestamp": 1771882125.8127995, "iteration_found": 49, "metrics": {"validity": 1.0, "sum_radii": 2.6289024020226384, "target_ratio": 0.9976859210712101, "combined_score": 0.9976859210712101, "radius_variance": 0.004950301792583467, "spatial_spread": 0.18579813382497223, "eval_time": 45.39852690696716}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following best practices:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n* You MUST think creatively, identify multiple alternative options of the algorithm design, analyze their pros and cons, and select the most promising algorithm.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: You MUST respond in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0000\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: module 'program' has no attribute 'run_packing'\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: module 'program' has no attribute 'run_packing'\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5854, target_ratio: 0.9812, combined_score: 0.9812, radius_variance: 0.0050, spatial_spread: 0.1900, eval_time: 18.6987\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9812)\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    scale_pairs = np.min(dist / (R_sum + 1e-10))\n    \n    scale_left = np.min(P[:, 0] / (R + 1e-10))\n    scale_right = np.min((1 - P[:, 0]) / (R + 1e-10))\n    scale_bottom = np.min(P[:, 1] / (R + 1e-10))\n    scale_top = np.min((1 - P[:, 1]) / (R + 1e-10))\n    \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x * 0.9999999  # Slightly scale to ensure strict bound compliance\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 40 and (time.time() - start_time) < 25.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 5\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[i] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n                \n        # Initialize initial radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.06 - 0.03 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.015\n        C = 1.0\n        steps = 4000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 800 == 0 and step < 2500:\n                P += np.random.randn(*P.shape) * 0.001\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5854), Performs well on target_ratio (0.9812), Performs well on combined_score (0.9812), Performs well on radius_variance (0.0050), Performs well on spatial_spread (0.1900), Performs well on eval_time (18.6987)\n\n### Program 2 (Score: 0.3333)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver (SciPy required).\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef run_packing():\n    \"\"\"\n    Main entry point for finding the optimal configuration.\n    Uses continuous optimization (Adam-based physics penalty method) combined\n    with simulated annealing and topological seeding.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    \n    # Run heavily randomized topological restarts within given time bounds\n    while attempt < 150 and (time.time() - start_time) < 180.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializing schemes\n        mode = attempt % 6\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n            P[9:] = np.random.rand(17, 2) * 0.8 + 0.1\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        lr = 0.02\n        C = 1.0  # Constraint weight starts gentle and anneals to strict\n        steps = 3500\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Iterative physics layout model via Adam optimization\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients calculation enforcing penalty violations + sum of R scaling\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            P = np.clip(P, 1e-5, 1 - 1e-5)\n            \n            C *= 1.0015\n            lr *= 0.9995\n            \n            # Injection of symmetry breaking noise\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        # Log successful improved iteration configurations\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n### Program 3 (Score: 0.0000)\n```python\n```python\nimport numpy as np\nimport time\n\ntry:\n    from scipy.optimize import minimize, linprog\n    HAS_SCIPY = True\nexcept ImportError:\n    HAS_SCIPY = False\n\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in pure NumPy.\n    Used for smooth, momentum-based gradient descent if SciPy is unavailable.\n    \"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"\n    Computes penalty-based overlap violations and mathematically exact gradients.\n    Penalty weight 'C' smoothly pushes bounds to solidify the packing.\n    \"\"\"\n    N = len(R)\n    \n    left = R - P[:, 0]\n    right = R - (1 - P[:, 0])\n    bottom = R - P[:, 1]\n    top = R - (1 - P[:, 1])\n    \n    v_left = np.maximum(0, left)\n    v_right = np.maximum(0, right)\n    v_bottom = np.maximum(0, bottom)\n    v_top = np.maximum(0, top)\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    v_overlap = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(v_left**2 + v_right**2 + v_bottom**2 + v_top**2)\n    loss += C * np.sum(np.triu(v_overlap)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (v_left + v_right + v_bottom + v_top)\n    \n    grad_P[:, 0] += 2 * C * (-v_left + v_right)\n    grad_P[:, 1] += 2 * C * (-v_bottom + v_top)\n    \n    grad_R += 2 * C * np.sum(v_overlap, axis=1)\n    \n    safe_dist = np.maximum(dist, 1e-10)\n\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\nimport time\nimport numpy as np\n\ntry:\n    from scipy.optimize import linprog\n    SCIPY_AVAILABLE = True\nexcept ImportError:\n    SCIPY_AVAILABLE = False\n\n\nclass AdamOptimizer:\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    dist[dist < 1e-10] = 1e-10\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (left + right + bottom + top)\n    grad_P[:, 0] += 2 * C * (-left + right)\n    grad_P[:, 1] += 2 * C * (-bottom + top)\n    \n    grad_R += 2 * C * np.sum(overlap_masked, axis=1)\n    \n    weight = 2 * C * overlap_masked / dist\n    grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n    \n    return loss, grad_P, grad_R\n\n\ndef get_initial_state(attempt, N):\n    np.random.seed(attempt)\n    P = np.random.rand(N, 2) * 0.8 + 0.1\n    \n    mode = attempt % \n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.0000)\n```python\nAn excellent approach to improving this score is to completely replace the static concentric arrangement with a robust, iterative physics-based solver. To find the optimal packing of 26 non-overlapping circles that maximizes the sum of their radii, we can formulate this as a continuous optimization problem using a simulated physics model with momentum.\n\nInstead of hardcoding positions, the circles start with strategically biased random initial positions and iteratively \"grow\" while repelling one another. This acts as a Penalty Method (or Augmented Lagrangian) algorithm, effectively finding the maximum possible sum of radii without overlapping.\n\n### Key Improvements Implemented:\n1. **Strategic Seed Initialization**: Multiple random restarts are employed. We selectively seed configurations strongly favoring corners and edges to maximize bounding box utilization.\n2. **Size Placement Bias**: The initial radii are mathematically parameterized based on their distance from the `[0.5, 0.5]` centroid\u2014biasing larger circles toward the center and letting small circles fill the corners. \n3. **Physics Optimization & Simulated Annealing**: We iterate using momentum gradients, a decaying learning rate, and an exponentially increasing constraint weight (`W`). This allows circles to easily swap positions early in the simulation before smoothly settling into a rigorous non-overlapping tight packing.\n4. **Symmetry Breaking**: We systematically introduce slight micro-perturbations (`np.random.randn`) during the early epochs to break symmetries and prevent the circles from stalling in unstable equilibrium local maxima.\n5. **Strict Overlap Resolution**: At the end of every simulation, an iterative rigid-scaling resolution is applied to ensure the solution is mathematically sound (preventing any floating-point violations).\n\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii using a physics-based relaxation algorithm.\n    \"\"\"\n    n = 26\n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    np.random.seed(42)  # For reproducibility\n    \n    # 12 restarts with different initializations to traverse multiple topographies\n    for attempt in range(12):\n        # 1. Strategic initialization\n        centers = np.random.rand(n, 2) * 0.8 + 0.1\n        \n        # Bias the initialization structurally for some attempts\n        if attempt % 3 == 0:\n            # Anchor elements into the tight 4 corners\n            centers[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            # Core centroid\n            centers[4] = [0.5, 0.5]\n            # Edge boundaries midpoints\n            centers[5:9] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            \n        # Size placement: mathematically bias larger circles toward the center\n        dist_to_center = np.linalg.norm(centers - 0.5, axis=1)\n        radii = 0.06 - 0.03 * dist_to_center\n        \n        # 2. Optimization parameters\n        lr = 0.015\n        W = 1.0  # Constraint weight\n        \n        vP = np.zeros_like(centers)\n        vR = np.zeros_like(radi\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\nAn excellent way to improve this score and systematically achieve a dense and valid circle packing is to implement a robust **Hybrid Optimization Pipeline**. \n\nThe improved algorithm breaks the optimization into three powerful stages:\n1. **Physics-based Relaxation (Simulated Annealing):** An initial phase using momentum gradients (Adam) with a decaying learning rate and an exponentially increasing constraint weight (`C`). This effectively acts as simulated annealing, allowing circles to fluidly push each other into optimal configurations before solidifying.\n2. **SLSQP Local Polishing:** With the topology established, we use SciPy\u2019s Sequential Least Squares Programming. A purely vectorized analytical Jacobian executes hundreds of iterations per second to rigorously snap the centers to their optimal coordinates.\n3. **Linear Programming Finalizer:** An exact mathematical fallback shrinks or strictly maximizes the final radii around the finalized centers to guarantee 0.0000 constraint violations and secure the final score.\n\nFurther improvements include symmetry breaking, genetic mutation pooling, and initial size/position biasing strictly as requested.\n\n```python\nimport time\nimport warnings\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\n\nclass AdamOptimizer:\n    \"\"\"Standard Adam Optimizer implemented in pure NumPy for physics relaxation.\"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"Computes penalty-based overlap violations and exact gradients for physics relaxation.\"\"\"\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, 1e-10)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P =\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\nAn excellent approach to improving this score is to completely replace the static concentric arrangement with a robust, iterative physics-based solver. To find the optimal packing of 26 non-overlapping circles that maximizes the sum of their radii, we can formulate this as a continuous optimization problem using a simulated physics model with momentum.\n\nInstead of hardcoding positions, the circles start with strategically biased random initial positions and iteratively \"grow\" while repelling one another. This acts as a Penalty Method (or Augmented Lagrangian) algorithm, effectively finding the maximum possible sum of radii without overlapping.\n\n### Key Improvements Implemented:\n1. **Strategic Seed Initialization**: Multiple random restarts are employed. We selectively seed configurations strongly favoring corners and edges to maximize bounding box utilization.\n2. **Size Placement Bias**: The initial radii are mathematically parameterized based on their distance from the `[0.5, 0.5]` centroid\u2014biasing larger circles toward the center and letting small circles fill the corners. \n3. **Physics Optimization & Simulated Annealing**: We iterate using momentum gradients, a decaying learning rate, and an exponentially increasing constraint weight (`W`). This allows circles to easily swap positions early in the simulation before smoothly settling into a rigorous non-overlapping tight packing.\n4. **Symmetry Breaking**: We systematically introduce slight micro-perturbations (`np.random.randn`) during the early epochs to break symmetries and prevent the circles from stalling in unstable equilibrium local maxima.\n5. **Strict Overlap Resolution**: At the end of every simulation, an iterative rigid-scaling resolution is applied to ensure the solution is mathematically sound (preventing any floating-point violations).\n\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii using a physics-based relaxation algorithm.\n    \"\"\"\n    n = 26\n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    np.random.seed(42)  # For reproducibility\n    \n    # 12 restarts with different initializations to traverse multiple topographies\n    for attempt in range(12):\n        # 1. Strategic initialization\n        centers = np.random.rand(n, 2) * 0.8 + 0.1\n        \n        # Bias the initialization structurally for some attempts\n        if attempt % 3 == 0:\n            # Anchor elements into the tight 4 corners\n            centers[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            # Core centroid\n            centers[4] = [0.5, 0.5]\n            # Edge boundaries midpoints\n            centers[5:9] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            \n        # Size placement: mathematically bias larger circles toward the center\n        dist_to_center = np.linalg.norm(centers - 0.5, axis=1)\n        radii = 0.06 - 0.03 * dist_to_center\n        \n        # 2. Optimization parameters\n        lr = 0.015\n        W = 1.0  # Constraint weight\n        \n        vP = np.zeros_like(centers)\n        vR = np.zeros_like(radi\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.9812, Type: High-Performer)\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    scale_pairs = np.min(dist / (R_sum + 1e-10))\n    \n    scale_left = np.min(P[:, 0] / (R + 1e-10))\n    scale_right = np.min((1 - P[:, 0]) / (R + 1e-10))\n    scale_bottom = np.min(P[:, 1] / (R + 1e-10))\n    scale_top = np.min((1 - P[:, 1]) / (R + 1e-10))\n    \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x * 0.9999999  # Slightly scale to ensure strict bound compliance\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 40 and (time.time() - start_time) < 25.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 5\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[i] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n                \n        # Initialize initial radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.06 - 0.03 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.015\n        C = 1.0\n        steps = 4000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 800 == 0 and step < 2500:\n                P += np.random.randn(*P.shape) * 0.001\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_initial_centers(attempt, n_circles):\n    \"\"\"\n    Generate strategic initial positions for the circles to maximize space utilization.\n    Biases placement towards corners and edges based on the attempt number.\n    \"\"\"\n    centers = np.zeros((n_circles, 2))\n    if attempt == 0:\n        # Concentric rings\n        centers[0] = [0.5, 0.5]\n        for i in range(8):\n            angle = 2 * np.pi * i / 8\n            centers[i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        for i in range(17):\n            angle = 2 * np.pi * i / 17\n            if i + 9 < n_circles:\n                centers[i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n    elif attempt == 1:\n        # 5x5 Grid with 1 extra center\n        grid_n = 5\n        xs = np.linspace(0.1, 0.9, grid_n)\n        ys = np.linspace(0.1, 0.9, grid_n)\n        idx = 0\n        for x in xs:\n            for y in ys:\n                if idx < 25:\n                    centers[idx] = [x, y]\n                    idx += 1\n        if n_circles > 25:\n            centers[25] = [0.5, 0.5]\n    elif attempt == 2:\n        # Edges and corners bias\n        for i in range(n_circles):\n            if i < 4:\n                centers[i] = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]][i]\n            elif i < 16:\n                t = ((i - 4) % 3 + 1) / 4.0\n                edge = (i - 4) // 3\n                if edge == 0: centers[i] = [t, 0.1]\n                elif edge == 1: centers[i] = [t, 0.9]\n                elif edge == 2: centers[i] = [0.1, t]\n                elif edge == 3: centers[i] = [0.9, t]\n            else:\n                centers[i] = [np.random.uniform(0.3, 0.7), np.random.uniform(0.3, 0.7)]\n    elif attempt == 3:\n        # Hexagonal-like pattern\n        idx = 0\n        rows = [5, 6, 5, 5, 5]\n        y_spacing = 0.8 / 4\n        for r, cols in enumerate(rows):\n            y = 0.1 + r * y_spacing\n            x_spacing = 0.8 / (cols - 1) if cols > 1 else 0\n            for c in range(cols):\n                x = 0.1 + c * x_spacing\n                \n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["import time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(*P.shape) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 100 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 7\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)"]}}, "artifacts_json": "{\"execution_time\": \"45.40s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.628902/2.635 = 0.9977\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.8% of target value\", \"radius_stats\": \"Min: 0.061584, Max: 0.136665, Avg: 0.101112\"}", "artifact_dir": null, "embedding": null}