{"id": "42ab3fa9-fef1-480e-83da-64ae029a2fc7", "code": "```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correctly handling floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to strictly maximize their sum without overlapping.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist[i, j])\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef final_polish_slsqp(P, R):\n    \"\"\"\n    Applies a non-linear co-optimization polishing phase to both the Centers\n    and Radii simultaneously using SLSQP. This helps squeeze the final decimal \n    points out of highly optimized configurations.\n    \"\"\"\n    try:\n        from scipy.optimize import minimize\n        N = len(P)\n        \n        def objective(x):\n            return -np.sum(x[2*N:])\n            \n        def obj_jac(x):\n            grad = np.zeros(3*N)\n", "changes_description": null, "language": "python", "parent_id": "def079be-f237-41af-94b4-2cc2a81c222c", "generation": 5, "timestamp": 1771883128.707327, "iteration_found": 72, "metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.5977796595393166, "target_ratio": 0.9858746336012587, "combined_score": 0.9858746336012587, "radius_variance": 0.004834541844247796, "spatial_spread": 0.1899387993343908, "eval_time": 36.15251922607422}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following best practices:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n* You MUST think creatively, identify multiple alternative options of the algorithm design, analyze their pros and cons, and select the most promising algorithm.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: You MUST respond in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9859\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.9859\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n36.15s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.597780/2.635 = 0.9859\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 98.6% of target value\n```\n\n### radius_stats\n```\nMin: 0.069520, Max: 0.134986, Avg: 0.099915\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5978, target_ratio: 0.9859, combined_score: 0.9859, radius_variance: 0.0048, spatial_spread: 0.1899, eval_time: 36.1525\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6289, target_ratio: 0.9977, combined_score: 0.9977, radius_variance: 0.0050, spatial_spread: 0.1858, eval_time: 45.3985\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6300, target_ratio: 0.9981, combined_score: 0.9981, radius_variance: 0.0049, spatial_spread: 0.1857, eval_time: 45.5303\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9981)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(P.shape[0], P.shape[1]) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 150 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 8\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            sizes = [5, 5, 6, 5, 5]\n            idx = 0\n            for r, cols in enumerate(sizes):\n                for c in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * c / max(1, cols - 1), 0.1 + 0.8 * r / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            # Purely randomized seeding\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n        elif mode == 7:\n            # Random perturb of 5x5 grid\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x + np.random.uniform(-0.02, 0.02), y + np.random.uniform(-0.02, 0.02)]\n                        idx += 1\n            P[25] = np.random.rand(2) * 0.8 + 0.1\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6300), Performs well on target_ratio (0.9981), Performs well on combined_score (0.9981), Performs well on radius_variance (0.0049), Performs well on spatial_spread (0.1857), Performs well on eval_time (45.5303)\n\n### Program 2 (Score: 0.9977)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = float(np.linalg.norm(P[i] - P[j]))\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef optimize_centers_and_radii(P, R, steps, initial_lr, initial_C, inject_noise=True):\n    \"\"\"\n    Physics-based constraint optimization via Adam gradient descent.\n    Uses simulated annealing with an increasing penalty constraint (C) and decaying learning rate.\n    \"\"\"\n    lr = initial_lr\n    C = initial_C\n    m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        left = np.maximum(0, R - P[:, 0])\n        right = np.maximum(0, R - (1 - P[:, 0]))\n        bottom = np.maximum(0, R - P[:, 1])\n        top = np.maximum(0, R - (1 - P[:, 1]))\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        dist_safe = np.maximum(dist, 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = R_sum - dist\n        np.fill_diagonal(overlap, -np.inf)\n        overlap_masked = np.maximum(0, overlap)\n        \n        grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n        \n        grad_P = np.zeros_like(P)\n        grad_P[:, 0] += 2 * C * (-left + right)\n        grad_P[:, 1] += 2 * C * (-bottom + top)\n        \n        weight = 2 * C * overlap_masked / dist_safe\n        grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n        \n        t = step + 1\n        \n        m_P = 0.9 * m_P + 0.1 * grad_P\n        v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n        m_hat_P = m_P / (1 - 0.9 ** t)\n        v_hat_P = v_P / (1 - 0.999 ** t)\n        P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n        \n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n        m_hat_R = m_R / (1 - 0.9 ** t)\n        v_hat_R = v_R / (1 - 0.999 ** t)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n        \n        R = np.maximum(1e-5, R)\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        C *= 1.002\n        lr *= 0.9995\n        \n        if inject_noise and step % 600 == 0 and step < steps * 0.6:\n            P += np.random.randn(*P.shape) * 0.0005\n            \n    return P, R\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    np.random.seed(42)\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    while attempt < 100 and (time.time() - start_time) < 45.0:\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initialization to explore diverse layout seeds\n        mode = attempt % 7\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n        elif mode == 6:\n            P[0] = [0.5, 0.5]\n            for i in range(6): \n                P[i+1] = [0.5 + 0.15*np.cos(2*np.pi*i/6), 0.5 + 0.15*np.sin(2*np.pi*i/6)]\n            for i in range(12): \n                P[i+7] = [0.5 + 0.3*np.cos(2*np.pi*i/12), 0.5 + 0.3*np.sin(2*np.pi*i/12)]\n            for i in range(7): \n                P[i+19] = [0.5 + 0.45*np.cos(2*np.pi*i/7), 0.5 + 0.45*np.sin(2*np.pi*i/7)]\n            P = np.clip(P, 0.05, 0.95)\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        # Two-stage physics optimization\n        P, R = optimize_centers_and_radii(P, R, steps=3000, initial_lr=0.015, initial_C=1.0, inject_noise=True)\n        P, R = optimize_centers_and_radii(P, R, steps=1000, initial_lr=0.002, initial_C=100.0, inject_noise=False)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback resolving precision faults\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6289), Performs well on target_ratio (0.9977), Performs well on combined_score (0.9977), Performs well on radius_variance (0.0050), Performs well on spatial_spread (0.1858), Performs well on eval_time (45.3985)\n\n### Program 3 (Score: 0.9859)\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 100 and (time.time() - start_time) < 40.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 6\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(12):\n                angle = 2 * np.pi * i / 12\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[12 + i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[20] = [0.5, 0.5]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1:\n                    P[i, 0] += 0.8\n                elif i % 4 == 2:\n                    P[i, 1] += 0.8\n                elif i % 4 == 3:\n                    P[i] += 0.8\n        elif mode == 4:\n            # Hexagonal-like bias\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n                \n        # Initialize radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.07 - 0.035 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.02\n        C = 1.0\n        steps = 3000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Final safety check\n        scale_final = compute_valid_scale(P, R_final)\n        if scale_final < 1.0:\n            R_final *= scale_final * 0.9999999\n            \n        current_sum = float(np.sum(R_final))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), best_sum\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5978), Performs well on target_ratio (0.9859), Performs well on combined_score (0.9859), Performs well on radius_variance (0.0048), Performs well on spatial_spread (0.1899), Performs well on eval_time (36.1525)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n```python\nimport numpy as np\nimport time\n\ntry:\n    from scipy.optimize import minimize, linprog\n    HAS_SCIPY = True\nexcept ImportError:\n    HAS_SCIPY = False\n\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in pure NumPy.\n    Used for smooth, momentum-based gradient descent if SciPy is unavailable.\n    \"\"\"\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    \"\"\"\n    Computes penalty-based overlap violations and mathematically exact gradients.\n    Penalty weight 'C' smoothly pushes bounds to solidify the packing.\n    \"\"\"\n    N = len(R)\n    \n    left = R - P[:, 0]\n    right = R - (1 - P[:, 0])\n    bottom = R - P[:, 1]\n    top = R - (1 - P[:, 1])\n    \n    v_left = np.maximum(0, left)\n    v_right = np.maximum(0, right)\n    v_bottom = np.maximum(0, bottom)\n    v_top = np.maximum(0, top)\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    v_overlap = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(v_left**2 + v_right**2 + v_bottom**2 + v_top**2)\n    loss += C * np.sum(np.triu(v_overlap)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (v_left + v_right + v_bottom + v_top)\n    \n    grad_P[:, 0] += 2 * C * (-v_left + v_right)\n    grad_P[:, 1] += 2 * C * (-v_bottom + v_top)\n    \n    grad_R += 2 * C * np.sum(v_overlap, axis=1)\n    \n    safe_dist = np.maximum(dist, 1e-10)\n\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.3333)\n```python\nimport time\nimport numpy as np\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a strict scaling factor to guarantee that no circles overlap and \n    all remain completely within the [0, 1] boundaries. This acts as a robust \n    correction step resolving any floating point precision inconsistencies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed topology of centers, calculates the mathematically strict maximum\n    possible radii using a Linear Programming solver (SciPy required).\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\ndef run_packing():\n    \"\"\"\n    Main entry point for finding the optimal configuration.\n    Uses continuous optimization (Adam-based physics penalty method) combined\n    with simulated annealing and topological seeding.\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    \n    # Run heavily randomized topological restarts within given time bounds\n    while attempt < 150 and (time.time() - start_time) < 180.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializing schemes\n        mode = attempt % 6\n        if mode == 0:\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n            P[9:] = np.random.rand(17, 2) * 0.8 + 0.1\n        elif mode == 1:\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[10+i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[18] = [0.5, 0.5]\n            P[19:] = np.random.rand(7, 2) * 0.8 + 0.1\n        elif mode == 2:\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n        elif mode == 4:\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1: P[i, 0] += 0.8\n                elif i % 4 == 2: P[i, 1] += 0.8\n                elif i % 4 == 3: P[i] += 0.8\n            P[12:] = np.random.rand(14, 2) * 0.8 + 0.1\n        elif mode == 5:\n            P = np.random.rand(N, 2) * 0.8 + 0.1\n            \n        # Initialize sizes inversely proportional to distance from the centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.08 - 0.04 * dist_to_center\n        \n        lr = 0.02\n        C = 1.0  # Constraint weight starts gentle and anneals to strict\n        steps = 3500\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Iterative physics layout model via Adam optimization\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients calculation enforcing penalty violations + sum of R scaling\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            P = np.clip(P, 1e-5, 1 - 1e-5)\n            \n            C *= 1.0015\n            lr *= 0.9995\n            \n            # Injection of symmetry breaking noise\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Upgrade optimized positions to rigorous maximum values through LP\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Enforce exact rigidness fallback\n        scale2 = compute_valid_scale(P, R_final)\n        if scale2 < 1.0:\n            R_final *= scale2 * 0.9999999\n            \n        current_sum = np.sum(R_final)\n        \n        # Log successful improved iteration configurations\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), float(best_sum)\n```\nKey features: Alternative approach to stage1_passed, Alternative approach to error\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\nimport numpy as np\n\nclass AdamOptimizer:\n    \"\"\"\n    Standard Adam Optimizer implemented in NumPy for fully vectorized operations.\n    Provides smooth, momentum-based gradient descent robust to gradient scaling.\n    \"\"\"\n    def __init__(self, shape):\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, lr):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params = params - lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes the maximum scaling factor for radii such that no overlaps occur\n    and all circles remain strictly within the [0, 1] bounds.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    safe_R_sum = np.where(R_sum > 0, R_sum, 1.0)\n    scale_pairs = np.where(R_sum > 0, dist / safe_R_sum, np.inf)\n    min_scale_pairs = np.min(scale_pairs)\n    \n    safe_R = np.where(R > 0, R, 1.0)\n    scale_left = np.where(R > 0, P[:, 0] / safe_R, np.inf)\n    scale_right = np.where(R > 0, (1 - P[:, 0]) / safe_R, np.inf)\n    scale_bottom = np.where(R > 0, P[:, 1] / safe_R, np.inf)\n    scale_top = np.where(R > 0, (1 - P[:, 1]) / safe_R, np.inf)\n    \n    min_scale_bounds = np.min([scale_left, scale_right, scale_bottom, scale_top])\n    \n    return max(0.0, min(min_scale_pairs, min_scale_bounds))\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, find the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n    except ImportError:\n        return None, None\n        \n    c = -np.ones(N)\n    A_ub = []\n    b_ub = []\n    \n    for i in range(N):\n        for j in range(i + 1, N):\n            dist = np.linalg.norm(P[i] - P[j])\n            row = np.zeros(N)\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\nAn excellent approach to improving this score is to completely replace the static concentric arrangement with a robust, iterative physics-based solver. To find the optimal packing of 26 non-overlapping circles that maximizes the sum of their radii, we can formulate this as a continuous optimization problem using a simulated physics model with momentum.\n\nInstead of hardcoding positions, the circles start with strategically biased random initial positions and iteratively \"grow\" while repelling one another. This acts as a Penalty Method (or Augmented Lagrangian) algorithm, effectively finding the maximum possible sum of radii without overlapping.\n\n### Key Improvements Implemented:\n1. **Strategic Seed Initialization**: Multiple random restarts are employed. We selectively seed configurations strongly favoring corners and edges to maximize bounding box utilization.\n2. **Size Placement Bias**: The initial radii are mathematically parameterized based on their distance from the `[0.5, 0.5]` centroid\u2014biasing larger circles toward the center and letting small circles fill the corners. \n3. **Physics Optimization & Simulated Annealing**: We iterate using momentum gradients, a decaying learning rate, and an exponentially increasing constraint weight (`W`). This allows circles to easily swap positions early in the simulation before smoothly settling into a rigorous non-overlapping tight packing.\n4. **Symmetry Breaking**: We systematically introduce slight micro-perturbations (`np.random.randn`) during the early epochs to break symmetries and prevent the circles from stalling in unstable equilibrium local maxima.\n5. **Strict Overlap Resolution**: At the end of every simulation, an iterative rigid-scaling resolution is applied to ensure the solution is mathematically sound (preventing any floating-point violations).\n\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii using a physics-based relaxation algorithm.\n    \"\"\"\n    n = 26\n    best_sum = 0\n    best_centers = None\n    best_radii = None\n    \n    np.random.seed(42)  # For reproducibility\n    \n    # 12 restarts with different initializations to traverse multiple topographies\n    for attempt in range(12):\n        # 1. Strategic initialization\n        centers = np.random.rand(n, 2) * 0.8 + 0.1\n        \n        # Bias the initialization structurally for some attempts\n        if attempt % 3 == 0:\n            # Anchor elements into the tight 4 corners\n            centers[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            # Core centroid\n            centers[4] = [0.5, 0.5]\n            # Edge boundaries midpoints\n            centers[5:9] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            \n        # Size placement: mathematically bias larger circles toward the center\n        dist_to_center = np.linalg.norm(centers - 0.5, axis=1)\n        radii = 0.06 - 0.03 * dist_to_center\n        \n        # 2. Optimization parameters\n        lr = 0.015\n        W = 1.0  # Constraint weight\n        \n        vP = np.zeros_like(centers)\n        vR = np.zeros_like(radi\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nimport time\nimport numpy as np\n\ntry:\n    from scipy.optimize import linprog\n    SCIPY_AVAILABLE = True\nexcept ImportError:\n    SCIPY_AVAILABLE = False\n\n\nclass AdamOptimizer:\n    def __init__(self, shape, lr=0.01):\n        self.lr = lr\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, current_lr=None):\n        self.t += 1\n        lr = current_lr if current_lr is not None else self.lr\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        params -= lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n        return params\n\n\ndef get_loss_and_grads(P, R, C):\n    N = len(R)\n    \n    left = np.maximum(0, R - P[:, 0])\n    right = np.maximum(0, R - (1 - P[:, 0]))\n    bottom = np.maximum(0, R - P[:, 1])\n    top = np.maximum(0, R - (1 - P[:, 1]))\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.linalg.norm(diff, axis=-1)\n    dist[dist < 1e-10] = 1e-10\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    overlap = R_sum - dist\n    np.fill_diagonal(overlap, -np.inf)\n    overlap_masked = np.maximum(0, overlap)\n    \n    loss = -np.sum(R)\n    loss += C * np.sum(left**2 + right**2 + bottom**2 + top**2)\n    loss += C * np.sum(np.triu(overlap_masked)**2)\n    \n    grad_R = -np.ones(N)\n    grad_P = np.zeros_like(P)\n    \n    grad_R += 2 * C * (left + right + bottom + top)\n    grad_P[:, 0] += 2 * C * (-left + right)\n    grad_P[:, 1] += 2 * C * (-bottom + top)\n    \n    grad_R += 2 * C * np.sum(overlap_masked, axis=1)\n    \n    weight = 2 * C * overlap_masked / dist\n    grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n    \n    return loss, grad_P, grad_R\n\n\ndef get_initial_state(attempt, N):\n    np.random.seed(attempt)\n    P = np.random.rand(N, 2) * 0.8 + 0.1\n    \n    mode = attempt % \n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correcting any floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to maximize their sum.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist = np.linalg.norm(P[i] - P[j])\n                A_row = np.zeros(N)\n                A_row[i] = 1\n                A_row[j] = 1\n                A_ub.append(A_row)\n                b_ub.append(max(float(dist), 1e-8))\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef run_packing():\n    \"\"\"\n    Main execution function called by the evaluator.\n    Finds the optimal packing of 26 non-overlapping circles to maximize sum of radii.\n    Returns: (centers, radii, sum_radii)\n    \"\"\"\n    N = 26\n    start_time = time.time()\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    attempt = 0\n    # Run multiple restarts to avoid local minima, stopping well before timeout\n    while attempt < 100 and (time.time() - start_time) < 40.0:\n        np.random.seed(attempt + 42)\n        P = np.random.rand(N, 2) * 0.8 + 0.1\n        \n        # Strategic topological initializations\n        mode = attempt % 6\n        if mode == 0:\n            # Emphasize corners and edges\n            P[0:4] = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n            P[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n            P[8] = [0.5, 0.5]\n        elif mode == 1:\n            # Concentric distribution\n            for i in range(12):\n                angle = 2 * np.pi * i / 12\n                P[i] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                P[12 + i] = [0.5 + 0.15 * np.cos(angle), 0.5 + 0.15 * np.sin(angle)]\n            P[20] = [0.5, 0.5]\n        elif mode == 2:\n            # Standard grid structure\n            idx = 0\n            for x in np.linspace(0.1, 0.9, 5):\n                for y in np.linspace(0.1, 0.9, 5):\n                    if idx < 25:\n                        P[idx] = [x, y]\n                        idx += 1\n            P[25] = [0.5, 0.5]\n        elif mode == 3:\n            # Dense corner clusters\n            for i in range(12):\n                P[i] = np.random.rand(2) * 0.2\n                if i % 4 == 1:\n                    P[i, 0] += 0.8\n                elif i % 4 == 2:\n                    P[i, 1] += 0.8\n                elif i % 4 == 3:\n                    P[i] += 0.8\n        elif mode == 4:\n            # Hexagonal-like bias\n            idx = 0\n            for row in range(5):\n                cols = 5 if row % 2 == 0 else 6\n                for col in range(cols):\n                    if idx < N:\n                        P[idx] = [0.1 + 0.8 * col / max(1, cols - 1), 0.1 + 0.8 * row / 4.0]\n                        idx += 1\n                \n        # Initialize radii inversely proportional to their distance from centroid\n        dist_to_center = np.linalg.norm(P - 0.5, axis=1)\n        R = 0.07 - 0.035 * dist_to_center\n        \n        # Optimization hyperparameters\n        lr = 0.02\n        C = 1.0\n        steps = 3000\n        \n        m_P, v_P = np.zeros_like(P), np.zeros_like(P)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        # Physics-based constraint optimization via Adam gradient descent\n        for step in range(steps):\n            left = np.maximum(0, R - P[:, 0])\n            right = np.maximum(0, R - (1 - P[:, 0]))\n            bottom = np.maximum(0, R - P[:, 1])\n            top = np.maximum(0, R - (1 - P[:, 1]))\n            \n            diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, np.inf)\n            dist_safe = np.maximum(dist, 1e-12)\n            \n            R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n            overlap = R_sum - dist\n            np.fill_diagonal(overlap, -np.inf)\n            overlap_masked = np.maximum(0, overlap)\n            \n            # Gradients for radii maximization + penalty bounds\n            grad_R = -1.0 + 2 * C * (left + right + bottom + top + np.sum(overlap_masked, axis=1))\n            \n            # Gradients for center positional adjustments\n            grad_P = np.zeros_like(P)\n            grad_P[:, 0] += 2 * C * (-left + right)\n            grad_P[:, 1] += 2 * C * (-bottom + top)\n            \n            weight = 2 * C * overlap_masked / dist_safe\n            grad_P -= np.sum(weight[:, :, np.newaxis] * diff, axis=1)\n            \n            t = step + 1\n            \n            # Apply Adam updates\n            m_P = 0.9 * m_P + 0.1 * grad_P\n            v_P = 0.999 * v_P + 0.001 * (grad_P ** 2)\n            m_hat_P = m_P / (1 - 0.9 ** t)\n            v_hat_P = v_P / (1 - 0.999 ** t)\n            P -= lr * m_hat_P / (np.sqrt(v_hat_P) + 1e-8)\n            \n            m_R = 0.9 * m_R + 0.1 * grad_R\n            v_R = 0.999 * v_R + 0.001 * (grad_R ** 2)\n            m_hat_R = m_R / (1 - 0.9 ** t)\n            v_hat_R = v_R / (1 - 0.999 ** t)\n            R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n            \n            R = np.maximum(1e-5, R)\n            \n            # Simulated Annealing mechanism\n            C *= 1.002\n            lr *= 0.9995\n            \n            # Inject micro-perturbations to break layout symmetries\n            if step % 500 == 0 and step < 2000:\n                P += np.random.randn(*P.shape) * 0.0005\n                \n        # Resolve any residual errors strictly\n        P = np.clip(P, 1e-5, 1 - 1e-5)\n        \n        # Elevate to absolute mathematical optimum via Linear Programming\n        R_lp = optimize_radii_lp(P)\n        if R_lp is not None:\n            R_final = R_lp * 0.9999999\n        else:\n            scale = compute_valid_scale(P, R)\n            R_final = R * scale * 0.9999999\n            \n        # Final safety check\n        scale_final = compute_valid_scale(P, R_final)\n        if scale_final < 1.0:\n            R_final *= scale_final * 0.9999999\n            \n        current_sum = float(np.sum(R_final))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = P.copy()\n            best_radii = R_final.copy()\n            \n        attempt += 1\n            \n    return best_centers.tolist(), best_radii.tolist(), best_sum\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport time\nimport numpy as np\n\n\ndef compute_valid_scale(P, R):\n    \"\"\"\n    Computes a scaling factor to guarantee that no circles overlap and all remain\n    strictly within the [0, 1] bounds, correctly handling floating point inaccuracies.\n    \"\"\"\n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n    \n    with np.errstate(divide='ignore', invalid='ignore'):\n        scale_pairs = np.min(dist / (R_sum + 1e-12))\n        scale_left = np.min(P[:, 0] / (R + 1e-12))\n        scale_right = np.min((1 - P[:, 0]) / (R + 1e-12))\n        scale_bottom = np.min(P[:, 1] / (R + 1e-12))\n        scale_top = np.min((1 - P[:, 1]) / (R + 1e-12))\n        \n    return max(0.0, min(1.0, scale_pairs, scale_left, scale_right, scale_bottom, scale_top))\n\n\ndef optimize_radii_lp(P):\n    \"\"\"\n    Given a fixed set of centers, calculates the mathematically optimal radii \n    using Linear Programming to strictly maximize their sum without overlapping.\n    \"\"\"\n    N = len(P)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(N)\n        A_ub = []\n        b_ub = []\n        \n        diff = P[:, np.newaxis, :] - P[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        for i in range(N):\n            for j in range(i + 1, N):\n                row = np.zeros(N)\n                row[i] = 1\n                row[j] = 1\n                A_ub.append(row)\n                b_ub.append(dist[i, j])\n                \n        bounds = [(0.0, max(0.0, min(float(P[i, 0]), 1.0 - float(P[i, 0]), float(P[i, 1]), 1.0 - float(P[i, 1])))) for i in range(N)]\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return res.x\n    except Exception:\n        pass\n    return None\n\n\ndef final_polish_slsqp(P, R):\n    \"\"\"\n    Applies a non-linear co-optimization polishing phase to both the Centers\n    and Radii simultaneously using SLSQP. This helps squeeze the final decimal \n    points out of highly optimized configurations.\n    \"\"\"\n    try:\n        from scipy.optimize import minimize\n        N = len(P)\n        \n        def objective(x):\n            return -np.sum(x[2*N:])\n            \n        def obj_jac(x):\n            grad = np.zeros(3*N)\n"]}}, "artifacts_json": "{\"stderr\": \"Stage 1 evaluation failed: Program execution failed: invalid syntax (tmp5ttqmjky.py, line 1)\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\\\", line 384, in evaluate_stage1\\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\\n  File \\\"/home/jupyter/Code/oe/dennis/run3_improved_si/evaluator.py\\\", line 172, in run_with_timeout\\n    raise RuntimeError(f\\\"Program execution failed: {results['error']}\\\")\\nRuntimeError: Program execution failed: invalid syntax (tmp5ttqmjky.py, line 1)\\n\", \"failure_stage\": \"stage1_execution\", \"suggestion\": \"Check basic syntax and imports before attempting full evaluation\"}", "artifact_dir": null, "embedding": null}