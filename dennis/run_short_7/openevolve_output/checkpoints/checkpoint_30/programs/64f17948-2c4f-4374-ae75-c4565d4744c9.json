{"id": "64f17948-2c4f-4374-ae75-c4565d4744c9", "code": "\"\"\"\nOptimized Circle Packing for N=26 using Vectorized Physics-Based Descent\n\"\"\"\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Computes an optimized arrangement of 26 circles in a 1x1 unit square\n    to maximize the sum of radii without overlap.\n    \n    Returns:\n        tuple: (centers_list, radii_list, sum_radii)\n    \"\"\"\n    n_circles = 26\n    batch_size = 128\n    steps = 8000\n    \n    # Randomly seeding for exploratory layout varieties while allowing stabilization\n    np.random.seed(42)\n    \n    # Run the parallel physics simulation optimization on multiple topologies\n    pos, radii = optimize_circles_parallel(n_circles, batch_size, steps)\n    \n    best_config = (pos[0], radii[0])\n    best_score = -1.0\n    \n    # Strictly validate geometries and select the global best packed configuration\n    for idx in range(batch_size):\n        p_final = pos[idx]\n        r_final = radii[idx]\n        \n        r_valid = enforce_validity(p_final, r_final)\n        current_sum = np.sum(r_valid)\n        \n        if current_sum > best_score:\n            best_score = current_sum\n            best_config = (p_final, r_valid)\n            \n    best_centers, best_radii = best_config\n    return best_centers.tolist(), best_radii.tolist(), float(best_score)\n\n\ndef init_batch(batch_size, n):\n    \"\"\"\n    Heuristic initialization distributing dynamic grid networks, central\n    hub clusters, and large bounds randomly injected to map parameter space.\n    \"\"\"\n    pos = np.random.uniform(0.1, 0.9, (batch_size, n, 2))\n    radii = np.full((batch_size, n), 0.05)\n    \n    for i in range(batch_size):\n        mode = i % 5\n        if mode == 1:\n            pos[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.22\n            a = np.linspace(0, 2 * np.pi, 8, endpoint=False) + np.random.uniform(0, 1)\n            for j in range(8):\n                if j + 1 < n:\n                    pos[i, j + 1] = [0.5 + 0.3 * np.cos(a[j]), 0.5 + 0.3 * np.sin(a[j])]\n                    radii[i, j + 1] = 0.10\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for j in range(4):\n                if j + 9 < n:\n                    pos[i, j + 9] = corners[j]\n                    radii[i, j + 9] = 0.12\n        elif mode == 2:\n            # Concentric hierarchical structuring\n            pos[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.20\n            a1 = np.linspace(0, 2 * np.pi, 6, endpoint=False)\n            for j in range(6):\n                if j + 1 < n:\n                    pos[i, j + 1] = [0.5 + 0.22 * np.cos(a1[j]), 0.5 + 0.22 * np.sin(a1[j])]\n                    radii[i, j + 1] = 0.11\n            a2 = np.linspace(0, 2 * np.pi, 12, endpoint=False) + 0.2\n            for j in range(12):\n                if j + 7 < n:\n                    pos[i, j + 7] = [0.5 + 0.42 * np.cos(a2[j]), 0.5 + 0.42 * np.sin(a2[j])]\n                    radii[i, j + 7] = 0.07\n        elif mode == 3:\n            # Hexagonal gap biased spread\n            gw, gh = 6, 5\n            idx = 0\n            for r in range(gh):\n                for c in range(gw):\n                    if idx < n:\n                        pos[i, idx] = [(c + 0.5 + 0.5 * (r % 2)) / gw, (r + 0.5) / gh]\n                        radii[i, idx] = 0.08\n                        idx += 1\n        elif mode == 4:\n            pos[i, 0] = [0.3, 0.3]\n            radii[i, 0] = 0.18\n            pos[i, 1] = [0.7, 0.7]\n            radii[i, 1] = 0.18\n            if n > 3:\n                pos[i, 2] = [0.3, 0.7]\n                radii[i, 2] = 0.15\n                pos[i, 3] = [0.7, 0.3]\n                radii[i, 3] = 0.15\n                \n    # Insert slight jitter avoiding perfect initial equilibrium stalling gradients\n    pos += np.random.normal(0, 0.005, pos.shape)\n    radii += np.random.normal(0, 0.002, radii.shape)\n    return np.clip(pos, 0.02, 0.98), np.clip(radii, 0.01, 0.3)\n\n\ndef optimize_circles_parallel(n, batch_size, steps):\n    \"\"\"\n    Core fully vectorized parallel Adam simulation leveraging matrix diff operations \n    representing gradients of hard penalty potentials combined closely with geometric logic.\n    \"\"\"\n    pos, radii = init_batch(batch_size, n)\n    \n    m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    identity = np.eye(n)[np.newaxis, :, :]\n    \n    for i in range(1, steps + 1):\n        t = i / steps\n        # Smoothed zero landing gradient sequence ensuring optimal resting stops\n        lr = 0.02 * (1.0 - t)\n        # Exponential constraint penalization walling correctly toward the boundaries safely \n        k_pen = 10.0 * (20000.0 ** t)\n        \n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        r_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlaps = np.maximum(0, r_sum - dist) * (1.0 - identity)\n        \n        wall_min = np.maximum(0, radii[:, :, np.newaxis] - pos)\n        wall_max = np.maximum(0, pos + radii[:, :, np.newaxis] - 1.0)\n        wall_overlaps = wall_min + wall_max\n        \n        # Proper repelling force analytical derivations using structural signs directly\n        norm_diff = diff / (dist[:, :, :, np.newaxis] + 1e-12)\n        grad_p_pairs = -np.sum(overlaps[:, :, :, np.newaxis] * norm_diff, axis=2)\n        grad_p_walls = -wall_min + wall_max\n        \n        grad_p = k_pen * (2.0 * grad_p_pairs + 2.0 * grad_p_walls)\n        \n        grad_r_pairs = 2.0 * np.sum(overlaps, axis=2)\n        grad_r_walls = 2.0 * np.sum(wall_overlaps, axis=2)\n        # Goal metric translates strictly as `-1.0` maximizing sum\n        grad_r = -1.0 + k_pen * (grad_r_pairs + grad_r_walls)\n        \n        # Iteration moments evaluating updates\n        m_p = beta1 * m_p + (1 - beta1) * grad_p\n        v_p = beta2 * v_p + (1 - beta2) * (grad_p**2)\n        h_m_p = m_p / (1 - beta1**i)\n        h_v_p = v_p / (1 - beta2**i)\n        pos -= lr * h_m_p / (np.sqrt(h_v_p) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        h_m_r = m_r / (1 - beta1**i)\n        h_v_r = v_r / (1 - beta2**i)\n        radii -= lr * h_m_r / (np.sqrt(h_v_r) + eps)\n        \n        # Progressively decaying layout breaking injection mapping escape topologies efficiently\n        if t < 0.8:\n            noise_level = 0.003 * ((0.8 - t) / 0.8)**2\n            pos += np.random.normal(0, noise_level, pos.shape)\n            \n        pos = np.clip(pos, 0.0, 1.0)\n        radii = np.maximum(radii, 1e-5)\n        \n    return pos, radii\n\n\ndef enforce_validity(p, r_guess):\n    \"\"\"\n    Absolutely ensuring geometry bounds exactly maintaining the highest limits structurally \n    using guaranteed iteratively narrowing checks preventing zero overmapping behaviors cleanly.\n    \"\"\"\n    r = r_guess.copy()\n    n = len(r)\n    \n    d_walls = np.minimum(p, 1.0 - p)\n    r = np.minimum(r, np.min(d_walls, axis=1))\n    \n    mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n    \n    for _ in range(500):\n        d_vec = p[:, np.newaxis, :] - p[np.newaxis, :, :]\n        dist_matrix = np.sqrt(np.sum(d_vec**2, axis=-1))\n        \n        r_sums = r[:, np.newaxis] + r[np.newaxis, :]\n        overlaps = r_sums - dist_matrix\n        \n        overlap_vals = overlaps[mask]\n        if np.max(overlap_vals) <= 1e-12:\n            break\n            \n        rows, cols = np.where((overlaps > 1e-12) & mask)\n        for i, j in zip(rows, cols):\n            excess = r[i] + r[j] - dist_matrix[i, j]\n            if excess > 0:\n                # Add micro padding ensuring cyclical decimal errors strictly resolved safely\n                shrink = excess * 0.5 + 1e-11\n                r[i] = max(0.0, r[i] - shrink)\n                r[j] = max(0.0, r[j] - shrink)\n                \n    # Execute single trailing wrap bound resolution cleanly perfectly ensuring absolute\n    r = np.minimum(r, np.min(np.minimum(p, 1.0 - p), axis=1))\n    \n    return r", "changes_description": null, "language": "python", "parent_id": "f5e4be8f-9918-42c4-bc82-c6e19d5be8ce", "generation": 2, "timestamp": 1772007011.129847, "iteration_found": 24, "metrics": {"validity": 1.0, "sum_radii": 2.594842397875875, "target_ratio": 0.9847599232925521, "combined_score": 0.9847599232925521, "radius_variance": 0.006080653387246044, "spatial_spread": 0.19324531778014511, "eval_time": 54.112059593200684}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0000\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: module 'program' has no attribute 'run_packing'\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/run_short_7/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/run_short_7/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: module 'program' has no attribute 'run_packing'\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 1.2260, target_ratio: 0.4653, combined_score: 0.4653, radius_variance: 0.0226, spatial_spread: 0.2084\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.4653)\n```python\n\"\"\"\nOptimized Circle Packing for N=26 using Physics-Based Descent\n\"\"\"\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Entry point for the circle packing execution.\n    Computes an optimized arrangement of 26 circles in a 1x1 unit square\n    to maximize the sum of radii without overlap.\n    \n    Returns:\n        tuple: (centers_list, radii_list, sum_radii)\n               centers_list: List of [x, y] coordinates.\n               radii_list: List of radii.\n               sum_radii: Float sum of radii.\n    \"\"\"\n    n_circles = 26\n    # Run the parallel optimization routine\n    centers, radii = optimize_circles_parallel(n_circles)\n    \n    # Convert numpy arrays to standard lists for output compliance\n    return centers.tolist(), radii.tolist(), float(np.sum(radii))\n\n\ndef optimize_circles_parallel(n):\n    \"\"\"\n    Performs batch optimization using vectorized physics simulation.\n    Simultaneously evolves multiple circle configurations to find global maxima.\n    \n    Args:\n        n (int): Number of circles.\n        \n    Returns:\n        tuple: (best_centers_array, best_radii_array)\n    \"\"\"\n    # 1. Hyperparameters\n    batch_size = 64\n    steps = 4000\n    learning_rate_start = 0.01\n    \n    # 2. Initialization\n    # Initialize random positions somewhat centrally to allow outward expansion\n    pos = np.random.uniform(0.1, 0.9, (batch_size, n, 2))\n    # Start with small radii to prevent explosion at start\n    radii = np.full((batch_size, n), 0.05)\n    \n    # Adam Optimizer Buffers\n    m_p = np.zeros_like(pos)\n    v_p = np.zeros_like(pos)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # 3. Physics Optimization Loop\n    for i in range(1, steps + 1):\n        # Progress (0 to 1)\n        t = i / steps\n        \n        # Decay learning rate\n        lr = learning_rate_start * (1.0 - t * 0.95)\n        \n        # Constraint stiffness: starts soft (10), ends very hard (50000)\n        # Allows rearrangement early on, forces valid configuration at end\n        k_pen = 10.0 * (5000.0 ** t)\n        \n        # --- Physics Forces Calculation ---\n        \n        # Pairwise Difference vectors: shape (Batch, N, N, 2)\n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        # Squared Distance Matrix: shape (Batch, N, N)\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        # Sum of Radii Matrix\n        r_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        \n        # --- Constraints ---\n        # 1. Pairwise Overlap (dist < r1 + r2)\n        identity = np.eye(n)[np.newaxis, :, :]\n        # Positive if overlap exists\n        overlaps = np.maximum(0, r_sum - dist) * (1.0 - identity)\n        \n        # 2. Boundary Violations\n        # Left/Bottom: x < r => r - x > 0\n        wall_min = np.maximum(0, radii[:, :, np.newaxis] - pos)\n        # Right/Top: x + r > 1 => x + r - 1 > 0\n        wall_max = np.maximum(0, pos + radii[:, :, np.newaxis] - 1.0)\n        wall_overlaps = wall_min + wall_max\n        \n        # --- Gradients ---\n        \n        # A. Position Gradients (Forces)\n        # Repulsion force = stiffness * overlap_amount * normalized_direction\n        norm_diff = diff / (dist[:, :, :, np.newaxis] + 1e-12)\n        grad_p_pairs = np.sum(overlaps[:, :, :, np.newaxis] * norm_diff, axis=2)\n        \n        # Wall repulsion: Push circle inward\n        # Deriv of (r-x)^2 w.r.t x is -2(r-x) -> pushes positive (right)\n        grad_p_walls = -wall_min + wall_max\n        \n        # Total position gradient (minimizing penalty energy)\n        grad_p = k_pen * (2.0 * grad_p_pairs + 2.0 * grad_p_walls)\n        \n        # B. Radius Gradients\n        # Objective: Maximize Sum(Radii) -> Minimize -Sum(Radii) -> Gradient is -1\n        grad_obj = -1.0\n        \n        # Penalty gradients (always positive, resisting growth if constrained)\n        # Deriv of (ov)^2 w.r.t r is 2*ov*1\n        grad_r_pairs = 2.0 * np.sum(overlaps, axis=2)\n        grad_r_walls = 2.0 * np.sum(wall_overlaps, axis=2) # sum over x/y axes\n        \n        grad_r = grad_obj + k_pen * (grad_r_pairs + grad_r_walls)\n        \n        # --- Adam Updates ---\n        \n        # Update Pos\n        m_p = beta1 * m_p + (1 - beta1) * grad_p\n        v_p = beta2 * v_p + (1 - beta2) * (grad_p**2)\n        h_m_p = m_p / (1 - beta1**i)\n        h_v_p = v_p / (1 - beta2**i)\n        pos -= lr * h_m_p / (np.sqrt(h_v_p) + eps)\n        \n        # Update Radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        h_m_r = m_r / (1 - beta1**i)\n        h_v_r = v_r / (1 - beta2**i)\n        radii -= lr * h_m_r / (np.sqrt(h_v_r) + eps)\n        \n        # Clip constraints to ensure basic valid domain\n        pos = np.clip(pos, 0.0, 1.0)\n        radii = np.maximum(radii, 1e-5)\n        \n        # Add decaying noise to positions to escape local jamming\n        if t < 0.8:\n            noise_level = 0.002 * ((0.8 - t) / 0.8)\n            pos += np.random.normal(0, noise_level, pos.shape)\n\n    # 4. Selection and Validation\n    # We choose the batch index that yields the highest score AFTER strict cleanup.\n    best_config = (pos[0], radii[0])\n    best_score = -1.0\n    \n    for idx in range(batch_size):\n        p_final = pos[idx]\n        r_final = radii[idx]\n        \n        # Enforce mathematical validity strictly\n        r_valid = enforce_validity(p_final, r_final)\n        \n        current_sum = np.sum(r_valid)\n        if current_sum > best_score:\n            best_score = current_sum\n            best_config = (p_final, r_valid)\n            \n    return best_config\n\n\ndef enforce_validity(p, r_guess):\n    \"\"\"\n    Given fixed centers 'p', shrink the radii 'r_guess' iteratively until\n    absolutely no overlaps or boundary violations remain.\n    \"\"\"\n    r = r_guess.copy()\n    n = len(r)\n    \n    # 1. Hard Box Constraints (Radius <= distance to wall)\n    d_walls = np.minimum(p, 1.0 - p)\n    max_r = np.min(d_walls, axis=1)\n    r = np.minimum(r, max_r)\n    \n    # 2. Resolve Pairwise Overlaps\n    # Iterate until convergence\n    for _ in range(300):\n        # Calculate distance matrix\n        d_vec = p[:, np.newaxis, :] - p[np.newaxis, :, :]\n        dist_matrix = np.sqrt(np.sum(d_vec**2, axis=-1))\n        \n        # Calculate Overlaps\n        r_sums = r[:, np.newaxis] + r[np.newaxis, :]\n        overlaps = r_sums - dist_matrix\n        \n        # Check if valid (Upper triangular only, exclude diagonal)\n        mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n        overlap_vals = overlaps[mask]\n        \n        if np.max(overlap_vals) <= 1e-10:\n            break\n            \n        # Find violation indices\n        rows, cols = np.where((overlaps > 1e-10) & mask)\n        \n        # Shrink overlapping pairs\n        for i, j in zip(rows, cols):\n            # Recalculate strict excess\n            current_dist = dist_matrix[i, j]\n            current_sum = r[i] + r[j]\n            excess = current_sum - current_dist\n            \n            if excess > 0:\n                # Distribute error evenly + small safety epsilon\n                shrink = excess * 0.5 + 1e-10\n                r[i] -= shrink\n                r[j] -= shrink\n                \n                # Floor at zero\n                if r[i] < 0: r[i] = 0.0\n                if r[j] < 0: r[j] = 0.0\n\n    return r\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (1.2260), Performs well on target_ratio (0.4653), Performs well on combined_score (0.4653), Performs well on radius_variance (0.0226), Performs well on spatial_spread (0.2084)\n\n### Program 2 (Score: 0.3333)\n```python\nimport numpy as np\n\n\ndef compute_valid_radii(P, R_opt, max_iters=1000):\n    \"\"\"\n    Ensure the geometry is strictly valid by rectifying residual numeric constraints.\n    Returns structurally guaranteed overlapping-free scaling arrays natively precisely.\n    \"\"\"\n    R = np.copy(R_opt)\n    n = len(R)\n    \n    # Boundary constraints enforcement linearly evaluating overlaps dynamically\n    for i in range(n):\n        R[i] = min(R[i], P[i][0], P[i][1], 1.0 - P[i][0], 1.0 - P[i][1])\n        if R[i] < 0:\n            R[i] = 0.0\n            \n    # Resolve all paired overlapping events iteratively ensuring robust containment\n    for _ in range(max_iters):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt((P[i][0] - P[j][0])**2 + (P[i][1] - P[j][1])**2)\n                if R[i] + R[j] > dist:\n                    ov = R[i] + R[j] - dist\n                    if ov > max_ov:\n                        max_ov = ov\n                    if dist > 1e-12:\n                        scale = dist / (R[i] + R[j])\n                        R[i] *= scale\n                        R[j] *= scale\n                    else:\n                        R[i] *= 0.5\n                        R[j] *= 0.5\n                        \n        if max_ov < 1e-12:\n            break\n            \n    return R * 0.99995\n\n\ndef init_layout(seed, n):\n    \"\"\"\n    Generates dynamic distinct heuristic packing variations systematically.\n    \"\"\"\n    np.random.seed(seed)\n    P = np.zeros((n, 2))\n    R = np.zeros(n)\n    \n    mode = seed % 5\n    if mode == 0:\n        P[0], R[0] = [0.5, 0.5], 0.25\n        for i in range(1, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.01, 0.1)\n    elif mode == 1:\n        P[:4] = [[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.85]]\n        R[:4] = 0.15\n        for i in range(4, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.01, 0.08)\n    elif mode == 2:\n        a = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n        for i in range(8):\n            P[i] = [0.5 + 0.3 * np.cos(a[i]), 0.5 + 0.3 * np.sin(a[i])]\n            R[i] = 0.12\n        for i in range(8, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.02, 0.06)\n    elif mode == 3:\n        idx = 0\n        for px in [0.25, 0.5, 0.75]:\n            for py in [0.25, 0.5, 0.75]:\n                if idx < n:\n                    P[idx], R[idx] = [px, py], 0.10\n                    idx += 1\n        while idx < n:\n            P[idx] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[idx] = np.random.uniform(0.01, 0.05)\n            idx += 1\n    else:\n        for i in range(n):\n            P[i] = [np.random.uniform(0.05, 0.95), np.random.uniform(0.05, 0.95)]\n            R[i] = np.random.uniform(0.05, 0.12)\n            \n    P += np.random.normal(0, 0.01, P.shape)\n    R += np.random.normal(0, 0.005, R.shape)\n    \n    P = np.clip(P, 0.05, 0.95)\n    R = np.clip(R, 0.01, 0.3)\n    return P, R\n\n\ndef optimize_arrangement(seed, n=26, steps=7500):\n    \"\"\"\n    Robust vectorized adam gradients targeting minimal functional configurations structurally iteratively dynamically uniformly globally linearly safely seamlessly mapping.\n    \"\"\"\n    P, R = init_layout(seed, n)\n    m_p, v_p = np.zeros_like(P), np.zeros_like(P)\n    m_r, v_r = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        t = step / max(1, steps - 1)\n        lr = 0.015 * (0.01)**t \n        k = 10.0 * (1e5)**t\n        \n        grad_p, grad_r = np.zeros_like(P), np.full(n, -1.0)\n        \n        d_xmin = np.maximum(0, R - P[:, 0])\n        grad_r += 2 * k * d_xmin\n        grad_p[:, 0] -= 2 * k * d_xmin\n        \n        d_xmax = np.maximum(0, R + P[:, 0] - 1.0)\n        grad_r += 2 * k * d_xmax\n        grad_p[:, 0] += 2 * k * d_xmax\n        \n        d_ymin = np.maximum(0, R - P[:, 1])\n        grad_r += 2 * k * d_ymin\n        grad_p[:, 1] -= 2 * k * d_ymin\n        \n        d_ymax = np.maximum(0, R + P[:, 1] - 1.0)\n        grad_r += 2 * k * d_ymax\n        grad_p[:, 1] += 2 * k * d_ymax\n        \n        dx = P[:, None, 0] - P[None, :, 0]\n        dy = P[:, None, 1] - P[None, :, 1]\n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, 1.0)\n        dist = np.maximum(np.sqrt(dist_sq), 1e-12)\n        \n        ov = R[:, None] + R[None, :] - dist\n        np.fill_diagonal(ov, -1.0)\n        ov_masked = np.maximum(0, ov)\n        \n        grad_r += 2 * k * np.sum(ov_masked, axis=1)\n        force = -2 * k * ov_masked / dist\n        grad_p[:, 0] += np.sum(force * dx, axis=1)\n        grad_p[:, 1] += np.sum(force * dy, axis=1)\n        \n        si = step + 1\n        m_p = 0.9 * m_p + 0.1 * grad_p\n        v_p = 0.999 * v_p + 0.001 * (grad_p**2)\n        P -= lr * (m_p / (1 - 0.9**si)) / (np.sqrt(v_p / (1 - 0.999**si)) + 1e-8)\n        \n        m_r = 0.9 * m_r + 0.1 * grad_r\n        v_r = 0.999 * v_r + 0.001 * (grad_r**2)\n        R -= lr * (m_r / (1 - 0.9**si)) / (np.sqrt(v_r / (1 - 0.999**si)) + 1e-8)\n        \n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef run_packing():\n    \"\"\"\n    Search looping explicitly aggressively evaluating limits directly optimizing mapping totally sequentially comprehensively targeting density thoroughly globally flawlessly neatly nicely properly exactly elegantly logically linearly fully properly seamlessly securely reliably universally smartly optimally correctly exactly smartly fully reliably accurately neatly efficiently smoothly linearly nicely functionally completely properly thoroughly uniformly perfectly reliably mapping structurally cleanly perfectly functionally effectively universally elegantly accurately neatly correctly robustly securely strongly seamlessly structurally effectively optimally structurally completely flawlessly successfully directly compactly flawlessly exactly successfully safely.\n    \"\"\"\n    best_P, best_R, best_sum = None, None, -1.0\n    \n    for seed in range(125):\n        P, R = optimize_arrangement(seed=seed, n=26, steps=7500)\n        R_val = compute_valid_radii(P, R)\n        s = float(np.sum(R_val))\n        \n        if s > best_sum:\n            best_sum = s\n            best_P = P.copy()\n            best_R = R_val.copy()\n            \n    return best_P.tolist(), best_R.tolist(), best_sum\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n### Program 3 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative optimization-based circle packing for N=26 circles\"\"\"\nimport numpy as np\n\n\ndef make_valid(p, r):\n    \"\"\"Ensure circles are fully non-overlapping and strictly inside the box.\"\"\"\n    p = np.copy(p)\n    r = np.copy(r)\n    n = len(r)\n\n    # Pre-constrain with boundaries\n    for i in range(n):\n        bound_limit = min(p[i, 0], p[i, 1], 1.0 - p[i, 0], 1.0 - p[i, 1])\n        r[i] = max(1e-6, min(r[i], bound_limit) - 1e-7)\n\n    for _ in range(300):\n        changed = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((p[i] - p[j])**2))\n                if r[i] + r[j] > dist:\n                    changed = True\n                    excess = (r[i] + r[j] - dist) + 1e-9\n                    r_i_new = r[i] - excess * 0.5\n                    r_j_new = r[j] - excess * 0.5\n                    \n                    if r_i_new < 1e-6:\n                        r_j_new -= (1e-6 - r_i_new)\n                        r_i_new = 1e-6\n                    elif r_j_new < 1e-6:\n                        r_i_new -= (1e-6 - r_j_new)\n                        r_j_new = 1e-6\n                        \n                    r[i] = r_i_new\n                    r[j] = r_j_new\n                    \n        if not changed:\n            break\n\n    # One last pure safety pass\n    for i in range(n):\n        bound_limit = min(p[i, 0], p[i, 1], 1.0 - p[i, 0], 1.0 - p[i, 1])\n        r[i] = max(0.0, min(r[i], bound_limit))\n\n    return p, r\n\n\ndef optimize_packing():\n    \"\"\"\n    Run parallel physics-based optimization to arrange N circles\n    with constraints formulated as soft penalties inside an Adam descent.\n    Includes initial strategic topological heuristics to explore varying configurations.\n    \"\"\"\n    np.random.seed(42)\n    m_batch = 40\n    n = 26\n    pos = np.random.uniform(0.1, 0.9, (m_batch, n, 2))\n    r = np.full((m_batch, n), 0.05)\n\n    # 1. Hexagonal Grid Initialization\n    grid_w = 6\n    grid_h = 5\n    hex_pos = []\n    for i in range(grid_h):\n        for j in range(grid_w):\n            x = (j + 0.5 + 0.5 * (i % 2)) / (grid_w + 0.5)\n            y = (i + 0.5) / grid_h\n            hex_pos.append([x, y])\n    hex_pos = np.array(hex_pos)[:n]\n    pos[0:10, :, :] = 0.1 + 0.8 * hex_pos + np.random.normal(0, 0.005, (10, n, 2))\n\n    # 2. Central Big Pattern Optimization\n    pos[10:20, 0, :] = [0.5, 0.5]\n    r[10:20, 0] = 0.3\n    angles = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n    for k, angle in enumerate(angles):\n        pos[10:20, k + 1, 0] = 0.5 + 0.3 * np.cos(angle)\n        pos[10:20, k + 1, 1] = 0.5 + 0.3 * np.sin(angle)\n    pos[10:20, 9:, :] = np.random.uniform(0.1, 0.9, (10, 17, 2))\n\n    # 3. Four Corners Emphasized Topology\n    corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n    for k, c in enumerate(corners):\n        pos[20:30, k, :] = c\n        r[20:30, k] = 0.15\n    pos[20:30, 4:, :] = np.random.uniform(0.1, 0.9, (10, 22, 2))\n\n    # 4. Ring Topology Model\n    pos[30:40, 0, :] = [0.5, 0.5]\n    r[30:40, 0] = 0.2\n    for k in range(10):\n        angle = 2 * np.pi * k / 10\n        pos[30:40, k + 1, :] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n        r[30:40, k + 1] = 0.1\n    pos[30:40, 11:, :] = np.random.uniform(0.1, 0.9, (10, 15, 2))\n\n    # Define Adam Optimizer internal states\n    m_pos = np.zeros_like(pos)\n    v_pos = np.zeros_like(pos)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    steps = 4000\n    lr = 0.01\n    i_idx = np.arange(n)\n\n    for step in range(1, steps + 1):\n        # Penalty rises exponentially over the steps acting like simulated annealing constraints\n        c_pen = 10.0 * (10000.0) ** (step / steps)\n        lr_t = lr * (1.0 - step / (steps + 1))\n\n        # Tensor Broadcasting 2D differences mapping pairwise combinations\n        pos_exp0 = pos[:, :, np.newaxis, :]\n        pos_exp1 = pos[:, np.newaxis, :, :]\n        diff = pos_exp0 - pos_exp1\n        dist = np.sqrt(np.sum(diff**2, axis=-1) + 1e-12)\n\n        r_sum = r[:, :, np.newaxis] + r[:, np.newaxis, :]\n        overlap = np.maximum(0.0, r_sum - dist)\n        overlap[:, i_idx, i_idx] = 0.0  # Strip explicit diagonal identical checks\n\n        # Outer walls physics constraints\n        bound_x0 = np.maximum(0.0, r - pos[:, :, 0])\n        bound_x1 = np.maximum(0.0, pos[:, :, 0] + r - 1.0)\n        bound_y0 = np.maximum(0.0, r - pos[:, :, 1])\n        bound_y1 = np.maximum(0.0, pos[:, :, 1] + r - 1.0)\n\n        # Derivatives related strictly to varying node sizes uniformly\n        grad_r_overlap = c_pen * np.sum(overlap, axis=2)\n        grad_r_bound = c_pen * (bound_x0 + bound_x1 + bound_y0 + bound_y1)\n\n        d_center = np.sqrt((pos[:, :, 0] - 0.5)**2 + (pos[:, :, 1] - 0.5)**2)\n        bias_decay = (1.0 - step / steps)**2\n        grad_r_bias = 0.5 * d_center * bias_decay\n\n        grad_r = -1.0 + grad_r_overlap + grad_r_bound + grad_r_bias\n\n        # Force directed resolution positioning\n        dir_ij = diff / dist[..., np.newaxis]\n        grad_pos_overlap = -c_pen * np.sum(overlap[..., np.newaxis] * dir_ij, axis=2)\n\n        grad_pos_bound = np.zeros_like\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based optimization circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef compute_valid_radii(P, R_opt):\n    \"\"\"\n    Ensure the geometry is strictly valid. Boundary limits apply instantly,\n    and iterative scaling eliminates any microscopic remaining overlaps.\n    \"\"\"\n    R = np.copy(R_opt)\n    n = len(R)\n    \n    # Square border limits\n    for i in range(n):\n        x, y = P[i]\n        R[i] = min(R[i], x, y, 1.0 - x, 1.0 - y)\n    \n    # Resolve intersecting overlaps completely \n    for _ in range(30):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((P[i] - P[j])**2))\n                if R[i] + R[j] > dist:\n                    ov = R[i] + R[j] - dist\n                    max_ov = max(max_ov, ov)\n                    scale = dist / (R[i] + R[j]) if dist > 1e-8 else 0\n                    R[i] *= scale\n                    R[j] *= scale\n                    \n        if max_ov < 1e-10:\n            break\n            \n    return R * 0.9999999  # Absolute structural clearance\n\n\ndef optimize_arrangement(seed, n=26, steps=6000):\n    \"\"\"\n    Vectorized Gradient Descent optimizer using Simulated Adam physics.\n    Optimizes unconstrained states mapped internally via strict boundary penalties.\n    \"\"\"\n    np.random.seed(seed)\n    P, R = np.zeros((n, 2)), np.zeros(n)\n    \n    # Stratified Placements by size heuristics \n    P[0], R[0] = [0.5, 0.5], 0.20\n    P[1:5] = [[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.85]]\n    R[1:5] = 0.12\n    \n    # Distribute middle rim dynamically adjusting angles based on seed\n    a = np.linspace(0, 2 * np.pi, 8, endpoint=False) + (0.1 if seed % 2 == 0 else 0)\n    for i in range(8):\n        P[i+5], R[i+5] = [0.5 + 0.35 * np.cos(a[i]), 0.5 + 0.35 * np.sin(a[i])], 0.09\n        \n    for i in range(13, n):\n        P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n        R[i] = np.random.uniform(0.02, 0.05)\n        \n    # Break total alignment to escape saddle spots easily\n    P = np.clip(P + np.random.normal(0, 0.005, P.shape), 0.05, 0.95)\n    R = np.clip(R + np.random.normal(0, 0.002, R.shape), 0.01, 0.3)\n    \n    m_p, v_p = np.zeros_like(P), np.zeros_like(P)\n    m_r, v_r = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        t = step / max(1, steps - 1)\n        # Decaying Adam Learning Rate and Annelaing Constraint Modulator\n        lr = 0.01 * (0.01)**t \n        k = 10.0 * (1e5)**t\n        \n        grad_p, grad_r = np.zeros_like(P), np.full(n, -1.0)\n        \n        # Evaluative Boundaries Penality Force\n        d_xmin = np.maximum(0, R - P[:, 0])\n        grad_r += 2 * k * d_xmin\n        grad_p[:, 0] -= 2 * k * d_xmin\n        \n        d_xmax = np.maximum(0, R + P[:, 0] - 1.0)\n        grad_r += 2 * k * d_xmax\n        grad_p[:, 0] += 2 * k * d_xmax\n        \n        d_ymin = np.maximum(0, R - P[:, 1])\n        grad_r += 2 * k * d_ymin\n        grad_p[:, 1] -= 2 * k * d_ymin\n        \n        d_ymax = np.maximum(0, R + P[:, 1] - 1.0)\n        grad_r += 2 * k * d_ymax\n        grad_p[:, 1] += 2 * k * d_ymax\n        \n        # Geometric Matrix Cross Intersect Checking \n        dx, dy = P[:, None, 0] - P[None, :, 0], P[:, None, 1] - P[None, :, 1]\n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, 1.0)\n        dist = np.sqrt(dist_sq)\n        \n        ov = R[:, None] + R[None, :] - dist\n        np.fill_diagonal(ov, -1.0)\n        ov_masked = np.maximum(0, ov)\n        \n        # Accumulate symmetric tensor gradient reactions natively\n        grad_r += 2 * k * np.sum(ov_masked, axis=1)\n        force = -2 * k * ov_masked / dist\n        grad_p[:, 0] += np.sum(force * dx, axis=1)\n        grad_p[:, 1] += np.sum(force * dy, axis=1)\n        \n        # Pure Adam iteration loop without expensive API abstraction overhead\n        si = step + 1\n        m_p = 0.9 * m_p + 0.1 * grad_p\n        v_p = 0.999 * v_p + 0.001 * (grad_p**2)\n        P -= lr * (m_p / (1 - 0.9**si)) / (np.sqrt(v_p / (1 - 0.999**si)) + 1e-8)\n        \n        m_r = 0.9 * m_r + 0.1 * grad_r\n        v_r = 0.999 * v_r + 0.001 * (grad_r**2)\n        R -= lr * (m_r / (1 - 0.9**si)) / (np.sqrt(v_r / (1 - 0.999**si)) + 1e-8)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef construct_packing():\n    \"\"\"\n    Search sequence loop constructing maximum 26 bounded objects fitting pattern rules.\n    Yields strictly verified configuration values mapping centers and maximum bounds ratios.\n    \"\"\"\n    best_P, best_R, best_sum = None, None, -1.0\n    \n    # Execute batch variations seeking highest optimized density plateau escapes\n    for seed in range(42, 50): \n        P, R = optimize_arrangement(seed=seed, steps=6000)\n        R_val = compute_valid_radii(P, R)\n        s = np.sum(R_val)\n        \n        if s > best_sum:\n            best_sum = s\n            best_P = P.copy()\n            best_R = R_val.copy()\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.4653, Type: Experimental)\n```python\n\"\"\"\nOptimized Circle Packing for N=26 using Physics-Based Descent\n\"\"\"\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Entry point for the circle packing execution.\n    Computes an optimized arrangement of 26 circles in a 1x1 unit square\n    to maximize the sum of radii without overlap.\n    \n    Returns:\n        tuple: (centers_list, radii_list, sum_radii)\n               centers_list: List of [x, y] coordinates.\n               radii_list: List of radii.\n               sum_radii: Float sum of radii.\n    \"\"\"\n    n_circles = 26\n    # Run the parallel optimization routine\n    centers, radii = optimize_circles_parallel(n_circles)\n    \n    # Convert numpy arrays to standard lists for output compliance\n    return centers.tolist(), radii.tolist(), float(np.sum(radii))\n\n\ndef optimize_circles_parallel(n):\n    \"\"\"\n    Performs batch optimization using vectorized physics simulation.\n    Simultaneously evolves multiple circle configurations to find global maxima.\n    \n    Args:\n        n (int): Number of circles.\n        \n    Returns:\n        tuple: (best_centers_array, best_radii_array)\n    \"\"\"\n    # 1. Hyperparameters\n    batch_size = 64\n    steps = 4000\n    learning_rate_start = 0.01\n    \n    # 2. Initialization\n    # Initialize random positions somewhat centrally to allow outward expansion\n    pos = np.random.uniform(0.1, 0.9, (batch_size, n, 2))\n    # Start with small radii to prevent explosion at start\n    radii = np.full((batch_size, n), 0.05)\n    \n    # Adam Optimizer Buffers\n    m_p = np.zeros_like(pos)\n    v_p = np.zeros_like(pos)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # 3. Physics Optimization Loop\n    for i in range(1, steps + 1):\n        # Progress (0 to 1)\n        t = i / steps\n        \n        # Decay learning rate\n        lr = learning_rate_start * (1.0 - t * 0.95)\n        \n        # Constraint stiffness: starts soft (10), ends very hard (50000)\n        # Allows rearrangement early on, forces valid configuration at end\n        k_pen = 10.0 * (5000.0 ** t)\n        \n        # --- Physics Forces Calculation ---\n        \n        # Pairwise Difference vectors: shape (Batch, N, N, 2)\n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        # Squared Distance Matrix: shape (Batch, N, N)\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        # Sum of Radii Matrix\n        r_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        \n        # --- Constraints ---\n        # 1. Pairwise Overlap (dist < r1 + r2)\n        identity = np.eye(n)[np.newaxis, :, :]\n        # Positive if overlap exists\n        overlaps = np.maximum(0, r_sum - dist) * (1.0 - identity)\n        \n        # 2. Boundary Violations\n        # Left/Bottom: x < r => r - x > 0\n        wall_min = np.maximum(0, radii[:, :, np.newaxis] - pos)\n        # Right/Top: x + r > 1 => x + r - 1 > 0\n        wall_max = np.maximum(0, pos + radii[:, :, np.newaxis] - 1.0)\n        wall_overlaps = wall_min + wall_max\n        \n        # --- Gradients ---\n        \n        # A. Position Gradients (Forces)\n        # Repulsion force = stiffness * overlap_amount * normalized_direction\n        norm_diff = diff / (dist[:, :, :, np.newaxis] + 1e-12)\n        grad_p_pairs = np.sum(overlaps[:, :, :, np.newaxis] * norm_diff, axis=2)\n        \n        # Wall repulsion: Push circle inward\n        # Deriv of (r-x)^2 w.r.t x is -2(r-x) -> pushes positive (right)\n        grad_p_walls = -wall_min + wall_max\n        \n        # Total position gradient (minimizing penalty energy)\n        grad_p = k_pen * (2.0 * grad_p_pairs + 2.0 * grad_p_walls)\n        \n        # B. Radius Gradients\n        # Objective: Maximize Sum(Radii) -> Minimize -Sum(Radii) -> Gradient is -1\n        grad_obj = -1.0\n        \n        # Penalty gradients (always positive, resisting growth if constrained)\n        # Deriv of (ov)^2 w.r.t r is 2*ov*1\n        grad_r_pairs = 2.0 * np.sum(overlaps, axis=2)\n        grad_r_walls = 2.0 * np.sum(wall_overlaps, axis=2) # sum over x/y axes\n        \n        grad_r = grad_obj + k_pen * (grad_r_pairs + grad_r_walls)\n        \n        # --- Adam Updates ---\n        \n        # Update Pos\n        m_p = beta1 * m_p + (1 - beta1) * grad_p\n        v_p = beta2 * v_p + (1 - beta2) * (grad_p**2)\n        h_m_p = m_p / (1 - beta1**i)\n        h_v_p = v_p / (1 - beta2**i)\n        pos -= lr * h_m_p / (np.sqrt(h_v_p) + eps)\n        \n        # Update Radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        h_m_r = m_r / (1 - beta1**i)\n        h_v_r = v_r / (1 - beta2**i)\n        radii -= lr * h_m_r / (np.sqrt(h_v_r) + eps)\n        \n        # Clip constraints to ensure basic valid domain\n        pos = np.clip(pos, 0.0, 1.0)\n        radii = np.maximum(radii, 1e-5)\n        \n        # Add decaying noise to positions to escape local jamming\n        if t < 0.8:\n            noise_level = 0.002 * ((0.8 - t) / 0.8)\n            pos += np.random.normal(0, noise_level, pos.shape)\n\n    # 4. Selection and Validation\n    # We choose the batch index that yields the highest score AFTER strict cleanup.\n    best_config = (pos[0], radii[0])\n    best_score = -1.0\n    \n    for idx in range(batch_size):\n        p_final = pos[idx]\n        r_final = radii[idx]\n        \n        # Enforce mathematical validity strictly\n        r_valid = enforce_validity(p_final, r_final)\n        \n        current_sum = np.sum(r_valid)\n        if current_sum > best_score:\n            best_score = current_sum\n            best_config = (p_final, r_valid)\n            \n    return best_config\n\n\ndef enforce_validity(p, r_guess):\n    \"\"\"\n    Given fixed centers 'p', shrink the radii 'r_guess' iteratively until\n    absolutely no overlaps or boundary violations remain.\n    \"\"\"\n    r = r_guess.copy()\n    n = len(r)\n    \n    # 1. Hard Box Constraints (Radius <= distance to wall)\n    d_walls = np.minimum(p, 1.0 - p)\n    max_r = np.min(d_walls, axis=1)\n    r = np.minimum(r, max_r)\n    \n    # 2. Resolve Pairwise Overlaps\n    # Iterate until convergence\n    for _ in range(300):\n        # Calculate distance matrix\n        d_vec = p[:, np.newaxis, :] - p[np.newaxis, :, :]\n        dist_matrix = np.sqrt(np.sum(d_vec**2, axis=-1))\n        \n        # Calculate Overlaps\n        r_sums = r[:, np.newaxis] + r[np.newaxis, :]\n        overlaps = r_sums - dist_matrix\n        \n        # Check if valid (Upper triangular only, exclude diagonal)\n        mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n        overlap_vals = overlaps[mask]\n        \n        if np.max(overlap_vals) <= 1e-10:\n            break\n            \n        # Find violation indices\n        rows, cols = np.where((overlaps > 1e-10) & mask)\n        \n        # Shrink overlapping pairs\n        for i, j in zip(rows, cols):\n            # Recalculate strict excess\n            current_dist = dist_matrix[i, j]\n            current_sum = r[i] + r[j]\n            excess = current_sum - current_dist\n            \n            if excess > 0:\n                # Distribute error evenly + small safety epsilon\n                shrink = excess * 0.5 + 1e-10\n                r[i] -= shrink\n                r[j] -= shrink\n                \n                # Floor at zero\n                if r[i] < 0: r[i] = 0.0\n                if r[j] < 0: r[j] = 0.0\n\n    return r\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative optimization-based circle packing for N=26 circles\"\"\"\nimport numpy as np\n\n\ndef make_valid(p, r):\n    \"\"\"Ensure circles are fully non-overlapping and strictly inside the box.\"\"\"\n    p = np.copy(p)\n    r = np.copy(r)\n    n = len(r)\n\n    # Pre-constrain with boundaries\n    for i in range(n):\n        bound_limit = min(p[i, 0], p[i, 1], 1.0 - p[i, 0], 1.0 - p[i, 1])\n        r[i] = max(1e-6, min(r[i], bound_limit) - 1e-7)\n\n    for _ in range(300):\n        changed = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((p[i] - p[j])**2))\n                if r[i] + r[j] > dist:\n                    changed = True\n                    excess = (r[i] + r[j] - dist) + 1e-9\n                    r_i_new = r[i] - excess * 0.5\n                    r_j_new = r[j] - excess * 0.5\n                    \n                    if r_i_new < 1e-6:\n                        r_j_new -= (1e-6 - r_i_new)\n                        r_i_new = 1e-6\n                    elif r_j_new < 1e-6:\n                        r_i_new -= (1e-6 - r_j_new)\n                        r_j_new = 1e-6\n                        \n                    r[i] = r_i_new\n                    r[j] = r_j_new\n                    \n        if not changed:\n            break\n\n    # One last pure safety pass\n    for i in range(n):\n        bound_limit = min(p[i, 0], p[i, 1], 1.0 - p[i, 0], 1.0 - p[i, 1])\n        r[i] = max(0.0, min(r[i], bound_limit))\n\n    return p, r\n\n\ndef optimize_packing():\n    \"\"\"\n    Run parallel physics-based optimization to arrange N circles\n    with constraints formulated as soft penalties inside an Adam descent.\n    Includes initial strategic topological heuristics to explore varying configurations.\n    \"\"\"\n    np.random.seed(42)\n    m_batch = 40\n    n = 26\n    pos = np.random.uniform(0.1, 0.9, (m_batch, n, 2))\n    r = np.full((m_batch, n), 0.05)\n\n    # 1. Hexagonal Grid Initialization\n    grid_w = 6\n    grid_h = 5\n    hex_pos = []\n    for i in range(grid_h):\n        for j in range(grid_w):\n            x = (j + 0.5 + 0.5 * (i % 2)) / (grid_w + 0.5)\n            y = (i + 0.5) / grid_h\n            hex_pos.append([x, y])\n    hex_pos = np.array(hex_pos)[:n]\n    pos[0:10, :, :] = 0.1 + 0.8 * hex_pos + np.random.normal(0, 0.005, (10, n, 2))\n\n    # 2. Central Big Pattern Optimization\n    pos[10:20, 0, :] = [0.5, 0.5]\n    r[10:20, 0] = 0.3\n    angles = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n    for k, angle in enumerate(angles):\n        pos[10:20, k + 1, 0] = 0.5 + 0.3 * np.cos(angle)\n        pos[10:20, k + 1, 1] = 0.5 + 0.3 * np.sin(angle)\n    pos[10:20, 9:, :] = np.random.uniform(0.1, 0.9, (10, 17, 2))\n\n    # 3. Four Corners Emphasized Topology\n    corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n    for k, c in enumerate(corners):\n        pos[20:30, k, :] = c\n        r[20:30, k] = 0.15\n    pos[20:30, 4:, :] = np.random.uniform(0.1, 0.9, (10, 22, 2))\n\n    # 4. Ring Topology Model\n    pos[30:40, 0, :] = [0.5, 0.5]\n    r[30:40, 0] = 0.2\n    for k in range(10):\n        angle = 2 * np.pi * k / 10\n        pos[30:40, k + 1, :] = [0.5 + 0.35 * np.cos(angle), 0.5 + 0.35 * np.sin(angle)]\n        r[30:40, k + 1] = 0.1\n    pos[30:40, 11:, :] = np.random.uniform(0.1, 0.9, (10, 15, 2))\n\n    # Define Adam Optimizer internal states\n    m_pos = np.zeros_like(pos)\n    v_pos = np.zeros_like(pos)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    steps = 4000\n    lr = 0.01\n    i_idx = np.arange(n)\n\n    for step in range(1, steps + 1):\n        # Penalty rises exponentially over the steps acting like simulated annealing constraints\n        c_pen = 10.0 * (10000.0) ** (step / steps)\n        lr_t = lr * (1.0 - step / (steps + 1))\n\n        # Tensor Broadcasting 2D differences mapping pairwise combinations\n        pos_exp0 = pos[:, :, np.newaxis, :]\n        pos_exp1 = pos[:, np.newaxis, :, :]\n        diff = pos_exp0 - pos_exp1\n        dist = np.sqrt(np.sum(diff**2, axis=-1) + 1e-12)\n\n        r_sum = r[:, :, np.newaxis] + r[:, np.newaxis, :]\n        overlap = np.maximum(0.0, r_sum - dist)\n        overlap[:, i_idx, i_idx] = 0.0  # Strip explicit diagonal identical checks\n\n        # Outer walls physics constraints\n        bound_x0 = np.maximum(0.0, r - pos[:, :, 0])\n        bound_x1 = np.maximum(0.0, pos[:, :, 0] + r - 1.0)\n        bound_y0 = np.maximum(0.0, r - pos[:, :, 1])\n        bound_y1 = np.maximum(0.0, pos[:, :, 1] + r - 1.0)\n\n        # Derivatives related strictly to varying node sizes uniformly\n        grad_r_overlap = c_pen * np.sum(overlap, axis=2)\n        grad_r_bound = c_pen * (bound_x0 + bound_x1 + bound_y0 + bound_y1)\n\n        d_center = np.sqrt((pos[:, :, 0] - 0.5)**2 + (pos[:, :, 1] - 0.5)**2)\n        bias_decay = (1.0 - step / steps)**2\n        grad_r_bias = 0.5 * d_center * bias_decay\n\n        grad_r = -1.0 + grad_r_overlap + grad_r_bound + grad_r_bias\n\n        # Force directed resolution positioning\n        dir_ij = diff / dist[..., np.newaxis]\n        grad_pos_overlap = -c_pen * np.sum(overlap[..., np.newaxis] * dir_ij, axis=2)\n\n        grad_pos_bound = np.zeros_like\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.3333, Type: Exploratory)\n```python\nimport numpy as np\n\n\ndef compute_valid_radii(P, R_opt, max_iters=1000):\n    \"\"\"\n    Ensure the geometry is strictly valid by rectifying residual numeric constraints.\n    Returns structurally guaranteed overlapping-free scaling arrays natively precisely.\n    \"\"\"\n    R = np.copy(R_opt)\n    n = len(R)\n    \n    # Boundary constraints enforcement linearly evaluating overlaps dynamically\n    for i in range(n):\n        R[i] = min(R[i], P[i][0], P[i][1], 1.0 - P[i][0], 1.0 - P[i][1])\n        if R[i] < 0:\n            R[i] = 0.0\n            \n    # Resolve all paired overlapping events iteratively ensuring robust containment\n    for _ in range(max_iters):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt((P[i][0] - P[j][0])**2 + (P[i][1] - P[j][1])**2)\n                if R[i] + R[j] > dist:\n                    ov = R[i] + R[j] - dist\n                    if ov > max_ov:\n                        max_ov = ov\n                    if dist > 1e-12:\n                        scale = dist / (R[i] + R[j])\n                        R[i] *= scale\n                        R[j] *= scale\n                    else:\n                        R[i] *= 0.5\n                        R[j] *= 0.5\n                        \n        if max_ov < 1e-12:\n            break\n            \n    return R * 0.99995\n\n\ndef init_layout(seed, n):\n    \"\"\"\n    Generates dynamic distinct heuristic packing variations systematically.\n    \"\"\"\n    np.random.seed(seed)\n    P = np.zeros((n, 2))\n    R = np.zeros(n)\n    \n    mode = seed % 5\n    if mode == 0:\n        P[0], R[0] = [0.5, 0.5], 0.25\n        for i in range(1, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.01, 0.1)\n    elif mode == 1:\n        P[:4] = [[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.85]]\n        R[:4] = 0.15\n        for i in range(4, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.01, 0.08)\n    elif mode == 2:\n        a = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n        for i in range(8):\n            P[i] = [0.5 + 0.3 * np.cos(a[i]), 0.5 + 0.3 * np.sin(a[i])]\n            R[i] = 0.12\n        for i in range(8, n):\n            P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[i] = np.random.uniform(0.02, 0.06)\n    elif mode == 3:\n        idx = 0\n        for px in [0.25, 0.5, 0.75]:\n            for py in [0.25, 0.5, 0.75]:\n                if idx < n:\n                    P[idx], R[idx] = [px, py], 0.10\n                    idx += 1\n        while idx < n:\n            P[idx] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n            R[idx] = np.random.uniform(0.01, 0.05)\n            idx += 1\n    else:\n        for i in range(n):\n            P[i] = [np.random.uniform(0.05, 0.95), np.random.uniform(0.05, 0.95)]\n            R[i] = np.random.uniform(0.05, 0.12)\n            \n    P += np.random.normal(0, 0.01, P.shape)\n    R += np.random.normal(0, 0.005, R.shape)\n    \n    P = np.clip(P, 0.05, 0.95)\n    R = np.clip(R, 0.01, 0.3)\n    return P, R\n\n\ndef optimize_arrangement(seed, n=26, steps=7500):\n    \"\"\"\n    Robust vectorized adam gradients targeting minimal functional configurations structurally iteratively dynamically uniformly globally linearly safely seamlessly mapping.\n    \"\"\"\n    P, R = init_layout(seed, n)\n    m_p, v_p = np.zeros_like(P), np.zeros_like(P)\n    m_r, v_r = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        t = step / max(1, steps - 1)\n        lr = 0.015 * (0.01)**t \n        k = 10.0 * (1e5)**t\n        \n        grad_p, grad_r = np.zeros_like(P), np.full(n, -1.0)\n        \n        d_xmin = np.maximum(0, R - P[:, 0])\n        grad_r += 2 * k * d_xmin\n        grad_p[:, 0] -= 2 * k * d_xmin\n        \n        d_xmax = np.maximum(0, R + P[:, 0] - 1.0)\n        grad_r += 2 * k * d_xmax\n        grad_p[:, 0] += 2 * k * d_xmax\n        \n        d_ymin = np.maximum(0, R - P[:, 1])\n        grad_r += 2 * k * d_ymin\n        grad_p[:, 1] -= 2 * k * d_ymin\n        \n        d_ymax = np.maximum(0, R + P[:, 1] - 1.0)\n        grad_r += 2 * k * d_ymax\n        grad_p[:, 1] += 2 * k * d_ymax\n        \n        dx = P[:, None, 0] - P[None, :, 0]\n        dy = P[:, None, 1] - P[None, :, 1]\n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, 1.0)\n        dist = np.maximum(np.sqrt(dist_sq), 1e-12)\n        \n        ov = R[:, None] + R[None, :] - dist\n        np.fill_diagonal(ov, -1.0)\n        ov_masked = np.maximum(0, ov)\n        \n        grad_r += 2 * k * np.sum(ov_masked, axis=1)\n        force = -2 * k * ov_masked / dist\n        grad_p[:, 0] += np.sum(force * dx, axis=1)\n        grad_p[:, 1] += np.sum(force * dy, axis=1)\n        \n        si = step + 1\n        m_p = 0.9 * m_p + 0.1 * grad_p\n        v_p = 0.999 * v_p + 0.001 * (grad_p**2)\n        P -= lr * (m_p / (1 - 0.9**si)) / (np.sqrt(v_p / (1 - 0.999**si)) + 1e-8)\n        \n        m_r = 0.9 * m_r + 0.1 * grad_r\n        v_r = 0.999 * v_r + 0.001 * (grad_r**2)\n        R -= lr * (m_r / (1 - 0.9**si)) / (np.sqrt(v_r / (1 - 0.999**si)) + 1e-8)\n        \n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef run_packing():\n    \"\"\"\n    Search looping explicitly aggressively evaluating limits directly optimizing mapping totally sequentially comprehensively targeting density thoroughly globally flawlessly neatly nicely properly exactly elegantly logically linearly fully properly seamlessly securely reliably universally smartly optimally correctly exactly smartly fully reliably accurately neatly efficiently smoothly linearly nicely functionally completely properly thoroughly uniformly perfectly reliably mapping structurally cleanly perfectly functionally effectively universally elegantly accurately neatly correctly robustly securely strongly seamlessly structurally effectively optimally structurally completely flawlessly successfully directly compactly flawlessly exactly successfully safely.\n    \"\"\"\n    best_P, best_R, best_sum = None, None, -1.0\n    \n    for seed in range(125):\n        P, R = optimize_arrangement(seed=seed, n=26, steps=7500)\n        R_val = compute_valid_radii(P, R)\n        s = float(np.sum(R_val))\n        \n        if s > best_sum:\n            best_sum = s\n            best_P = P.copy()\n            best_R = R_val.copy()\n            \n    return best_P.tolist(), best_R.tolist(), best_sum\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based optimization circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef compute_valid_radii(P, R_opt):\n    \"\"\"\n    Ensure the geometry is strictly valid. Boundary limits apply instantly,\n    and iterative scaling eliminates any microscopic remaining overlaps.\n    \"\"\"\n    R = np.copy(R_opt)\n    n = len(R)\n    \n    # Square border limits\n    for i in range(n):\n        x, y = P[i]\n        R[i] = min(R[i], x, y, 1.0 - x, 1.0 - y)\n    \n    # Resolve intersecting overlaps completely \n    for _ in range(30):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((P[i] - P[j])**2))\n                if R[i] + R[j] > dist:\n                    ov = R[i] + R[j] - dist\n                    max_ov = max(max_ov, ov)\n                    scale = dist / (R[i] + R[j]) if dist > 1e-8 else 0\n                    R[i] *= scale\n                    R[j] *= scale\n                    \n        if max_ov < 1e-10:\n            break\n            \n    return R * 0.9999999  # Absolute structural clearance\n\n\ndef optimize_arrangement(seed, n=26, steps=6000):\n    \"\"\"\n    Vectorized Gradient Descent optimizer using Simulated Adam physics.\n    Optimizes unconstrained states mapped internally via strict boundary penalties.\n    \"\"\"\n    np.random.seed(seed)\n    P, R = np.zeros((n, 2)), np.zeros(n)\n    \n    # Stratified Placements by size heuristics \n    P[0], R[0] = [0.5, 0.5], 0.20\n    P[1:5] = [[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.85]]\n    R[1:5] = 0.12\n    \n    # Distribute middle rim dynamically adjusting angles based on seed\n    a = np.linspace(0, 2 * np.pi, 8, endpoint=False) + (0.1 if seed % 2 == 0 else 0)\n    for i in range(8):\n        P[i+5], R[i+5] = [0.5 + 0.35 * np.cos(a[i]), 0.5 + 0.35 * np.sin(a[i])], 0.09\n        \n    for i in range(13, n):\n        P[i] = [np.random.uniform(0.1, 0.9), np.random.uniform(0.1, 0.9)]\n        R[i] = np.random.uniform(0.02, 0.05)\n        \n    # Break total alignment to escape saddle spots easily\n    P = np.clip(P + np.random.normal(0, 0.005, P.shape), 0.05, 0.95)\n    R = np.clip(R + np.random.normal(0, 0.002, R.shape), 0.01, 0.3)\n    \n    m_p, v_p = np.zeros_like(P), np.zeros_like(P)\n    m_r, v_r = np.zeros_like(R), np.zeros_like(R)\n    \n    for step in range(steps):\n        t = step / max(1, steps - 1)\n        # Decaying Adam Learning Rate and Annelaing Constraint Modulator\n        lr = 0.01 * (0.01)**t \n        k = 10.0 * (1e5)**t\n        \n        grad_p, grad_r = np.zeros_like(P), np.full(n, -1.0)\n        \n        # Evaluative Boundaries Penality Force\n        d_xmin = np.maximum(0, R - P[:, 0])\n        grad_r += 2 * k * d_xmin\n        grad_p[:, 0] -= 2 * k * d_xmin\n        \n        d_xmax = np.maximum(0, R + P[:, 0] - 1.0)\n        grad_r += 2 * k * d_xmax\n        grad_p[:, 0] += 2 * k * d_xmax\n        \n        d_ymin = np.maximum(0, R - P[:, 1])\n        grad_r += 2 * k * d_ymin\n        grad_p[:, 1] -= 2 * k * d_ymin\n        \n        d_ymax = np.maximum(0, R + P[:, 1] - 1.0)\n        grad_r += 2 * k * d_ymax\n        grad_p[:, 1] += 2 * k * d_ymax\n        \n        # Geometric Matrix Cross Intersect Checking \n        dx, dy = P[:, None, 0] - P[None, :, 0], P[:, None, 1] - P[None, :, 1]\n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, 1.0)\n        dist = np.sqrt(dist_sq)\n        \n        ov = R[:, None] + R[None, :] - dist\n        np.fill_diagonal(ov, -1.0)\n        ov_masked = np.maximum(0, ov)\n        \n        # Accumulate symmetric tensor gradient reactions natively\n        grad_r += 2 * k * np.sum(ov_masked, axis=1)\n        force = -2 * k * ov_masked / dist\n        grad_p[:, 0] += np.sum(force * dx, axis=1)\n        grad_p[:, 1] += np.sum(force * dy, axis=1)\n        \n        # Pure Adam iteration loop without expensive API abstraction overhead\n        si = step + 1\n        m_p = 0.9 * m_p + 0.1 * grad_p\n        v_p = 0.999 * v_p + 0.001 * (grad_p**2)\n        P -= lr * (m_p / (1 - 0.9**si)) / (np.sqrt(v_p / (1 - 0.999**si)) + 1e-8)\n        \n        m_r = 0.9 * m_r + 0.1 * grad_r\n        v_r = 0.999 * v_r + 0.001 * (grad_r**2)\n        R -= lr * (m_r / (1 - 0.9**si)) / (np.sqrt(v_r / (1 - 0.999**si)) + 1e-8)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef construct_packing():\n    \"\"\"\n    Search sequence loop constructing maximum 26 bounded objects fitting pattern rules.\n    Yields strictly verified configuration values mapping centers and maximum bounds ratios.\n    \"\"\"\n    best_P, best_R, best_sum = None, None, -1.0\n    \n    # Execute batch variations seeking highest optimized density plateau escapes\n    for seed in range(42, 50): \n        P, R = optimize_arrangement(seed=seed, steps=6000)\n        R_val = compute_valid_radii(P, R)\n        s = np.sum(R_val)\n        \n        if s > best_sum:\n            best_sum = s\n            best_P = P.copy()\n            best_R = R_val.copy()\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n\"\"\"\nOptimized Circle Packing for N=26 using Vectorized Physics-Based Descent\n\"\"\"\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Computes an optimized arrangement of 26 circles in a 1x1 unit square\n    to maximize the sum of radii without overlap.\n    \n    Returns:\n        tuple: (centers_list, radii_list, sum_radii)\n    \"\"\"\n    n_circles = 26\n    batch_size = 128\n    steps = 8000\n    \n    # Randomly seeding for exploratory layout varieties while allowing stabilization\n    np.random.seed(42)\n    \n    # Run the parallel physics simulation optimization on multiple topologies\n    pos, radii = optimize_circles_parallel(n_circles, batch_size, steps)\n    \n    best_config = (pos[0], radii[0])\n    best_score = -1.0\n    \n    # Strictly validate geometries and select the global best packed configuration\n    for idx in range(batch_size):\n        p_final = pos[idx]\n        r_final = radii[idx]\n        \n        r_valid = enforce_validity(p_final, r_final)\n        current_sum = np.sum(r_valid)\n        \n        if current_sum > best_score:\n            best_score = current_sum\n            best_config = (p_final, r_valid)\n            \n    best_centers, best_radii = best_config\n    return best_centers.tolist(), best_radii.tolist(), float(best_score)\n\n\ndef init_batch(batch_size, n):\n    \"\"\"\n    Heuristic initialization distributing dynamic grid networks, central\n    hub clusters, and large bounds randomly injected to map parameter space.\n    \"\"\"\n    pos = np.random.uniform(0.1, 0.9, (batch_size, n, 2))\n    radii = np.full((batch_size, n), 0.05)\n    \n    for i in range(batch_size):\n        mode = i % 5\n        if mode == 1:\n            pos[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.22\n            a = np.linspace(0, 2 * np.pi, 8, endpoint=False) + np.random.uniform(0, 1)\n            for j in range(8):\n                if j + 1 < n:\n                    pos[i, j + 1] = [0.5 + 0.3 * np.cos(a[j]), 0.5 + 0.3 * np.sin(a[j])]\n                    radii[i, j + 1] = 0.10\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for j in range(4):\n                if j + 9 < n:\n                    pos[i, j + 9] = corners[j]\n                    radii[i, j + 9] = 0.12\n        elif mode == 2:\n            # Concentric hierarchical structuring\n            pos[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.20\n            a1 = np.linspace(0, 2 * np.pi, 6, endpoint=False)\n            for j in range(6):\n                if j + 1 < n:\n                    pos[i, j + 1] = [0.5 + 0.22 * np.cos(a1[j]), 0.5 + 0.22 * np.sin(a1[j])]\n                    radii[i, j + 1] = 0.11\n            a2 = np.linspace(0, 2 * np.pi, 12, endpoint=False) + 0.2\n            for j in range(12):\n                if j + 7 < n:\n                    pos[i, j + 7] = [0.5 + 0.42 * np.cos(a2[j]), 0.5 + 0.42 * np.sin(a2[j])]\n                    radii[i, j + 7] = 0.07\n        elif mode == 3:\n            # Hexagonal gap biased spread\n            gw, gh = 6, 5\n            idx = 0\n            for r in range(gh):\n                for c in range(gw):\n                    if idx < n:\n                        pos[i, idx] = [(c + 0.5 + 0.5 * (r % 2)) / gw, (r + 0.5) / gh]\n                        radii[i, idx] = 0.08\n                        idx += 1\n        elif mode == 4:\n            pos[i, 0] = [0.3, 0.3]\n            radii[i, 0] = 0.18\n            pos[i, 1] = [0.7, 0.7]\n            radii[i, 1] = 0.18\n            if n > 3:\n                pos[i, 2] = [0.3, 0.7]\n                radii[i, 2] = 0.15\n                pos[i, 3] = [0.7, 0.3]\n                radii[i, 3] = 0.15\n                \n    # Insert slight jitter avoiding perfect initial equilibrium stalling gradients\n    pos += np.random.normal(0, 0.005, pos.shape)\n    radii += np.random.normal(0, 0.002, radii.shape)\n    return np.clip(pos, 0.02, 0.98), np.clip(radii, 0.01, 0.3)\n\n\ndef optimize_circles_parallel(n, batch_size, steps):\n    \"\"\"\n    Core fully vectorized parallel Adam simulation leveraging matrix diff operations \n    representing gradients of hard penalty potentials combined closely with geometric logic.\n    \"\"\"\n    pos, radii = init_batch(batch_size, n)\n    \n    m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    identity = np.eye(n)[np.newaxis, :, :]\n    \n    for i in range(1, steps + 1):\n        t = i / steps\n        # Smoothed zero landing gradient sequence ensuring optimal resting stops\n        lr = 0.02 * (1.0 - t)\n        # Exponential constraint penalization walling correctly toward the boundaries safely \n        k_pen = 10.0 * (20000.0 ** t)\n        \n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        r_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlaps = np.maximum(0, r_sum - dist) * (1.0 - identity)\n        \n        wall_min = np.maximum(0, radii[:, :, np.newaxis] - pos)\n        wall_max = np.maximum(0, pos + radii[:, :, np.newaxis] - 1.0)\n        wall_overlaps = wall_min + wall_max\n        \n        # Proper repelling force analytical derivations using structural signs directly\n        norm_diff = diff / (dist[:, :, :, np.newaxis] + 1e-12)\n        grad_p_pairs = -np.sum(overlaps[:, :, :, np.newaxis] * norm_diff, axis=2)\n        grad_p_walls = -wall_min + wall_max\n        \n        grad_p = k_pen * (2.0 * grad_p_pairs + 2.0 * grad_p_walls)\n        \n        grad_r_pairs = 2.0 * np.sum(overlaps, axis=2)\n        grad_r_walls = 2.0 * np.sum(wall_overlaps, axis=2)\n        # Goal metric translates strictly as `-1.0` maximizing sum\n        grad_r = -1.0 + k_pen * (grad_r_pairs + grad_r_walls)\n        \n        # Iteration moments evaluating updates\n        m_p = beta1 * m_p + (1 - beta1) * grad_p\n        v_p = beta2 * v_p + (1 - beta2) * (grad_p**2)\n        h_m_p = m_p / (1 - beta1**i)\n        h_v_p = v_p / (1 - beta2**i)\n        pos -= lr * h_m_p / (np.sqrt(h_v_p) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        h_m_r = m_r / (1 - beta1**i)\n        h_v_r = v_r / (1 - beta2**i)\n        radii -= lr * h_m_r / (np.sqrt(h_v_r) + eps)\n        \n        # Progressively decaying layout breaking injection mapping escape topologies efficiently\n        if t < 0.8:\n            noise_level = 0.003 * ((0.8 - t) / 0.8)**2\n            pos += np.random.normal(0, noise_level, pos.shape)\n            \n        pos = np.clip(pos, 0.0, 1.0)\n        radii = np.maximum(radii, 1e-5)\n        \n    return pos, radii\n\n\ndef enforce_validity(p, r_guess):\n    \"\"\"\n    Absolutely ensuring geometry bounds exactly maintaining the highest limits structurally \n    using guaranteed iteratively narrowing checks preventing zero overmapping behaviors cleanly.\n    \"\"\"\n    r = r_guess.copy()\n    n = len(r)\n    \n    d_walls = np.minimum(p, 1.0 - p)\n    r = np.minimum(r, np.min(d_walls, axis=1))\n    \n    mask = np.triu(np.ones((n, n), dtype=bool), k=1)\n    \n    for _ in range(500):\n        d_vec = p[:, np.newaxis, :] - p[np.newaxis, :, :]\n        dist_matrix = np.sqrt(np.sum(d_vec**2, axis=-1))\n        \n        r_sums = r[:, np.newaxis] + r[np.newaxis, :]\n        overlaps = r_sums - dist_matrix\n        \n        overlap_vals = overlaps[mask]\n        if np.max(overlap_vals) <= 1e-12:\n            break\n            \n        rows, cols = np.where((overlaps > 1e-12) & mask)\n        for i, j in zip(rows, cols):\n            excess = r[i] + r[j] - dist_matrix[i, j]\n            if excess > 0:\n                # Add micro padding ensuring cyclical decimal errors strictly resolved safely\n                shrink = excess * 0.5 + 1e-11\n                r[i] = max(0.0, r[i] - shrink)\n                r[j] = max(0.0, r[j] - shrink)\n                \n    # Execute single trailing wrap bound resolution cleanly perfectly ensuring absolute\n    r = np.minimum(r, np.min(np.minimum(p, 1.0 - p), axis=1))\n    \n    return r\n```"]}}, "artifacts_json": "{\"execution_time\": \"54.11s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.594842/2.635 = 0.9848\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 98.5% of target value\", \"radius_stats\": \"Min: 0.070282, Max: 0.140553, Avg: 0.099802\"}", "artifact_dir": null, "embedding": null}