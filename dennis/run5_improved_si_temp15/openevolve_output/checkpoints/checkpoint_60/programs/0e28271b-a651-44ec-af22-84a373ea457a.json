{"id": "0e28271b-a651-44ec-af22-84a373ea457a", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass AdamOptimizer:\n    \"\"\"A standard Adam optimizer for gradient descent over parameters.\"\"\"\n    def __init__(self, shape_X, shape_R, lr=0.01):\n        self.lr = lr\n        self.m_X = np.zeros(shape_X)\n        self.v_X = np.zeros(shape_X)\n        self.m_R = np.zeros(shape_R)\n        self.v_R = np.zeros(shape_R)\n        self.beta1 = 0.9\n        self.beta2 = 0.999\n        self.eps = 1e-8\n        self.t = 0\n        \n    def step(self, X, R, grad_X, grad_R):\n        self.t += 1\n        \n        self.m_X = self.beta1 * self.m_X + (1 - self.beta1) * grad_X\n        self.v_X = self.beta2 * self.v_X + (1 - self.beta2) * (grad_X**2)\n        m_X_hat = self.m_X / (1 - self.beta1**self.t)\n        v_X_hat = self.v_X / (1 - self.beta2**self.t)\n        X_new = X - self.lr * m_X_hat / (np.sqrt(v_X_hat) + self.eps)\n        \n        self.m_R = self.beta1 * self.m_R + (1 - self.beta1) * grad_R\n        self.v_R = self.beta2 * self.v_R + (1 - self.beta2) * (grad_R**2)\n        m_R_hat = self.m_R / (1 - self.beta1**self.t)\n        v_R_hat = self.v_R / (1 - self.beta2**self.t)\n        R_new = R - self.lr * m_R_hat / (np.sqrt(v_R_hat) + self.eps)\n        \n        return X_new, R_new\n\n\ndef make_valid(X, R):\n    \"\"\"Ensure fully rigid geometric compliance by resolving overlaps, bounding dynamically,\n    and pushing coordinates precisely towards mathematical kissing constraints to inflate bounds.\n    \"\"\"\n    X = np.clip(X, 0.0, 1.0)\n    R = np.clip(R, 0.0, 1.0)\n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    n = len(R)\n    \n    # Resolving intersecting structural bounds loop safely geometrically\n    for _ in range(4000):\n        violation = False\n        dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n        dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, np.inf)\n        \n        sum_R = R.reshape(-1, 1) + R\n        overlap = sum_R - dist\n        if np.max(overlap) > 1e-12:\n            violation = True\n            for i in range(n):\n                for j in range(i + 1, n):\n                    if overlap[i, j] > 1e-12:\n                        scale = dist[i, j] / (R[i] + R[j] + 1e-16)\n                        R[i] *= scale\n                        R[j] *= scale\n        if not violation:\n            break\n            \n    # Iterative aggressive local block-coordinate space nudging & optimization\n    # Expands inner spaces by sliding circles mathematically along multiple constraint interfaces\n    for pass_idx in range(80):\n        order = np.random.permutation(n)\n        expanded = False\n        \n        for i in order:\n            pos = X[i].copy()\n            lr = 0.02 * (0.95 ** pass_idx)\n            best_pos = pos.copy()\n            best_r = R[i]\n            \n            # Active microscopic coordinate drift gradient against closest topological barriers\n            for _ in range(15):\n                dx = pos[0] - X[:, 0]\n                dy = pos[1] - X[:, 1]\n                dists = np.sqrt(dx**2 + dy**2)\n                dists[i] = np.inf\n                \n                m_circ = dists - R\n                m_bnd = np.array([pos[0], 1.0 - pos[0], pos[1], 1.0 - pos[1]])\n                min_m = min(np.min(m_circ), np.min(m_bnd))\n                \n                if min_m > best_r:\n                    best_r = min_m\n                    best_pos = pos.copy()\n                \n                # Temperature based vector formulation directing into deepest space pools safely\n                u_circ_x = dx / (dists + 1e-12)\n                u_circ_y = dy / (dists + 1e-12)\n                \n                w_circ = np.exp(-200.0 * np.maximum(0, m_circ - min_m))\n                w_circ[i] = 0.0\n                \n                fx = np.sum(u_circ_x * w_circ)\n                fy = np.sum(u_circ_y * w_circ)\n                \n                w_bnd = np.exp(-200.0 * np.maximum(0, m_bnd - min_m))\n                fx += w_bnd[0] * 1.0 - w_bnd[1] * 1.0\n                fy += w_bnd[2] * 1.0 - w_bnd[3] * 1.0\n                \n                norm = np.sqrt(fx**2 + fy**2)\n                if norm > 1e-12:\n                    pos[0] += lr * fx / norm\n                    pos[1] += lr * fy / norm\n                    pos = np.clip(pos, 0.0, 1.0)\n                else:\n                    break\n\n            # Confirm and capture safe bounds limits improvements continuously\n            if best_r > R[i] + 1e-9:\n                X[i] = best_pos\n                R[i] = best_r\n                expanded = True\n                \n        if not expanded and pass_idx > 10:\n            break\n            \n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    R = np.maximum(R, 0.0)\n    return X, R\n\n\ndef solve_packing(n=26, iterations=7000, restarts=12, lr_start=0.015):\n    \"\"\"Execute dynamic penalty-scaled Adam physics with targeted varied structured seeds.\"\"\"\n    best_X = None\n    best_R = None\n    best_score = -1\n\n    for restart in range(restarts):\n        np.random.seed(1337 + restart)\n        \n        # Heterogeneous structured parameter placements balancing varied densities intelligently\n        if restart < 3:\n            X = np.random.rand(n, 2) * 0.9 + 0.05\n            R = np.random.rand(n) * 0.05 + 0.01\n            \n        elif restart < 6:\n            X = np.zeros((n, 2))\n            if n > 0: X[0] = [0.5, 0.5]\n            n_inner = min((n - 1) // 3, 8) if n > 1 else 0\n            n_outer = max(0, n - 1 - n_inner)\n            \n            for i in range(n_inner):\n                angle = 2 * np.pi * i / max(1, n_inner) + np.random.randn() * 0.1\n                X[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n            for i in range(n_outer):\n                angle = 2 * np.pi * i / max(1, n_outer) + np.random.randn() * 0.1\n                X[i + 1 + n_inner] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                \n            X = np.clip(X, 0.05, 0.95)\n            R = np.ones(n) * 0.05\n            if n > 0: R[0] = 0.1\n            \n        elif restart < 9:\n            X = np.random.rand(n, 2) * 0.8 + 0.1\n            R = np.random.rand(n) * 0.04 + 0.01\n            max_c = min(n, 4)\n            bases = [[0.2, 0.2], [0.2, 0.8], [0.8, 0.2], [0.8, 0.8]]\n            for i in range(max_c):\n                X[i] = bases[i]\n                R[i] = 0.15\n            if n > 4:\n                X[4] = [0.5, 0.5]\n                R[4] = 0.15\n                \n        else:\n            X = np.random.rand(n, 2)\n            edge_x_mask = np.random.rand(n) > 0.5\n            edge_y_mask = np.random.rand(n) > 0.5\n            X[edge_x_mask, 0] = np.where(np.random.rand(np.sum(edge_x_mask)) > 0.5, 0.05, 0.95)\n            X[edge_y_mask, 1] = np.where(np.random.rand(np.sum(edge_y_mask)) > 0.5, 0.05, 0.95)\n            X = np.clip(X + np.random.randn(n, 2) * 0.02, 0.05, 0.95)\n            R = np.ones(n) * 0.03\n            \n        opt = AdamOptimizer((n, 2), n, lr=lr_start)\n        \n        # Annealing engine parameters safely integrating complex gradient intersections\n        for step in range(iterations):\n            progress = step / iterations\n            opt.lr = lr_start * (1 - progress) ** 2 + 1e-5\n            k = 10 * (100000 ** progress)\n            \n            dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n            dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n            eye = np.eye(n, dtype=bool)\n            \n            dist = np.sqrt(dx**2 + dy**2)\n            dist[eye] = 1.0  \n            safe_dist = np.maximum(dist, 1e-10)\n            \n            dir_x = dx / safe_dist\n            dir_y = dy / safe_dist\n            dist[eye] = np.inf\n            \n            sum_R = R.reshape(-1, 1) + R\n            C_ij = np.maximum(0, sum_R - dist)\n            np.fill_diagonal(C_ij, 0)\n            \n            C_x0 = np.maximum(0, R - X[:, 0])\n            C_x1 = np.maximum(0, R - (1 - X[:, 0]))\n            C_y0 = np.maximum(0, R - X[:, 1])\n            C_y1 = np.maximum(0, R - (1 - X[:, 1]))\n            \n            dR = -np.ones(n) + k * (np.sum(C_ij, axis=1) + C_x0 + C_x1 + C_y0 + C_y1)\n            grad_X_x = k * (-np.sum(C_ij * dir_x, axis=1) - C_x0 + C_x1)\n            grad_X_y = k * (-np.sum(C_ij * dir_y, axis=1) - C_y0 + C_y1)\n            dX = np.column_stack((grad_X_x, grad_X_y))\n            \n            # Injection bounds preventing symmetrically stalled forces mathematically resolving space locks\n            if progress < 0.6:\n                noise_scale = 0.002 * (0.6 - progress)\n                dX += np.random.randn(*dX.shape) * noise_scale\n            \n            X, R = opt.step(X, R, dX, dR)\n            \n            X = np.clip(X, 0.0, 1.0)\n            R = np.clip(R, 0.0, 1.0)\n            \n        # Post evaluate strict limits to bounds ensuring safe returns globally scaling perfectly \n        val_X, val_R = make_valid(X, R)\n        score = np.sum(val_R)\n        \n        if score > best_score:\n            best_score = score\n            best_X = val_X.copy()\n            best_R = val_R.copy()\n            \n    return best_X, best_R, best_score\n\n\ndef construct_packing():\n    \"\"\"Construct highly optimized mathematically tight layouts evaluated inside strictly rigorous boundaries.\"\"\"\n    centers, radii, sum_radii = solve_packing(n=26)\n    return centers, radii, sum_radii\n\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "83886f61-52cc-4fa4-a678-18f637c64535", "generation": 2, "timestamp": 1771902338.440127, "iteration_found": 14, "metrics": {"validity": 1.0, "sum_radii": 2.6331524161544184, "target_ratio": 0.999298829660121, "combined_score": 0.999298829660121, "radius_variance": 0.004920736423024544, "spatial_spread": 0.18567601166702546, "eval_time": 10.272722244262695}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6185123132991954, "target_ratio": 0.9937428133962792, "combined_score": 0.9937428133962792, "radius_variance": 0.005130805948919403, "spatial_spread": 0.19312578712178657, "eval_time": 8.336174011230469}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9937\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.9937\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n8.34s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.618512/2.635 = 0.9937\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.4% of target value\n```\n\n### radius_stats\n```\nMin: 0.058553, Max: 0.131277, Avg: 0.100712\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6185, target_ratio: 0.9937, combined_score: 0.9937, radius_variance: 0.0051, spatial_spread: 0.1931, eval_time: 8.3362\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9937)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass AdamOptimizer:\n    \"\"\"A standard Adam optimizer for gradient descent over parameters.\"\"\"\n    def __init__(self, shape_X, shape_R, lr=0.01):\n        self.lr = lr\n        self.m_X = np.zeros(shape_X)\n        self.v_X = np.zeros(shape_X)\n        self.m_R = np.zeros(shape_R)\n        self.v_R = np.zeros(shape_R)\n        self.beta1 = 0.9\n        self.beta2 = 0.999\n        self.eps = 1e-8\n        self.t = 0\n        \n    def step(self, X, R, grad_X, grad_R):\n        self.t += 1\n        \n        self.m_X = self.beta1 * self.m_X + (1 - self.beta1) * grad_X\n        self.v_X = self.beta2 * self.v_X + (1 - self.beta2) * (grad_X**2)\n        m_X_hat = self.m_X / (1 - self.beta1**self.t)\n        v_X_hat = self.v_X / (1 - self.beta2**self.t)\n        X_new = X - self.lr * m_X_hat / (np.sqrt(v_X_hat) + self.eps)\n        \n        self.m_R = self.beta1 * self.m_R + (1 - self.beta1) * grad_R\n        self.v_R = self.beta2 * self.v_R + (1 - self.beta2) * (grad_R**2)\n        m_R_hat = self.m_R / (1 - self.beta1**self.t)\n        v_R_hat = self.v_R / (1 - self.beta2**self.t)\n        R_new = R - self.lr * m_R_hat / (np.sqrt(v_R_hat) + self.eps)\n        \n        return X_new, R_new\n\n\ndef make_valid(X, R):\n    \"\"\"Ensure fully rigid geometric compliance by safely constraining inside logical boundaries.\"\"\"\n    # Enforce basic constraints\n    X = np.clip(X, 0.0, 1.0)\n    R = np.clip(R, 0.0, 1.0)\n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    n = len(R)\n    \n    # Clean overlapping space optimally with symmetric radius reduction loops\n    for _ in range(2000):\n        violation = False\n        dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n        dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n        dist = np.sqrt(dx**2 + dy**2)\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                if R[i] + R[j] > dist[i, j] + 1e-12:\n                    scale = dist[i, j] / (R[i] + R[j] + 1e-16)\n                    R[i] *= scale\n                    R[j] *= scale\n                    violation = True\n        if not violation:\n            break\n            \n    # Sub-pass aggressive localized radius expansion into micro-residual space\n    for _ in range(25):\n        order = np.random.permutation(n)\n        for i in order:\n            max_r = min(X[i, 0], 1.0 - X[i, 0], X[i, 1], 1.0 - X[i, 1])\n            for j in range(n):\n                if i != j:\n                    d = np.linalg.norm(X[i] - X[j])\n                    max_r = min(max_r, d - R[j])\n            if max_r > R[i]:\n                R[i] = max_r\n                \n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    R = np.maximum(R, 0.0)\n    return X, R\n\n\ndef solve_packing(n=26, iterations=8000, restarts=10, lr_start=0.015):\n    \"\"\"Execute projected constraint minimization using varied seeds iteratively.\"\"\"\n    best_X = None\n    best_R = None\n    best_score = -1\n\n    # Using heterogeneous restarts to discover maximum optimal boundaries without hardcoding topology.\n    for restart in range(restarts):\n        np.random.seed(1337 + restart)\n        \n        # Divergent architectural seeding biases (corners, uniform array mapping, core density clustering)\n        if restart < 2:\n            X = np.random.rand(n, 2) * 0.9 + 0.05\n            R = np.random.rand(n) * 0.05 + 0.01\n        elif restart < 6:\n            X = np.zeros((n, 2))\n            X[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8 + np.random.randn() * 0.1\n                X[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n            for i in range(17):\n                angle = 2 * np.pi * i / 17 + np.random.randn() * 0.1\n                X[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n            X = np.clip(X, 0.05, 0.95)\n            R = np.ones(n) * 0.05\n            R[0] = 0.1\n        else:\n            X = np.random.rand(n, 2)\n            edge_x_mask = np.random.rand(n) > 0.6\n            edge_y_mask = np.random.rand(n) > 0.6\n            X[edge_x_mask, 0] = np.where(np.random.rand(np.sum(edge_x_mask)) > 0.5, 0.05, 0.95)\n            X[edge_y_mask, 1] = np.where(np.random.rand(np.sum(edge_y_mask)) > 0.5, 0.05, 0.95)\n            X = np.clip(X + np.random.randn(n, 2) * 0.01, 0.05, 0.95)\n            R = np.ones(n) * 0.04\n            \n        opt = AdamOptimizer((n, 2), n, lr=lr_start)\n        \n        for step in range(iterations):\n            progress = step / iterations\n            \n            # Simulated annealing physics parameter schedule\n            opt.lr = lr_start * (1 - progress) ** 2 + 1e-5\n            k = 10 * (100000 ** progress)\n            \n            # Intersective topological differentials mapped cleanly\n            dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n            dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n            eye = np.eye(n, dtype=bool)\n            \n            dist = np.sqrt(dx**2 + dy**2)\n            dist[eye] = 1.0  \n            \n            dir_x = dx / dist\n            dir_y = dy / dist\n            dist[eye] = np.inf\n            \n            sum_R = R.reshape(-1, 1) + R\n            C_ij = np.maximum(0, sum_R - dist)\n            np.fill_diagonal(C_ij, 0)\n            \n            C_x0 = np.maximum(0, R - X[:, 0])\n            C_x1 = np.maximum(0, R - (1 - X[:, 0]))\n            C_y0 = np.maximum(0, R - X[:, 1])\n            C_y1 = np.maximum(0, R - (1 - X[:, 1]))\n            \n            # Maximize gradient (-1 scales with iteration expansion bounds via descent engine mechanics)\n            dR = -np.ones(n) + k * (np.sum(C_ij, axis=1) + C_x0 + C_x1 + C_y0 + C_y1)\n            \n            grad_X_x = k * (-np.sum(C_ij * dir_x, axis=1) - C_x0 + C_x1)\n            grad_X_y = k * (-np.sum(C_ij * dir_y, axis=1) - C_y0 + C_y1)\n            dX = np.column_stack((grad_X_x, grad_X_y))\n            \n            if progress < 0.5:\n                noise_scale = 0.001 * (0.5 - progress)\n                dX += np.random.randn(*dX.shape) * noise_scale\n            \n            X, R = opt.step(X, R, dX, dR)\n            \n            X = np.clip(X, 0.0, 1.0)\n            R = np.clip(R, 0.0, 1.0)\n            \n        val_X, val_R = make_valid(X, R)\n        score = np.sum(val_R)\n        \n        # Evaluation metric extraction per model pass framework limitation scope boundaries \n        if score > best_score:\n            best_score = score\n            best_X = val_X.copy()\n            best_R = val_R.copy()\n            \n    return best_X, best_R, best_score\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs the highly optimized mathematically accurate mapping\n    Returns coordinates and specific size metrics safely evaluated inside parameters bounds.\n    \"\"\"\n    centers, radii, sum_radii = solve_packing(n=26)\n    return centers, radii, sum_radii\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6185), Performs well on target_ratio (0.9937), Performs well on combined_score (0.9937), Performs well on radius_variance (0.0051), Performs well on spatial_spread (0.1931), Performs well on eval_time (8.3362)\n\n\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass AdamOptimizer:\n    \"\"\"A standard Adam optimizer for gradient descent over parameters.\"\"\"\n    def __init__(self, shape_X, shape_R, lr=0.01):\n        self.lr = lr\n        self.m_X = np.zeros(shape_X)\n        self.v_X = np.zeros(shape_X)\n        self.m_R = np.zeros(shape_R)\n        self.v_R = np.zeros(shape_R)\n        self.beta1 = 0.9\n        self.beta2 = 0.999\n        self.eps = 1e-8\n        self.t = 0\n        \n    def step(self, X, R, grad_X, grad_R):\n        self.t += 1\n        \n        self.m_X = self.beta1 * self.m_X + (1 - self.beta1) * grad_X\n        self.v_X = self.beta2 * self.v_X + (1 - self.beta2) * (grad_X**2)\n        m_X_hat = self.m_X / (1 - self.beta1**self.t)\n        v_X_hat = self.v_X / (1 - self.beta2**self.t)\n        X_new = X - self.lr * m_X_hat / (np.sqrt(v_X_hat) + self.eps)\n        \n        self.m_R = self.beta1 * self.m_R + (1 - self.beta1) * grad_R\n        self.v_R = self.beta2 * self.v_R + (1 - self.beta2) * (grad_R**2)\n        m_R_hat = self.m_R / (1 - self.beta1**self.t)\n        v_R_hat = self.v_R / (1 - self.beta2**self.t)\n        R_new = R - self.lr * m_R_hat / (np.sqrt(v_R_hat) + self.eps)\n        \n        return X_new, R_new\n\n\ndef make_valid(X, R):\n    \"\"\"Ensure fully rigid geometric compliance by safely constraining inside logical boundaries.\"\"\"\n    # Enforce basic constraints\n    X = np.clip(X, 0.0, 1.0)\n    R = np.clip(R, 0.0, 1.0)\n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    n = len(R)\n    \n    # Clean overlapping space optimally with symmetric radius reduction loops\n    for _ in range(2000):\n        violation = False\n        dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n        dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n        dist = np.sqrt(dx**2 + dy**2)\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                if R[i] + R[j] > dist[i, j] + 1e-12:\n                    scale = dist[i, j] / (R[i] + R[j] + 1e-16)\n                    R[i] *= scale\n                    R[j] *= scale\n                    violation = True\n        if not violation:\n            break\n            \n    # Sub-pass aggressive localized radius expansion into micro-residual space\n    for _ in range(25):\n        order = np.random.permutation(n)\n        for i in order:\n            max_r = min(X[i, 0], 1.0 - X[i, 0], X[i, 1], 1.0 - X[i, 1])\n            for j in range(n):\n                if i != j:\n                    d = np.linalg.norm(X[i] - X[j])\n                    max_r = min(max_r, d - R[j])\n            if max_r > R[i]:\n                R[i] = max_r\n                \n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    R = np.maximum(R, 0.0)\n    return X, R\n\n\ndef solve_packing(n=26, iterations=8000, restarts=10, lr_start=0.015):\n    \"\"\"Execute projected constraint minimization using varied seeds iteratively.\"\"\"\n    best_X = None\n    best_R = None\n    best_score = -1\n\n    # Using heterogeneous restarts to discover maximum optimal boundaries without hardcoding topology.\n    for restart in range(restarts):\n        np.random.seed(1337 + restart)\n        \n        # Divergent architectural seeding biases (corners, uniform array mapping, core density clustering)\n        if restart < 2:\n            X = np.random.rand(n, 2) * 0.9 + 0.05\n            R = np.random.rand(n) * 0.05 + 0.01\n        elif restart < 6:\n            X = np.zeros((n, 2))\n            X[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8 + np.random.randn() * 0.1\n                X[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n            for i in range(17):\n                angle = 2 * np.pi * i / 17 + np.random.randn() * 0.1\n                X[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n            X = np.clip(X, 0.05, 0.95)\n            R = np.ones(n) * 0.05\n            R[0] = 0.1\n        else:\n            X = np.random.rand(n, 2)\n            edge_x_mask = np.random.rand(n) > 0.6\n            edge_y_mask = np.random.rand(n) > 0.6\n            X[edge_x_mask, 0] = np.where(np.random.rand(np.sum(edge_x_mask)) > 0.5, 0.05, 0.95)\n            X[edge_y_mask, 1] = np.where(np.random.rand(np.sum(edge_y_mask)) > 0.5, 0.05, 0.95)\n            X = np.clip(X + np.random.randn(n, 2) * 0.01, 0.05, 0.95)\n            R = np.ones(n) * 0.04\n            \n        opt = AdamOptimizer((n, 2), n, lr=lr_start)\n        \n        for step in range(iterations):\n            progress = step / iterations\n            \n            # Simulated annealing physics parameter schedule\n            opt.lr = lr_start * (1 - progress) ** 2 + 1e-5\n            k = 10 * (100000 ** progress)\n            \n            # Intersective topological differentials mapped cleanly\n            dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n            dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n            eye = np.eye(n, dtype=bool)\n            \n            dist = np.sqrt(dx**2 + dy**2)\n            dist[eye] = 1.0  \n            \n            dir_x = dx / dist\n            dir_y = dy / dist\n            dist[eye] = np.inf\n            \n            sum_R = R.reshape(-1, 1) + R\n            C_ij = np.maximum(0, sum_R - dist)\n            np.fill_diagonal(C_ij, 0)\n            \n            C_x0 = np.maximum(0, R - X[:, 0])\n            C_x1 = np.maximum(0, R - (1 - X[:, 0]))\n            C_y0 = np.maximum(0, R - X[:, 1])\n            C_y1 = np.maximum(0, R - (1 - X[:, 1]))\n            \n            # Maximize gradient (-1 scales with iteration expansion bounds via descent engine mechanics)\n            dR = -np.ones(n) + k * (np.sum(C_ij, axis=1) + C_x0 + C_x1 + C_y0 + C_y1)\n            \n            grad_X_x = k * (-np.sum(C_ij * dir_x, axis=1) - C_x0 + C_x1)\n            grad_X_y = k * (-np.sum(C_ij * dir_y, axis=1) - C_y0 + C_y1)\n            dX = np.column_stack((grad_X_x, grad_X_y))\n            \n            if progress < 0.5:\n                noise_scale = 0.001 * (0.5 - progress)\n                dX += np.random.randn(*dX.shape) * noise_scale\n            \n            X, R = opt.step(X, R, dX, dR)\n            \n            X = np.clip(X, 0.0, 1.0)\n            R = np.clip(R, 0.0, 1.0)\n            \n        val_X, val_R = make_valid(X, R)\n        score = np.sum(val_R)\n        \n        # Evaluation metric extraction per model pass framework limitation scope boundaries \n        if score > best_score:\n            best_score = score\n            best_X = val_X.copy()\n            best_R = val_R.copy()\n            \n    return best_X, best_R, best_score\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs the highly optimized mathematically accurate mapping\n    Returns coordinates and specific size metrics safely evaluated inside parameters bounds.\n    \"\"\"\n    centers, radii, sum_radii = solve_packing(n=26)\n    return centers, radii, sum_radii\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass AdamOptimizer:\n    \"\"\"A standard Adam optimizer for gradient descent over parameters.\"\"\"\n    def __init__(self, shape_X, shape_R, lr=0.01):\n        self.lr = lr\n        self.m_X = np.zeros(shape_X)\n        self.v_X = np.zeros(shape_X)\n        self.m_R = np.zeros(shape_R)\n        self.v_R = np.zeros(shape_R)\n        self.beta1 = 0.9\n        self.beta2 = 0.999\n        self.eps = 1e-8\n        self.t = 0\n        \n    def step(self, X, R, grad_X, grad_R):\n        self.t += 1\n        \n        self.m_X = self.beta1 * self.m_X + (1 - self.beta1) * grad_X\n        self.v_X = self.beta2 * self.v_X + (1 - self.beta2) * (grad_X**2)\n        m_X_hat = self.m_X / (1 - self.beta1**self.t)\n        v_X_hat = self.v_X / (1 - self.beta2**self.t)\n        X_new = X - self.lr * m_X_hat / (np.sqrt(v_X_hat) + self.eps)\n        \n        self.m_R = self.beta1 * self.m_R + (1 - self.beta1) * grad_R\n        self.v_R = self.beta2 * self.v_R + (1 - self.beta2) * (grad_R**2)\n        m_R_hat = self.m_R / (1 - self.beta1**self.t)\n        v_R_hat = self.v_R / (1 - self.beta2**self.t)\n        R_new = R - self.lr * m_R_hat / (np.sqrt(v_R_hat) + self.eps)\n        \n        return X_new, R_new\n\n\ndef make_valid(X, R):\n    \"\"\"Ensure fully rigid geometric compliance by resolving overlaps, bounding dynamically,\n    and pushing coordinates precisely towards mathematical kissing constraints to inflate bounds.\n    \"\"\"\n    X = np.clip(X, 0.0, 1.0)\n    R = np.clip(R, 0.0, 1.0)\n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    n = len(R)\n    \n    # Resolving intersecting structural bounds loop safely geometrically\n    for _ in range(4000):\n        violation = False\n        dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n        dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, np.inf)\n        \n        sum_R = R.reshape(-1, 1) + R\n        overlap = sum_R - dist\n        if np.max(overlap) > 1e-12:\n            violation = True\n            for i in range(n):\n                for j in range(i + 1, n):\n                    if overlap[i, j] > 1e-12:\n                        scale = dist[i, j] / (R[i] + R[j] + 1e-16)\n                        R[i] *= scale\n                        R[j] *= scale\n        if not violation:\n            break\n            \n    # Iterative aggressive local block-coordinate space nudging & optimization\n    # Expands inner spaces by sliding circles mathematically along multiple constraint interfaces\n    for pass_idx in range(80):\n        order = np.random.permutation(n)\n        expanded = False\n        \n        for i in order:\n            pos = X[i].copy()\n            lr = 0.02 * (0.95 ** pass_idx)\n            best_pos = pos.copy()\n            best_r = R[i]\n            \n            # Active microscopic coordinate drift gradient against closest topological barriers\n            for _ in range(15):\n                dx = pos[0] - X[:, 0]\n                dy = pos[1] - X[:, 1]\n                dists = np.sqrt(dx**2 + dy**2)\n                dists[i] = np.inf\n                \n                m_circ = dists - R\n                m_bnd = np.array([pos[0], 1.0 - pos[0], pos[1], 1.0 - pos[1]])\n                min_m = min(np.min(m_circ), np.min(m_bnd))\n                \n                if min_m > best_r:\n                    best_r = min_m\n                    best_pos = pos.copy()\n                \n                # Temperature based vector formulation directing into deepest space pools safely\n                u_circ_x = dx / (dists + 1e-12)\n                u_circ_y = dy / (dists + 1e-12)\n                \n                w_circ = np.exp(-200.0 * np.maximum(0, m_circ - min_m))\n                w_circ[i] = 0.0\n                \n                fx = np.sum(u_circ_x * w_circ)\n                fy = np.sum(u_circ_y * w_circ)\n                \n                w_bnd = np.exp(-200.0 * np.maximum(0, m_bnd - min_m))\n                fx += w_bnd[0] * 1.0 - w_bnd[1] * 1.0\n                fy += w_bnd[2] * 1.0 - w_bnd[3] * 1.0\n                \n                norm = np.sqrt(fx**2 + fy**2)\n                if norm > 1e-12:\n                    pos[0] += lr * fx / norm\n                    pos[1] += lr * fy / norm\n                    pos = np.clip(pos, 0.0, 1.0)\n                else:\n                    break\n\n            # Confirm and capture safe bounds limits improvements continuously\n            if best_r > R[i] + 1e-9:\n                X[i] = best_pos\n                R[i] = best_r\n                expanded = True\n                \n        if not expanded and pass_idx > 10:\n            break\n            \n    R = np.minimum.reduce([R, X[:, 0], 1.0 - X[:, 0], X[:, 1], 1.0 - X[:, 1]])\n    R = np.maximum(R, 0.0)\n    return X, R\n\n\ndef solve_packing(n=26, iterations=7000, restarts=12, lr_start=0.015):\n    \"\"\"Execute dynamic penalty-scaled Adam physics with targeted varied structured seeds.\"\"\"\n    best_X = None\n    best_R = None\n    best_score = -1\n\n    for restart in range(restarts):\n        np.random.seed(1337 + restart)\n        \n        # Heterogeneous structured parameter placements balancing varied densities intelligently\n        if restart < 3:\n            X = np.random.rand(n, 2) * 0.9 + 0.05\n            R = np.random.rand(n) * 0.05 + 0.01\n            \n        elif restart < 6:\n            X = np.zeros((n, 2))\n            if n > 0: X[0] = [0.5, 0.5]\n            n_inner = min((n - 1) // 3, 8) if n > 1 else 0\n            n_outer = max(0, n - 1 - n_inner)\n            \n            for i in range(n_inner):\n                angle = 2 * np.pi * i / max(1, n_inner) + np.random.randn() * 0.1\n                X[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n            for i in range(n_outer):\n                angle = 2 * np.pi * i / max(1, n_outer) + np.random.randn() * 0.1\n                X[i + 1 + n_inner] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                \n            X = np.clip(X, 0.05, 0.95)\n            R = np.ones(n) * 0.05\n            if n > 0: R[0] = 0.1\n            \n        elif restart < 9:\n            X = np.random.rand(n, 2) * 0.8 + 0.1\n            R = np.random.rand(n) * 0.04 + 0.01\n            max_c = min(n, 4)\n            bases = [[0.2, 0.2], [0.2, 0.8], [0.8, 0.2], [0.8, 0.8]]\n            for i in range(max_c):\n                X[i] = bases[i]\n                R[i] = 0.15\n            if n > 4:\n                X[4] = [0.5, 0.5]\n                R[4] = 0.15\n                \n        else:\n            X = np.random.rand(n, 2)\n            edge_x_mask = np.random.rand(n) > 0.5\n            edge_y_mask = np.random.rand(n) > 0.5\n            X[edge_x_mask, 0] = np.where(np.random.rand(np.sum(edge_x_mask)) > 0.5, 0.05, 0.95)\n            X[edge_y_mask, 1] = np.where(np.random.rand(np.sum(edge_y_mask)) > 0.5, 0.05, 0.95)\n            X = np.clip(X + np.random.randn(n, 2) * 0.02, 0.05, 0.95)\n            R = np.ones(n) * 0.03\n            \n        opt = AdamOptimizer((n, 2), n, lr=lr_start)\n        \n        # Annealing engine parameters safely integrating complex gradient intersections\n        for step in range(iterations):\n            progress = step / iterations\n            opt.lr = lr_start * (1 - progress) ** 2 + 1e-5\n            k = 10 * (100000 ** progress)\n            \n            dx = X[:, 0].reshape(-1, 1) - X[:, 0]\n            dy = X[:, 1].reshape(-1, 1) - X[:, 1]\n            eye = np.eye(n, dtype=bool)\n            \n            dist = np.sqrt(dx**2 + dy**2)\n            dist[eye] = 1.0  \n            safe_dist = np.maximum(dist, 1e-10)\n            \n            dir_x = dx / safe_dist\n            dir_y = dy / safe_dist\n            dist[eye] = np.inf\n            \n            sum_R = R.reshape(-1, 1) + R\n            C_ij = np.maximum(0, sum_R - dist)\n            np.fill_diagonal(C_ij, 0)\n            \n            C_x0 = np.maximum(0, R - X[:, 0])\n            C_x1 = np.maximum(0, R - (1 - X[:, 0]))\n            C_y0 = np.maximum(0, R - X[:, 1])\n            C_y1 = np.maximum(0, R - (1 - X[:, 1]))\n            \n            dR = -np.ones(n) + k * (np.sum(C_ij, axis=1) + C_x0 + C_x1 + C_y0 + C_y1)\n            grad_X_x = k * (-np.sum(C_ij * dir_x, axis=1) - C_x0 + C_x1)\n            grad_X_y = k * (-np.sum(C_ij * dir_y, axis=1) - C_y0 + C_y1)\n            dX = np.column_stack((grad_X_x, grad_X_y))\n            \n            # Injection bounds preventing symmetrically stalled forces mathematically resolving space locks\n            if progress < 0.6:\n                noise_scale = 0.002 * (0.6 - progress)\n                dX += np.random.randn(*dX.shape) * noise_scale\n            \n            X, R = opt.step(X, R, dX, dR)\n            \n            X = np.clip(X, 0.0, 1.0)\n            R = np.clip(R, 0.0, 1.0)\n            \n        # Post evaluate strict limits to bounds ensuring safe returns globally scaling perfectly \n        val_X, val_R = make_valid(X, R)\n        score = np.sum(val_R)\n        \n        if score > best_score:\n            best_score = score\n            best_X = val_X.copy()\n            best_R = val_R.copy()\n            \n    return best_X, best_R, best_score\n\n\ndef construct_packing():\n    \"\"\"Construct highly optimized mathematically tight layouts evaluated inside strictly rigorous boundaries.\"\"\"\n    centers, radii, sum_radii = solve_packing(n=26)\n    return centers, radii, sum_radii\n\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"10.27s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.633152/2.635 = 0.9993\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.9% of target value\", \"radius_stats\": \"Min: 0.061913, Max: 0.135446, Avg: 0.101275\"}", "artifact_dir": null, "embedding": null}