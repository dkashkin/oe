{"id": "4c77da0a-d785-453b-8a08-214055db6058", "code": "import numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses a fully vectorized\n    iterative Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 120  # Extensive batch size for parallel topology exploration\n    iters = 18000  # High iteration count for deep convergence\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    np.random.seed(42)\n\n    # Initialize seeds with structurally diverse geometrical priors\n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # Anchor large circles in the corners, leaving a hollow middle for scattering\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # Rough grid-like distribution + central disruption\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]; r[b, 25] = 0.05\n        elif mode == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n: \n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n: break\n                if idx == n: break\n        elif mode == 4:\n            # Alternative tight concentric shells\n            c[b, 0] = [0.5, 0.5]; r[b, 0] = 0.25\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                c[b, i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n                r[b, i + 1] = 0.08\n            for i in range(15):\n                angle = 2 * np.pi * i / 15\n                c[b, i + 11] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 11] = 0.04\n        elif mode == 5:\n            # 5 large circles: 4 corners + 1 center\n            c[b, 0] = [0.5, 0.5]; r[b, 0] = 0.15\n            c[b, 1] = [0.15, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.85, 0.15]; r[b, 2] = 0.15\n            c[b, 3] = [0.15, 0.85]; r[b, 3] = 0.15\n            c[b, 4] = [0.85, 0.85]; r[b, 4] = 0.15\n            c[b, 5:] = np.random.rand(n - 5, 2) * 0.8 + 0.1\n            r[b, 5:] = 0.04\n        elif mode == 6:\n            # Mostly random but dominated by 3 massive circles acting as repellers\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.02 + 0.01\n            for i in range(3):\n                r[b, i] = 0.15\n        else:\n            # Radial size gradient: large in the center, smaller towards edges\n            for i in range(n):\n                c[b, i] = np.random.rand(2) * 0.8 + 0.1\n                d_center = np.linalg.norm(c[b, i] - [0.5, 0.5])\n                r[b, i] = max(0.01, 0.12 - 0.15 * d_center)\n\n        # Add random noise to break perfect symmetries and escape saddle points\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    # Keep initial guesses strictly inside feasible boundaries\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state tracking\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Physics-inspired iterative penalty method for joint optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponential learning rate decay and escalating penalty enforcement\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (1000000.0 ** progress)\n\n        # Vectorized pairwise distance computation\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps penalty and gradients\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        overlap[:, np.arange(n), np.arange(n)] = 0.0  # Erase self-overlaps\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Wall boundary penalties and gradients\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Combine objectives: max sum(r) subject to min(violations)\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like random exploration in early stages\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam update mechanics for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam update mechanics for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft physical bounding box\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Pre-compute static LP constraint matrix to severely reduce overhead\n    i_idx, j_idx = np.triu_indices(n, k=1)\n    A_ub = np.zeros((len(i_idx), n))\n    A_ub[np.arange(len(i_idx)), i_idx] = 1.0\n    A_ub[np.arange(len(i_idx)), j_idx] = 1.0\n    c_obj = -np.ones(n)\n\n    # Post-process with exact linear programming for pristine mathematical validity\n    for b in range(B):\n        cb = c[b]\n        \n        diff = cb[:, None, :] - cb[None, :, :]\n        dist_matrix = np.linalg.norm(diff, axis=-1)\n        b_ub = dist_matrix[i_idx, j_idx]\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            opt_r = res.x\n            # Include a strict safety epsilon to obliterate floating point error risk\n            opt_r = np.maximum(opt_r - 1e-9, 0.0)\n            \n            # Guarantee bounds definitively\n            for i in range(n):\n                opt_r[i] = min(opt_r[i], bounds[i][1])\n            \n            s = np.sum(opt_r)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = opt_r.copy()\n\n    # Fallback to defaults in case of catastrophic solver failure (highly unlikely)\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum", "changes_description": null, "language": "python", "parent_id": "3987a1de-fe14-4783-885d-4cf928951b38", "generation": 3, "timestamp": 1771875393.7516556, "iteration_found": 44, "metrics": {"stage1_passed": 0.0, "error": 0.0, "timeout": true}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0000\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: module 'program' has no attribute 'run_packing'\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/run2_improved_si/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/run2_improved_si/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: module 'program' has no attribute 'run_packing'\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6094, target_ratio: 0.9903, combined_score: 0.9903, radius_variance: 0.0056, spatial_spread: 0.1937, eval_time: 21.1736\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6144, target_ratio: 0.9922, combined_score: 0.9922, radius_variance: 0.0045, spatial_spread: 0.1921, eval_time: 38.8016\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9922)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses an iterative\n    Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 60\n    iters = 12000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    np.random.seed(42)\n    for b in range(B):\n        mode = b % 6\n        if mode == 0:\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            c[b, 0] = [0.15, 0.15]\n            r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]\n            r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]\n            r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]\n            r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]\n            r[b, 25] = 0.05\n        elif mode == 3:\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n:\n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n:\n                        break\n                if idx == n:\n                    break\n        elif mode == 4:\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.25\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                c[b, i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n                r[b, i + 1] = 0.08\n            for i in range(15):\n                angle = 2 * np.pi * i / 15\n                c[b, i + 11] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 11] = 0.04\n        else:\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.05 + 0.01\n\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    for step in range(1, iters + 1):\n        progress = step / iters\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (100000.0 ** progress)\n\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    for b in range(B):\n        cb = c[b]\n        dist_matrix = np.linalg.norm(cb[:, None, :] - cb[None, :, :], axis=-1)\n        \n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_matrix[i, j])\n                \n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n        c_obj = -np.ones(n)\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            opt_r = res.x\n            opt_r = np.maximum(opt_r - 1e-9, 0.0)\n            \n            s = np.sum(opt_r)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = opt_r.copy()\n\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n\nrun_packing = construct_packing\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6144), Performs well on target_ratio (0.9922), Performs well on combined_score (0.9922), Performs well on radius_variance (0.0045), Performs well on spatial_spread (0.1921), Performs well on eval_time (38.8016)\n\n### Program 2 (Score: 0.9903)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef run_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses an iterative\n    Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 40  # Number of parallel initializations to search diverse topologies\n    iters = 10000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialize with heuristics to bias toward corners, edges, and dense center\n    np.random.seed(42)\n    for b in range(B):\n        mode = b % 5\n        if mode == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # Anchor largest possible circles in the corners\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # Rough grid-like distribution\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]; r[b, 25] = 0.05\n        elif mode == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n: \n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n: break\n                if idx == n: break\n        else:\n            # Random scattering\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.05 + 0.01\n\n        # Add random noise to break perfect symmetry\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        # Decaying learning rate and exponentially increasing penalty weight\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (100000.0 ** progress)\n\n        # Pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps computation\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        \n        # Zero out diagonal self-overlap\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Gradients aggregation\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like perturbation\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam updates for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam updates for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft boundary clipping\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Resolve finalized radii via exact linear programming for maximum possible fit\n    for b in range(B):\n        cb = c[b]\n        dist_matrix = np.linalg.norm(cb[:, None, :] - cb[None, :, :], axis=-1)\n        \n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_matrix[i, j])\n                \n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n        c_obj = -np.ones(n)\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            opt_r = res.x\n            # Include a strict safety margin to handle floating point accuracy\n            opt_r = np.maximum(opt_r - 1e-9, 0.0)\n            \n            s = np.sum(opt_r)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = opt_r.copy()\n\n    # Fallback to defaults\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6094), Performs well on target_ratio (0.9903), Performs well on combined_score (0.9903), Performs well on radius_variance (0.0056), Performs well on spatial_spread (0.1937), Performs well on eval_time (21.1736)\n\n### Program 3 (Score: 0.0000)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses an iterative\n    Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 50  # Number of parallel initializations to search diverse topologies\n    iters = 15000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialize with heuristics to bias toward corners, edges, and dense center\n    np.random.seed(42)\n    for b in range(B):\n        mode = b % 5\n        if mode == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # Anchor largest possible circles in the corners\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # Rough grid-like distribution\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]; r[b, 25] = 0.05\n        elif mode == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n: \n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n: break\n                if idx == n: break\n        else:\n            # Random scattering\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.05 + 0.01\n\n        # Add random noise to break perfect symmetry\n        c[b] += np.random.randn(n, 2) * 0.02\n\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        # Decaying learning rate and exponentially increasing penalty weight\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (100000.0 ** progress)\n\n        # Pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps computation\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        \n        # Zero out diagonal self-overlap\n        for i in range(n):\n            overlap[:, i, i] = 0.0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Gradients aggregation\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like perturbation\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam updates for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam updates for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft boundary clipping\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Resolve finalized radii via exact linear programming for maximum possible fit\n    for b in range(B):\n        cb = c[b]\n        dist_matrix = np.linalg.norm(cb[:, None, :] - cb[None, :, :], axis=-1)\n        \n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_matrix[i, j])\n                \n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n        c_obj = -np.ones(n)\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            r_opt = res.x.copy()\n            # Safety margin to handle floating point inaccuracies\n            r_opt = np.maximum(0, r_opt - 1e-10)\n            \n            # Enforce boundaries strictly\n            max_bounds = np.minimum.reduce([cb[:, 0], 1 - cb[:, 0], cb[:, 1], 1 - cb[:, 1]])\n            r_opt = np.minimum(r_opt, np.maximum(0, max_bounds))\n            \n            # Enforce overlaps strictly using proportional reduction fallback\n            dist_fallback = dist_matrix.copy()\n            np.fill_diagonal(dist_fallback, np.inf)\n            \n            for _ in range(5):\n                r_sum_opt = r_opt[:, None] + r_opt[None, :]\n                overlap_mask = r_sum_opt > dist_fallback\n                if not np.any(overlap_mask):\n                    break\n                scales = np.ones_like(dist_fallback)\n                valid_mask = overlap_mask & (r_sum_opt > 1e-12)\n                np.divide(dist_fallback, r_sum_opt, out=scales, where=valid_mask)\n                r_opt *= np.min(scales, axis=1)\n\n            s = np.sum(r_opt)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = r_opt.copy()\n\n    # Fallback to defaults if LP fails on all topologies\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing for n=26 circles\"\"\"\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses a simulated\n    physics model with Adam optimization and final linear programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 60  # Number of parallel restarts to explore different topologies\n    iters = 15000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Heuristic Initialization: Bias toward corners, edges, and center\n    # Introducing structural diversity and breaking symmetry.\n    for b in range(B):\n        if b % 5 == 0:\n            # Pattern 1: One huge center, others in concentric rings\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [\n                    0.5 + 0.25 * np.cos(angle),\n                    0.5 + 0.25 * np.sin(angle)\n                ]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [\n                    0.5 + 0.45 * np.cos(angle),\n                    0.5 + 0.45 * np.sin(angle)\n                ]\n                r[b, i + 9] = 0.05\n            c[b] += np.random.randn(n, 2) * 0.01\n        elif b % 5 == 1:\n            # Pattern 2: Four massive circles in corners to maximize space, rest scattered\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif b % 5 == 2:\n            # Pattern 3: 5x5 Grid + 1\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]\n            r[b, 25] = 0.05\n            c[b] += np.random.randn(n, 2) * 0.02\n        elif b % 5 == 3:\n            # Pattern 4: Roughly hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > 26: \n                    cols = 26 - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == 26: \n                        break\n                if idx == 26: \n                    break\n            c[b] += np.random.randn(n, 2) * 0.01\n        else:\n            # Pattern 5: Random scattering\n            c[b] = np.random.rand(n, 2)\n            r[b] = np.random.rand(n) * 0.05 + 0.01\n\n    # Keep initial guesses strictly inside bounds\n    c = np.clip(c, 0.05, 0.95)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam Optimizer State\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    mask = np.eye(n, dtype=bool)[None, :, :]\n\n    # Physics-based iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        lr = 0.01 * (0.01 ** progress)\n        w_pen = 10.0 * (10000.0 ** progress)\n\n        # Compute pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Compute overlap violations\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        overlap[mask] = 0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Compute boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Combine gradients (maximize sum of radii, penalize violations)\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like random perturbation to escape local minima\n        if progress < 0.8:\n            noise_scale = 1e-4 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Apply Adam Updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Clip variables to feasible numerical ranges\n\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.0000)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative physics-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass Adam:\n    \"\"\"Simple Adam optimizer for vectorized parameter updates.\"\"\"\n    def __init__(self, shape):\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, lr):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        return params - lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n\n\ndef compute_max_radii(centers, initial_radii=None):\n    \"\"\"\n    Compute the maximum valid radii given the centers to ensure absolutely\n    no overlaps or boundary violations, using a proportional scaling approach.\n    \"\"\"\n    n = centers.shape[0]\n    if initial_radii is None:\n        radii = np.ones(n) * 0.5\n    else:\n        radii = initial_radii.copy()\n\n    # Apply 3 iterations to completely resolve any floating point inaccuracies\n    for _ in range(3):\n        # Ensure boundary constraints\n        radii = np.minimum(radii, centers[:, 0])\n        radii = np.minimum(radii, 1 - centers[:, 0])\n        radii = np.minimum(radii, centers[:, 1])\n        radii = np.minimum(radii, 1 - centers[:, 1])\n\n        # Resolve inter-circle overlaps\n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n\n        R_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n        overlap_mask = R_sum > dist\n\n        scales = np.ones_like(dist)\n        np.divide(dist, R_sum, out=scales, where=overlap_mask)\n\n        min_scale = np.min(scales, axis=1)\n        radii = radii * min_scale\n\n    return radii\n\n\ndef optimize_packing(seed, noise_level):\n    \"\"\"\n    Run an optimization step with physics-based simulated annealing\n    using Adam optimizer on a penalty loss function.\n    \"\"\"\n    n = 26\n    np.random.seed(seed)\n    \n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n\n    # Smart symmetric seeding as a strong prior\n    centers[0] = [0.5, 0.5]  # Center\n    radii[0] = 0.15\n\n    centers[1:5] = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]  # Corners\n    radii[1:5] = 0.08\n\n    centers[5:9\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative physics-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\nclass Adam:\n    \"\"\"Simple Adam optimizer for vectorized parameter updates.\"\"\"\n    def __init__(self, shape):\n        self.m = np.zeros(shape)\n        self.v = np.zeros(shape)\n        self.t = 0\n        \n    def step(self, params, grads, lr):\n        self.t += 1\n        self.m = 0.9 * self.m + 0.1 * grads\n        self.v = 0.999 * self.v + 0.001 * (grads ** 2)\n        m_hat = self.m / (1 - 0.9 ** self.t)\n        v_hat = self.v / (1 - 0.999 ** self.t)\n        return params - lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n\n\ndef compute_max_radii(centers, initial_radii=None):\n    \"\"\"\n    Compute the maximum valid radii given the centers to ensure absolutely\n    no overlaps or boundary violations, using a proportional scaling approach.\n    \"\"\"\n    n = centers.shape[0]\n    if initial_radii is None:\n        radii = np.ones(n) * 0.5\n    else:\n        radii = initial_radii.copy()\n\n    # Apply 3 iterations to completely resolve any floating point inaccuracies\n    for _ in range(3):\n        # Ensure boundary constraints\n        radii = np.minimum(radii, centers[:, 0])\n        radii = np.minimum(radii, 1 - centers[:, 0])\n        radii = np.minimum(radii, centers[:, 1])\n        radii = np.minimum(radii, 1 - centers[:, 1])\n\n        # Resolve inter-circle overlaps\n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n\n        R_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n        overlap_mask = R_sum > dist\n\n        scales = np.ones_like(dist)\n        np.divide(dist, R_sum, out=scales, where=overlap_mask)\n\n        min_scale = np.min(scales, axis=1)\n        radii = radii * min_scale\n\n    return radii\n\n\ndef optimize_packing(seed, noise_level):\n    \"\"\"\n    Run an optimization step with physics-based simulated annealing\n    using Adam optimizer on a penalty loss function.\n    \"\"\"\n    n = 26\n    np.random.seed(seed)\n    \n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n\n    # Smart symmetric seeding as a strong prior\n    centers[0] = [0.5, 0.5]  # Center\n    radii[0] = 0.15\n\n    centers[1:5] = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]  # Corners\n    radii[1:5] = 0.08\n\n    centers[5:9\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses an iterative\n    Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 30  # Number of parallel initializations to search diverse topologies\n    iters = 10000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialize with heuristics to bias toward corners, edges, and dense center\n    np.random.seed(42)\n    for b in range(B):\n        if b % 4 == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [\n                    0.5 + 0.25 * np.cos(angle),\n                    0.5 + 0.25 * np.sin(angle)\n                ]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [\n                    0.5 + 0.45 * np.cos(angle),\n                    0.5 + 0.45 * np.sin(angle)\n                ]\n                r[b, i + 9] = 0.05\n        elif b % 4 == 1:\n            # Anchor largest possible circles in the corners\n            c[b, 0] = [0.15, 0.15]\n            r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]\n            r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]\n            r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]\n            r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif b % 4 == 2:\n            # Rough grid-like distribution\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]\n            r[b, 25] = 0.05\n        elif b % 4 == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > 26: \n                    cols = 26 - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == 26:\n                        break\n                if idx == 26:\n                    break\n                    \n        # Add random noise to break perfect symmetry\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        # Decaying learning rate and exponentially increasing penalty weight\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (100000.0 ** progress)\n\n        # Pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps computation\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        \n        # Zero out diagonal self-overlap\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Gradients aggregation\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like perturbation\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam updates for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam updates for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft boundary clipping\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Resolve finalized radii via exact linear programming for maximum possible fit\n    for b in range(B):\n        cb = c[b]\n        dist_matrix = np.linalg.norm(cb[:, None, :] - cb[None, :, :], axis=-1)\n        \n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_matrix[i, j])\n                \n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n        c_obj = -np.ones(n)\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            opt_r = res.x\n            # Include a strict safety margin to handle floating point accuracy\n            opt_r = np.maximum(opt_r - 1e-9, 0.0)\n            \n            s = np.sum(opt_r)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = opt_r.copy()\n\n    # Fallback to defaults\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses a simulated\n    physics model with Adam optimization and final linear programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 60  # Number of parallel restarts to explore different topologies\n    iters = 10000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    np.random.seed(42)\n\n    # Heuristic Initialization: Bias toward corners, edges, and center\n    for b in range(B):\n        mode = b % 6\n        # Base random scattering for all circles\n        c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n        r[b] = np.random.rand(n) * 0.05 + 0.01\n\n        if mode == 0:\n            # Concentric rings\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [\n                    0.5 + 0.25 * np.cos(angle),\n                    0.5 + 0.25 * np.sin(angle)\n                ]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [\n                    0.5 + 0.45 * np.cos(angle),\n                    0.5 + 0.45 * np.sin(angle)\n                ]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # 4 large circles in corners to maximize space, rest scattered\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # 5x5 Grid + 1 center\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]\n            r[b, 25] = 0.05\n        elif mode == 3:\n            # Roughly hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > 26:\n                    cols = 26 - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == 26:\n                        break\n                if idx == 26:\n                    break\n        elif mode == 4:\n            # 1 massive center, others small scattered\n            c[b, 0] = [0.5, 0.5]; r[b, 0] = 0.45\n            c[b, 1:] = np.random.rand(n - 1, 2) * 0.9 + 0.05\n            r[b, 1:] = 0.02\n        else:\n            # Pure random scattering layout\n            pass\n\n        # Introduce slight random perturbations to break perfect symmetries\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    # Keep initial guesses strictly inside bounds\n    c = np.clip(c, 0.0, 1.0)\n    r = np.clip(r, 0.0, 0.5)\n\n    # Adam Optimizer State\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    mask = np.eye(n, dtype=bool)\n\n    # Physics-based iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        lr = 0.01 * (0.01 ** progress)\n        w_pen = 1.0 * (10000.0 ** progress)\n\n        # Compute pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Compute overlap violations\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        overlap[:, mask] = 0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Compute boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Combine gradients (maximize sum of radii, penalize violations)\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like random perturbation to escape local minima\n        if progress < 0.7:\n            noise_scale = 1e-3 * (1.0 - progress / 0.7)\n            grad_c += np.random.randn(*c.shape) * noise_scale\n\n        # Apply Adam Updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Clip variables to feasible physical ranges\n        c = np.clip(c, 0.0, 1.0)\n        r = np.clip(r, 0.0, 0.5)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    for b in range(B):\n        c_b = c[b].copy()\n        r_b = r[b].copy()\n\n        # Proportional reduction fallback to guarantee absolute spatial validity\n        r_fallback = r_b.copy()\n        r_fallback = np.minimum(r_fallback, c_b[:, 0])\n        r_fallback = np.minimum(r_fallback, 1 - c_b[:, 0])\n        r_fallback = np.minimum(r_fallback, c_b[:, 1])\n        r_fallback = np.minimum(r_fallback, 1 - c_b[:, 1])\n        r_fallback = np.maximum(r_fallback, 0)\n\n        for _ in range(20):\n            diff_fallback = c_b[:, None, :] - c_b[None, :, :]\n            dist_fallback = np.sqrt(np.sum(diff_fallback**2, axis=-1))\n            np.fill_diagonal(dist_fallback, np.inf)\n\n            r_sum_fallback = r_fallback[:, None] + r_fallback[None, :]\n            mask_ov = r_sum_fallback > dist_fallback\n            if not np.any(mask_ov):\n                break\n\n            scales = np.ones_like(dist_fallback)\n            valid = mask_ov & (r_sum_fallback > 1e-12)\n            np.divide(dist_fallback, r_sum_fallback, out=scales, where=valid)\n            min_scale = np.min(scales, axis=1)\n            r_fallback *= min_scale\n\n        r_fallback = np.maximum(r_fallback - 1e-8, 0)\n        sum_fallback = np.sum(r_fallback)\n\n        r_final = r_fallback\n        sum_final = sum_fallback\n\n        # Try to find exactly optimal bounds using LinProg for max area expansion\n        try:\n            from scipy.optimize import linprog\n            n_c = len(c_b)\n            c_obj = -np.ones(n_c)\n            A_ub = []\n            b_ub = []\n\n            for i in range(n_c):\n                for j in range(i + 1, n_c):\n                    d = np.linalg.norm(c_b[i] - c_b[j])\n                    row = np.zeros(n_c)\n                    row[i] = 1\n                    row[j] = 1\n                    A_ub.append(row)\n                    b_ub.append(d)\n\n            bounds = []\n            for i in range(n_c):\n                max_r = min(c_b[i, 0], 1 - c_b[i, 0], c_b[i, 1], 1 - c_b[i, 1])\n                bounds.append((0, max(0.0, float(max_r))))\n\n            res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if res.success:\n                r_lp = res.x\n                r_lp = np.maximum(r_lp - 1e-8, 0)\n                sum_lp = np.sum(r_lp)\n\n                # Verify LP solution is completely valid without numerical bleed\n                is_valid = True\n                for i in range(n_c):\n                    max_allowable = min(c_b[i, 0], 1 - c_b[i, 0], c_b[i, 1], 1 - c_b[i, 1])\n                    if r_lp[i] > max_allowable + 1e-7:\n                        is_valid = False\n                    for j in range(i + 1, n_c):\n                        if r_lp[i] + r_lp[j] > np.linalg.norm(c_b[i] - c_b[j]) + 1e-7:\n                            is_valid = False\n\n                if is_valid and sum_lp > sum_final:\n                    r_final = r_lp\n                    sum_final = sum_lp\n        except Exception:\n            pass\n\n        if sum_final > best_sum:\n            best_sum = sum_final\n            best_c = c_b.copy()\n            best_r = r_final.copy()\n\n    return best_c, best_r, best_sum\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses an iterative\n    Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 50  # Number of parallel initializations to search diverse topologies\n    iters = 15000\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialize with heuristics to bias toward corners, edges, and dense center\n    np.random.seed(42)\n    for b in range(B):\n        mode = b % 5\n        if mode == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # Anchor largest possible circles in the corners\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # Rough grid-like distribution\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]; r[b, 25] = 0.05\n        elif mode == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n: \n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n: break\n                if idx == n: break\n        else:\n            # Random scattering\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.05 + 0.01\n\n        # Add random noise to break perfect symmetry\n        c[b] += np.random.randn(n, 2) * 0.02\n\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Iterative penalty method optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        # Decaying learning rate and exponentially increasing penalty weight\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (100000.0 ** progress)\n\n        # Pairwise distances\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps computation\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        \n        # Zero out diagonal self-overlap\n        for i in range(n):\n            overlap[:, i, i] = 0.0\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Boundary violations\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Gradients aggregation\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like perturbation\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam updates for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam updates for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft boundary clipping\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Resolve finalized radii via exact linear programming for maximum possible fit\n    for b in range(B):\n        cb = c[b]\n        dist_matrix = np.linalg.norm(cb[:, None, :] - cb[None, :, :], axis=-1)\n        \n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_matrix[i, j])\n                \n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n        c_obj = -np.ones(n)\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            r_opt = res.x.copy()\n            # Safety margin to handle floating point inaccuracies\n            r_opt = np.maximum(0, r_opt - 1e-10)\n            \n            # Enforce boundaries strictly\n            max_bounds = np.minimum.reduce([cb[:, 0], 1 - cb[:, 0], cb[:, 1], 1 - cb[:, 1]])\n            r_opt = np.minimum(r_opt, np.maximum(0, max_bounds))\n            \n            # Enforce overlaps strictly using proportional reduction fallback\n            dist_fallback = dist_matrix.copy()\n            np.fill_diagonal(dist_fallback, np.inf)\n            \n            for _ in range(5):\n                r_sum_opt = r_opt[:, None] + r_opt[None, :]\n                overlap_mask = r_sum_opt > dist_fallback\n                if not np.any(overlap_mask):\n                    break\n                scales = np.ones_like(dist_fallback)\n                valid_mask = overlap_mask & (r_sum_opt > 1e-12)\n                np.divide(dist_fallback, r_sum_opt, out=scales, where=valid_mask)\n                r_opt *= np.min(scales, axis=1)\n\n            s = np.sum(r_opt)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = r_opt.copy()\n\n    # Fallback to defaults if LP fails on all topologies\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii. Uses a fully vectorized\n    iterative Adam-based penalty method followed by exact Linear Programming.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n = 26\n    B = 120  # Extensive batch size for parallel topology exploration\n    iters = 18000  # High iteration count for deep convergence\n\n    c = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    np.random.seed(42)\n\n    # Initialize seeds with structurally diverse geometrical priors\n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            # Concentric rings around a massive center\n            c[b, 0] = [0.5, 0.5]\n            r[b, 0] = 0.2\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                c[b, i + 1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n                r[b, i + 1] = 0.1\n            for i in range(17):\n                angle = 2 * np.pi * i / 17\n                c[b, i + 9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 9] = 0.05\n        elif mode == 1:\n            # Anchor large circles in the corners, leaving a hollow middle for scattering\n            c[b, 0] = [0.15, 0.15]; r[b, 0] = 0.15\n            c[b, 1] = [0.85, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.15, 0.85]; r[b, 2] = 0.15\n            c[b, 3] = [0.85, 0.85]; r[b, 3] = 0.15\n            c[b, 4:] = np.random.rand(n - 4, 2) * 0.6 + 0.2\n            r[b, 4:] = 0.05\n        elif mode == 2:\n            # Rough grid-like distribution + central disruption\n            for i in range(25):\n                row, col = divmod(i, 5)\n                c[b, i] = [0.1 + 0.2 * col, 0.1 + 0.2 * row]\n                r[b, i] = 0.08\n            c[b, 25] = [0.5, 0.5]; r[b, 25] = 0.05\n        elif mode == 3:\n            # Hexagonal dense packing\n            idx = 0\n            for row in range(6):\n                cols = 5 if row % 2 == 0 else 4\n                if idx + cols > n: \n                    cols = n - idx\n                for col in range(cols):\n                    x = 0.1 + col * 0.2 + (0.1 if row % 2 != 0 else 0)\n                    y = 0.1 + row * 0.16\n                    c[b, idx] = [x, y]\n                    r[b, idx] = 0.08\n                    idx += 1\n                    if idx == n: break\n                if idx == n: break\n        elif mode == 4:\n            # Alternative tight concentric shells\n            c[b, 0] = [0.5, 0.5]; r[b, 0] = 0.25\n            for i in range(10):\n                angle = 2 * np.pi * i / 10\n                c[b, i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n                r[b, i + 1] = 0.08\n            for i in range(15):\n                angle = 2 * np.pi * i / 15\n                c[b, i + 11] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n                r[b, i + 11] = 0.04\n        elif mode == 5:\n            # 5 large circles: 4 corners + 1 center\n            c[b, 0] = [0.5, 0.5]; r[b, 0] = 0.15\n            c[b, 1] = [0.15, 0.15]; r[b, 1] = 0.15\n            c[b, 2] = [0.85, 0.15]; r[b, 2] = 0.15\n            c[b, 3] = [0.15, 0.85]; r[b, 3] = 0.15\n            c[b, 4] = [0.85, 0.85]; r[b, 4] = 0.15\n            c[b, 5:] = np.random.rand(n - 5, 2) * 0.8 + 0.1\n            r[b, 5:] = 0.04\n        elif mode == 6:\n            # Mostly random but dominated by 3 massive circles acting as repellers\n            c[b] = np.random.rand(n, 2) * 0.8 + 0.1\n            r[b] = np.random.rand(n) * 0.02 + 0.01\n            for i in range(3):\n                r[b, i] = 0.15\n        else:\n            # Radial size gradient: large in the center, smaller towards edges\n            for i in range(n):\n                c[b, i] = np.random.rand(2) * 0.8 + 0.1\n                d_center = np.linalg.norm(c[b, i] - [0.5, 0.5])\n                r[b, i] = max(0.01, 0.12 - 0.15 * d_center)\n\n        # Add random noise to break perfect symmetries and escape saddle points\n        c[b] += np.random.randn(n, 2) * 0.01\n\n    # Keep initial guesses strictly inside feasible boundaries\n    c = np.clip(c, 0.01, 0.99)\n    r = np.clip(r, 0.01, 0.5)\n\n    # Adam optimizer state tracking\n    m_c = np.zeros_like(c)\n    v_c = np.zeros_like(c)\n    m_r = np.zeros_like(r)\n    v_r = np.zeros_like(r)\n\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    # Physics-inspired iterative penalty method for joint optimization\n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponential learning rate decay and escalating penalty enforcement\n        lr = 0.02 * (0.01 ** progress)\n        w_pen = 10.0 * (1000000.0 ** progress)\n\n        # Vectorized pairwise distance computation\n        diff = c[:, :, None, :] - c[:, None, :, :]\n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n\n        # Overlaps penalty and gradients\n        r_sum = r[:, :, None] + r[:, None, :]\n        overlap = np.maximum(0, r_sum - dist)\n        overlap[:, np.arange(n), np.arange(n)] = 0.0  # Erase self-overlaps\n\n        grad_r_overlap = np.sum(overlap, axis=2)\n        direction = diff / dist[..., None]\n        grad_c_overlap = np.sum(-overlap[..., None] * direction, axis=2)\n\n        # Wall boundary penalties and gradients\n        viol_x_low = np.maximum(0, r - c[:, :, 0])\n        viol_x_high = np.maximum(0, c[:, :, 0] + r - 1)\n        viol_y_low = np.maximum(0, r - c[:, :, 1])\n        viol_y_high = np.maximum(0, c[:, :, 1] + r - 1)\n\n        grad_r_bound = viol_x_low + viol_x_high + viol_y_low + viol_y_high\n        grad_c_x_bound = -viol_x_low + viol_x_high\n        grad_c_y_bound = -viol_y_low + viol_y_high\n        grad_c_bound = np.stack([grad_c_x_bound, grad_c_y_bound], axis=-1)\n\n        # Combine objectives: max sum(r) subject to min(violations)\n        grad_r = -1.0 + w_pen * (grad_r_overlap + grad_r_bound)\n        grad_c = w_pen * (grad_c_overlap + grad_c_bound)\n\n        # Simulated annealing-like random exploration in early stages\n        if progress < 0.8:\n            noise_scale = 1e-3 * (1.0 - progress / 0.8)\n            c += np.random.randn(*c.shape) * noise_scale\n\n        # Adam update mechanics for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c**2)\n        m_c_hat = m_c / (1 - beta1**step)\n        v_c_hat = v_c / (1 - beta2**step)\n        c -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n\n        # Adam update mechanics for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r**2)\n        m_r_hat = m_r / (1 - beta1**step)\n        v_r_hat = v_r / (1 - beta2**step)\n        r -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n\n        # Soft physical bounding box\n        c = np.clip(c, 0.001, 0.999)\n        r = np.maximum(r, 0.001)\n\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Pre-compute static LP constraint matrix to severely reduce overhead\n    i_idx, j_idx = np.triu_indices(n, k=1)\n    A_ub = np.zeros((len(i_idx), n))\n    A_ub[np.arange(len(i_idx)), i_idx] = 1.0\n    A_ub[np.arange(len(i_idx)), j_idx] = 1.0\n    c_obj = -np.ones(n)\n\n    # Post-process with exact linear programming for pristine mathematical validity\n    for b in range(B):\n        cb = c[b]\n        \n        diff = cb[:, None, :] - cb[None, :, :]\n        dist_matrix = np.linalg.norm(diff, axis=-1)\n        b_ub = dist_matrix[i_idx, j_idx]\n        \n        bounds = []\n        for i in range(n):\n            cx, cy = cb[i]\n            max_r = min(cx, 1.0 - cx, cy, 1.0 - cy)\n            max_r = max(0.0, float(max_r))\n            bounds.append((0, max_r))\n            \n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        \n        if res.success:\n            opt_r = res.x\n            # Include a strict safety epsilon to obliterate floating point error risk\n            opt_r = np.maximum(opt_r - 1e-9, 0.0)\n            \n            # Guarantee bounds definitively\n            for i in range(n):\n                opt_r[i] = min(opt_r[i], bounds[i][1])\n            \n            s = np.sum(opt_r)\n            if s > best_sum:\n                best_sum = s\n                best_c = cb.copy()\n                best_r = opt_r.copy()\n\n    # Fallback to defaults in case of catastrophic solver failure (highly unlikely)\n    if best_c is None:\n        best_c = c[0].copy()\n        best_r = np.zeros(n)\n        best_sum = 0.0\n\n    return best_c, best_r, best_sum\n```"]}}, "artifacts_json": "{\"timeout\": true, \"timeout_duration\": 60, \"failure_stage\": \"stage1\", \"error_type\": \"timeout\"}", "artifact_dir": null, "embedding": null}