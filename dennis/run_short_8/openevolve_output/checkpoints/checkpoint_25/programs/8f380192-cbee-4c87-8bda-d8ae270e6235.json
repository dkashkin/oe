{"id": "8f380192-cbee-4c87-8bda-d8ae270e6235", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_batches(B, n, T):\n    \"\"\"\n    Executes an aggressively batched gradient optimization natively executing simultaneously across highly\n    diversified spatial initialization clusters maximizing geometrical packing efficiencies optimally.\n    \"\"\"\n    pos = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialization generating distinct mathematical permutations accurately discovering maximally mapped geometries\n    for b in range(B):\n        np.random.seed(314 + b)\n        curr_r = np.random.uniform(0.04, 0.16, n)\n        curr_r[::-1].sort()\n        r[b] = curr_r\n        \n        pos_b = np.zeros((n, 2))\n        topo_id = b % 10\n        \n        if topo_id == 0:\n            pos_b[0] = [0.5, 0.5]\n            for i in range(1, 6): pos_b[i] = [0.5 + 0.16*np.cos(i*np.pi*2/5), 0.5 + 0.16*np.sin(i*np.pi*2/5)]\n            for i in range(6, 16): pos_b[i] = [0.5 + 0.32*np.cos(i*np.pi*2/10), 0.5 + 0.32*np.sin(i*np.pi*2/10)]\n            for i in range(16, 26): pos_b[i] = [0.5 + 0.44*np.cos(i*np.pi*2/10), 0.5 + 0.44*np.sin(i*np.pi*2/10)]\n        elif topo_id == 1:\n            idx = 0\n            for count, y in zip([5, 6, 4, 6, 5], np.linspace(0.1, 0.9, 5)):\n                for x in np.linspace(0.1, 0.9, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 2:\n            for i in range(n):\n                a = i * 2.39996\n                rad = 0.05 + i * 0.016\n                pos_b[i] = [0.5 + rad*np.cos(a), 0.5 + rad*np.sin(a)]\n        elif topo_id == 3:\n            pos_b = np.random.uniform(0.1, 0.9, (n, 2))\n            pos_b[0:4] = [[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]]\n            pos_b[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n        elif topo_id == 4:\n            idx = 0\n            for count, y in zip([6, 4, 6, 4, 6], np.linspace(0.1, 0.9, 5)):\n                for x in np.linspace(0.1, 0.9, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 5:\n            idx = 0\n            for count, y in zip([5, 5, 6, 5, 5], np.linspace(0.08, 0.92, 5)):\n                for x in np.linspace(0.08, 0.92, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 6:\n            for i in range(8): pos_b[i] = [0.1 + 0.8*(i % 2), 0.1 + (i // 2)*0.25]\n            for i in range(8, 26): pos_b[i] = [np.random.uniform(0.2, 0.8), np.random.uniform(0.1, 0.9)]\n        elif topo_id == 7:\n            for i in range(12): pos_b[i] = [0.5 + 0.4*np.cos(i*np.pi/6), 0.5 + 0.4*np.sin(i*np.pi/6)]\n            for i in range(12, 20): pos_b[i] = [0.5 + 0.2*np.cos(i*np.pi/4), 0.5 + 0.2*np.sin(i*np.pi/4)]\n            pos_b[20:] = np.random.uniform(0.3, 0.7, (6, 2))\n        elif topo_id == 8:\n            pos_b = np.random.uniform(0.05, 0.95, (n, 2))\n            pos_b[0] = [0.5, 0.5]\n            pos_b[1:5] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n        elif topo_id == 9:\n            idx = 0\n            for center_c in [[0.25, 0.25], [0.75, 0.25], [0.25, 0.75], [0.75, 0.75], [0.5, 0.5]]:\n                for _ in range(5):\n                    pos_b[idx] = center_c\n                    idx += 1\n            pos_b[25] = [0.5, 0.1]\n            \n        pos_b += np.random.normal(0, 0.015, (n, 2))\n        pos[b] = np.clip(pos_b, 0.02, 0.98)\n\n    # Natively precomputing mathematical exponential and scaling coefficients maximizing cycle efficency completely\n    steps = np.arange(T)\n    cos_val = 1 + np.cos(np.pi * steps / T)\n    K_arr = 10.0 * (10000.0) ** (steps / (T - 1.0))\n    lr_pos_arr = 1e-4 + 0.5 * (0.012 - 1e-4) * cos_val\n    lr_r_arr = 1e-5 + 0.5 * (0.005 - 1e-5) * cos_val\n\n    active_steps = int(T * 0.7)\n    noise_pos_arr = np.zeros(T)\n    noise_pos_arr[:active_steps] = 0.001 * (1 - np.arange(active_steps) / active_steps)\n    noise_r_arr = noise_pos_arr * 0.05\n\n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n\n    # Core physics optimization vectorized resolving boundaries seamlessly reliably\n    for step in range(T):\n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1) + 1e-12\n        dist[:, np.arange(n), np.arange(n)] = 100.0\n        \n        overlap = r[:, :, np.newaxis] + r[:, np.newaxis, :] - dist\n        np.maximum(0, overlap, out=overlap)\n        \n        left_ov = r - pos[..., 0]\n        np.maximum(0, left_ov, out=left_ov)\n        right_ov = r - (1 - pos[..., 0])\n        np.maximum(0, right_ov, out=right_ov)\n        bottom_ov = r - pos[..., 1]\n        np.maximum(0, bottom_ov, out=bottom_ov)\n        top_ov = r - (1 - pos[..., 1])\n        np.maximum(0, top_ov, out=top_ov)\n        \n        K = K_arr[step]\n        \n        grad_r = np.sum(overlap, axis=2)\n        grad_r += left_ov + right_ov + bottom_ov + top_ov\n        grad_r *= (2 * K)\n        grad_r -= 1.0\n        \n        direction = diff / dist[..., np.newaxis]\n        grad_pos = np.sum(overlap[..., np.newaxis] * direction, axis=2)\n        grad_pos *= (-2 * K)\n        \n        grad_pos[..., 0] += 2 * K * (-left_ov + right_ov)\n        grad_pos[..., 1] += 2 * K * (-bottom_ov + top_ov)\n        \n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * (grad_pos ** 2)\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        \n        b1_t = 1 - beta1 ** (step + 1)\n        b2_t = 1 - beta2 ** (step + 1)\n        \n        m_hat_pos = m_pos / b1_t\n        v_hat_pos = v_pos / b2_t\n        m_hat_r = m_r / b1_t\n        v_hat_r = v_r / b2_t\n        \n        pos -= lr_pos_arr[step] * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        r -= lr_r_arr[step] * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        if noise_pos_arr[step] > 0:\n            pos += np.random.normal(0, noise_pos_arr[step], pos.shape)\n            r += np.random.normal(0, noise_r_arr[step], r.shape)\n            \n        np.clip(pos, 0.001, 0.999, out=pos)\n        np.clip(r, 0.001, 0.5, out=r)\n        \n    return pos, r\n\n\ndef fix_and_expand_radii(pos, r):\n    \"\"\"\n    Absolutely solidifies domain limiting validating constraint boundaries fully explicitly.\n    Additionally incorporates incrementally cascading expansion scales cleanly sealing internal voids precisely.\n    \"\"\"\n    n = len(r)\n    # Strictly bind limits seamlessly securely dynamically\n    for _ in range(300):\n        r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n        \n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-12:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        d_ij = dist[i, j]\n        tr = r[i] + r[j]\n        if tr > d_ij:\n            scale = (d_ij / tr) - 1e-12\n            r[i] *= scale\n            r[j] *= scale\n\n    # Reevaluate mapping mathematical distances natively correctly\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            d_ij = dist[i, j]\n            if r[i] + r[j] > d_ij:\n                scale = d_ij / (r[i] + r[j]) - 1e-12\n                r[i] *= scale\n                r[j] *= scale\n                \n    r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n\n    # Broad to fine incremental expansion maximizing tight geometric pockets elegantly\n    dr_scales = [0.002, 0.0002, 0.00002, 0.000002]\n    \n    for dr in dr_scales:\n        active = np.ones(n, dtype=bool)\n        for _ in range(1200):\n            if not np.any(active):\n                break\n                \n            r[active] += dr\n            \n            wall_fail = (r > pos[:, 0]) | (r > 1 - pos[:, 0]) | \\\n                        (r > pos[:, 1]) | (r > 1 - pos[:, 1])\n            if np.any(wall_fail & active):\n                r[wall_fail & active] -= dr\n                active[wall_fail & active] = False\n                \n            r_sum = r[:, np.newaxis] + r[np.newaxis, :]\n            collisions = r_sum > dist + 1e-11\n            if np.any(collisions):\n                rows, cols = np.where(collisions)\n                for i, j in zip(rows, cols):\n                    if active[i]:\n                        r[i] -= dr\n                        active[i] = False\n                    if active[j]:\n                        r[j] -= dr\n                        active[j] = False\n                        \n    # Safety final clip guaranteeing zero structural validation issues implicitly safely\n    for i in range(n):\n        for j in range(i + 1, n):\n            if r[i] + r[j] > dist[i, j]:\n                sc = dist[i, j] / (r[i] + r[j]) - 1e-14\n                r[i] *= sc\n                r[j] *= sc\n                \n    r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs optimally allocated dense arrangements via massive perfectly batched parallel tensor mapping cleanly.\n    \"\"\"\n    B = 30\n    n = 26\n    T = 3600\n    \n    pos_batched, r_batched = optimize_batches(B, n, T)\n    \n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n    \n    # Iterate resolved geometries determining explicitly the maximal global combination properly naturally cleanly\n    for b in range(B):\n        fixed_r = fix_and_expand_radii(pos_batched[b].copy(), r_batched[b].copy())\n        val = float(np.sum(fixed_r))\n        if val > best_sum:\n            best_sum = val\n            best_pos = pos_batched[b].copy()\n            best_r = fixed_r.copy()\n            \n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to significantly higher spatial allocation efficiency.\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "be410022-e6c0-4d58-ac90-b997d52653bc", "generation": 2, "timestamp": 1772009387.4415226, "iteration_found": 26, "metrics": {"validity": 1.0, "sum_radii": 2.6268413182753174, "target_ratio": 0.9969037261006898, "combined_score": 0.9969037261006898, "radius_variance": 0.00564107324809272, "spatial_spread": 0.1887266182561056, "eval_time": 5.877417802810669}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6252777227268416, "target_ratio": 0.9963103312056325, "combined_score": 0.9963103312056325, "radius_variance": 0.004938544465210516, "spatial_spread": 0.19029669633771895, "eval_time": 2.1331355571746826}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9963\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.9973 \u2192 0.9963. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n2.13s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.625278/2.635 = 0.9963\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.6% of target value\n```\n\n### radius_stats\n```\nMin: 0.075794, Max: 0.137204, Avg: 0.100972\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6278, target_ratio: 0.9973, combined_score: 0.9973, radius_variance: 0.0058, spatial_spread: 0.1942, eval_time: 2.9775\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6309, target_ratio: 0.9984, combined_score: 0.9984, radius_variance: 0.0055, spatial_spread: 0.1975, eval_time: 4.3183\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6357, target_ratio: 1.0003, combined_score: 1.0003, radius_variance: 0.0045, spatial_spread: 0.1885, eval_time: 4.3045\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.0003)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_packing(seed):\n    \"\"\"\n    Optimizes positions and sizes for 26 circles via simulated expansion using \n    an escalating penalty-augmented gradient descent method (Adam). \n    Strategic hex-layer heuristics maximize convergence stability towards the ideal fit.\n    \"\"\"\n    np.random.seed(seed)\n    n = 26\n    \n    # Initialize radii with decay sizing bias allowing diverse central placement\n    r = np.random.uniform(0.04, 0.16, n)\n    r[::-1].sort()\n    \n    pos = np.zeros((n, 2))\n    \n    # Construct geometric initial symmetry layout matching expected tight formations\n    # [0] Center piece\n    pos[0] = [0.5, 0.5]\n    \n    # [1-6] 6-sided inner core wrapping\n    for i in range(1, 7):\n        angle = 2 * np.pi * i / 6.0 + np.random.randn() * 0.1\n        r_dist = 0.16 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(angle), 0.5 + r_dist * np.sin(angle)]\n        \n    # [7-18] 12-sided outer corona ring\n    for i in range(7, 19):\n        angle = 2 * np.pi * (i - 7) / 12.0 + np.random.randn() * 0.1\n        r_dist = 0.35 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(angle), 0.5 + r_dist * np.sin(angle)]\n        \n    # [19-22] Exact corner filler bubbles\n    corners = [[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]]\n    for i in range(19, 23):\n        pos[i] = corners[i - 19]\n    \n    # [23-25] Interstitial edge mappings biased variably across multiple seeds\n    if seed % 2 == 0:\n        edge_coords = [[0.5, 0.05], [0.05, 0.5], [0.95, 0.5]]\n    else:\n        edge_coords = [[0.33, 0.95], [0.66, 0.95], [0.5, 0.05]]\n        \n    for i in range(23, 26):\n        pos[i] = edge_coords[i - 23]\n        \n    # Break rigid symmetry smoothly \n    pos += np.random.normal(0, 0.015, pos.shape)\n    pos = np.clip(pos, 0.02, 0.98)\n    \n    # Adam parameters tracking physical momentums \n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    T = 3200\n    for step in range(T):\n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        np.fill_diagonal(dist, np.inf)\n        \n        overlap = np.maximum(0, r[:, np.newaxis] + r[np.newaxis, :] - dist)\n        \n        # Determine geometric wall constraint overrides limiting space\n        left_ov = np.maximum(0, r - pos[:, 0])\n        right_ov = np.maximum(0, r - (1 - pos[:, 0]))\n        bottom_ov = np.maximum(0, r - pos[:, 1])\n        top_ov = np.maximum(0, r - (1 - pos[:, 1]))\n        \n        # Continuously expanding hardness factor driving strictly mutually exclusive spaces\n        K = 10.0 * (10000.0) ** (step / float(T - 1.0))\n        \n        grad_r = -np.ones(n)\n        grad_r += 2 * K * np.sum(overlap, axis=1)\n        grad_r += 2 * K * (left_ov + right_ov + bottom_ov + top_ov)\n        \n        direction = diff / dist[:, :, np.newaxis]\n        grad_pos = -2 * K * np.sum(overlap[:, :, np.newaxis] * direction, axis=1)\n        \n        grad_pos[:, 0] -= 2 * K * left_ov\n        grad_pos[:, 0] += 2 * K * right_ov\n        grad_pos[:, 1] -= 2 * K * bottom_ov\n        grad_pos[:, 1] += 2 * K * top_ov\n        \n        # Implement cosine schedule driving precise stable equilibrium settlement\n        lr_pos = 1e-5 + 0.5 * (0.01 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        lr_r = 1e-5 + 0.5 * (0.005 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        \n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * grad_pos**2\n        m_hat_pos = m_pos / (1 - beta1**(step + 1))\n        v_hat_pos = v_pos / (1 - beta2**(step + 1))\n        pos -= lr_pos * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * grad_r**2\n        m_hat_r = m_r / (1 - beta1**(step + 1))\n        v_hat_r = v_r / (1 - beta2**(step + 1))\n        r -= lr_r * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Gentle random thermal energy breaks possible metastable suboptimal lattice geometries\n        if step < int(T * 0.7):\n            noise_scale = 0.001 * (1 - step / (T * 0.7))\n            pos += np.random.normal(0, noise_scale, pos.shape)\n            r += np.random.normal(0, noise_scale * 0.05, r.shape)\n            \n        pos = np.clip(pos, 0.001, 0.999)\n        r = np.clip(r, 0.001, 0.5)\n        \n    return pos, r\n\n\ndef fix_and_expand_radii(pos, r):\n    \"\"\"\n    Absolutely solidifies domain limits strictly verifying zero spatial overlaps globally.\n    Additionally incorporates dynamic inflation passes expanding strictly permitted gaps.\n    \"\"\"\n    r = np.copy(r)\n    n = len(r)\n    \n    # 1. Fallback exact shrinking enforcing reliable constraints\n    for _ in range(500):\n        # Apply strict coordinate limiting\n        max_r_x = np.minimum(pos[:, 0], 1 - pos[:, 0])\n        max_r_y = np.minimum(pos[:, 1], 1 - pos[:, 1])\n        r = np.minimum(r, max_r_x)\n        r = np.minimum(r, max_r_y)\n        \n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1))\n        np.fill_diagonal(dist, np.inf)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-9:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        dist_ij = dist[i, j]\n        total_r = r[i] + r[j]\n        if total_r > dist_ij:\n            scale = (dist_ij / total_r) - 1e-8\n            r[i] *= scale\n            r[j] *= scale\n            \n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    # Assured check establishing global domain validation\n    for i in range(n):\n        for j in range(i + 1, n):\n            if r[i] + r[j] > dist[i, j]:\n                scale = dist[i, j] / (r[i] + r[j]) - 1e-10\n                r[i] *= scale\n                r[j] *= scale\n                \n    for i in range(n):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n\n    # 2. Re-expansion safely scaling previously bounded circles to capture missing volume bits\n    dr_scales = [0.0005, 0.00005]\n    for dr in dr_scales:\n        active = np.ones(n, dtype=bool)\n        for _ in range(1000):\n            if not np.any(active):\n                break\n                \n            r[active] += dr\n            \n            # Bound condition drops actively scaling indices failing boundary guarantees\n            wall_mask = (r > pos[:, 0]) | (r > 1 - pos[:, 0]) | \\\n                        (r > pos[:, 1]) | (r > 1 - pos[:, 1])\n            if np.any(wall_mask & active):\n                r[wall_mask & active] -= dr\n                active[wall_mask & active] = False\n                \n            r_sum = r[:, np.newaxis] + r[np.newaxis, :]\n            collisions = r_sum > dist + 1e-11\n            if np.any(collisions):\n                rows, cols = np.where(collisions)\n                for i, j in zip(rows, cols):\n                    if active[i]:\n                        r[i] -= dr\n                        active[i] = False\n                    if active[j]:\n                        r[j] -= dr\n                        active[j] = False\n                        \n    # Safety final clip guaranteeing zero rounding discrepancy overlap penalties internally\n    for i in range(n):\n        for j in range(i + 1, n):\n            if r[i] + r[j] > dist[i, j]:\n                scale = dist[i, j] / (r[i] + r[j]) - 1e-12\n                r[i] *= scale\n                r[j] *= scale\n                \n    for i in range(n):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n        \n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimized 2D layout topology maximizing radii totals\n    mapping simulated Adam physics annealing combining distinct geometric restarts.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n\n    # Diversify seed conditions securing globally optimized configurations avoiding isolated traps\n    for seed in range(42, 52):  # Execute across 10 random variations\n        pos, r = optimize_packing(seed)\n        r_fixed = fix_and_expand_radii(pos, r)\n        current_sum = np.sum(r_fixed)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_fixed.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to significantly higher spatial allocation efficiency.\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6357), Performs well on target_ratio (1.0003), Performs well on combined_score (1.0003), Performs well on radius_variance (0.0045), Performs well on spatial_spread (0.1885), Performs well on eval_time (4.3045)\n\n### Program 2 (Score: 0.9984)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_packing(seed):\n    \"\"\"\n    Optimizes 26 circles via physically-constrained gradient simulation.\n    Uses Adam mapping with highly-calibrated initial geometrical\n    layouts matching naturally dense configuration distributions in rectangles.\n    \"\"\"\n    np.random.seed(seed)\n    n = 26\n    \n    # Initialize initial radiuses scaled biased to favor adaptive packing \n    r = np.random.uniform(0.04, 0.16, n)\n    r[::-1].sort()\n    \n    pos = np.zeros((n, 2))\n    \n    # Intelligently permute seeds driving Adam towards fundamentally separate local minima\n    topo = seed % 6\n    if topo == 0:\n        # Layout 0: Center, 6 inner ring, 11 outer ring, 4 corners, 4 edge points\n        pos[0] = [0.5, 0.5]\n        for i in range(1, 7):\n            a = 2 * np.pi * i / 6.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.18 * np.cos(a), 0.5 + 0.18 * np.sin(a)]\n        for i in range(7, 18):\n            a = 2 * np.pi * i / 11.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n        pos[18:22] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n        pos[22:26] = [[0.5, 0.06], [0.5, 0.94], [0.06, 0.5], [0.94, 0.5]]\n        \n    elif topo == 1:\n        # Layout 1: Dense 5-5-6-5-5 interleaved rows directly occupying interior planes uniformly\n        idx = 0\n        for count, y in zip([5, 5, 6, 5, 5], [0.1, 0.3, 0.5, 0.7, 0.9]):\n            xs = np.linspace(0.1, 0.9, count)\n            for x in xs:\n                pos[idx] = [x, y]\n                idx += 1\n                \n    elif topo == 2:\n        # Layout 2: Offset rows 6-4-6-4-6 structure favoring boundary compression gaps securely \n        idx = 0\n        for count, y in zip([6, 4, 6, 4, 6], [0.1, 0.3, 0.5, 0.7, 0.9]):\n            xs = np.linspace(0.1, 0.9, count)\n            for x in xs:\n                pos[idx] = [x, y]\n                idx += 1\n                \n    elif topo == 3:\n        # Layout 3: Center, Inner ring(6), Outer uniform ring(12), corners(4), bottom heavy edge(3)\n        pos[0] = [0.5, 0.5]\n        for i in range(1, 7):\n            a = 2 * np.pi * i / 6.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.17 * np.cos(a), 0.5 + 0.17 * np.sin(a)]\n        for i in range(7, 19):\n            a = 2 * np.pi * i / 12.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n        pos[19:23] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n        pos[23:26] = [[0.33, 0.94], [0.67, 0.94], [0.5, 0.06]]\n        \n    elif topo == 4:\n        # Layout 4: Hexagonal-hybrid rows 5-6-4-6-5 mapped vertically\n        idx = 0\n        for count, y in zip([5, 6, 4, 6, 5], [0.1, 0.3, 0.5, 0.7, 0.9]):\n            xs = np.linspace(0.1, 0.9, count)\n            for x in xs:\n                pos[idx] = [x, y]\n                idx += 1\n                \n    else:\n        # Layout 5: Alternative binary multi-shell map containing distinct radial frequencies 2-8-12 + 4 corners \n        pos[0:2] = [[0.4, 0.5], [0.6, 0.5]]\n        for i in range(2, 10):\n            a = 2 * np.pi * (i - 2) / 8.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.22 * np.cos(a), 0.5 + 0.22 * np.sin(a)]\n        for i in range(10, 22):\n            a = 2 * np.pi * (i - 10) / 12.0 + np.random.randn() * 0.05\n            pos[i] = [0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)]\n        pos[22:26] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n\n    # Apply general perturbations naturally shattering perfectly uniform grid symmetry anomalies mapping smooth descents natively\n    pos += np.random.normal(0, 0.015, pos.shape)\n    pos = np.clip(pos, 0.02, 0.98)\n    \n    # Establish dynamic descent mechanics storing momentum strictly enforcing overlaps heavily\n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    T = 2800\n    for step in range(T):\n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        np.fill_diagonal(dist, 100.0)\n        \n        # Geometrical interactions limiting spaces aggressively\n        overlap = np.maximum(0, r[:, np.newaxis] + r[np.newaxis, :] - dist)\n        \n        left_ov = np.maximum(0, r - pos[:, 0])\n        right_ov = np.maximum(0, r - (1 - pos[:, 0]))\n        bottom_ov = np.maximum(0, r - pos[:, 1])\n        top_ov = np.maximum(0, r - (1 - pos[:, 1]))\n        \n        # Multiplier steadily restricting domains into wholly non-overlapping hard spheres continuously strictly perfectly \n        K = 10.0 * (10000.0) ** (step / float(T - 1.0))\n        \n        grad_r = -1.0 + 2 * K * (np.sum(overlap, axis=1) + left_ov + right_ov + bottom_ov + top_ov)\n        \n        direction = diff / dist[..., np.newaxis]\n        grad_pos = -2 * K * np.sum(overlap[..., np.newaxis] * direction, axis=1)\n        \n        grad_pos[:, 0] += 2 * K * (-left_ov + right_ov)\n        grad_pos[:, 1] += 2 * K * (-bottom_ov + top_ov)\n        \n        # Exponential curve decaying rates maintaining resolution fidelity effectively safely\n        lr_pos = 1e-5 + 0.5 * (0.012 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        lr_r = 1e-5 + 0.5 * (0.006 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        \n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * grad_pos**2\n        m_hat_pos = m_pos / (1 - beta1**(step + 1))\n        v_hat_pos = v_pos / (1 - beta2**(step + 1))\n        pos -= lr_pos * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * grad_r**2\n        m_hat_r = m_r / (1 - beta1**(step + 1))\n        v_hat_r = v_r / (1 - beta2**(step + 1))\n        r -= lr_r * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Temperature schedules gently displacing items resolving grid rigidities naturally bypassing trap points cleanly \n        if step < int(T * 0.65):\n            noise_scale = 0.001 * (1 - step / (T * 0.65))\n            pos += np.random.normal(0, noise_scale, pos.shape)\n            r += np.random.normal(0, noise_scale * 0.05, r.shape)\n            \n        pos = np.clip(pos, 0.001, 0.999)\n        r = np.clip(r, 0.001, 0.5)\n        \n    return pos, r\n\n\ndef fix_and_expand_radii(pos, r):\n    \"\"\"\n    Validates geometrical integrity rigidly restricting overflows while expanding unallocated gaps perfectly iteratively.\n    \"\"\"\n    r = np.copy(r)\n    n = len(r)\n    \n    # 1. Fallback clipping applying strictly constrained exterior borders enforcing completely safe margins cleanly\n    max_rx = np.minimum(pos[:, 0], 1 - pos[:, 0])\n    max_ry = np.minimum(pos[:, 1], 1 - pos[:, 1])\n    r = np.minimum(r, max_rx)\n    r = np.minimum(r, max_ry)\n    \n    for _ in range(500):\n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1))\n        np.fill_diagonal(dist, 100.0)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-12:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        d_ij = dist[i, j]\n        total_r = r[i] + r[j]\n        if total_r > d_ij:\n            scale = (d_ij / total_r) - 1e-10\n            r[i] *= scale\n            r[j] *= scale\n\n    # Enforced overlap resolution resolving anomalies guaranteeing solid states mathematically properly \n    for i in range(n):\n        for j in range(i + 1, n):\n            d_ij = np.sqrt(np.sum((pos[i] - pos[j])**2))\n            if r[i] + r[j] > d_ij:\n                sc = d_ij / (r[i] + r[j]) - 1e-12\n                r[i] *= sc\n                r[j] *= sc\n\n    for i in range(n):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n\n    # 2. Expand uniformly maximizing gaps perfectly safely utilizing successively constrained scalar passes \n    dr_scales = [0.001, 0.0001, 0.00001, 0.000001]\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, 100.0)\n    \n    for dr in dr_scales:\n        active = np.ones(n, dtype=bool)\n        for _ in range(1500):\n            if not np.any(active):\n                break\n                \n            r[active] += dr\n            \n            wall_fail = (r > pos[:, 0]) | (r > 1 - pos[:, 0]) | \\\n                        (r > pos[:, 1]) | (r > 1 - pos[:, 1])\n            if np.any(wall_fail & active):\n                r[wall_fail & active] -= dr\n                active[wall_fail & active] = False\n                \n            r_sum = r[:, np.newaxis] + r[np.newaxis, :]\n            collisions = r_sum > dist + 1e-11\n            if np.any(collisions):\n                rows, cols = np.where(collisions)\n                for i, j in zip(rows, cols):\n                    if active[i]:\n                        r[i] -= dr\n                        active[i] = False\n                    if active[j]:\n                        r[j] -= dr\n                        active[j] = False\n                        \n    # Safety checks mapping explicitly avoiding completely numerical overflow possibilities\n    for i in range(n):\n        for j in range(i + 1, n):\n            d_ij = dist[i, j]\n            if r[i] + r[j] > d_ij:\n                scale = d_ij / (r[i] + r[j]) - 1e-13\n                r[i] *= scale\n                r[j] *= scale\n                \n    for i in range(n):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n        \n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Execute exhaustive physical configuration models finding optimally distributed geometrical circles.\n    Constructs layouts mapped across varied diverse random initial domains evaluating fully optimally completely!\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii) representing ideally solved domain geometries smoothly natively strictly optimally safely effectively accurately securely globally! \n    \"\"\"\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n\n    # Evolve 12 seeds comprehensively discovering globally maximally fitting layouts avoiding early optimal blocks reliably  \n    for seed in range(42, 54):\n        pos, r = optimize_packing(seed)\n        r_fixed = fix_and_expand_radii(pos, r)\n        current_sum = np.sum(r_fixed)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_fixed.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to significantly higher spatial allocation efficiency.\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6309), Performs well on target_ratio (0.9984), Performs well on combined_score (0.9984), Performs well on radius_variance (0.0055), Performs well on spatial_spread (0.1975), Performs well on eval_time (4.3183)\n\n### Program 3 (Score: 0.9973)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_packing(seed):\n    \"\"\"\n    Simulated expanding bubble optimization algorithm via Adam gradient descent.\n    Places sizes strategically and uses simulated annealing noise schedule.\n    \"\"\"\n    np.random.seed(seed)\n    n = 26\n    \n    # Initialize radii with bias (large to small)\n    r = np.random.uniform(0.05, 0.15, n)\n    r[::-1].sort()  # Sort descending so early indices get larger radius initially\n    \n    pos = np.zeros((n, 2))\n    # Strategically place largest in center\n    pos[0] = [0.5 + np.random.randn() * 0.01, 0.5 + np.random.randn() * 0.01]\n    \n    # First inner ring\n    for i in range(1, 6):\n        a = 2 * np.pi * i / 5 + np.random.randn() * 0.2\n        r_dist = 0.15 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(a), 0.5 + r_dist * np.sin(a)]\n        \n    # Second outer ring\n    for i in range(6, 14):\n        a = 2 * np.pi * i / 8 + np.random.randn() * 0.2\n        r_dist = 0.3 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(a), 0.5 + r_dist * np.sin(a)]\n        \n    # Send small bubbles heavily to the boundaries and tight corners\n    pos[14] = [0.05, 0.05]\n    pos[15] = [0.95, 0.05]\n    pos[16] = [0.05, 0.95]\n    pos[17] = [0.95, 0.95]\n    \n    # Specific edge placements\n    edge_coords = [\n        [0.33, 0.05], [0.66, 0.05], [0.33, 0.95], [0.66, 0.95],\n        [0.05, 0.33], [0.05, 0.66], [0.95, 0.33], [0.95, 0.66]\n    ]\n    for i in range(18, 26):\n        pos[i] = edge_coords[i - 18]\n        \n    # Soft perturb boundaries to break any remaining perfect symmetries\n    pos[14:26] += np.random.normal(0, 0.01, (12, 2))\n    \n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    T = 3500\n    for step in range(T):\n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        np.fill_diagonal(dist, 100.0)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, 0.0)\n        overlap = np.maximum(0, overlap)\n        \n        left_ov = np.maximum(0, r - pos[:, 0])\n        right_ov = np.maximum(0, r - (1 - pos[:, 0]))\n        bottom_ov = np.maximum(0, r - pos[:, 1])\n        top_ov = np.maximum(0, r - (1 - pos[:, 1]))\n        \n        # Exponential growth of strictness from soft overlaps to strictly exclusive boundaries\n        K = 10.0 * (10000.0) ** (step / (T - 1.0))\n        \n        # Maximize sum(r) by treating radius growth as steady baseline force pulling down cost gradient\n        grad_r = -np.ones(n)\n        grad_pos = np.zeros_like(pos)\n        \n        # Apply strictly escalating gradient forces resolving geometric intersects\n        grad_r += 2 * K * np.sum(overlap, axis=1)\n        direction = diff / dist[..., np.newaxis]\n        grad_pos -= 2 * K * np.sum(overlap[..., np.newaxis] * direction, axis=1)\n        \n        grad_r += 2 * K * (left_ov + right_ov + bottom_ov + top_ov)\n        grad_pos[:, 0] -= 2 * K * left_ov\n        grad_pos[:, 0] += 2 * K * right_ov\n        grad_pos[:, 1] -= 2 * K * bottom_ov\n        grad_pos[:, 1] += 2 * K * top_ov\n        \n        # Cosine learning rate decay to tune smoothly to optimal dense configuration settling out oscillations\n        lr_pos_step = 1e-5 + 0.5 * (0.01 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        lr_r_step = 1e-5 + 0.5 * (0.005 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        \n        # Adam descent state parameter update\n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * grad_pos**2\n        m_hat_pos = m_pos / (1 - beta1**(step + 1))\n        v_hat_pos = v_pos / (1 - beta2**(step + 1))\n        pos -= lr_pos_step * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * grad_r**2\n        m_hat_r = m_r / (1 - beta1**(step + 1))\n        v_hat_r = v_r / (1 - beta2**(step + 1))\n        r -= lr_r_step * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Simulated annealing initialization injects jiggle energy safely bypassing sub-optimal geometric ruts\n        if step < T - 1000:\n            noise = 0.001 * (1 - step / (T - 1000.0))\n            pos += np.random.normal(0, noise, pos.shape)\n            r += np.random.normal(0, noise * 0.1, r.shape)\n            \n        pos = np.clip(pos, 0.001, 0.999)\n        r = np.clip(r, 0.001, 0.5)\n        \n    return pos, r\n\n\ndef fix_radii(pos, r):\n    \"\"\"\n    Fallback exact shrinkage solver cleanly eliminating infinitesimally remaining penalty overlaps.\n    \"\"\"\n    r = np.copy(r)\n    # Perform strict conservative corrections\n    for _ in range(500):\n        # Clip absolutely strictly within exterior boundaries first \n        max_r_x = np.minimum(pos[:, 0], 1 - pos[:, 0])\n        max_r_y = np.minimum(pos[:, 1], 1 - pos[:, 1])\n        r = np.minimum(r, max_r_x)\n        r = np.minimum(r, max_r_y)\n        \n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1))\n        np.fill_diagonal(dist, 100.0)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-9:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        # Apply scaled tight elimination\n        dist_ij = dist[i, j]\n        total_r = r[i] + r[j]\n        if total_r > dist_ij:\n            scale = (dist_ij / total_r) - 1e-8\n            r[i] *= scale\n            r[j] *= scale\n            \n    # Perform a fast final check confirming uniform and reliable spatial integrity\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, 100.0)\n    for i in range(len(r)):\n        for j in range(i + 1, len(r)):\n            if r[i] + r[j] > dist[i, j]:\n                scale = dist[i, j] / (r[i] + r[j]) - 1e-10\n                r[i] *= scale\n                r[j] *= scale\n                \n    for i in range(len(r)):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n        \n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii, utilizing a combination of physics simulation \n    with noise annealing and diverse start seed topologies for the fittest layout execution.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n\n    # Evolve multiple initialization topology searches locating globally maximal fits \n    for seed in range(42, 48):\n        pos, r = optimize_packing(seed)\n        r_fixed = fix_radii(pos, r)\n        current_sum = np.sum(r_fixed)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_fixed.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6278), Performs well on target_ratio (0.9973), Performs well on combined_score (0.9973), Performs well on radius_variance (0.0058), Performs well on spatial_spread (0.1942), Performs well on eval_time (2.9775)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.9934)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles within a 1x1 unit square\n    to maximize the sum of their radii via an Adam-optimized soft-sphere layout technique.\n    Leverages strategically heuristic seed topologies natively structured iteratively organically smoothly seamlessly.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n    \n    # Sweep systematically generating structured cluster variations structurally breaking symmetry optimally purely randomly logically\n    for seed in range(8):\n        np.random.seed(42 + seed * 13)\n        \n        # Heuristically sort initial random scales actively pushing largest bubbles deeply centering stably reliably\n        r = np.random.uniform(0.01, 0.15, n)\n        r[::-1].sort()\n        \n        pos = np.zeros((n, 2))\n        \n        if seed % 3 == 0:\n            # Structurally fully random topology guaranteeing global scope emergence seamlessly structurally functionally \n            pos = np.random.uniform(0.1, 0.9, (n, 2))\n            pos[0] = [0.5, 0.5]\n            # Assure specific elements definitively actively bounding bounds reliably robustly\n            pos[16:20] = [[0.08, 0.08], [0.92, 0.08], [0.08, 0.92], [0.92, 0.92]]\n        else:\n            # Phenomenally strongly formed heuristic topologies structured tightly structurally resolving dynamically tightly smoothly \n            pos[0] = [0.5 + np.random.randn() * 0.02, 0.5 + np.random.randn() * 0.02]\n            \n            for i in range(1, 6):\n                a = 2 * np.pi * i / 5 + np.random.randn() * 0.25\n                dist = 0.18 + np.random.randn() * 0.02\n                pos[i] = [0.5 + dist * np.cos(a), 0.5 + dist * np.sin(a)]\n                \n            for i in range(6, 16):\n                a = 2 * np.pi * i / 10 + np.random.randn() * 0.25\n                dist = 0.36 + np.random.randn() * 0.02\n                pos[i] = [0.5 + dist * np.cos(a), 0.5 + dist * np.sin(a)]\n                \n            pos[16:20] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n            \n            for i in range(20, 26):\n                side = np.random.randint(4)\n                val = np.random.uniform(0.2, 0.8)\n                if side == 0: pos[i] = [val, 0.04]\n                elif side == 1: pos[i] = [val, 0.96]\n                elif side == 2: pos[i] = [0.04, val]\n                else: pos[i] = [0.96, val]\n                \n            pos += np.random.normal(0, 0.005, (n, 2))\n            \n        pos = np.clip(pos, 0.05, 0.95)\n        \n        # State tensors enabling cleanly scaled precision gradient trajectories consistently properly strictly successfully   \n        m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n        m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n        \n        T = 2400\n        for step in range(1, T + 1):\n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1) + 1e-12\n            np.fill_diagonal(dist, 100.0)\n            \n            # Smooth penalty overlap boundaries steadily scaling definitively robustly ensuring stability completely continuously mathematically safely\n            overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n            np.fill_diagonal(overlap, 0.0)\n            overlap = np.maximum(0, overlap)\n            \n            w_left = np.maximum(0, r - pos[:, 0])\n            w_right = np.maximum(0, r - (1 - pos[:, 0]))\n            w_bot = np.maximum(0, r - pos[:, 1])\n            w_top = np.maximum(0, r - (1 - pos[:, 1]))\n            \n            K = 5.0 * (10000.0 ** (step / float(T)))\n            \n            grad_p = -2 * K * np.sum(overlap[..., np.newaxis] * (diff / dist[..., np.newaxis]), axis=1)\n            grad_p[:, 0] += 2 * K * (-w_left + w_right)\n            grad_p[:, 1] += 2 * K * (-w_bot + w_top)\n            \n            grad_r = -1.0 + 2 * K * (np.sum(overlap, axis=1) + w_left + w_right + w_bot + w_top)\n            \n            lr_p = 1e-4 + 0.5 * 0.015 * (1 + np.cos(np.pi * step / T))\n            lr_r = 1e-4 + 0.5 * 0.008 * (1 + np.cos(np.pi * step / T))\n            \n            m_p = 0.9 * m_p + 0.1 * grad_p\n            v_p = 0.999 * v_p + 0.001 * grad_p**2\n            pos -= lr_p * (m_p / (1 - 0.9**step)) / (np.sqrt(v_p / (1 - 0.999**step)) + 1e-8)\n            \n            m_r = 0.9 * m_r + 0.1 * grad_r\n            v_r = 0.999 * v_r + 0.001 * grad_r**2\n            r -= lr_r * (m_r / (1 - 0.9**step)) / (np.sqrt(v_r / (1 - 0.999**step)) + 1e-8)\n            \n            # Shaking matrix structure strictly explicitly effectively circumventing geometrical local maxima smoothly flawlessly\n            if step < int(0.65 * T):\n                noise = 0.002 * (1 - step / (0.65 * T))\n                pos += np.random.normal(0, noise, pos.shape)\n                r += np.random.normal(0, noise * 0.05, r.shape)\n                \n            pos = np.clip(pos, 1e-6, 1 - 1e-6)\n            r = np.clip(r, 1e-6, 0.5)\n            \n        r_clean = np.copy(r)\n        \n        # Ensure exact perfect bounding mathematically firmly flawlessly guaranteeing cleanly reliable packing rigorously reliably precisely comprehensively optimally efficiently  \n        for _ in range(800):\n            r_clean = np.minimum(r_clean, pos[:, 0])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n            r_clean = np.minimum(r_clean, pos[:, 1])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n            \n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, 100.0)\n            \n            overlap = r_clean[:, np.newaxis] + r_clean[np.newaxis, :] - dist\n            if np.max(overlap) <= 1e-12:\n                break\n                \n            i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n            d_ij = dist[i, j]\n            tr = r_clean[i] + r_clean[j]\n            if tr > d_ij:\n                scale = max(0.0, (d_ij / tr) - 1e-13)\n                r_clean[i] *= scale\n                r_clean[j] *= scale\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(pos[i] - pos[j])\n                if r_clean[i] + r_clean[j] > d:\n                    sc = max(0.0, (d / (r_clean[i] + r_clean[j])) - 1e-15)\n                    r_clean[i] *= sc\n                    r_clean[j] *= sc\n                    \n        r_clean = np.minimum(r_clean, pos[:, 0])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n        r_clean = np.minimum(r_clean, pos[:, 1])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n        \n        current_sum = float(np.sum(r_clean))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_clean.copy()\n            \n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n### Program D2 (Score: 0.9963)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles within a 1x1 square\n    to maximize the sum of their radii via a simulated physical expansion system.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n, best_sum, best_pos, best_r = 26, -1.0, None, None\n    \n    # Iterate across multiple configuration seeds sequentially preventing convergence in single local minima\n    for seed in range(7):\n        np.random.seed(42 + seed)\n        r = np.random.uniform(0.01, 0.12, n)\n        r[::-1].sort()  # Assign the initial maximum radii cleanly enabling central growth expansion\n        \n        # Strategic starting layout structurally positioning heavy entities neutrally to reduce immediate geometric locks\n        pos = np.random.uniform(0.1, 0.9, (n, 2))\n        pos[0] = [0.5 + np.random.randn() * 0.01, 0.5 + np.random.randn() * 0.01]\n        \n        # Guide smaller spheres explicitly towards extremities natively accommodating empty spaces smoothly\n        for i, (dx, dy) in enumerate([[-1, -1], [1, -1], [-1, 1], [1, 1]]):\n            pos[n - 4 + i] = [0.5 + 0.45 * dx, 0.5 + 0.45 * dy]\n        \n        # Simulate an iterative expansion matrix dynamically adjusting overlaps leveraging standard Adam momentum forces\n        m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n        m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n        \n        T = 2200\n        for step in range(1, T + 1):\n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1) + 1e-12\n            np.fill_diagonal(dist, 100.0)\n            \n            # Formulate overlap constraints naturally penalizing overlapping bounds smoothly ensuring separation \n            overlap = np.maximum(0, r[:, np.newaxis] + r[np.newaxis, :] - dist)\n            np.fill_diagonal(overlap, 0.0)\n            \n            w_left = np.maximum(0, r - pos[:, 0])\n            w_right = np.maximum(0, r - (1 - pos[:, 0]))\n            w_bot = np.maximum(0, r - pos[:, 1])\n            w_top = np.maximum(0, r - (1 - pos[:, 1]))\n            \n            # Progressively harden exclusivity strictly solidifying overlapping intersections preventing breaches steadily \n            K = 5.0 * (8000.0 ** (step / float(T)))\n            \n            # Map descent scalar forces structurally directly matching constraint deviations seamlessly\n            grad_p = -2 * K * np.sum(overlap[..., np.newaxis] * (diff / dist[..., np.newaxis]), axis=1)\n            grad_p[:, 0] += 2 * K * (-w_left + w_right)\n            grad_p[:, 1] += 2 * K * (-w_bot + w_top)\n            \n            # Gradient pulls naturally scaling continuous sizes outward against penalties balancing dynamically  \n            grad_r = -1.0 + 2 * K * (np.sum(overlap, axis=1) + w_left + w_right + w_bot + w_top)\n            \n            lr_p = 1e-4 + 0.5 * 0.012 * (1 + np.cos(np.pi * step / T))\n            lr_r = 1e-4 + 0.5 * 0.005 * (1 + np.cos(np.pi * step / T))\n            \n            # State vector standard processing utilizing gradient accumulations stably smoothing step magnitudes cleanly\n            m_p = 0.9 * m_p + 0.1 * grad_p\n            v_p = 0.999 * v_p + 0.001 * grad_p**2\n            pos -= lr_p * (m_p / (1 - 0.9**step)) / (np.sqrt(v_p / (1 - 0.999**step)) + 1e-8)\n            \n            m_r = 0.9 * m_r + 0.1 * grad_r\n            v_r = 0.999 * v_r + 0.001 * grad_r**2\n            r -= lr_r * (m_r / (1 - 0.9**step)) / (np.sqrt(v_r / (1 - 0.999**step)) + 1e-8)\n            \n            # Perturb heavily actively shaking configurations avoiding localized stalling patterns uniformly\n            if step < 0.65 * T:\n                noise = 0.0015 * (1 - step / (0.65 * T))\n                pos += np.random.normal(0, noise, pos.shape)\n                r += np.random.normal(0, noise * 0.05, r.shape)\n            \n            pos = np.clip(pos, 1e-5, 1 - 1e-5)\n            r = np.clip(r, 1e-5, 0.5)\n\n        # Eliminate trace inconsistencies fully conforming variables definitively guaranteeing geometry robustness  \n        r_clean = np.copy(r)\n        for _ in range(500):\n            r_clean = np.minimum(r_clean, pos[:, 0])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n            r_clean = np.minimum(r_clean, pos[:, 1])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n            \n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, 100.0)\n            \n            overlap = r_clean[:, np.newaxis] + r_clean[np.newaxis, :] - dist\n            if np.max(overlap) <= 1e-12:\n                break\n                \n            i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n            d_ij = dist[i, j]\n            tr = r_clean[i] + r_clean[j]\n            if tr > d_ij:\n                scale = (d_ij / tr) - 1e-12\n                r_clean[i] *= scale\n                r_clean[j] *= scale\n        \n        # Verify explicitly preventing overlaps universally assuring metric compliance strictly definitively\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(pos[i] - pos[j]) + 1e-15\n                if r_clean[i] + r_clean[j] > d:\n                    sc = d / (r_clean[i] + r_clean[j]) - 1e-12\n                    r_clean[i] *= sc\n                    r_clean[j] *= sc\n                    \n        r_clean = np.minimum(r_clean, pos[:, 0])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n        r_clean = np.minimum(r_clean, pos[:, 1])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n        \n        current_sum = float(np.sum(r_clean))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_clean.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.9973, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_packing(seed):\n    \"\"\"\n    Simulated expanding bubble optimization algorithm via Adam gradient descent.\n    Places sizes strategically and uses simulated annealing noise schedule.\n    \"\"\"\n    np.random.seed(seed)\n    n = 26\n    \n    # Initialize radii with bias (large to small)\n    r = np.random.uniform(0.05, 0.15, n)\n    r[::-1].sort()  # Sort descending so early indices get larger radius initially\n    \n    pos = np.zeros((n, 2))\n    # Strategically place largest in center\n    pos[0] = [0.5 + np.random.randn() * 0.01, 0.5 + np.random.randn() * 0.01]\n    \n    # First inner ring\n    for i in range(1, 6):\n        a = 2 * np.pi * i / 5 + np.random.randn() * 0.2\n        r_dist = 0.15 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(a), 0.5 + r_dist * np.sin(a)]\n        \n    # Second outer ring\n    for i in range(6, 14):\n        a = 2 * np.pi * i / 8 + np.random.randn() * 0.2\n        r_dist = 0.3 + np.random.randn() * 0.02\n        pos[i] = [0.5 + r_dist * np.cos(a), 0.5 + r_dist * np.sin(a)]\n        \n    # Send small bubbles heavily to the boundaries and tight corners\n    pos[14] = [0.05, 0.05]\n    pos[15] = [0.95, 0.05]\n    pos[16] = [0.05, 0.95]\n    pos[17] = [0.95, 0.95]\n    \n    # Specific edge placements\n    edge_coords = [\n        [0.33, 0.05], [0.66, 0.05], [0.33, 0.95], [0.66, 0.95],\n        [0.05, 0.33], [0.05, 0.66], [0.95, 0.33], [0.95, 0.66]\n    ]\n    for i in range(18, 26):\n        pos[i] = edge_coords[i - 18]\n        \n    # Soft perturb boundaries to break any remaining perfect symmetries\n    pos[14:26] += np.random.normal(0, 0.01, (12, 2))\n    \n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    T = 3500\n    for step in range(T):\n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        np.fill_diagonal(dist, 100.0)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, 0.0)\n        overlap = np.maximum(0, overlap)\n        \n        left_ov = np.maximum(0, r - pos[:, 0])\n        right_ov = np.maximum(0, r - (1 - pos[:, 0]))\n        bottom_ov = np.maximum(0, r - pos[:, 1])\n        top_ov = np.maximum(0, r - (1 - pos[:, 1]))\n        \n        # Exponential growth of strictness from soft overlaps to strictly exclusive boundaries\n        K = 10.0 * (10000.0) ** (step / (T - 1.0))\n        \n        # Maximize sum(r) by treating radius growth as steady baseline force pulling down cost gradient\n        grad_r = -np.ones(n)\n        grad_pos = np.zeros_like(pos)\n        \n        # Apply strictly escalating gradient forces resolving geometric intersects\n        grad_r += 2 * K * np.sum(overlap, axis=1)\n        direction = diff / dist[..., np.newaxis]\n        grad_pos -= 2 * K * np.sum(overlap[..., np.newaxis] * direction, axis=1)\n        \n        grad_r += 2 * K * (left_ov + right_ov + bottom_ov + top_ov)\n        grad_pos[:, 0] -= 2 * K * left_ov\n        grad_pos[:, 0] += 2 * K * right_ov\n        grad_pos[:, 1] -= 2 * K * bottom_ov\n        grad_pos[:, 1] += 2 * K * top_ov\n        \n        # Cosine learning rate decay to tune smoothly to optimal dense configuration settling out oscillations\n        lr_pos_step = 1e-5 + 0.5 * (0.01 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        lr_r_step = 1e-5 + 0.5 * (0.005 - 1e-5) * (1 + np.cos(np.pi * step / T))\n        \n        # Adam descent state parameter update\n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * grad_pos**2\n        m_hat_pos = m_pos / (1 - beta1**(step + 1))\n        v_hat_pos = v_pos / (1 - beta2**(step + 1))\n        pos -= lr_pos_step * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * grad_r**2\n        m_hat_r = m_r / (1 - beta1**(step + 1))\n        v_hat_r = v_r / (1 - beta2**(step + 1))\n        r -= lr_r_step * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Simulated annealing initialization injects jiggle energy safely bypassing sub-optimal geometric ruts\n        if step < T - 1000:\n            noise = 0.001 * (1 - step / (T - 1000.0))\n            pos += np.random.normal(0, noise, pos.shape)\n            r += np.random.normal(0, noise * 0.1, r.shape)\n            \n        pos = np.clip(pos, 0.001, 0.999)\n        r = np.clip(r, 0.001, 0.5)\n        \n    return pos, r\n\n\ndef fix_radii(pos, r):\n    \"\"\"\n    Fallback exact shrinkage solver cleanly eliminating infinitesimally remaining penalty overlaps.\n    \"\"\"\n    r = np.copy(r)\n    # Perform strict conservative corrections\n    for _ in range(500):\n        # Clip absolutely strictly within exterior boundaries first \n        max_r_x = np.minimum(pos[:, 0], 1 - pos[:, 0])\n        max_r_y = np.minimum(pos[:, 1], 1 - pos[:, 1])\n        r = np.minimum(r, max_r_x)\n        r = np.minimum(r, max_r_y)\n        \n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1))\n        np.fill_diagonal(dist, 100.0)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-9:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        # Apply scaled tight elimination\n        dist_ij = dist[i, j]\n        total_r = r[i] + r[j]\n        if total_r > dist_ij:\n            scale = (dist_ij / total_r) - 1e-8\n            r[i] *= scale\n            r[j] *= scale\n            \n    # Perform a fast final check confirming uniform and reliable spatial integrity\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, 100.0)\n    for i in range(len(r)):\n        for j in range(i + 1, len(r)):\n            if r[i] + r[j] > dist[i, j]:\n                scale = dist[i, j] / (r[i] + r[j]) - 1e-10\n                r[i] *= scale\n                r[j] *= scale\n                \n    for i in range(len(r)):\n        r[i] = min([r[i], pos[i, 0], 1 - pos[i, 0], pos[i, 1], 1 - pos[i, 1]])\n        \n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii, utilizing a combination of physics simulation \n    with noise annealing and diverse start seed topologies for the fittest layout execution.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n\n    # Evolve multiple initialization topology searches locating globally maximal fits \n    for seed in range(42, 48):\n        pos, r = optimize_packing(seed)\n        r_fixed = fix_radii(pos, r)\n        current_sum = np.sum(r_fixed)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_fixed.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9934, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles within a 1x1 unit square\n    to maximize the sum of their radii via an Adam-optimized soft-sphere layout technique.\n    Leverages strategically heuristic seed topologies natively structured iteratively organically smoothly seamlessly.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n    \n    # Sweep systematically generating structured cluster variations structurally breaking symmetry optimally purely randomly logically\n    for seed in range(8):\n        np.random.seed(42 + seed * 13)\n        \n        # Heuristically sort initial random scales actively pushing largest bubbles deeply centering stably reliably\n        r = np.random.uniform(0.01, 0.15, n)\n        r[::-1].sort()\n        \n        pos = np.zeros((n, 2))\n        \n        if seed % 3 == 0:\n            # Structurally fully random topology guaranteeing global scope emergence seamlessly structurally functionally \n            pos = np.random.uniform(0.1, 0.9, (n, 2))\n            pos[0] = [0.5, 0.5]\n            # Assure specific elements definitively actively bounding bounds reliably robustly\n            pos[16:20] = [[0.08, 0.08], [0.92, 0.08], [0.08, 0.92], [0.92, 0.92]]\n        else:\n            # Phenomenally strongly formed heuristic topologies structured tightly structurally resolving dynamically tightly smoothly \n            pos[0] = [0.5 + np.random.randn() * 0.02, 0.5 + np.random.randn() * 0.02]\n            \n            for i in range(1, 6):\n                a = 2 * np.pi * i / 5 + np.random.randn() * 0.25\n                dist = 0.18 + np.random.randn() * 0.02\n                pos[i] = [0.5 + dist * np.cos(a), 0.5 + dist * np.sin(a)]\n                \n            for i in range(6, 16):\n                a = 2 * np.pi * i / 10 + np.random.randn() * 0.25\n                dist = 0.36 + np.random.randn() * 0.02\n                pos[i] = [0.5 + dist * np.cos(a), 0.5 + dist * np.sin(a)]\n                \n            pos[16:20] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n            \n            for i in range(20, 26):\n                side = np.random.randint(4)\n                val = np.random.uniform(0.2, 0.8)\n                if side == 0: pos[i] = [val, 0.04]\n                elif side == 1: pos[i] = [val, 0.96]\n                elif side == 2: pos[i] = [0.04, val]\n                else: pos[i] = [0.96, val]\n                \n            pos += np.random.normal(0, 0.005, (n, 2))\n            \n        pos = np.clip(pos, 0.05, 0.95)\n        \n        # State tensors enabling cleanly scaled precision gradient trajectories consistently properly strictly successfully   \n        m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n        m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n        \n        T = 2400\n        for step in range(1, T + 1):\n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1) + 1e-12\n            np.fill_diagonal(dist, 100.0)\n            \n            # Smooth penalty overlap boundaries steadily scaling definitively robustly ensuring stability completely continuously mathematically safely\n            overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n            np.fill_diagonal(overlap, 0.0)\n            overlap = np.maximum(0, overlap)\n            \n            w_left = np.maximum(0, r - pos[:, 0])\n            w_right = np.maximum(0, r - (1 - pos[:, 0]))\n            w_bot = np.maximum(0, r - pos[:, 1])\n            w_top = np.maximum(0, r - (1 - pos[:, 1]))\n            \n            K = 5.0 * (10000.0 ** (step / float(T)))\n            \n            grad_p = -2 * K * np.sum(overlap[..., np.newaxis] * (diff / dist[..., np.newaxis]), axis=1)\n            grad_p[:, 0] += 2 * K * (-w_left + w_right)\n            grad_p[:, 1] += 2 * K * (-w_bot + w_top)\n            \n            grad_r = -1.0 + 2 * K * (np.sum(overlap, axis=1) + w_left + w_right + w_bot + w_top)\n            \n            lr_p = 1e-4 + 0.5 * 0.015 * (1 + np.cos(np.pi * step / T))\n            lr_r = 1e-4 + 0.5 * 0.008 * (1 + np.cos(np.pi * step / T))\n            \n            m_p = 0.9 * m_p + 0.1 * grad_p\n            v_p = 0.999 * v_p + 0.001 * grad_p**2\n            pos -= lr_p * (m_p / (1 - 0.9**step)) / (np.sqrt(v_p / (1 - 0.999**step)) + 1e-8)\n            \n            m_r = 0.9 * m_r + 0.1 * grad_r\n            v_r = 0.999 * v_r + 0.001 * grad_r**2\n            r -= lr_r * (m_r / (1 - 0.9**step)) / (np.sqrt(v_r / (1 - 0.999**step)) + 1e-8)\n            \n            # Shaking matrix structure strictly explicitly effectively circumventing geometrical local maxima smoothly flawlessly\n            if step < int(0.65 * T):\n                noise = 0.002 * (1 - step / (0.65 * T))\n                pos += np.random.normal(0, noise, pos.shape)\n                r += np.random.normal(0, noise * 0.05, r.shape)\n                \n            pos = np.clip(pos, 1e-6, 1 - 1e-6)\n            r = np.clip(r, 1e-6, 0.5)\n            \n        r_clean = np.copy(r)\n        \n        # Ensure exact perfect bounding mathematically firmly flawlessly guaranteeing cleanly reliable packing rigorously reliably precisely comprehensively optimally efficiently  \n        for _ in range(800):\n            r_clean = np.minimum(r_clean, pos[:, 0])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n            r_clean = np.minimum(r_clean, pos[:, 1])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n            \n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, 100.0)\n            \n            overlap = r_clean[:, np.newaxis] + r_clean[np.newaxis, :] - dist\n            if np.max(overlap) <= 1e-12:\n                break\n                \n            i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n            d_ij = dist[i, j]\n            tr = r_clean[i] + r_clean[j]\n            if tr > d_ij:\n                scale = max(0.0, (d_ij / tr) - 1e-13)\n                r_clean[i] *= scale\n                r_clean[j] *= scale\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(pos[i] - pos[j])\n                if r_clean[i] + r_clean[j] > d:\n                    sc = max(0.0, (d / (r_clean[i] + r_clean[j])) - 1e-15)\n                    r_clean[i] *= sc\n                    r_clean[j] *= sc\n                    \n        r_clean = np.minimum(r_clean, pos[:, 0])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n        r_clean = np.minimum(r_clean, pos[:, 1])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n        \n        current_sum = float(np.sum(r_clean))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_clean.copy()\n            \n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.7156, Type: Alternative)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    using an iterative physics-based soft-sphere repelling algorithm\n    followed by linear constrained growth.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    n_seeds = 15  # Multiple random restarts to break local optima\n    best_sum = 0.0\n    best_centers = None\n    best_radii = None\n    n = 26\n\n    for seed in range(n_seeds):\n        np.random.seed(42 + seed)\n\n        centers = np.random.uniform(0.1, 0.9, (n, 2))\n\n        # Seed initial placements heuristically: \n        # bias toward corners and edges to maximize space utilization.\n        corners = [[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]]\n        edges = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n        \n        for i, c in enumerate(corners):\n            centers[i] = c + np.random.normal(0, 0.01, 2)\n        for i, c in enumerate(edges):\n            centers[4 + i] = c + np.random.normal(0, 0.01, 2)\n\n        lr = 0.015\n        n_steps = 1000\n        \n        for step in range(n_steps):\n            # Break perfect symmetry gently during optimization\n            if step < int(n_steps * 0.7):\n                centers += np.random.normal(0, 0.0002 * (1 - step / n_steps), centers.shape)\n\n            diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=2)\n            np.fill_diagonal(dist, np.inf)\n\n            # High exponent maps strongly to hard-sphere potential model limits\n            p = 4.0\n            \n            mask = dist < 0.5\n            f_mag = np.zeros_like(dist)\n            valid_dist = np.maximum(dist[mask], 1e-4)\n            f_mag[mask] = 1.0 / (valid_dist ** p)\n\n            # Apply mutually repelling inter-circle forces\n            dir_norm = dist + 1e-12\n            f_others = np.sum((diff / dir_norm[:, :, np.newaxis]) * f_mag[:, :, np.newaxis], axis=1)\n\n            # Apply domain wall repulsion forces safely\n            safe_c_x = np.clip(centers[:, 0], 1e-4, 1.0 - 1e-4)\n            safe_c_y = np.clip(centers[:, 1], 1e-4, 1.0 - 1e-4)\n\n            w_lower_x = 1.0 / (safe_c_x ** p)\n            w_upper_x = -1.0 / ((1.0 - safe_c_x) ** p)\n            w_lower_y = 1.0 / (safe_c_y ** p)\n            w_upper_y = -1.0 / ((1.0 - safe_c_y) ** p)\n\n            f_walls = np.zeros_like(centers)\n            f_walls[:, 0] = w_lower_x + w_upper_x\n            f_walls[:, 1] = w_lower_y + w_upper_y\n\n            total_force = f_others + f_walls\n\n            f_limit = 10.0\n            f_norm = np.linalg.norm(total_force, axis=1)\n            scale = np.where(f_norm > f_limit, f_limit / (f_norm + 1e-12), 1.0)\n            total_force *= scale[:, np.newaxis]\n\n            # Decaying annealing to allow fine settling\n            current_lr = lr * (0.99 ** (step / 10.0))\n            if current_lr < 0.0005:\n                current_lr = 0.0005\n\n            centers += total_force * current_lr\n            centers = np.clip(centers, 0.001, 0.999)\n\n        r = compute_max_radii(centers)\n        current_sum = np.sum(r)\n\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = centers.copy()\n            best_radii = r.copy()\n\n    return best_centers, best_radii, best_sum\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Computes valid radii efficiently maximizing combined target allocations.\n    Replaces static iterative shrinkage bounded to arrays ordering \n    with dynamic continuous area utilization resolving constraint overlap.\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n\n    Returns:\n        np.array of shape (n) with radius of each circle strictly guaranteeing limit compliance\n    \"\"\"\n    n = centers.shape[0]\n    r = np.zeros(n)\n    \n    # Calculate extreme permissible domain constraint per coordinate wall \n    max_w = np.array([min(c[0], 1 - c[0], c[1], 1 - c[1]) for c in centers])\n\n    diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n    dists = np.linalg.norm(diff, axis=2)\n    np.fill_diagonal(dists, np.inf)\n\n    active = np.ones(n, dtype=bool)\n    dr = 0.0005\n\n    # Rapid simulated allocation allowing tight corner compression packing dynamically limits radii bounding \n    for _ in range(2000):\n        if not np.any(active):\n            break\n\n        r[active] += dr\n\n        # Exceeded max frame constraints -> strictly stop sizing\n        wall_mask = r > max_w\n        if np.any(wall_mask):\n            r[wall_mask] = max_w[wall_mask]\n            active[wall_mask] = False\n\n        r_sum = r[:, np.newaxis] + r[np.newaxis, :]\n        collisions = r_sum > dists + 1e-9  # Margin blocks minor frame oscillations  \n\n        if np.any(collisions):\n            rows, cols = np.where(collisions)\n            for i, j in zip(rows, cols):\n                if active[i] or active[j]:\n                    overlap = r[i] + r[j] - dists[i, j]\n                    \n                    if active[i] and active[j]:\n                        r[i] -= overlap / 2.0\n                        r[j] -= overlap / 2.0\n                        active[i] = False\n                        active[j] = False\n                    elif active[i]:\n                        r[i] -= overlap\n                        active[i] = False\n                    elif active[j]:\n                        r[j] -= overlap\n                        active[j] = False\n\n    # Assured hard numeric pass explicitly resolves slop bounds perfectly assuring strictly valid format guarantees\n    r = np.clip(r, 0.0, max_w)\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            d = dists[i, j]\n            if r[i] + r[j] > d:\n                # Retains sub-epsilon compliance tolerance gap ensuring safety below bounding logic criteria\n                scale = d / (r[i] + r[j]) * 0.9999999 \n                r[i] *= scale\n                r[j] *= scale\n\n    return r\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles within a 1x1 square\n    to maximize the sum of their radii via a simulated physical expansion system.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n, best_sum, best_pos, best_r = 26, -1.0, None, None\n    \n    # Iterate across multiple configuration seeds sequentially preventing convergence in single local minima\n    for seed in range(7):\n        np.random.seed(42 + seed)\n        r = np.random.uniform(0.01, 0.12, n)\n        r[::-1].sort()  # Assign the initial maximum radii cleanly enabling central growth expansion\n        \n        # Strategic starting layout structurally positioning heavy entities neutrally to reduce immediate geometric locks\n        pos = np.random.uniform(0.1, 0.9, (n, 2))\n        pos[0] = [0.5 + np.random.randn() * 0.01, 0.5 + np.random.randn() * 0.01]\n        \n        # Guide smaller spheres explicitly towards extremities natively accommodating empty spaces smoothly\n        for i, (dx, dy) in enumerate([[-1, -1], [1, -1], [-1, 1], [1, 1]]):\n            pos[n - 4 + i] = [0.5 + 0.45 * dx, 0.5 + 0.45 * dy]\n        \n        # Simulate an iterative expansion matrix dynamically adjusting overlaps leveraging standard Adam momentum forces\n        m_p, v_p = np.zeros_like(pos), np.zeros_like(pos)\n        m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n        \n        T = 2200\n        for step in range(1, T + 1):\n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1) + 1e-12\n            np.fill_diagonal(dist, 100.0)\n            \n            # Formulate overlap constraints naturally penalizing overlapping bounds smoothly ensuring separation \n            overlap = np.maximum(0, r[:, np.newaxis] + r[np.newaxis, :] - dist)\n            np.fill_diagonal(overlap, 0.0)\n            \n            w_left = np.maximum(0, r - pos[:, 0])\n            w_right = np.maximum(0, r - (1 - pos[:, 0]))\n            w_bot = np.maximum(0, r - pos[:, 1])\n            w_top = np.maximum(0, r - (1 - pos[:, 1]))\n            \n            # Progressively harden exclusivity strictly solidifying overlapping intersections preventing breaches steadily \n            K = 5.0 * (8000.0 ** (step / float(T)))\n            \n            # Map descent scalar forces structurally directly matching constraint deviations seamlessly\n            grad_p = -2 * K * np.sum(overlap[..., np.newaxis] * (diff / dist[..., np.newaxis]), axis=1)\n            grad_p[:, 0] += 2 * K * (-w_left + w_right)\n            grad_p[:, 1] += 2 * K * (-w_bot + w_top)\n            \n            # Gradient pulls naturally scaling continuous sizes outward against penalties balancing dynamically  \n            grad_r = -1.0 + 2 * K * (np.sum(overlap, axis=1) + w_left + w_right + w_bot + w_top)\n            \n            lr_p = 1e-4 + 0.5 * 0.012 * (1 + np.cos(np.pi * step / T))\n            lr_r = 1e-4 + 0.5 * 0.005 * (1 + np.cos(np.pi * step / T))\n            \n            # State vector standard processing utilizing gradient accumulations stably smoothing step magnitudes cleanly\n            m_p = 0.9 * m_p + 0.1 * grad_p\n            v_p = 0.999 * v_p + 0.001 * grad_p**2\n            pos -= lr_p * (m_p / (1 - 0.9**step)) / (np.sqrt(v_p / (1 - 0.999**step)) + 1e-8)\n            \n            m_r = 0.9 * m_r + 0.1 * grad_r\n            v_r = 0.999 * v_r + 0.001 * grad_r**2\n            r -= lr_r * (m_r / (1 - 0.9**step)) / (np.sqrt(v_r / (1 - 0.999**step)) + 1e-8)\n            \n            # Perturb heavily actively shaking configurations avoiding localized stalling patterns uniformly\n            if step < 0.65 * T:\n                noise = 0.0015 * (1 - step / (0.65 * T))\n                pos += np.random.normal(0, noise, pos.shape)\n                r += np.random.normal(0, noise * 0.05, r.shape)\n            \n            pos = np.clip(pos, 1e-5, 1 - 1e-5)\n            r = np.clip(r, 1e-5, 0.5)\n\n        # Eliminate trace inconsistencies fully conforming variables definitively guaranteeing geometry robustness  \n        r_clean = np.copy(r)\n        for _ in range(500):\n            r_clean = np.minimum(r_clean, pos[:, 0])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n            r_clean = np.minimum(r_clean, pos[:, 1])\n            r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n            \n            diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n            dist = np.linalg.norm(diff, axis=-1)\n            np.fill_diagonal(dist, 100.0)\n            \n            overlap = r_clean[:, np.newaxis] + r_clean[np.newaxis, :] - dist\n            if np.max(overlap) <= 1e-12:\n                break\n                \n            i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n            d_ij = dist[i, j]\n            tr = r_clean[i] + r_clean[j]\n            if tr > d_ij:\n                scale = (d_ij / tr) - 1e-12\n                r_clean[i] *= scale\n                r_clean[j] *= scale\n        \n        # Verify explicitly preventing overlaps universally assuring metric compliance strictly definitively\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(pos[i] - pos[j]) + 1e-15\n                if r_clean[i] + r_clean[j] > d:\n                    sc = d / (r_clean[i] + r_clean[j]) - 1e-12\n                    r_clean[i] *= sc\n                    r_clean[j] *= sc\n                    \n        r_clean = np.minimum(r_clean, pos[:, 0])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 0])\n        r_clean = np.minimum(r_clean, pos[:, 1])\n        r_clean = np.minimum(r_clean, 1 - pos[:, 1])\n        \n        current_sum = float(np.sum(r_clean))\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_pos = pos.copy()\n            best_r = r_clean.copy()\n\n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef optimize_batches(B, n, T):\n    \"\"\"\n    Executes an aggressively batched gradient optimization natively executing simultaneously across highly\n    diversified spatial initialization clusters maximizing geometrical packing efficiencies optimally.\n    \"\"\"\n    pos = np.zeros((B, n, 2))\n    r = np.zeros((B, n))\n\n    # Initialization generating distinct mathematical permutations accurately discovering maximally mapped geometries\n    for b in range(B):\n        np.random.seed(314 + b)\n        curr_r = np.random.uniform(0.04, 0.16, n)\n        curr_r[::-1].sort()\n        r[b] = curr_r\n        \n        pos_b = np.zeros((n, 2))\n        topo_id = b % 10\n        \n        if topo_id == 0:\n            pos_b[0] = [0.5, 0.5]\n            for i in range(1, 6): pos_b[i] = [0.5 + 0.16*np.cos(i*np.pi*2/5), 0.5 + 0.16*np.sin(i*np.pi*2/5)]\n            for i in range(6, 16): pos_b[i] = [0.5 + 0.32*np.cos(i*np.pi*2/10), 0.5 + 0.32*np.sin(i*np.pi*2/10)]\n            for i in range(16, 26): pos_b[i] = [0.5 + 0.44*np.cos(i*np.pi*2/10), 0.5 + 0.44*np.sin(i*np.pi*2/10)]\n        elif topo_id == 1:\n            idx = 0\n            for count, y in zip([5, 6, 4, 6, 5], np.linspace(0.1, 0.9, 5)):\n                for x in np.linspace(0.1, 0.9, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 2:\n            for i in range(n):\n                a = i * 2.39996\n                rad = 0.05 + i * 0.016\n                pos_b[i] = [0.5 + rad*np.cos(a), 0.5 + rad*np.sin(a)]\n        elif topo_id == 3:\n            pos_b = np.random.uniform(0.1, 0.9, (n, 2))\n            pos_b[0:4] = [[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]]\n            pos_b[4:8] = [[0.5, 0.05], [0.5, 0.95], [0.05, 0.5], [0.95, 0.5]]\n        elif topo_id == 4:\n            idx = 0\n            for count, y in zip([6, 4, 6, 4, 6], np.linspace(0.1, 0.9, 5)):\n                for x in np.linspace(0.1, 0.9, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 5:\n            idx = 0\n            for count, y in zip([5, 5, 6, 5, 5], np.linspace(0.08, 0.92, 5)):\n                for x in np.linspace(0.08, 0.92, count):\n                    pos_b[idx] = [x, y]\n                    idx += 1\n        elif topo_id == 6:\n            for i in range(8): pos_b[i] = [0.1 + 0.8*(i % 2), 0.1 + (i // 2)*0.25]\n            for i in range(8, 26): pos_b[i] = [np.random.uniform(0.2, 0.8), np.random.uniform(0.1, 0.9)]\n        elif topo_id == 7:\n            for i in range(12): pos_b[i] = [0.5 + 0.4*np.cos(i*np.pi/6), 0.5 + 0.4*np.sin(i*np.pi/6)]\n            for i in range(12, 20): pos_b[i] = [0.5 + 0.2*np.cos(i*np.pi/4), 0.5 + 0.2*np.sin(i*np.pi/4)]\n            pos_b[20:] = np.random.uniform(0.3, 0.7, (6, 2))\n        elif topo_id == 8:\n            pos_b = np.random.uniform(0.05, 0.95, (n, 2))\n            pos_b[0] = [0.5, 0.5]\n            pos_b[1:5] = [[0.06, 0.06], [0.94, 0.06], [0.06, 0.94], [0.94, 0.94]]\n        elif topo_id == 9:\n            idx = 0\n            for center_c in [[0.25, 0.25], [0.75, 0.25], [0.25, 0.75], [0.75, 0.75], [0.5, 0.5]]:\n                for _ in range(5):\n                    pos_b[idx] = center_c\n                    idx += 1\n            pos_b[25] = [0.5, 0.1]\n            \n        pos_b += np.random.normal(0, 0.015, (n, 2))\n        pos[b] = np.clip(pos_b, 0.02, 0.98)\n\n    # Natively precomputing mathematical exponential and scaling coefficients maximizing cycle efficency completely\n    steps = np.arange(T)\n    cos_val = 1 + np.cos(np.pi * steps / T)\n    K_arr = 10.0 * (10000.0) ** (steps / (T - 1.0))\n    lr_pos_arr = 1e-4 + 0.5 * (0.012 - 1e-4) * cos_val\n    lr_r_arr = 1e-5 + 0.5 * (0.005 - 1e-5) * cos_val\n\n    active_steps = int(T * 0.7)\n    noise_pos_arr = np.zeros(T)\n    noise_pos_arr[:active_steps] = 0.001 * (1 - np.arange(active_steps) / active_steps)\n    noise_r_arr = noise_pos_arr * 0.05\n\n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    m_pos, v_pos = np.zeros_like(pos), np.zeros_like(pos)\n    m_r, v_r = np.zeros_like(r), np.zeros_like(r)\n\n    # Core physics optimization vectorized resolving boundaries seamlessly reliably\n    for step in range(T):\n        diff = pos[:, :, np.newaxis, :] - pos[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1) + 1e-12\n        dist[:, np.arange(n), np.arange(n)] = 100.0\n        \n        overlap = r[:, :, np.newaxis] + r[:, np.newaxis, :] - dist\n        np.maximum(0, overlap, out=overlap)\n        \n        left_ov = r - pos[..., 0]\n        np.maximum(0, left_ov, out=left_ov)\n        right_ov = r - (1 - pos[..., 0])\n        np.maximum(0, right_ov, out=right_ov)\n        bottom_ov = r - pos[..., 1]\n        np.maximum(0, bottom_ov, out=bottom_ov)\n        top_ov = r - (1 - pos[..., 1])\n        np.maximum(0, top_ov, out=top_ov)\n        \n        K = K_arr[step]\n        \n        grad_r = np.sum(overlap, axis=2)\n        grad_r += left_ov + right_ov + bottom_ov + top_ov\n        grad_r *= (2 * K)\n        grad_r -= 1.0\n        \n        direction = diff / dist[..., np.newaxis]\n        grad_pos = np.sum(overlap[..., np.newaxis] * direction, axis=2)\n        grad_pos *= (-2 * K)\n        \n        grad_pos[..., 0] += 2 * K * (-left_ov + right_ov)\n        grad_pos[..., 1] += 2 * K * (-bottom_ov + top_ov)\n        \n        m_pos = beta1 * m_pos + (1 - beta1) * grad_pos\n        v_pos = beta2 * v_pos + (1 - beta2) * (grad_pos ** 2)\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        \n        b1_t = 1 - beta1 ** (step + 1)\n        b2_t = 1 - beta2 ** (step + 1)\n        \n        m_hat_pos = m_pos / b1_t\n        v_hat_pos = v_pos / b2_t\n        m_hat_r = m_r / b1_t\n        v_hat_r = v_r / b2_t\n        \n        pos -= lr_pos_arr[step] * m_hat_pos / (np.sqrt(v_hat_pos) + eps)\n        r -= lr_r_arr[step] * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        if noise_pos_arr[step] > 0:\n            pos += np.random.normal(0, noise_pos_arr[step], pos.shape)\n            r += np.random.normal(0, noise_r_arr[step], r.shape)\n            \n        np.clip(pos, 0.001, 0.999, out=pos)\n        np.clip(r, 0.001, 0.5, out=r)\n        \n    return pos, r\n\n\ndef fix_and_expand_radii(pos, r):\n    \"\"\"\n    Absolutely solidifies domain limiting validating constraint boundaries fully explicitly.\n    Additionally incorporates incrementally cascading expansion scales cleanly sealing internal voids precisely.\n    \"\"\"\n    n = len(r)\n    # Strictly bind limits seamlessly securely dynamically\n    for _ in range(300):\n        r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n        \n        diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        overlap = r[:, np.newaxis] + r[np.newaxis, :] - dist\n        if np.max(overlap) <= 1e-12:\n            break\n            \n        i, j = np.unravel_index(np.argmax(overlap), overlap.shape)\n        d_ij = dist[i, j]\n        tr = r[i] + r[j]\n        if tr > d_ij:\n            scale = (d_ij / tr) - 1e-12\n            r[i] *= scale\n            r[j] *= scale\n\n    # Reevaluate mapping mathematical distances natively correctly\n    diff = pos[:, np.newaxis, :] - pos[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    np.fill_diagonal(dist, np.inf)\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            d_ij = dist[i, j]\n            if r[i] + r[j] > d_ij:\n                scale = d_ij / (r[i] + r[j]) - 1e-12\n                r[i] *= scale\n                r[j] *= scale\n                \n    r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n\n    # Broad to fine incremental expansion maximizing tight geometric pockets elegantly\n    dr_scales = [0.002, 0.0002, 0.00002, 0.000002]\n    \n    for dr in dr_scales:\n        active = np.ones(n, dtype=bool)\n        for _ in range(1200):\n            if not np.any(active):\n                break\n                \n            r[active] += dr\n            \n            wall_fail = (r > pos[:, 0]) | (r > 1 - pos[:, 0]) | \\\n                        (r > pos[:, 1]) | (r > 1 - pos[:, 1])\n            if np.any(wall_fail & active):\n                r[wall_fail & active] -= dr\n                active[wall_fail & active] = False\n                \n            r_sum = r[:, np.newaxis] + r[np.newaxis, :]\n            collisions = r_sum > dist + 1e-11\n            if np.any(collisions):\n                rows, cols = np.where(collisions)\n                for i, j in zip(rows, cols):\n                    if active[i]:\n                        r[i] -= dr\n                        active[i] = False\n                    if active[j]:\n                        r[j] -= dr\n                        active[j] = False\n                        \n    # Safety final clip guaranteeing zero structural validation issues implicitly safely\n    for i in range(n):\n        for j in range(i + 1, n):\n            if r[i] + r[j] > dist[i, j]:\n                sc = dist[i, j] / (r[i] + r[j]) - 1e-14\n                r[i] *= sc\n                r[j] *= sc\n                \n    r = np.minimum.reduce([r, pos[:, 0], 1 - pos[:, 0], pos[:, 1], 1 - pos[:, 1]])\n    return r\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs optimally allocated dense arrangements via massive perfectly batched parallel tensor mapping cleanly.\n    \"\"\"\n    B = 30\n    n = 26\n    T = 3600\n    \n    pos_batched, r_batched = optimize_batches(B, n, T)\n    \n    best_sum = -1.0\n    best_pos = None\n    best_r = None\n    \n    # Iterate resolved geometries determining explicitly the maximal global combination properly naturally cleanly\n    for b in range(B):\n        fixed_r = fix_and_expand_radii(pos_batched[b].copy(), r_batched[b].copy())\n        val = float(np.sum(fixed_r))\n        if val > best_sum:\n            best_sum = val\n            best_pos = pos_batched[b].copy()\n            best_r = fixed_r.copy()\n            \n    return best_pos, best_r, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to significantly higher spatial allocation efficiency.\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"5.88s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.626841/2.635 = 0.9969\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.7% of target value\", \"radius_stats\": \"Min: 0.063911, Max: 0.134086, Avg: 0.101032\"}", "artifact_dir": null, "embedding": null}