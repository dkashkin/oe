{"id": "15582937-8862-45e3-9341-d127cfc66747", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-8, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-9)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1.0 - centers[i, 0], 1.0 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(4000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1.0 - centers[:, 0], \n                                       centers[:, 1], 1.0 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.55\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(100):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-10:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n\ndef polish_slsqp(X, R):\n    \"\"\"\n    Fine-tunes mathematically feasible solutions continuously into strict optima securely.\n    Utilizes localized SLSQP constrained projections precisely smoothly.\n    \"\"\"\n    from scipy.optimize import minimize\n    N = len(R)\n    \n    def obj(p):\n        return -np.sum(p[2*N:])\n        \n    def grad_obj(p):\n        g = np.zeros(3*N)\n        g[2*N:] = -1.0\n        return g\n        \n    bounds = [(1e-7, 1.0 - 1e-7)] * (2*N) + [(0.001, 1.0)] * N\n    \n    def boundary_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        return np.concatenate([\n            X_p - R_p,\n            1.0 - X_p - R_p,\n            Y_p - R_p,\n            1.0 - Y_p - R_p\n        ])\n        \n    def boundary_jac(p):\n        J = np.zeros((4*N, 3*N))\n        idx = np.arange(N)\n        J[idx, idx] = 1.0\n        J[idx, 2*N + idx] = -1.0\n        J[N + idx, idx] = -1.0\n        J[N + idx, 2*N + idx] = -1.0\n        J[2*N + idx, N + idx] = 1.0\n        J[2*N + idx, 2*N + idx] = -1.0\n        J[3*N + idx, N + idx] = -1.0\n        J[3*N + idx, 2*N + idx] = -1.0\n        return J\n\n    def overlap_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dist2 = (X_p[i_idx] - X_p[j_idx])**2 + (Y_p[i_idx] - Y_p[j_idx])**2\n        return dist2 - (R_p[i_idx] + R_p[j_idx])**2\n        \n    def overlap_jac(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        num_pairs = len(i_idx)\n        J = np.zeros((num_pairs, 3*N))\n        \n        dx = X_p[i_idx] - X_p[j_idx]\n        dy = Y_p[i_idx] - Y_p[j_idx]\n        dr = R_p[i_idx] + R_p[j_idx]\n        \n        pair_range = np.arange(num_pairs)\n        J[pair_range, i_idx] = 2.0 * dx\n        J[pair_range, j_idx] = -2.0 * dx\n        J[pair_range, N + i_idx] = 2.0 * dy\n        J[pair_range, N + j_idx] = -2.0 * dy\n        J[pair_range, 2*N + i_idx] = -2.0 * dr\n        J[pair_range, 2*N + j_idx] = -2.0 * dr\n        return J\n\n    cons = [\n        {'type': 'ineq', 'fun': boundary_cons, 'jac': boundary_jac},\n        {'type': 'ineq', 'fun': overlap_cons, 'jac': overlap_jac}\n    ]\n    \n    p0 = np.concatenate([X[:, 0], X[:, 1], R])\n    try:\n        res = minimize(\n            obj, p0, method='SLSQP', jac=grad_obj, bounds=bounds,\n            constraints=cons, options={'maxiter': 500, 'ftol': 1e-7}\n        )\n        p = res.x\n    except Exception:\n        p = p0\n        \n    X_fin = np.column_stack((p[:N], p[N:2*N]))\n    R_fin = p[2*N:]\n    return X_fin, R_fin\n\n\ndef generate_seeds(B, n):\n    \"\"\"\n    Generates diverse set of layout seed structures securely avoiding identical minima.\n    \"\"\"\n    X_init = np.zeros((B, n, 2))\n    np.random.seed(427)\n    for b in range(B):\n        mode = b % 8\n        pts = []\n        if mode == 0:\n            for x in np.linspace(0.12, 0.88, 5):\n                for y in np.linspace(0.12, 0.88, 5):\n                    pts.append([x, y])\n            pts.append([0.5, 0.5])\n        elif mode == 1:\n            pts.append([0.5, 0.5])\n            for i in range(7):\n                a = 2 * np.pi * i / 7\n                pts.append([0.5 + 0.18*np.cos(a), 0.5 + 0.18*np.sin(a)])\n            for i in range(18):\n                a = 2 * np.pi * i / 18\n                pts.append([0.5 + 0.4*np.cos(a), 0.5 + 0.4*np.sin(a)])\n        elif mode == 2:\n            for t in np.linspace(0.05, 0.95, 6):\n                pts.extend([[t, 0.05], [t, 0.95]])\n            for t in np.linspace(0.23, 0.77, 4):\n                pts.extend([[0.05, t], [0.95, t]])\n        elif mode == 3:\n            for i in range(n):\n                r = 0.45 * np.sqrt(i / (n - 1.0))\n                theta = i * 2.3999632\n                pts.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n        elif mode == 4:\n            for _ in range(n):\n                pts.append(np.random.uniform(0.08, 0.92, 2))\n        elif mode == 5:\n            dx = 0.14\n            dy = 0.16\n            for ir, cnt in enumerate([5, 6, 5, 6, 4]):\n                y = 0.15 + ir * dy\n                offset = 0 if ir % 2 == 0 else -dx/2\n                cx = 0.5 - (cnt - 1) * dx / 2 - offset\n                for ic in range(cnt):\n                    x = cx + offset + ic * dx\n                    pts.append([x, y])\n        elif mode == 6:\n            pts.extend([[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]])\n            for i in range(12):\n                a = 2 * np.pi * i / 12\n                pts.append([0.5 + 0.38*np.cos(a), 0.5 + 0.38*np.sin(a)])\n            for i in range(10):\n                a = 2 * np.pi * i / 10\n                pts.append([0.5 + 0.2*np.cos(a), 0.5 + 0.2*np.sin(a)])\n        elif mode == 7:\n            for i in range(4):\n                a = 2 * np.pi * i / 4 + np.pi/4\n                pts.append([0.5 + 0.1*np.cos(a), 0.5 + 0.1*np.sin(a)])\n            for i in range(8):\n                a = 2 * np.pi * i / 8\n                pts.append([0.5 + 0.25*np.cos(a), 0.5 + 0.25*np.sin(a)])\n            for i in range(14):\n                a = 2 * np.pi * i / 14\n                pts.append([0.5 + 0.42*np.cos(a), 0.5 + 0.42*np.sin(a)])\n        \n        arr = np.array(pts)\n        if len(arr) < n:\n            rem = n - len(arr)\n            arr = np.vstack([arr, np.random.uniform(0.1, 0.9, (rem, 2))])\n        X_init[b] = arr[:n]\n    \n    noises = np.linspace(0.001, 0.03, 5)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noises[b // 8]\n        \n    return np.clip(X_init, 0.05, 0.95)\n\n\ndef run_physics_simulations(B, n, steps):\n    \"\"\"\n    Simultaneously accelerates robust convergence applying Adam optimizer correctly geometrically smoothly.\n    \"\"\"\n    X = generate_seeds(B, n)\n    R = np.full((B, n), 0.04)\n    R += np.random.uniform(-0.01, 0.01, (B, n))\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    idx = np.arange(n)\n    \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.012 * (1.0 - progress) + 0.0005\n        \n        # Anneal parameter dynamically forces locking geometries efficiently\n        C = 10.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-12)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap[:, idx, idx] = -1.0 \n        \n        overlap_vals = np.maximum(0, overlap)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0 \n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1.0 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1.0 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.35:\n            noise_scale = 0.02 * (1.0 - progress / 0.35)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / (1.0 - beta1 ** step)\n        v_X_hat = v_X / (1.0 - beta2 ** step)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / (1.0 - beta1 ** step)\n        v_R_hat = v_R / (1.0 - beta2 ** step)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0.0, 1.0)\n        R = np.maximum(R, 0.005)\n        \n    return X\n\n\ndef construct_packing():\n    \"\"\"\n    Main constructor routing generating strictly optimal geometric structures maximally safely exactly.\n    \"\"\"\n    B = 40\n    N = 26\n    X_candidates = run_physics_simulations(B, N, steps=2800)\n    \n    scored_candidates = []\n    for b in range(B):\n        R_exact = compute_max_radii(X_candidates[b])\n        score = np.sum(R_exact)\n        scored_candidates.append((score, X_candidates[b], R_exact))\n        \n    scored_candidates.sort(key=lambda item: item[0], reverse=True)\n    \n    best_X = None\n    best_R = None\n    best_score = -1.0\n    \n    # Process extreme elite layouts natively executing maximum exact refinements seamlessly\n    for score, X_val, R_val in scored_candidates[:5]:\n        X_p, R_p = polish_slsqp(X_val, R_val)\n        X_p = np.clip(X_p, 1e-7, 1.0 - 1e-7) \n        \n        R_fin = compute_max_radii(X_p)\n        fin_score = np.sum(R_fin)\n        \n        if fin_score > best_score:\n            best_score = fin_score\n            best_X = X_p\n            best_R = R_fin\n            \n    return best_X, best_R, best_score\n\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "c5b31d83-649e-482f-9ebf-59db4ef5991b", "generation": 3, "timestamp": 1771993711.9728942, "iteration_found": 24, "metrics": {"validity": 1.0, "sum_radii": 2.630562284773481, "target_ratio": 0.9983158575990442, "combined_score": 0.9983158575990442, "radius_variance": 0.0050117640665009395, "spatial_spread": 0.19857253549382003, "eval_time": 6.157000780105591}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.5530607460102965, "target_ratio": 0.9689035089223138, "combined_score": 0.9689035089223138, "radius_variance": 0.005120560108542859, "spatial_spread": 0.20332271895157744, "eval_time": 12.481019973754883}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9689\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.9712 \u2192 0.9689. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n12.48s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.553061/2.635 = 0.9689\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 96.9% of target value\n```\n\n### radius_stats\n```\nMin: 0.061096, Max: 0.130508, Avg: 0.098195\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5592, target_ratio: 0.9712, combined_score: 0.9712, radius_variance: 0.0058, spatial_spread: 0.2021, eval_time: 6.4081\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6116, target_ratio: 0.9911, combined_score: 0.9911, radius_variance: 0.0061, spatial_spread: 0.1869, eval_time: 5.1508\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6355, target_ratio: 1.0002, combined_score: 1.0002, radius_variance: 0.0045, spatial_spread: 0.1884, eval_time: 3.6588\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.0002)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a heavily optimized arrangement of 26 circles in a unit square\n    that tightly maximizes the sum of their radii via simulated annealing physics.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Run a continuous restart scheme to traverse and select best optimal geometries\n    for seed in range(12):\n        X = optimize_seed(seed)\n        final_radii = compute_max_radii(X)\n        score = np.sum(final_radii)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X\n            best_radii = final_radii\n            \n    return best_centers, best_radii, best_sum\n\n\ndef optimize_seed(seed):\n    \"\"\"Executes gradient ascent physical optimizer applying non-linear repulsions\"\"\"\n    n = 26\n    np.random.seed(seed * 42 + 7)\n    X = []\n    \n    # Generate structural layout biases targeting interstitial properties \n    if seed % 4 == 0:\n        grid = np.linspace(0.1, 0.9, 5)\n        for x in grid:\n            for y in grid:\n                X.append([x, y])\n        X.append([0.5, 0.5])\n    elif seed % 4 == 1:\n        X.append([0.5, 0.5])\n        for i in range(7):\n            a = 2 * np.pi * i / 7\n            X.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        for i in range(18):\n            a = 2 * np.pi * i / 18\n            X.append([0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)])\n    elif seed % 4 == 2:\n        # Bias boundaries strategically\n        X.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n        for t in np.linspace(0.2, 0.8, 4):\n            X.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n        for _ in range(n - len(X)):\n            X.append(np.random.uniform(0.2, 0.8, 2).tolist())\n    else:\n        # Radial symmetry fibonacci break layout \n        for i in range(n):\n            r = 0.45 * np.sqrt((i + 1) / float(n))\n            theta = i * 2.3999632\n            X.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n            \n    # Apply thermal random breaks ensuring robust positional gradient responses\n    X = np.array(X)[:n] + np.random.randn(n, 2) * 0.005\n    X = np.clip(X, 0.02, 0.98)\n    \n    R = np.full(n, 0.06)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 2200\n    \n    # Advanced gradient scheduling simulated layout physics settling iterations\n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.005 * (1.0 - progress) + 0.0002\n        \n        # Exponential penalization scaling solidifying boundary geometries gracefully\n        C = 5.0 * (2000.0 ** progress)\n        \n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        \n        overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, -1.0)\n        overlap_vals = overlap * (overlap > 0)\n        \n        grad_X = np.zeros_like(X)\n        grad_R = np.full(n, -1.0)\n        \n        # Dynamic internal forces generated inversely proportional towards interstitial gaps \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X += np.sum(factor[:, :, np.newaxis] * diff, axis=1)\n        grad_R += np.sum(2.0 * C * overlap_vals, axis=1)\n        \n        w_l = np.maximum(0, R - X[:, 0])\n        w_r = np.maximum(0, R - (1 - X[:, 0]))\n        w_b = np.maximum(0, R - X[:, 1])\n        w_t = np.maximum(0, R - (1 - X[:, 1]))\n        \n        grad_X[:, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        # Anneal structural constraints breaking edge symmetry lock-ups securely\n        if step < steps * 0.35:\n            grad_X += np.random.randn(n, 2) * 0.03 * (1.0 - step / (steps * 0.35))\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        X -= lr_base * (m_X / (1 - beta1 ** step)) / (np.sqrt(v_X / (1 - beta2 ** step)) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        R -= lr_base * (m_R / (1 - beta1 ** step)) / (np.sqrt(v_R / (1 - beta2 ** step)) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n        \n    return X\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized strict distributions securely enforcing non-overlap, \n    evaluating geometrical capabilities resiliently without user sequencing prejudice.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical attempt evaluating precise extreme maximum geometric boundaries limits\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(0.0, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable dynamic geometric compression graceful-recovery fallback\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Assured residual overlap removal phase mathematically assuring clean submission states\n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6355), Performs well on target_ratio (1.0002), Performs well on combined_score (1.0002), Performs well on radius_variance (0.0045), Performs well on spatial_spread (0.1884), Performs well on eval_time (3.6588)\n\n### Program 2 (Score: 0.9911)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\nfrom scipy.optimize import minimize\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages to create proper layouts.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # Maximize sum(R) -> Equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime mathematically,\n    shrinking only physically colliding or bound-infringing objects efficiently.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(int(idx), N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring absolute float-truncation constraint truth\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding entirely offsets precision drift\n    \n    return X, Y, R\n\n\ndef polish_slsqp(X, Y, R):\n    \"\"\"\n    Fine-tunes mathematically feasible solutions continuously into strict optima.\n    Utilizes localized L-BFGS constrained projections heavily pushing radius magnitudes upwards\n    towards maximum configuration geometries smoothly against identical local configurations.\n    \"\"\"\n    N = len(R)\n    \n    def obj(p):\n        return -np.sum(p[2*N:])\n        \n    def grad_obj(p):\n        g = np.zeros(3*N)\n        g[2*N:] = -1.0\n        return g\n        \n    bounds = [(0.0, 1.0)] * (2*N) + [(0.001, 1.0)] * N\n    \n    def boundary_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        return np.concatenate([\n            X_p - R_p,\n            1.0 - X_p - R_p,\n            Y_p - R_p,\n            1.0 - Y_p - R_p\n        ])\n        \n    def boundary_jac(p):\n        J = np.zeros((4*N, 3*N))\n        idx = np.arange(N)\n        # Vectorized assignment representing explicit border constraint components respectively\n        J[idx, idx] = 1.0\n        J[idx, 2*N + idx] = -1.0\n        J[N + idx, idx] = -1.0\n        J[N + idx, 2*N + idx] = -1.0\n        J[2*N + idx, N + idx] = 1.0\n        J[2*N + idx, 2*N + idx] = -1.0\n        J[3*N + idx, N + idx] = -1.0\n        J[3*N + idx, 2*N + idx] = -1.0\n        return J\n\n    def overlap_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dist2 = (X_p[i_idx] - X_p[j_idx])**2 + (Y_p[i_idx] - Y_p[j_idx])**2\n        return dist2 - (R_p[i_idx] + R_p[j_idx])**2\n        \n    def overlap_jac(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        num_pairs = len(i_idx)\n        J = np.zeros((num_pairs, 3*N))\n        \n        dx = X_p[i_idx] - X_p[j_idx]\n        dy = Y_p[i_idx] - Y_p[j_idx]\n        dr = R_p[i_idx] + R_p[j_idx]\n        \n        pair_range = np.arange(num_pairs)\n        J[pair_range, i_idx] = 2.0 * dx\n        J[pair_range, j_idx] = -2.0 * dx\n        J[pair_range, N + i_idx] = 2.0 * dy\n        J[pair_range, N + j_idx] = -2.0 * dy\n        J[pair_range, 2*N + i_idx] = -2.0 * dr\n        J[pair_range, 2*N + j_idx] = -2.0 * dr\n        return J\n\n    cons = [\n        {'type': 'ineq', 'fun': boundary_cons, 'jac': boundary_jac},\n        {'type': 'ineq', 'fun': overlap_cons, 'jac': overlap_jac}\n    ]\n    \n    p0 = np.concatenate([X, Y, R])\n    res = minimize(\n        obj, p0, method='SLSQP', jac=grad_obj, bounds=bounds,\n        constraints=cons, options={'maxiter': 400, 'ftol': 1e-6}\n    )\n    \n    p = res.x\n    return p[:N], p[N:2*N], p[2*N:]\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing optimization combined with distinct symmetry-breaking seeds.\n    Final solutions iteratively passed through deterministic physical expansion maximizations utilizing SQP bounds mapping natively.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    num_runs = 16\n    N = 26\n    candidates = []\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Sequentially map distinctly varied geometric layout arrangements forcing extensive diverse searches initially\n        X_init, Y_init = [], []\n        if run % 4 == 0:\n            X_init.extend([0.05, 0.95, 0.05, 0.95])\n            Y_init.extend([0.05, 0.05, 0.95, 0.95])\n            for _ in range(N - 4):\n                X_init.append(np.random.uniform(0.1, 0.9))\n                Y_init.append(np.random.uniform(0.1, 0.9))\n        elif run % 4 == 1:\n            for _ in range(N):\n                X_init.append(np.random.uniform(0.05, 0.95))\n                Y_init.append(np.random.uniform(0.05, 0.95))\n        elif run % 4 == 2:\n            n_outer = 12\n            for i in range(n_outer):\n                th = 2 * np.pi * i / n_outer\n                X_init.append(0.5 + 0.38 * np.cos(th))\n                Y_init.append(0.5 + 0.38 * np.sin(th))\n            for _ in range(N - n_outer):\n                X_init.append(np.random.uniform(0.25, 0.75))\n                Y_init.append(np.random.uniform(0.25, 0.75))\n        else:\n            grid_dim = int(np.ceil(np.sqrt(N)))\n            for i in range(N):\n                r_pos = i // grid_dim\n                c_pos = i % grid_dim\n                X_init.append(0.1 + 0.8 * r_pos / max(1, grid_dim - 1))\n                Y_init.append(0.1 + 0.8 * c_pos / max(1, grid_dim - 1))\n            \n        X = np.array(X_init[:N])\n        Y = np.array(Y_init[:N])\n        \n        if run % 2 == 0:\n            dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n            R = 0.06 - 0.04 * dist_c\n        else:\n            R = np.random.uniform(0.02, 0.06, N)\n        \n        # Adaptive gradient descent hyperparameters structurally locking positions down gracefully.\n        num_steps = 2000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        c_t = 10.0\n        c_max = 500000.0 \n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter dynamically preventing edge-constraint trapping effectively natively\n            if t % 300 == 0 and t < 1200:\n                X += np.random.normal(0, 0.002, N)\n                Y += np.random.normal(0, 0.002, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds cleanly formatting true feasibility states conditionally ready to deploy strictly via refinement\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        candidates.append((np.sum(R_val), X_val, Y_val, R_val))\n\n    # Evaluate sequentially expanding potential utilizing the absolute mathematically precise bound solver directly.\n    candidates.sort(key=lambda x: x[0], reverse=True)\n    \n    # Process only the highest-potential configuration distributions saving overhead structurally ensuring high maximization.\n    for score, X_val, Y_val, R_val in candidates[:10]:\n        X_p, Y_p, R_p = polish_slsqp(X_val, Y_val, R_val)\n        \n        # Reinforcing strict constraints to prevent trace float inaccuracies in automated boundary validations inherently guaranteeing robustness perfectly.\n        X_fin, Y_fin, R_fin = make_valid(X_p, Y_p, R_p)\n        fin_sum = np.sum(R_fin)\n        \n        if fin_sum > best_sum:\n            best_sum = fin_sum\n            best_X = X_fin\n            best_Y = Y_fin\n            best_R = R_fin\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6116), Performs well on target_ratio (0.9911), Performs well on combined_score (0.9911), Performs well on radius_variance (0.0061), Performs well on spatial_spread (0.1869), Performs well on eval_time (5.1508)\n\n### Program 3 (Score: 0.9712)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # We want to maximize sum(R), equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    # Penalty ensures circles are fully inside bounds: x-r > 0 => r-x < 0\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards ensuring safety from duplicate division\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime,\n    maintaining position arrangement whilst shrinking only clashing constraints linearly.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(idx, N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring float-truncation exactness\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding prevents floating inequalities on the boundary test wrapper\n    \n    return X, Y, R\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing combined with an explicit multistart unconstrained optimizer.\n    Generates varied topology arrangements natively. \n    Larger target sizes start centrally to create hierarchal Apollonian filling dynamics.\n    \n    Returns:\n        centers, radii, sum_radii safely inside all non-overlapping domain thresholds.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    # Extremely robust multistart optimization setup guaranteeing globally resilient optima \n    num_runs = 15\n    N = 26\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Bias placements spatially \n        X_init, Y_init = [], []\n        # Assign seed layout for space efficiency handling edges natively\n        X_init.extend([0.05, 0.95, 0.05, 0.95])\n        Y_init.extend([0.05, 0.05, 0.95, 0.95])\n        \n        # Sequentially scatter randomized fillers\n        for _ in range(N - 4):\n            X_init.append(np.random.uniform(0.1, 0.9))\n            Y_init.append(np.random.uniform(0.1, 0.9))\n            \n        X = np.array(X_init)\n        Y = np.array(Y_init)\n        \n        # Target assignment explicitly favoring centered bodies to push corner circles into tight spaces\n        dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n        R = 0.06 - 0.04 * dist_c\n        \n        # Smooth simulated annealing learning constraints configuration\n        num_steps = 3000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        # Exponent continuation approach forcing parameters tightly on penalty limits towards end\n        c_t = 10.0\n        c_max = 2000000.0\n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            # Adam descent exponentially decreasing standard learning threshold smoothly locking configurations\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            # Step updates safely parameterized\n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter overcoming dense local arrangement lockdowns\n            if t % 300 == 0 and t < 1500:\n                X += np.random.normal(0, 0.003, N)\n                Y += np.random.normal(0, 0.003, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds snap strictly to true mathematical feasible regimes unconditionally\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        curr_sum = np.sum(R_val)\n        \n        if curr_sum > best_sum:\n            best_sum = curr_sum\n            best_X = X_val\n            best_Y = Y_val\n            best_R = R_val\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5592), Performs well on target_ratio (0.9712), Performs well on combined_score (0.9712), Performs well on radius_variance (0.0058), Performs well on spatial_spread (0.2021), Performs well on eval_time (6.4081)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.9689)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-7, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-7)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-7)\n\n\ndef construct_packing():\n    \"\"\"\n    Simultaneously accelerates globally across massive parallel geometries exploring \n    optimal mathematical distributions using fully vectorized physical gradient trajectories.\n    \"\"\"\n    B = 72\n    n = 26\n    np.random.seed(42)\n    X_init = np.zeros((B, n, 2))\n    \n    # Procedurally generate widely spanning varied physical configuration topologies  \n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            X_init[b] = np.random.uniform(0.1, 0.9, (n, 2))\n        elif mode == 1:\n            for i in range(16):\n                a = 2 * np.pi * i / 16\n                X_init[b, i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n            for i in range(16, n):\n                X_init[b, i] = np.random.uniform(0.3, 0.7, 2)\n        elif mode == 2:\n            c1, c2 = 8, 18\n            for i in range(c1):\n                a = 2 * np.pi * i / c1\n                X_init[b, i] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, c1+i] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]\n        elif mode == 3:\n            grid = np.linspace(0.15, 0.85, 5)\n            k = 0\n            for x in grid:\n                for y in grid:\n                    X_init[b, k] = [x, y]\n                    k += 1\n            X_init[b, k] = [0.5, 0.5]\n        elif mode == 4:\n            pts = []\n            pts.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n            for t in np.linspace(0.2, 0.8, 4):\n                pts.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n            for _ in range(n - len(pts)):\n                pts.append(np.random.uniform(0.2, 0.8, 2).tolist())\n            X_init[b] = pts\n        elif mode == 5:\n            for i in range(n):\n                r = 0.45 * np.sqrt((i + 1) / float(n))\n                theta = i * 2.3999632\n                X_init[b, i] = [0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)]\n        elif mode == 6:\n            c1, c2, c3 = 4, 9, 13\n            k = 0\n            for i in range(c1):\n                a = 2 * np.pi * i / c1 + 0.2\n                X_init[b, k] = [0.5 + 0.12 * np.cos(a), 0.5 + 0.12 * np.sin(a)]; k += 1\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, k] = [0.5 + 0.28 * np.cos(a), 0.5 + 0.28 * np.sin(a)]; k += 1\n            for i in range(c3):\n                a = 2 * np.pi * i / c3 + 0.1\n                X_init[b, k] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]; k += 1\n        elif mode == 7:\n            k = 0\n            for dist in [0.05, 0.25]:\n                for px, py in [(dist, dist), (1-dist, dist), (dist, 1-dist), (1-dist, 1-dist)]:\n                    X_init[b, k] = [px, py]\n                    k += 1\n            while k < n:\n                X_init[b, k] = np.random.uniform(0.2, 0.8, 2)\n                k += 1\n\n    noise_factors = np.linspace(0.001, 0.008, 9)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noise_factors[b // 8]\n        \n    X = np.clip(X_init, 0.05, 0.95)\n    R = np.full((B, n), 0.04)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 3500\n    \n    # Physics parameters optimization integration completely seamlessly handled efficiently \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.015 * (1.0 - progress) + 0.001\n        \n        # Anneal parameter dynamically forces locking rigid walls fully  \n        C = 5.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-10)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap -= np.eye(n) * 10.0\n        overlap_vals = overlap * (overlap > 0)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0\n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.5:\n            noise_scale = 0.03 * (1.0 - progress / 0.5)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / max(1.0 - beta1 ** step, 1e-12)\n        v_X_hat = v_X / max(1.0 - beta2 ** step, 1e-12)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / max(1.0 - beta1 ** step, 1e-12)\n        v_R_hat = v_R / max(1.0 - beta2 ** step, 1e-12)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n\n    # Sort generated models filtering exactly most optimized promising configurations precisely \n    scores = np.sum(R, axis=1)\n    best_indices = np.argsort(scores)[::-1][:16]\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Clean fallback resolving constraints extracting strictly sound layout maxima completely \n    for b in best_indices:\n        final_R = compute_max_radii(X[b])\n        score = np.sum(final_R)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X[b]\n            best_radii = final_R\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 1.0002, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a heavily optimized arrangement of 26 circles in a unit square\n    that tightly maximizes the sum of their radii via simulated annealing physics.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Run a continuous restart scheme to traverse and select best optimal geometries\n    for seed in range(12):\n        X = optimize_seed(seed)\n        final_radii = compute_max_radii(X)\n        score = np.sum(final_radii)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X\n            best_radii = final_radii\n            \n    return best_centers, best_radii, best_sum\n\n\ndef optimize_seed(seed):\n    \"\"\"Executes gradient ascent physical optimizer applying non-linear repulsions\"\"\"\n    n = 26\n    np.random.seed(seed * 42 + 7)\n    X = []\n    \n    # Generate structural layout biases targeting interstitial properties \n    if seed % 4 == 0:\n        grid = np.linspace(0.1, 0.9, 5)\n        for x in grid:\n            for y in grid:\n                X.append([x, y])\n        X.append([0.5, 0.5])\n    elif seed % 4 == 1:\n        X.append([0.5, 0.5])\n        for i in range(7):\n            a = 2 * np.pi * i / 7\n            X.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        for i in range(18):\n            a = 2 * np.pi * i / 18\n            X.append([0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)])\n    elif seed % 4 == 2:\n        # Bias boundaries strategically\n        X.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n        for t in np.linspace(0.2, 0.8, 4):\n            X.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n        for _ in range(n - len(X)):\n            X.append(np.random.uniform(0.2, 0.8, 2).tolist())\n    else:\n        # Radial symmetry fibonacci break layout \n        for i in range(n):\n            r = 0.45 * np.sqrt((i + 1) / float(n))\n            theta = i * 2.3999632\n            X.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n            \n    # Apply thermal random breaks ensuring robust positional gradient responses\n    X = np.array(X)[:n] + np.random.randn(n, 2) * 0.005\n    X = np.clip(X, 0.02, 0.98)\n    \n    R = np.full(n, 0.06)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 2200\n    \n    # Advanced gradient scheduling simulated layout physics settling iterations\n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.005 * (1.0 - progress) + 0.0002\n        \n        # Exponential penalization scaling solidifying boundary geometries gracefully\n        C = 5.0 * (2000.0 ** progress)\n        \n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        \n        overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, -1.0)\n        overlap_vals = overlap * (overlap > 0)\n        \n        grad_X = np.zeros_like(X)\n        grad_R = np.full(n, -1.0)\n        \n        # Dynamic internal forces generated inversely proportional towards interstitial gaps \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X += np.sum(factor[:, :, np.newaxis] * diff, axis=1)\n        grad_R += np.sum(2.0 * C * overlap_vals, axis=1)\n        \n        w_l = np.maximum(0, R - X[:, 0])\n        w_r = np.maximum(0, R - (1 - X[:, 0]))\n        w_b = np.maximum(0, R - X[:, 1])\n        w_t = np.maximum(0, R - (1 - X[:, 1]))\n        \n        grad_X[:, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        # Anneal structural constraints breaking edge symmetry lock-ups securely\n        if step < steps * 0.35:\n            grad_X += np.random.randn(n, 2) * 0.03 * (1.0 - step / (steps * 0.35))\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        X -= lr_base * (m_X / (1 - beta1 ** step)) / (np.sqrt(v_X / (1 - beta2 ** step)) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        R -= lr_base * (m_R / (1 - beta1 ** step)) / (np.sqrt(v_R / (1 - beta2 ** step)) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n        \n    return X\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized strict distributions securely enforcing non-overlap, \n    evaluating geometrical capabilities resiliently without user sequencing prejudice.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical attempt evaluating precise extreme maximum geometric boundaries limits\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(0.0, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable dynamic geometric compression graceful-recovery fallback\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Assured residual overlap removal phase mathematically assuring clean submission states\n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9712, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # We want to maximize sum(R), equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    # Penalty ensures circles are fully inside bounds: x-r > 0 => r-x < 0\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards ensuring safety from duplicate division\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime,\n    maintaining position arrangement whilst shrinking only clashing constraints linearly.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(idx, N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring float-truncation exactness\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding prevents floating inequalities on the boundary test wrapper\n    \n    return X, Y, R\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing combined with an explicit multistart unconstrained optimizer.\n    Generates varied topology arrangements natively. \n    Larger target sizes start centrally to create hierarchal Apollonian filling dynamics.\n    \n    Returns:\n        centers, radii, sum_radii safely inside all non-overlapping domain thresholds.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    # Extremely robust multistart optimization setup guaranteeing globally resilient optima \n    num_runs = 15\n    N = 26\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Bias placements spatially \n        X_init, Y_init = [], []\n        # Assign seed layout for space efficiency handling edges natively\n        X_init.extend([0.05, 0.95, 0.05, 0.95])\n        Y_init.extend([0.05, 0.05, 0.95, 0.95])\n        \n        # Sequentially scatter randomized fillers\n        for _ in range(N - 4):\n            X_init.append(np.random.uniform(0.1, 0.9))\n            Y_init.append(np.random.uniform(0.1, 0.9))\n            \n        X = np.array(X_init)\n        Y = np.array(Y_init)\n        \n        # Target assignment explicitly favoring centered bodies to push corner circles into tight spaces\n        dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n        R = 0.06 - 0.04 * dist_c\n        \n        # Smooth simulated annealing learning constraints configuration\n        num_steps = 3000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        # Exponent continuation approach forcing parameters tightly on penalty limits towards end\n        c_t = 10.0\n        c_max = 2000000.0\n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            # Adam descent exponentially decreasing standard learning threshold smoothly locking configurations\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            # Step updates safely parameterized\n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter overcoming dense local arrangement lockdowns\n            if t % 300 == 0 and t < 1500:\n                X += np.random.normal(0, 0.003, N)\n                Y += np.random.normal(0, 0.003, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds snap strictly to true mathematical feasible regimes unconditionally\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        curr_sum = np.sum(R_val)\n        \n        if curr_sum > best_sum:\n            best_sum = curr_sum\n            best_X = X_val\n            best_Y = Y_val\n            best_R = R_val\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.9911, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\nfrom scipy.optimize import minimize\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages to create proper layouts.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # Maximize sum(R) -> Equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime mathematically,\n    shrinking only physically colliding or bound-infringing objects efficiently.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(int(idx), N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring absolute float-truncation constraint truth\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding entirely offsets precision drift\n    \n    return X, Y, R\n\n\ndef polish_slsqp(X, Y, R):\n    \"\"\"\n    Fine-tunes mathematically feasible solutions continuously into strict optima.\n    Utilizes localized L-BFGS constrained projections heavily pushing radius magnitudes upwards\n    towards maximum configuration geometries smoothly against identical local configurations.\n    \"\"\"\n    N = len(R)\n    \n    def obj(p):\n        return -np.sum(p[2*N:])\n        \n    def grad_obj(p):\n        g = np.zeros(3*N)\n        g[2*N:] = -1.0\n        return g\n        \n    bounds = [(0.0, 1.0)] * (2*N) + [(0.001, 1.0)] * N\n    \n    def boundary_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        return np.concatenate([\n            X_p - R_p,\n            1.0 - X_p - R_p,\n            Y_p - R_p,\n            1.0 - Y_p - R_p\n        ])\n        \n    def boundary_jac(p):\n        J = np.zeros((4*N, 3*N))\n        idx = np.arange(N)\n        # Vectorized assignment representing explicit border constraint components respectively\n        J[idx, idx] = 1.0\n        J[idx, 2*N + idx] = -1.0\n        J[N + idx, idx] = -1.0\n        J[N + idx, 2*N + idx] = -1.0\n        J[2*N + idx, N + idx] = 1.0\n        J[2*N + idx, 2*N + idx] = -1.0\n        J[3*N + idx, N + idx] = -1.0\n        J[3*N + idx, 2*N + idx] = -1.0\n        return J\n\n    def overlap_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dist2 = (X_p[i_idx] - X_p[j_idx])**2 + (Y_p[i_idx] - Y_p[j_idx])**2\n        return dist2 - (R_p[i_idx] + R_p[j_idx])**2\n        \n    def overlap_jac(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        num_pairs = len(i_idx)\n        J = np.zeros((num_pairs, 3*N))\n        \n        dx = X_p[i_idx] - X_p[j_idx]\n        dy = Y_p[i_idx] - Y_p[j_idx]\n        dr = R_p[i_idx] + R_p[j_idx]\n        \n        pair_range = np.arange(num_pairs)\n        J[pair_range, i_idx] = 2.0 * dx\n        J[pair_range, j_idx] = -2.0 * dx\n        J[pair_range, N + i_idx] = 2.0 * dy\n        J[pair_range, N + j_idx] = -2.0 * dy\n        J[pair_range, 2*N + i_idx] = -2.0 * dr\n        J[pair_range, 2*N + j_idx] = -2.0 * dr\n        return J\n\n    cons = [\n        {'type': 'ineq', 'fun': boundary_cons, 'jac': boundary_jac},\n        {'type': 'ineq', 'fun': overlap_cons, 'jac': overlap_jac}\n    ]\n    \n    p0 = np.concatenate([X, Y, R])\n    res = minimize(\n        obj, p0, method='SLSQP', jac=grad_obj, bounds=bounds,\n        constraints=cons, options={'maxiter': 400, 'ftol': 1e-6}\n    )\n    \n    p = res.x\n    return p[:N], p[N:2*N], p[2*N:]\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing optimization combined with distinct symmetry-breaking seeds.\n    Final solutions iteratively passed through deterministic physical expansion maximizations utilizing SQP bounds mapping natively.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    num_runs = 16\n    N = 26\n    candidates = []\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Sequentially map distinctly varied geometric layout arrangements forcing extensive diverse searches initially\n        X_init, Y_init = [], []\n        if run % 4 == 0:\n            X_init.extend([0.05, 0.95, 0.05, 0.95])\n            Y_init.extend([0.05, 0.05, 0.95, 0.95])\n            for _ in range(N - 4):\n                X_init.append(np.random.uniform(0.1, 0.9))\n                Y_init.append(np.random.uniform(0.1, 0.9))\n        elif run % 4 == 1:\n            for _ in range(N):\n                X_init.append(np.random.uniform(0.05, 0.95))\n                Y_init.append(np.random.uniform(0.05, 0.95))\n        elif run % 4 == 2:\n            n_outer = 12\n            for i in range(n_outer):\n                th = 2 * np.pi * i / n_outer\n                X_init.append(0.5 + 0.38 * np.cos(th))\n                Y_init.append(0.5 + 0.38 * np.sin(th))\n            for _ in range(N - n_outer):\n                X_init.append(np.random.uniform(0.25, 0.75))\n                Y_init.append(np.random.uniform(0.25, 0.75))\n        else:\n            grid_dim = int(np.ceil(np.sqrt(N)))\n            for i in range(N):\n                r_pos = i // grid_dim\n                c_pos = i % grid_dim\n                X_init.append(0.1 + 0.8 * r_pos / max(1, grid_dim - 1))\n                Y_init.append(0.1 + 0.8 * c_pos / max(1, grid_dim - 1))\n            \n        X = np.array(X_init[:N])\n        Y = np.array(Y_init[:N])\n        \n        if run % 2 == 0:\n            dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n            R = 0.06 - 0.04 * dist_c\n        else:\n            R = np.random.uniform(0.02, 0.06, N)\n        \n        # Adaptive gradient descent hyperparameters structurally locking positions down gracefully.\n        num_steps = 2000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        c_t = 10.0\n        c_max = 500000.0 \n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter dynamically preventing edge-constraint trapping effectively natively\n            if t % 300 == 0 and t < 1200:\n                X += np.random.normal(0, 0.002, N)\n                Y += np.random.normal(0, 0.002, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds cleanly formatting true feasibility states conditionally ready to deploy strictly via refinement\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        candidates.append((np.sum(R_val), X_val, Y_val, R_val))\n\n    # Evaluate sequentially expanding potential utilizing the absolute mathematically precise bound solver directly.\n    candidates.sort(key=lambda x: x[0], reverse=True)\n    \n    # Process only the highest-potential configuration distributions saving overhead structurally ensuring high maximization.\n    for score, X_val, Y_val, R_val in candidates[:10]:\n        X_p, Y_p, R_p = polish_slsqp(X_val, Y_val, R_val)\n        \n        # Reinforcing strict constraints to prevent trace float inaccuracies in automated boundary validations inherently guaranteeing robustness perfectly.\n        X_fin, Y_fin, R_fin = make_valid(X_p, Y_p, R_p)\n        fin_sum = np.sum(R_fin)\n        \n        if fin_sum > best_sum:\n            best_sum = fin_sum\n            best_X = X_fin\n            best_Y = Y_fin\n            best_R = R_fin\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-7, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-7)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-7)\n\n\ndef construct_packing():\n    \"\"\"\n    Simultaneously accelerates globally across massive parallel geometries exploring \n    optimal mathematical distributions using fully vectorized physical gradient trajectories.\n    \"\"\"\n    B = 72\n    n = 26\n    np.random.seed(42)\n    X_init = np.zeros((B, n, 2))\n    \n    # Procedurally generate widely spanning varied physical configuration topologies  \n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            X_init[b] = np.random.uniform(0.1, 0.9, (n, 2))\n        elif mode == 1:\n            for i in range(16):\n                a = 2 * np.pi * i / 16\n                X_init[b, i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n            for i in range(16, n):\n                X_init[b, i] = np.random.uniform(0.3, 0.7, 2)\n        elif mode == 2:\n            c1, c2 = 8, 18\n            for i in range(c1):\n                a = 2 * np.pi * i / c1\n                X_init[b, i] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, c1+i] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]\n        elif mode == 3:\n            grid = np.linspace(0.15, 0.85, 5)\n            k = 0\n            for x in grid:\n                for y in grid:\n                    X_init[b, k] = [x, y]\n                    k += 1\n            X_init[b, k] = [0.5, 0.5]\n        elif mode == 4:\n            pts = []\n            pts.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n            for t in np.linspace(0.2, 0.8, 4):\n                pts.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n            for _ in range(n - len(pts)):\n                pts.append(np.random.uniform(0.2, 0.8, 2).tolist())\n            X_init[b] = pts\n        elif mode == 5:\n            for i in range(n):\n                r = 0.45 * np.sqrt((i + 1) / float(n))\n                theta = i * 2.3999632\n                X_init[b, i] = [0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)]\n        elif mode == 6:\n            c1, c2, c3 = 4, 9, 13\n            k = 0\n            for i in range(c1):\n                a = 2 * np.pi * i / c1 + 0.2\n                X_init[b, k] = [0.5 + 0.12 * np.cos(a), 0.5 + 0.12 * np.sin(a)]; k += 1\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, k] = [0.5 + 0.28 * np.cos(a), 0.5 + 0.28 * np.sin(a)]; k += 1\n            for i in range(c3):\n                a = 2 * np.pi * i / c3 + 0.1\n                X_init[b, k] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]; k += 1\n        elif mode == 7:\n            k = 0\n            for dist in [0.05, 0.25]:\n                for px, py in [(dist, dist), (1-dist, dist), (dist, 1-dist), (1-dist, 1-dist)]:\n                    X_init[b, k] = [px, py]\n                    k += 1\n            while k < n:\n                X_init[b, k] = np.random.uniform(0.2, 0.8, 2)\n                k += 1\n\n    noise_factors = np.linspace(0.001, 0.008, 9)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noise_factors[b // 8]\n        \n    X = np.clip(X_init, 0.05, 0.95)\n    R = np.full((B, n), 0.04)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 3500\n    \n    # Physics parameters optimization integration completely seamlessly handled efficiently \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.015 * (1.0 - progress) + 0.001\n        \n        # Anneal parameter dynamically forces locking rigid walls fully  \n        C = 5.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-10)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap -= np.eye(n) * 10.0\n        overlap_vals = overlap * (overlap > 0)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0\n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.5:\n            noise_scale = 0.03 * (1.0 - progress / 0.5)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / max(1.0 - beta1 ** step, 1e-12)\n        v_X_hat = v_X / max(1.0 - beta2 ** step, 1e-12)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / max(1.0 - beta1 ** step, 1e-12)\n        v_R_hat = v_R / max(1.0 - beta2 ** step, 1e-12)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n\n    # Sort generated models filtering exactly most optimized promising configurations precisely \n    scores = np.sum(R, axis=1)\n    best_indices = np.argsort(scores)[::-1][:16]\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Clean fallback resolving constraints extracting strictly sound layout maxima completely \n    for b in best_indices:\n        final_R = compute_max_radii(X[b])\n        score = np.sum(final_R)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X[b]\n            best_radii = final_R\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-8, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-9)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1.0 - centers[i, 0], 1.0 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(4000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1.0 - centers[:, 0], \n                                       centers[:, 1], 1.0 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.55\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(100):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-10:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n\ndef polish_slsqp(X, R):\n    \"\"\"\n    Fine-tunes mathematically feasible solutions continuously into strict optima securely.\n    Utilizes localized SLSQP constrained projections precisely smoothly.\n    \"\"\"\n    from scipy.optimize import minimize\n    N = len(R)\n    \n    def obj(p):\n        return -np.sum(p[2*N:])\n        \n    def grad_obj(p):\n        g = np.zeros(3*N)\n        g[2*N:] = -1.0\n        return g\n        \n    bounds = [(1e-7, 1.0 - 1e-7)] * (2*N) + [(0.001, 1.0)] * N\n    \n    def boundary_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        return np.concatenate([\n            X_p - R_p,\n            1.0 - X_p - R_p,\n            Y_p - R_p,\n            1.0 - Y_p - R_p\n        ])\n        \n    def boundary_jac(p):\n        J = np.zeros((4*N, 3*N))\n        idx = np.arange(N)\n        J[idx, idx] = 1.0\n        J[idx, 2*N + idx] = -1.0\n        J[N + idx, idx] = -1.0\n        J[N + idx, 2*N + idx] = -1.0\n        J[2*N + idx, N + idx] = 1.0\n        J[2*N + idx, 2*N + idx] = -1.0\n        J[3*N + idx, N + idx] = -1.0\n        J[3*N + idx, 2*N + idx] = -1.0\n        return J\n\n    def overlap_cons(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        dist2 = (X_p[i_idx] - X_p[j_idx])**2 + (Y_p[i_idx] - Y_p[j_idx])**2\n        return dist2 - (R_p[i_idx] + R_p[j_idx])**2\n        \n    def overlap_jac(p):\n        X_p = p[:N]\n        Y_p = p[N:2*N]\n        R_p = p[2*N:]\n        i_idx, j_idx = np.triu_indices(N, k=1)\n        num_pairs = len(i_idx)\n        J = np.zeros((num_pairs, 3*N))\n        \n        dx = X_p[i_idx] - X_p[j_idx]\n        dy = Y_p[i_idx] - Y_p[j_idx]\n        dr = R_p[i_idx] + R_p[j_idx]\n        \n        pair_range = np.arange(num_pairs)\n        J[pair_range, i_idx] = 2.0 * dx\n        J[pair_range, j_idx] = -2.0 * dx\n        J[pair_range, N + i_idx] = 2.0 * dy\n        J[pair_range, N + j_idx] = -2.0 * dy\n        J[pair_range, 2*N + i_idx] = -2.0 * dr\n        J[pair_range, 2*N + j_idx] = -2.0 * dr\n        return J\n\n    cons = [\n        {'type': 'ineq', 'fun': boundary_cons, 'jac': boundary_jac},\n        {'type': 'ineq', 'fun': overlap_cons, 'jac': overlap_jac}\n    ]\n    \n    p0 = np.concatenate([X[:, 0], X[:, 1], R])\n    try:\n        res = minimize(\n            obj, p0, method='SLSQP', jac=grad_obj, bounds=bounds,\n            constraints=cons, options={'maxiter': 500, 'ftol': 1e-7}\n        )\n        p = res.x\n    except Exception:\n        p = p0\n        \n    X_fin = np.column_stack((p[:N], p[N:2*N]))\n    R_fin = p[2*N:]\n    return X_fin, R_fin\n\n\ndef generate_seeds(B, n):\n    \"\"\"\n    Generates diverse set of layout seed structures securely avoiding identical minima.\n    \"\"\"\n    X_init = np.zeros((B, n, 2))\n    np.random.seed(427)\n    for b in range(B):\n        mode = b % 8\n        pts = []\n        if mode == 0:\n            for x in np.linspace(0.12, 0.88, 5):\n                for y in np.linspace(0.12, 0.88, 5):\n                    pts.append([x, y])\n            pts.append([0.5, 0.5])\n        elif mode == 1:\n            pts.append([0.5, 0.5])\n            for i in range(7):\n                a = 2 * np.pi * i / 7\n                pts.append([0.5 + 0.18*np.cos(a), 0.5 + 0.18*np.sin(a)])\n            for i in range(18):\n                a = 2 * np.pi * i / 18\n                pts.append([0.5 + 0.4*np.cos(a), 0.5 + 0.4*np.sin(a)])\n        elif mode == 2:\n            for t in np.linspace(0.05, 0.95, 6):\n                pts.extend([[t, 0.05], [t, 0.95]])\n            for t in np.linspace(0.23, 0.77, 4):\n                pts.extend([[0.05, t], [0.95, t]])\n        elif mode == 3:\n            for i in range(n):\n                r = 0.45 * np.sqrt(i / (n - 1.0))\n                theta = i * 2.3999632\n                pts.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n        elif mode == 4:\n            for _ in range(n):\n                pts.append(np.random.uniform(0.08, 0.92, 2))\n        elif mode == 5:\n            dx = 0.14\n            dy = 0.16\n            for ir, cnt in enumerate([5, 6, 5, 6, 4]):\n                y = 0.15 + ir * dy\n                offset = 0 if ir % 2 == 0 else -dx/2\n                cx = 0.5 - (cnt - 1) * dx / 2 - offset\n                for ic in range(cnt):\n                    x = cx + offset + ic * dx\n                    pts.append([x, y])\n        elif mode == 6:\n            pts.extend([[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]])\n            for i in range(12):\n                a = 2 * np.pi * i / 12\n                pts.append([0.5 + 0.38*np.cos(a), 0.5 + 0.38*np.sin(a)])\n            for i in range(10):\n                a = 2 * np.pi * i / 10\n                pts.append([0.5 + 0.2*np.cos(a), 0.5 + 0.2*np.sin(a)])\n        elif mode == 7:\n            for i in range(4):\n                a = 2 * np.pi * i / 4 + np.pi/4\n                pts.append([0.5 + 0.1*np.cos(a), 0.5 + 0.1*np.sin(a)])\n            for i in range(8):\n                a = 2 * np.pi * i / 8\n                pts.append([0.5 + 0.25*np.cos(a), 0.5 + 0.25*np.sin(a)])\n            for i in range(14):\n                a = 2 * np.pi * i / 14\n                pts.append([0.5 + 0.42*np.cos(a), 0.5 + 0.42*np.sin(a)])\n        \n        arr = np.array(pts)\n        if len(arr) < n:\n            rem = n - len(arr)\n            arr = np.vstack([arr, np.random.uniform(0.1, 0.9, (rem, 2))])\n        X_init[b] = arr[:n]\n    \n    noises = np.linspace(0.001, 0.03, 5)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noises[b // 8]\n        \n    return np.clip(X_init, 0.05, 0.95)\n\n\ndef run_physics_simulations(B, n, steps):\n    \"\"\"\n    Simultaneously accelerates robust convergence applying Adam optimizer correctly geometrically smoothly.\n    \"\"\"\n    X = generate_seeds(B, n)\n    R = np.full((B, n), 0.04)\n    R += np.random.uniform(-0.01, 0.01, (B, n))\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    idx = np.arange(n)\n    \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.012 * (1.0 - progress) + 0.0005\n        \n        # Anneal parameter dynamically forces locking geometries efficiently\n        C = 10.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-12)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap[:, idx, idx] = -1.0 \n        \n        overlap_vals = np.maximum(0, overlap)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0 \n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1.0 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1.0 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.35:\n            noise_scale = 0.02 * (1.0 - progress / 0.35)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / (1.0 - beta1 ** step)\n        v_X_hat = v_X / (1.0 - beta2 ** step)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / (1.0 - beta1 ** step)\n        v_R_hat = v_R / (1.0 - beta2 ** step)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0.0, 1.0)\n        R = np.maximum(R, 0.005)\n        \n    return X\n\n\ndef construct_packing():\n    \"\"\"\n    Main constructor routing generating strictly optimal geometric structures maximally safely exactly.\n    \"\"\"\n    B = 40\n    N = 26\n    X_candidates = run_physics_simulations(B, N, steps=2800)\n    \n    scored_candidates = []\n    for b in range(B):\n        R_exact = compute_max_radii(X_candidates[b])\n        score = np.sum(R_exact)\n        scored_candidates.append((score, X_candidates[b], R_exact))\n        \n    scored_candidates.sort(key=lambda item: item[0], reverse=True)\n    \n    best_X = None\n    best_R = None\n    best_score = -1.0\n    \n    # Process extreme elite layouts natively executing maximum exact refinements seamlessly\n    for score, X_val, R_val in scored_candidates[:5]:\n        X_p, R_p = polish_slsqp(X_val, R_val)\n        X_p = np.clip(X_p, 1e-7, 1.0 - 1e-7) \n        \n        R_fin = compute_max_radii(X_p)\n        fin_score = np.sum(R_fin)\n        \n        if fin_score > best_score:\n            best_score = fin_score\n            best_X = X_p\n            best_R = R_fin\n            \n    return best_X, best_R, best_score\n\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"6.16s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.630562/2.635 = 0.9983\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.8% of target value\", \"radius_stats\": \"Min: 0.070605, Max: 0.137214, Avg: 0.101175\"}", "artifact_dir": null, "embedding": null}