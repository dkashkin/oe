{"id": "c5b31d83-649e-482f-9ebf-59db4ef5991b", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-7, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-7)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-7)\n\n\ndef construct_packing():\n    \"\"\"\n    Simultaneously accelerates globally across massive parallel geometries exploring \n    optimal mathematical distributions using fully vectorized physical gradient trajectories.\n    \"\"\"\n    B = 72\n    n = 26\n    np.random.seed(42)\n    X_init = np.zeros((B, n, 2))\n    \n    # Procedurally generate widely spanning varied physical configuration topologies  \n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            X_init[b] = np.random.uniform(0.1, 0.9, (n, 2))\n        elif mode == 1:\n            for i in range(16):\n                a = 2 * np.pi * i / 16\n                X_init[b, i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n            for i in range(16, n):\n                X_init[b, i] = np.random.uniform(0.3, 0.7, 2)\n        elif mode == 2:\n            c1, c2 = 8, 18\n            for i in range(c1):\n                a = 2 * np.pi * i / c1\n                X_init[b, i] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, c1+i] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]\n        elif mode == 3:\n            grid = np.linspace(0.15, 0.85, 5)\n            k = 0\n            for x in grid:\n                for y in grid:\n                    X_init[b, k] = [x, y]\n                    k += 1\n            X_init[b, k] = [0.5, 0.5]\n        elif mode == 4:\n            pts = []\n            pts.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n            for t in np.linspace(0.2, 0.8, 4):\n                pts.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n            for _ in range(n - len(pts)):\n                pts.append(np.random.uniform(0.2, 0.8, 2).tolist())\n            X_init[b] = pts\n        elif mode == 5:\n            for i in range(n):\n                r = 0.45 * np.sqrt((i + 1) / float(n))\n                theta = i * 2.3999632\n                X_init[b, i] = [0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)]\n        elif mode == 6:\n            c1, c2, c3 = 4, 9, 13\n            k = 0\n            for i in range(c1):\n                a = 2 * np.pi * i / c1 + 0.2\n                X_init[b, k] = [0.5 + 0.12 * np.cos(a), 0.5 + 0.12 * np.sin(a)]; k += 1\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, k] = [0.5 + 0.28 * np.cos(a), 0.5 + 0.28 * np.sin(a)]; k += 1\n            for i in range(c3):\n                a = 2 * np.pi * i / c3 + 0.1\n                X_init[b, k] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]; k += 1\n        elif mode == 7:\n            k = 0\n            for dist in [0.05, 0.25]:\n                for px, py in [(dist, dist), (1-dist, dist), (dist, 1-dist), (1-dist, 1-dist)]:\n                    X_init[b, k] = [px, py]\n                    k += 1\n            while k < n:\n                X_init[b, k] = np.random.uniform(0.2, 0.8, 2)\n                k += 1\n\n    noise_factors = np.linspace(0.001, 0.008, 9)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noise_factors[b // 8]\n        \n    X = np.clip(X_init, 0.05, 0.95)\n    R = np.full((B, n), 0.04)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 3500\n    \n    # Physics parameters optimization integration completely seamlessly handled efficiently \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.015 * (1.0 - progress) + 0.001\n        \n        # Anneal parameter dynamically forces locking rigid walls fully  \n        C = 5.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-10)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap -= np.eye(n) * 10.0\n        overlap_vals = overlap * (overlap > 0)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0\n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.5:\n            noise_scale = 0.03 * (1.0 - progress / 0.5)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / max(1.0 - beta1 ** step, 1e-12)\n        v_X_hat = v_X / max(1.0 - beta2 ** step, 1e-12)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / max(1.0 - beta1 ** step, 1e-12)\n        v_R_hat = v_R / max(1.0 - beta2 ** step, 1e-12)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n\n    # Sort generated models filtering exactly most optimized promising configurations precisely \n    scores = np.sum(R, axis=1)\n    best_indices = np.argsort(scores)[::-1][:16]\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Clean fallback resolving constraints extracting strictly sound layout maxima completely \n    for b in best_indices:\n        final_R = compute_max_radii(X[b])\n        score = np.sum(final_R)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X[b]\n            best_radii = final_R\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "f2ced48c-8643-4979-b7cd-0c62a210d30d", "generation": 2, "timestamp": 1771993181.3037467, "iteration_found": 16, "metrics": {"validity": 1.0, "sum_radii": 2.5530607460102965, "target_ratio": 0.9689035089223138, "combined_score": 0.9689035089223138, "radius_variance": 0.005120560108542859, "spatial_spread": 0.20332271895157744, "eval_time": 12.481019973754883}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6355143592089623, "target_ratio": 1.0001952027358492, "combined_score": 1.0001952027358492, "radius_variance": 0.004488808088140577, "spatial_spread": 0.18842246290531667, "eval_time": 3.6588120460510254}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 1.0002\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.9712 \u2192 1.0002\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n3.66s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.635514/2.635 = 1.0002\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 100.0% of target value\n```\n\n### radius_stats\n```\nMin: 0.069815, Max: 0.136771, Avg: 0.101366\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5592, target_ratio: 0.9712, combined_score: 0.9712, radius_variance: 0.0058, spatial_spread: 0.2021, eval_time: 6.4081\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6355, target_ratio: 1.0002, combined_score: 1.0002, radius_variance: 0.0045, spatial_spread: 0.1884, eval_time: 3.6588\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.0002)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a heavily optimized arrangement of 26 circles in a unit square\n    that tightly maximizes the sum of their radii via simulated annealing physics.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Run a continuous restart scheme to traverse and select best optimal geometries\n    for seed in range(12):\n        X = optimize_seed(seed)\n        final_radii = compute_max_radii(X)\n        score = np.sum(final_radii)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X\n            best_radii = final_radii\n            \n    return best_centers, best_radii, best_sum\n\n\ndef optimize_seed(seed):\n    \"\"\"Executes gradient ascent physical optimizer applying non-linear repulsions\"\"\"\n    n = 26\n    np.random.seed(seed * 42 + 7)\n    X = []\n    \n    # Generate structural layout biases targeting interstitial properties \n    if seed % 4 == 0:\n        grid = np.linspace(0.1, 0.9, 5)\n        for x in grid:\n            for y in grid:\n                X.append([x, y])\n        X.append([0.5, 0.5])\n    elif seed % 4 == 1:\n        X.append([0.5, 0.5])\n        for i in range(7):\n            a = 2 * np.pi * i / 7\n            X.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        for i in range(18):\n            a = 2 * np.pi * i / 18\n            X.append([0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)])\n    elif seed % 4 == 2:\n        # Bias boundaries strategically\n        X.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n        for t in np.linspace(0.2, 0.8, 4):\n            X.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n        for _ in range(n - len(X)):\n            X.append(np.random.uniform(0.2, 0.8, 2).tolist())\n    else:\n        # Radial symmetry fibonacci break layout \n        for i in range(n):\n            r = 0.45 * np.sqrt((i + 1) / float(n))\n            theta = i * 2.3999632\n            X.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n            \n    # Apply thermal random breaks ensuring robust positional gradient responses\n    X = np.array(X)[:n] + np.random.randn(n, 2) * 0.005\n    X = np.clip(X, 0.02, 0.98)\n    \n    R = np.full(n, 0.06)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 2200\n    \n    # Advanced gradient scheduling simulated layout physics settling iterations\n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.005 * (1.0 - progress) + 0.0002\n        \n        # Exponential penalization scaling solidifying boundary geometries gracefully\n        C = 5.0 * (2000.0 ** progress)\n        \n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        \n        overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, -1.0)\n        overlap_vals = overlap * (overlap > 0)\n        \n        grad_X = np.zeros_like(X)\n        grad_R = np.full(n, -1.0)\n        \n        # Dynamic internal forces generated inversely proportional towards interstitial gaps \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X += np.sum(factor[:, :, np.newaxis] * diff, axis=1)\n        grad_R += np.sum(2.0 * C * overlap_vals, axis=1)\n        \n        w_l = np.maximum(0, R - X[:, 0])\n        w_r = np.maximum(0, R - (1 - X[:, 0]))\n        w_b = np.maximum(0, R - X[:, 1])\n        w_t = np.maximum(0, R - (1 - X[:, 1]))\n        \n        grad_X[:, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        # Anneal structural constraints breaking edge symmetry lock-ups securely\n        if step < steps * 0.35:\n            grad_X += np.random.randn(n, 2) * 0.03 * (1.0 - step / (steps * 0.35))\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        X -= lr_base * (m_X / (1 - beta1 ** step)) / (np.sqrt(v_X / (1 - beta2 ** step)) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        R -= lr_base * (m_R / (1 - beta1 ** step)) / (np.sqrt(v_R / (1 - beta2 ** step)) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n        \n    return X\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized strict distributions securely enforcing non-overlap, \n    evaluating geometrical capabilities resiliently without user sequencing prejudice.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical attempt evaluating precise extreme maximum geometric boundaries limits\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(0.0, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable dynamic geometric compression graceful-recovery fallback\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Assured residual overlap removal phase mathematically assuring clean submission states\n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6355), Performs well on target_ratio (1.0002), Performs well on combined_score (1.0002), Performs well on radius_variance (0.0045), Performs well on spatial_spread (0.1884), Performs well on eval_time (3.6588)\n\n### Program 2 (Score: 0.9712)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # We want to maximize sum(R), equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    # Penalty ensures circles are fully inside bounds: x-r > 0 => r-x < 0\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards ensuring safety from duplicate division\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime,\n    maintaining position arrangement whilst shrinking only clashing constraints linearly.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(idx, N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring float-truncation exactness\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding prevents floating inequalities on the boundary test wrapper\n    \n    return X, Y, R\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing combined with an explicit multistart unconstrained optimizer.\n    Generates varied topology arrangements natively. \n    Larger target sizes start centrally to create hierarchal Apollonian filling dynamics.\n    \n    Returns:\n        centers, radii, sum_radii safely inside all non-overlapping domain thresholds.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    # Extremely robust multistart optimization setup guaranteeing globally resilient optima \n    num_runs = 15\n    N = 26\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Bias placements spatially \n        X_init, Y_init = [], []\n        # Assign seed layout for space efficiency handling edges natively\n        X_init.extend([0.05, 0.95, 0.05, 0.95])\n        Y_init.extend([0.05, 0.05, 0.95, 0.95])\n        \n        # Sequentially scatter randomized fillers\n        for _ in range(N - 4):\n            X_init.append(np.random.uniform(0.1, 0.9))\n            Y_init.append(np.random.uniform(0.1, 0.9))\n            \n        X = np.array(X_init)\n        Y = np.array(Y_init)\n        \n        # Target assignment explicitly favoring centered bodies to push corner circles into tight spaces\n        dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n        R = 0.06 - 0.04 * dist_c\n        \n        # Smooth simulated annealing learning constraints configuration\n        num_steps = 3000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        # Exponent continuation approach forcing parameters tightly on penalty limits towards end\n        c_t = 10.0\n        c_max = 2000000.0\n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            # Adam descent exponentially decreasing standard learning threshold smoothly locking configurations\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            # Step updates safely parameterized\n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter overcoming dense local arrangement lockdowns\n            if t % 300 == 0 and t < 1500:\n                X += np.random.normal(0, 0.003, N)\n                Y += np.random.normal(0, 0.003, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds snap strictly to true mathematical feasible regimes unconditionally\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        curr_sum = np.sum(R_val)\n        \n        if curr_sum > best_sum:\n            best_sum = curr_sum\n            best_X = X_val\n            best_Y = Y_val\n            best_R = R_val\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5592), Performs well on target_ratio (0.9712), Performs well on combined_score (0.9712), Performs well on radius_variance (0.0058), Performs well on spatial_spread (0.2021), Performs well on eval_time (6.4081)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.9712, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_loss_and_grads(X, Y, R, c_t):\n    \"\"\"\n    Computes penalty-based loss and vectorized gradients to evaluate boundaries and overlaps.\n    Penalty weight `c_t` strictly forces constraints at later stages.\n    \"\"\"\n    grad_X = np.zeros_like(X)\n    grad_Y = np.zeros_like(Y)\n    \n    # We want to maximize sum(R), equivalent to minimizing -sum(R)\n    grad_R = np.full_like(R, -1.0)\n    loss = -np.sum(R)\n    \n    # Square Boundary Restrictions [0, 1]\n    # Penalty ensures circles are fully inside bounds: x-r > 0 => r-x < 0\n    viol_xmin = R - X\n    mask_xmin = viol_xmin > 0\n    if np.any(mask_xmin):\n        grad_R[mask_xmin] += c_t * 2.0 * viol_xmin[mask_xmin]\n        grad_X[mask_xmin] -= c_t * 2.0 * viol_xmin[mask_xmin]\n        loss += c_t * np.sum(viol_xmin[mask_xmin]**2)\n        \n    viol_xmax = X + R - 1.0\n    mask_xmax = viol_xmax > 0\n    if np.any(mask_xmax):\n        grad_R[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        grad_X[mask_xmax] += c_t * 2.0 * viol_xmax[mask_xmax]\n        loss += c_t * np.sum(viol_xmax[mask_xmax]**2)\n        \n    viol_ymin = R - Y\n    mask_ymin = viol_ymin > 0\n    if np.any(mask_ymin):\n        grad_R[mask_ymin] += c_t * 2.0 * viol_ymin[mask_ymin]\n        grad_Y[mask_ymin] -= c_t * 2.0 * viol_ymin[mask_ymin]\n        loss += c_t * np.sum(viol_ymin[mask_ymin]**2)\n        \n    viol_ymax = Y + R - 1.0\n    mask_ymax = viol_ymax > 0\n    if np.any(mask_ymax):\n        grad_R[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        grad_Y[mask_ymax] += c_t * 2.0 * viol_ymax[mask_ymax]\n        loss += c_t * np.sum(viol_ymax[mask_ymax]**2)\n        \n    # Non-overlapping circles Constraints\n    dx = X[:, None] - X[None, :]\n    dy = Y[:, None] - Y[None, :]\n    dist2 = dx**2 + dy**2\n    np.fill_diagonal(dist2, 1.0)\n    \n    # Float stability safeguards ensuring safety from duplicate division\n    dist = np.maximum(np.sqrt(dist2), 1e-10)\n    \n    sum_R = R[:, None] + R[None, :]\n    viol_overlap = sum_R - dist\n    np.fill_diagonal(viol_overlap, -1.0) # ignore self-overlaps\n    \n    mask_overlap = viol_overlap > 0\n    \n    if np.any(mask_overlap):\n        loss += c_t * np.sum(viol_overlap[mask_overlap]**2) / 2.0\n        \n        # Derivatives for pairs\n        factor = c_t * 2.0 * (viol_overlap * mask_overlap)\n        grad_R += np.sum(factor, axis=1)\n        \n        factor_dist = factor / dist\n        grad_X += np.sum(-factor_dist * dx, axis=1)\n        grad_Y += np.sum(-factor_dist * dy, axis=1)\n        \n    return loss, grad_X, grad_Y, grad_R\n\n\ndef make_valid(X, Y, R):\n    \"\"\"\n    Safely forces parameters down onto an exactly strict feasible regime,\n    maintaining position arrangement whilst shrinking only clashing constraints linearly.\n    \"\"\"\n    N = len(R)\n    # Global explicit clamp bounds:\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 1e-6)\n    \n    for _ in range(50):\n        dx = X[:, None] - X[None, :]\n        dy = Y[:, None] - Y[None, :]\n        dist = np.sqrt(dx**2 + dy**2)\n        np.fill_diagonal(dist, 10.0)\n        \n        sum_R = R[:, None] + R[None, :]\n        overlap = sum_R - dist\n        \n        if np.max(overlap) <= 1e-8:\n            break\n            \n        indices = np.argsort(overlap.flatten())[::-1]\n        for idx in indices:\n            i, j = divmod(idx, N)\n            if i >= j:\n                continue\n            \n            curr_overlap = R[i] + R[j] - dist[i, j]\n            if curr_overlap > 1e-9:\n                scale = dist[i, j] / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    # Exhaustive final pair-clashing scan ensuring float-truncation exactness\n    for i in range(N):\n        for j in range(i + 1, N):\n            d = np.sqrt((X[i]-X[j])**2 + (Y[i]-Y[j])**2)\n            if R[i] + R[j] > d:\n                scale = d / (R[i] + R[j])\n                R[i] *= scale\n                R[j] *= scale\n                \n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    R = np.maximum(R, 0.0)\n    R *= 0.999999 # Micro padding prevents floating inequalities on the boundary test wrapper\n    \n    return X, Y, R\n\n\ndef construct_packing():\n    \"\"\"\n    Implements simulated annealing combined with an explicit multistart unconstrained optimizer.\n    Generates varied topology arrangements natively. \n    Larger target sizes start centrally to create hierarchal Apollonian filling dynamics.\n    \n    Returns:\n        centers, radii, sum_radii safely inside all non-overlapping domain thresholds.\n    \"\"\"\n    best_sum = -1.0\n    best_X = None\n    best_Y = None\n    best_R = None\n    \n    # Extremely robust multistart optimization setup guaranteeing globally resilient optima \n    num_runs = 15\n    N = 26\n    \n    for run in range(num_runs):\n        np.random.seed(42 + run)\n        \n        # Bias placements spatially \n        X_init, Y_init = [], []\n        # Assign seed layout for space efficiency handling edges natively\n        X_init.extend([0.05, 0.95, 0.05, 0.95])\n        Y_init.extend([0.05, 0.05, 0.95, 0.95])\n        \n        # Sequentially scatter randomized fillers\n        for _ in range(N - 4):\n            X_init.append(np.random.uniform(0.1, 0.9))\n            Y_init.append(np.random.uniform(0.1, 0.9))\n            \n        X = np.array(X_init)\n        Y = np.array(Y_init)\n        \n        # Target assignment explicitly favoring centered bodies to push corner circles into tight spaces\n        dist_c = np.sqrt((X - 0.5)**2 + (Y - 0.5)**2)\n        R = 0.06 - 0.04 * dist_c\n        \n        # Smooth simulated annealing learning constraints configuration\n        num_steps = 3000\n        m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n        m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n        m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n        \n        lr_init = 0.015\n        beta1, beta2 = 0.9, 0.999\n        epsilon = 1e-8\n        \n        # Exponent continuation approach forcing parameters tightly on penalty limits towards end\n        c_t = 10.0\n        c_max = 2000000.0\n        c_mult = (c_max / c_t) ** (1.0 / num_steps)\n        \n        for t in range(1, num_steps + 1):\n            # Adam descent exponentially decreasing standard learning threshold smoothly locking configurations\n            curr_lr = lr_init * (0.01 ** (t / num_steps))\n            \n            _, g_X, g_Y, g_R = get_loss_and_grads(X, Y, R, c_t)\n            \n            # Step updates safely parameterized\n            m_X = beta1 * m_X + (1 - beta1) * g_X\n            v_X = beta2 * v_X + (1 - beta2) * (g_X ** 2)\n            m_X_h = m_X / (1 - beta1 ** t)\n            v_X_h = v_X / (1 - beta2 ** t)\n            X -= curr_lr * m_X_h / (np.sqrt(v_X_h) + epsilon)\n            \n            m_Y = beta1 * m_Y + (1 - beta1) * g_Y\n            v_Y = beta2 * v_Y + (1 - beta2) * (g_Y ** 2)\n            m_Y_h = m_Y / (1 - beta1 ** t)\n            v_Y_h = v_Y / (1 - beta2 ** t)\n            Y -= curr_lr * m_Y_h / (np.sqrt(v_Y_h) + epsilon)\n            \n            m_R = beta1 * m_R + (1 - beta1) * g_R\n            v_R = beta2 * v_R + (1 - beta2) * (g_R ** 2)\n            m_R_h = m_R / (1 - beta1 ** t)\n            v_R_h = v_R / (1 - beta2 ** t)\n            R -= curr_lr * m_R_h / (np.sqrt(v_R_h) + epsilon)\n            \n            X = np.clip(X, 0.0, 1.0)\n            Y = np.clip(Y, 0.0, 1.0)\n            R = np.maximum(R, 0.001)\n            \n            c_t *= c_mult\n            \n            # Sub-stage random topological perturbation jitter overcoming dense local arrangement lockdowns\n            if t % 300 == 0 and t < 1500:\n                X += np.random.normal(0, 0.003, N)\n                Y += np.random.normal(0, 0.003, N)\n                X = np.clip(X, 0.0, 1.0)\n                Y = np.clip(Y, 0.0, 1.0)\n                \n        # Rigid bounds snap strictly to true mathematical feasible regimes unconditionally\n        X_val, Y_val, R_val = make_valid(X, Y, R)\n        curr_sum = np.sum(R_val)\n        \n        if curr_sum > best_sum:\n            best_sum = curr_sum\n            best_X = X_val\n            best_Y = Y_val\n            best_R = R_val\n\n    return np.column_stack((best_X, best_Y)), best_R, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a heavily optimized arrangement of 26 circles in a unit square\n    that tightly maximizes the sum of their radii via simulated annealing physics.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Run a continuous restart scheme to traverse and select best optimal geometries\n    for seed in range(12):\n        X = optimize_seed(seed)\n        final_radii = compute_max_radii(X)\n        score = np.sum(final_radii)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X\n            best_radii = final_radii\n            \n    return best_centers, best_radii, best_sum\n\n\ndef optimize_seed(seed):\n    \"\"\"Executes gradient ascent physical optimizer applying non-linear repulsions\"\"\"\n    n = 26\n    np.random.seed(seed * 42 + 7)\n    X = []\n    \n    # Generate structural layout biases targeting interstitial properties \n    if seed % 4 == 0:\n        grid = np.linspace(0.1, 0.9, 5)\n        for x in grid:\n            for y in grid:\n                X.append([x, y])\n        X.append([0.5, 0.5])\n    elif seed % 4 == 1:\n        X.append([0.5, 0.5])\n        for i in range(7):\n            a = 2 * np.pi * i / 7\n            X.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        for i in range(18):\n            a = 2 * np.pi * i / 18\n            X.append([0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)])\n    elif seed % 4 == 2:\n        # Bias boundaries strategically\n        X.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n        for t in np.linspace(0.2, 0.8, 4):\n            X.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n        for _ in range(n - len(X)):\n            X.append(np.random.uniform(0.2, 0.8, 2).tolist())\n    else:\n        # Radial symmetry fibonacci break layout \n        for i in range(n):\n            r = 0.45 * np.sqrt((i + 1) / float(n))\n            theta = i * 2.3999632\n            X.append([0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)])\n            \n    # Apply thermal random breaks ensuring robust positional gradient responses\n    X = np.array(X)[:n] + np.random.randn(n, 2) * 0.005\n    X = np.clip(X, 0.02, 0.98)\n    \n    R = np.full(n, 0.06)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 2200\n    \n    # Advanced gradient scheduling simulated layout physics settling iterations\n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.005 * (1.0 - progress) + 0.0002\n        \n        # Exponential penalization scaling solidifying boundary geometries gracefully\n        C = 5.0 * (2000.0 ** progress)\n        \n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :]\n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + 1e-12\n        \n        overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n        np.fill_diagonal(overlap, -1.0)\n        overlap_vals = overlap * (overlap > 0)\n        \n        grad_X = np.zeros_like(X)\n        grad_R = np.full(n, -1.0)\n        \n        # Dynamic internal forces generated inversely proportional towards interstitial gaps \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X += np.sum(factor[:, :, np.newaxis] * diff, axis=1)\n        grad_R += np.sum(2.0 * C * overlap_vals, axis=1)\n        \n        w_l = np.maximum(0, R - X[:, 0])\n        w_r = np.maximum(0, R - (1 - X[:, 0]))\n        w_b = np.maximum(0, R - X[:, 1])\n        w_t = np.maximum(0, R - (1 - X[:, 1]))\n        \n        grad_X[:, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        # Anneal structural constraints breaking edge symmetry lock-ups securely\n        if step < steps * 0.35:\n            grad_X += np.random.randn(n, 2) * 0.03 * (1.0 - step / (steps * 0.35))\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        X -= lr_base * (m_X / (1 - beta1 ** step)) / (np.sqrt(v_X / (1 - beta2 ** step)) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        R -= lr_base * (m_R / (1 - beta1 ** step)) / (np.sqrt(v_R / (1 - beta2 ** step)) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n        \n    return X\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized strict distributions securely enforcing non-overlap, \n    evaluating geometrical capabilities resiliently without user sequencing prejudice.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical attempt evaluating precise extreme maximum geometric boundaries limits\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(0.0, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n        if res.success:\n            return np.maximum(0.0, res.x - 1e-6)\n    except Exception:\n        pass\n\n    # Unprejudiced stable dynamic geometric compression graceful-recovery fallback\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Assured residual overlap removal phase mathematically assuring clean submission states\n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-6)\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based vectorized multistart circle packing optimization for n=26\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Compute mathematically optimized exact maximal radius envelopes via robust linear programming.\n    Solves constraints perfectly enforcing precise solid bounds reliably.\n    \"\"\"\n    n = centers.shape[0]\n    \n    # Mathematical limits resolving true precise topological thresholds linearly \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i+1, n):\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(np.linalg.norm(centers[i] - centers[j]))\n                \n        bounds = []\n        for i in range(n):\n            safe_wall = max(1e-7, min(centers[i, 0], centers[i, 1], \n                                     1.0 - centers[i, 0], 1.0 - centers[i, 1]) - 1e-8)\n            bounds.append((0, safe_wall))\n            \n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        except Exception:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds)\n            \n        if res.success:\n            return np.maximum(0.0, res.x - 1e-7)\n    except Exception:\n        pass\n\n    # Unprejudiced stable geometric bounding compression fallback mechanism\n    r = np.zeros(n)\n    for i in range(n):\n        r[i] = min(centers[i, 0], centers[i, 1], 1 - centers[i, 0], 1 - centers[i, 1])\n        \n    dist = np.sqrt(np.sum((centers[:, None] - centers[None, :]) ** 2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    for _ in range(3000):\n        r += 0.002\n        max_walls = np.minimum.reduce([centers[:, 0], 1 - centers[:, 0], \n                                       centers[:, 1], 1 - centers[:, 1]])\n        r = np.minimum(r, max_walls)\n        \n        overlap = r[:, None] + r[None, :] - dist\n        if np.max(overlap) > 1e-9:\n            excess = np.maximum(0, overlap)\n            scale = r[:, None] / (r[:, None] + r[None, :] + 1e-9)\n            r -= np.sum(excess * scale, axis=1) * 0.5\n\n    # Safe float residue clean-up routine validating geometry compliance cleanly \n    for _ in range(50):\n        changed = False\n        for i in range(n):\n            for j in range(i+1, n):\n                if r[i] + r[j] > dist[i, j] + 1e-9:\n                    excess = r[i] + r[j] - dist[i, j]\n                    r[i] -= excess / 2.0\n                    r[j] -= excess / 2.0\n                    changed = True\n        if not changed:\n            break\n            \n    return np.maximum(0.0, r - 1e-7)\n\n\ndef construct_packing():\n    \"\"\"\n    Simultaneously accelerates globally across massive parallel geometries exploring \n    optimal mathematical distributions using fully vectorized physical gradient trajectories.\n    \"\"\"\n    B = 72\n    n = 26\n    np.random.seed(42)\n    X_init = np.zeros((B, n, 2))\n    \n    # Procedurally generate widely spanning varied physical configuration topologies  \n    for b in range(B):\n        mode = b % 8\n        if mode == 0:\n            X_init[b] = np.random.uniform(0.1, 0.9, (n, 2))\n        elif mode == 1:\n            for i in range(16):\n                a = 2 * np.pi * i / 16\n                X_init[b, i] = [0.5 + 0.35 * np.cos(a), 0.5 + 0.35 * np.sin(a)]\n            for i in range(16, n):\n                X_init[b, i] = np.random.uniform(0.3, 0.7, 2)\n        elif mode == 2:\n            c1, c2 = 8, 18\n            for i in range(c1):\n                a = 2 * np.pi * i / c1\n                X_init[b, i] = [0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)]\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, c1+i] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]\n        elif mode == 3:\n            grid = np.linspace(0.15, 0.85, 5)\n            k = 0\n            for x in grid:\n                for y in grid:\n                    X_init[b, k] = [x, y]\n                    k += 1\n            X_init[b, k] = [0.5, 0.5]\n        elif mode == 4:\n            pts = []\n            pts.extend([[0.05, 0.05], [0.95, 0.05], [0.05, 0.95], [0.95, 0.95]])\n            for t in np.linspace(0.2, 0.8, 4):\n                pts.extend([[t, 0.05], [t, 0.95], [0.05, t], [0.95, t]])\n            for _ in range(n - len(pts)):\n                pts.append(np.random.uniform(0.2, 0.8, 2).tolist())\n            X_init[b] = pts\n        elif mode == 5:\n            for i in range(n):\n                r = 0.45 * np.sqrt((i + 1) / float(n))\n                theta = i * 2.3999632\n                X_init[b, i] = [0.5 + r * np.cos(theta), 0.5 + r * np.sin(theta)]\n        elif mode == 6:\n            c1, c2, c3 = 4, 9, 13\n            k = 0\n            for i in range(c1):\n                a = 2 * np.pi * i / c1 + 0.2\n                X_init[b, k] = [0.5 + 0.12 * np.cos(a), 0.5 + 0.12 * np.sin(a)]; k += 1\n            for i in range(c2):\n                a = 2 * np.pi * i / c2\n                X_init[b, k] = [0.5 + 0.28 * np.cos(a), 0.5 + 0.28 * np.sin(a)]; k += 1\n            for i in range(c3):\n                a = 2 * np.pi * i / c3 + 0.1\n                X_init[b, k] = [0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)]; k += 1\n        elif mode == 7:\n            k = 0\n            for dist in [0.05, 0.25]:\n                for px, py in [(dist, dist), (1-dist, dist), (dist, 1-dist), (1-dist, 1-dist)]:\n                    X_init[b, k] = [px, py]\n                    k += 1\n            while k < n:\n                X_init[b, k] = np.random.uniform(0.2, 0.8, 2)\n                k += 1\n\n    noise_factors = np.linspace(0.001, 0.008, 9)\n    for b in range(B):\n        X_init[b] += np.random.randn(n, 2) * noise_factors[b // 8]\n        \n    X = np.clip(X_init, 0.05, 0.95)\n    R = np.full((B, n), 0.04)\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2, eps = 0.9, 0.999, 1e-8\n    steps = 3500\n    \n    # Physics parameters optimization integration completely seamlessly handled efficiently \n    for step in range(1, steps + 1):\n        progress = step / steps\n        lr_base = 0.015 * (1.0 - progress) + 0.001\n        \n        # Anneal parameter dynamically forces locking rigid walls fully  \n        C = 5.0 * (10000.0 ** progress)\n        \n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :]\n        dist = np.maximum(np.sqrt(np.sum(diff**2, axis=-1)), 1e-10)\n        \n        overlap = R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist\n        overlap -= np.eye(n) * 10.0\n        overlap_vals = overlap * (overlap > 0)\n        \n        factor = -2.0 * C * overlap_vals / dist \n        grad_X = np.sum(factor[:, :, :, np.newaxis] * diff, axis=2)\n        grad_R = np.sum(2.0 * C * overlap_vals, axis=2) - 1.0\n        \n        w_l = np.maximum(0, R - X[:, :, 0])\n        w_r = np.maximum(0, R - (1 - X[:, :, 0]))\n        w_b = np.maximum(0, R - X[:, :, 1])\n        w_t = np.maximum(0, R - (1 - X[:, :, 1]))\n        \n        grad_X[:, :, 0] += 2.0 * C * (-w_l + w_r)\n        grad_X[:, :, 1] += 2.0 * C * (-w_b + w_t)\n        grad_R += 2.0 * C * (w_l + w_r + w_b + w_t)\n        \n        if progress < 0.5:\n            noise_scale = 0.03 * (1.0 - progress / 0.5)\n            grad_X += np.random.randn(B, n, 2) * noise_scale\n            \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X ** 2)\n        m_X_hat = m_X / max(1.0 - beta1 ** step, 1e-12)\n        v_X_hat = v_X / max(1.0 - beta2 ** step, 1e-12)\n        X -= lr_base * m_X_hat / (np.sqrt(v_X_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R ** 2)\n        m_R_hat = m_R / max(1.0 - beta1 ** step, 1e-12)\n        v_R_hat = v_R / max(1.0 - beta2 ** step, 1e-12)\n        R -= lr_base * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        X = np.clip(X, 0, 1)\n        R = np.maximum(R, 0.0)\n\n    # Sort generated models filtering exactly most optimized promising configurations precisely \n    scores = np.sum(R, axis=1)\n    best_indices = np.argsort(scores)[::-1][:16]\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Clean fallback resolving constraints extracting strictly sound layout maxima completely \n    for b in best_indices:\n        final_R = compute_max_radii(X[b])\n        score = np.sum(final_R)\n        \n        if score > best_sum:\n            best_sum = score\n            best_centers = X[b]\n            best_radii = final_R\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"12.48s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.553061/2.635 = 0.9689\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 96.9% of target value\", \"radius_stats\": \"Min: 0.061096, Max: 0.130508, Avg: 0.098195\"}", "artifact_dir": null, "embedding": null}