{"id": "e5592d93-4257-461a-8474-a1faa464ef5d", "code": "import numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts, buffer=1e-11):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - buffer\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    b_ub[num_pairs::4] = x - buffer\n    b_ub[num_pairs+1::4] = 1.0 - x - buffer\n    b_ub[num_pairs+2::4] = y - buffer\n    b_ub[num_pairs+3::4] = 1.0 - y - buffer\n    \n    # Ensure bounds are strictly non-negative\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use HiGHS solver for efficiency and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent. The gradients\n    are derived from the sensitivity of the LP objective to center movements.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Generate diverse initial configurations to explore potential optimal topologies\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 6x4 Grid with two circles on the side\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx2.ravel(), gy2.ravel()]), [[0.2, 0.5], [0.8, 0.5]]]))\n    \n    # 3: Staggered layers to cover the square densely\n    for layers in [[5, 4, 5, 4, 5, 3], [6, 5, 6, 5, 4], [7, 6, 7, 6], [5, 5, 5, 5, 6]]:\n        c = []\n        for r_idx, n_row in enumerate(layers):\n            for i_idx in range(n_row):\n                c.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n        inits.append(np.array(c)[:n])\n        \n    # 4: Concentric Ring layouts (Phyllotaxis and manually defined)\n    for ring_counts in [[1, 8, 17], [1, 7, 18]]:\n        c_ring = [[0.5, 0.5]]\n        for rad, count in [(0.22, ring_counts[1]), (0.44, ring_counts[2])]:\n            for i in range(count):\n                a = 2 * np.pi * i / count\n                c_ring.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n        inits.append(np.array(c_ring)[:n])\n        \n    # 5: Fibonacci Spiral / Phyllotaxis\n    phi = (1 + 5**0.5) / 2\n    spir = np.array([[0.5 + 0.45 * np.sqrt((i + 0.5) / n) * np.cos(2 * np.pi * i / phi**2),\n                      0.5 + 0.45 * np.sqrt((i + 0.5) / n) * np.sin(2 * np.pi * i / phi**2)] \n                      for i in range(n)])\n    inits.append(spir)\n    \n    # 6: Pure random starts to cover less structured topologies\n    np.random.seed(1337)\n    for _ in range(4):\n        inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n\n    # Multi-start optimization loop\n    for c_start in inits:\n        # Time limit of 550 seconds for the entire process\n        if time.time() - start_time > 550:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.018  # Learning rate for gradient ascent\n        \n        for step in range(400):\n            # Check for time limit inside the iteration loop\n            if step % 25 == 0 and time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Use dual variables (marginal sensitivities) to compute gradient\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distance sensitivity (pushing centers apart)\n            lams_p = lambdas[:num_pairs]\n            active_p = lams_p > 1e-9\n            if np.any(active_p):\n                ii, jj = i_idx[active_p], j_idx[active_p]\n                diffs = curr_c[ii] - curr_c[jj]\n                # Normalized directions scaled by sensitivity\n                g_vals = lams_p[active_p, np.newaxis] * diffs / (dists[active_p, np.newaxis] + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity (pushing centers away from walls)\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]\n            grad[:, 1] += mus[:, 2] - mus[:, 3]\n            \n            # Apply normalized gradient update for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-11:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within the square and decay the learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.994\n            \n    # Re-calculate optimal radii for the best centers found across all starts\n    final_radii, _, _, _, _ = solve_max_radii(best_centers, buffer=1e-12)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Standard entry point for circle packing evaluations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")", "changes_description": null, "language": "python", "parent_id": "97d33656-3427-4516-b89a-076027f959dc", "generation": 4, "timestamp": 1771870704.040728, "iteration_found": 79, "metrics": {"validity": 1.0, "sum_radii": 2.5625791516868053, "target_ratio": 0.9725158070917668, "combined_score": 0.9725158070917668, "radius_variance": 0.008725426090777273, "spatial_spread": 0.1656492247615725, "eval_time": 10.656079769134521}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.4797382079429555, "target_ratio": 0.9410771187639301, "combined_score": 0.9410771187639301, "radius_variance": 0.0033994973812845213, "spatial_spread": 0.19275911129667, "eval_time": 1.2359836101531982}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician specializing in circle packing problems and computational geometry. \nYour task is to improve a constructor function that directly produces a specific arrangement of 26 circles in a unit square, maximizing the sum of their radii. \nTry to improve the results reported in the AlphaEvolve paper which achieved a sum of 2.635 for n=26.\n\nKey insights:\n- The optimization routine is critically important - simple physics-based models with carefully tuned parameters\n- Consider strategic placement of circles at square corners and edges\n- Adjusting the pattern to place larger circles at the center and smaller at the edges\n- Similar radius circles often form regular patterns, while varied radii allow better space utilization\n- Perfect symmetry may not yield the optimal packing due to edge effects\n\nMake sure that your codecod is syntactically perfect, strictly adheres to PEP 8 indentation, and contains no ellipses, comments-as-placeholders, or unclosed structures.\n", "user": "# Current Program Information\n- Fitness: 0.9411\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.9672 \u2192 0.9411. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n1.24s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.479738/2.635 = 0.9411\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5485, target_ratio: 0.9672, combined_score: 0.9672, radius_variance: 0.0080, spatial_spread: 0.1644, eval_time: 5.2918\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5591, target_ratio: 0.9712, combined_score: 0.9712, radius_variance: 0.0086, spatial_spread: 0.1660, eval_time: 7.7775\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.5778, target_ratio: 0.9783, combined_score: 0.9783, radius_variance: 0.0044, spatial_spread: 0.2088, eval_time: 9.6580\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9783)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    x, y = pts[:, 0], pts[:, 1]\n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Ensure bounds are strictly non-negative\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent derived from LP.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # 3: Staggered layers (5, 4, 5, 4, 5, 3) = 26\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # 4: Another staggered layout (6, 7, 6, 7) = 26\n    c4 = []\n    for r_idx, n_row in enumerate([6, 7, 6, 7]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 4])\n    inits.append(np.array(c4))\n    \n    # 5: Staggered (5, 5, 5, 5, 6) = 26\n    c5 = []\n    for r_idx, n_row in enumerate([5, 5, 5, 5, 6]):\n        for i_idx in range(n_row):\n            c5.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 5])\n    inits.append(np.array(c5))\n\n    # 6: Ring distribution (1 center, 8 middle, 17 outer)\n    c6 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c6.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c6))\n    \n    # 7: Fibonacci / Spiral layout\n    c7 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt(i / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c7.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c7))\n\n    # 8: Randomly perturbed grid\n    np.random.seed(42)\n    inits.append(np.clip(inits[0] + np.random.normal(0, 0.02, (n, 2)), 0.05, 0.95))\n    \n    # 9: 6x4 Grid plus 2 extra circles\n    gx9, gy9 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx9.ravel(), gy9.ravel()]), [[0.5, 0.4], [0.5, 0.6]]]))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.01  # Initial learning rate\n        \n        for step in range(450):\n            # Check time limit periodically\n            if time.time() - start_time > 560:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distances\n            lams_p = lambdas[:num_pairs]\n            diffs = curr_c[i_idx] - curr_c[j_idx]\n            g_vals = lams_p[:, np.newaxis] * diffs / (dists[:, np.newaxis] + 1e-15)\n            np.add.at(grad, i_idx, g_vals)\n            np.add.at(grad, j_idx, -g_vals)\n            \n            # Gradients from boundary constraints\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]\n            grad[:, 1] += mus[:, 2] - mus[:, 3]\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final optimize and validity check for the best centers found\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Standard entry point for circle packing evaluations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5778), Performs well on target_ratio (0.9783), Performs well on combined_score (0.9783), Performs well on radius_variance (0.0044), Performs well on spatial_spread (0.2088), Performs well on eval_time (9.6580)\n\n### Program 2 (Score: 0.9712)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    \n    Returns:\n        radii: Optimal radii for each center\n        duals: Dual variables (marginals) from the LP\n        i_idx, j_idx: Indices of circle pairs\n        dists: Euclidean distances between centers\n    \"\"\"\n    n = pts.shape[0]\n    # Minimize -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.sqrt(np.sum(diffs**2, axis=1))\n    num_pairs = len(i_idx)\n    \n    # Constraints: pairwise (r_i + r_j <= d_ij) and boundary (r_i <= d_wall)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = np.maximum(0, dists - 1e-12)\n    \n    # Boundary constraints: x_i, 1-x_i, y_i, 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        # r_i <= x[i]\n        A_ub[base, i], b_ub[base] = 1, np.maximum(0, x[i] - 1e-12)\n        # r_i <= 1.0 - x[i]\n        A_ub[base + 1, i], b_ub[base + 1] = 1, np.maximum(0, 1.0 - x[i] - 1e-12)\n        # r_i <= y[i]\n        A_ub[base + 2, i], b_ub[base + 2] = 1, np.maximum(0, y[i] - 1e-12)\n        # r_i <= 1.0 - y[i]\n        A_ub[base + 3, i], b_ub[base + 3] = 1, np.maximum(0, 1.0 - y[i] - 1e-12)\n        \n    try:\n        # Use HiGHS solver for efficiency and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent. The gradients\n    are derived from the sensitivity of the LP objective to changes in center\n    coordinates (pairwise distances and boundary distances).\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = np.random.uniform(0.1, 0.9, (n, 2))\n    best_radii = np.zeros(n)\n    start_time = time.time()\n    \n    # Diverse initial layouts to explore potential optimal topologies\n    inits = []\n    \n    # 1. Perturbed Grid 5x5 plus one extra circle near center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.505, 0.495]]))\n    \n    # 2. Various staggered/hexagonal layers\n    # Layouts: 5-4-5-4-5-3, 4-5-4-5-4-4, and 6-5-6-5-4\n    for layout in [[5, 4, 5, 4, 5, 3], [4, 5, 4, 5, 4, 4], [6, 5, 6, 5, 4]]:\n        c = []\n        for r_idx, n_row in enumerate(layout):\n            for i_idx in range(n_row):\n                c.append([(i_idx + 0.5) / (n_row + 0.1), (r_idx + 0.5) / (len(layout) + 0.1)])\n        inits.append(np.array(c)[:n])\n        \n    # 3. Phyllotaxis Spiral (efficient natural packing)\n    phi = (1 + 5**0.5) / 2\n    idx_arr = np.arange(n) + 0.5\n    r_spiral = 0.47 * np.sqrt(idx_arr / n)\n    theta = 2 * np.pi * idx_arr / (phi**2)\n    inits.append(np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)]))\n    \n    # 4. Concentric Rings (1 center, 8 middle, 17 outer)\n    c_rings = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c_rings.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c_rings)[:n])\n    \n    # 5. Random starts with different seeds\n    np.random.seed(1337)\n    for _ in range(4):\n        inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n        \n    # Multi-start optimization loop\n    for c_start in inits:\n        # Respect a 540-second execution limit for the whole construction process\n        if time.time() - start_time > 540:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.015  # Initial learning rate\n        \n        for step in range(350):\n            # Frequent time check within the iteration loop\n            if step % 25 == 0 and time.time() - start_time > 540:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            curr_sum = np.sum(radii)\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n                \n            # Compute gradients from dual variables (marginal sensitivities)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Pairwise distance sensitivity: pushes centers apart to enlarge sum(radii)\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                d = dists[active_mask][:, np.newaxis]\n                # Normalized direction vectors scaled by dual importance\n                g_vectors = lams * diffs / (d + 1e-15)\n                np.add.at(grad, ii, g_vectors)\n                np.add.at(grad, jj, -g_vectors)\n                \n            # Boundary sensitivity: pushes centers away from walls\n            mus = np.abs(duals[num_pairs:]).reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]  # x_i and 1-x_i\n            grad[:, 1] += mus[:, 2] - mus[:, 3]  # y_i and 1-y_i\n            \n            # Apply normalized gradient update for numerical stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n                \n            # Keep centers strictly within the unit square square\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            # Gradual learning rate decay to fine-tune final position\n            lr *= 0.995\n            \n    # Re-calculate optimal radii for the best centers found across all starts\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Evaluate the packing arrangement for the target number of circles.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5591), Performs well on target_ratio (0.9712), Performs well on combined_score (0.9712), Performs well on radius_variance (0.0086), Performs well on spatial_spread (0.1660), Performs well on eval_time (7.7775)\n\n### Program 3 (Score: 0.9672)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= distance to wall.\n    \n    Returns:\n        radii: Optimal radii for each center.\n        duals: Dual variables (marginals) providing sensitivity to center movement.\n        i_idx, j_idx: Indices of circle pairs used for constraints.\n        dists: Euclidean distances between centers.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes the objective function, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combine pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Small epsilon to ensure strict validity within floating point precision\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Correct any negative bounds caused by centers being slightly out of square\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use the HiGHS solver for efficiency and access to marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return None, None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent derived from LP.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts to explore different packing topologies\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # 3: Staggered layers (5, 4, 5, 4, 5, 3) = 26\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # 4: Staggered layers (4, 5, 4, 5, 4, 4) = 26\n    c4 = []\n    for r_idx, n_row in enumerate([4, 5, 4, 5, 4, 4]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c4))\n\n    # 5: Ring distribution (1 center, 8 middle, 17 outer)\n    c5 = [[0.5, 0.5]]\n    for rad, count in [(0.24, 8), (0.46, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c5))\n    \n    # 6: Fibonacci / Spiral layout\n    c6 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt((i + 0.5) / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c6.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c6))\n\n    # 7: Concentric layers (1, 7, 18)\n    c7 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 7), (0.44, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c7.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c7))\n    \n    # 8: Grid 6x4 with 2 extras\n    gx8, gy8 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx8.ravel(), gy8.ravel()]), [[0.2, 0.5], [0.8, 0.5]]]))\n\n    # Optimization loop for each initialization\n    for c_start in inits:\n        if time.time() - start_time > 550:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.015  # Starting learning rate\n        \n        for step in range(300):\n            # Check for early exit based on time\n            if step % 20 == 0 and time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on sensitivity from dual variables\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            # Dual variables indicate the rate of change of the sum w.r.t the constraint bounds\n            # For maximize sum(r_i), we move the centers in directions that increase b_ub\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distances: push centers apart\n            lams_p = lambdas[:num_pairs]\n            active_p = lams_p > 1e-9\n            if np.any(active_p):\n                ii, jj = i_idx[active_p], j_idx[active_p]\n                diffs = curr_c[ii] - curr_c[jj]\n                # Normalized direction vectors scaled by dual sensitivity\n                g_vals = lams_p[active_p, np.newaxis] * diffs / (dists[active_p, np.newaxis] + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints: move centers inward to make room\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]  # Sensitivity for x and 1-x\n            grad[:, 1] += mus[:, 2] - mus[:, 3]  # Sensitivity for y and 1-y\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-12:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within the unit square and apply decay to step size\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.99\n            \n    # Final cleanup: ensure radii are strictly optimal for the best centers found\n    if best_centers is not None:\n        final_radii, _, _, _, _ = solve_max_radii(best_centers)\n        return best_centers, final_radii, np.sum(final_radii)\n    else:\n        # Fallback in case of failure\n        random_c = np.random.uniform(0.1, 0.9, (n, 2))\n        random_r, _, _, _, _ = solve_max_radii(random_c)\n        return random_c, random_r, np.sum(random_r)\n\ndef run_packing():\n    \"\"\"Main execution function to be called by evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.5485), Performs well on target_ratio (0.9672), Performs well on combined_score (0.9672), Performs well on radius_variance (0.0080), Performs well on spatial_spread (0.1644), Performs well on eval_time (5.2918)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.9648)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    for k, (i, j) in enumerate(zip(i_idx, j_idx)):\n        A_ub[k, i] = 1\n        A_ub[k, j] = 1\n        b_ub[k] = dists[k] - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    for i in range(n):\n        base = num_pairs + 4 * i\n        A_ub[base, i], b_ub[base] = 1, x[i] - 1e-11\n        A_ub[base + 1, i], b_ub[base + 1] = 1, 1.0 - x[i] - 1e-11\n        A_ub[base + 2, i], b_ub[base + 2] = 1, y[i] - 1e-11\n        A_ub[base + 3, i], b_ub[base + 3] = 1, 1.0 - y[i] - 1e-11\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # Layout 1: 5x5 Grid with one circle near the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # Layout 2: Staggered layers (5, 4, 5, 4, 5, 3) to fill the square\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # Layout 3: Ring distribution (1 center, 8 middle, 17 outer)\n    c3 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c3.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c3))\n\n    # Layout 4: Another staggered layout (4, 5, 4, 5, 4, 4)\n    c4 = []\n    layers4 = [4, 5, 4, 5, 4, 4]\n    for r_idx, n_row in enumerate(layers4):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers4)])\n    inits.append(np.array(c4))\n    \n    # Layout 5: Random distribution\n    np.random.seed(42)\n    inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n    \n    # Optimization loop per initialization\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.008  # Initial learning rate\n        \n        for step in range(350):\n            # Periodically check time limit\n            if time.time() - start_time > 560:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient based on dual variables (marginals)\n            # Duals tell us how the sum of radii changes with center positions\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii = i_idx[active_mask]\n                jj = j_idx[active_mask]\n                lams = lambdas[active_mask]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Direction of movement to increase the distance\n                g_vals = (lams[:, np.newaxis] * diffs / (ds + 1e-12))\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary constraints\n            # Sensitivity to moving away from the four walls\n            mu0 = np.abs(duals[num_pairs + 4 * np.arange(n)])      # r_i <= x_i\n            mu1 = np.abs(duals[num_pairs + 4 * np.arange(n) + 1])  # r_i <= 1-x_i\n            mu2 = np.abs(duals[num_pairs + 4 * np.arange(n) + 2])  # r_i <= y_i\n            mu3 = np.abs(duals[num_pairs + 4 * np.arange(n) + 3])  # r_i <= 1-y_i\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Apply update with normalized gradient for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within square and decay learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final cleanup to ensure radii are optimal for the best centers found\n    final_radii, _, _, _, _ = solve_max_radii(best_centers)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Entry point for evaluation scripts.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n### Program D2 (Score: 0.9411)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii. \nThe dual variables of this LP provide the sensitivity of the sum of radii to the \ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and the tightest boundary constraints.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: minimize -sum(radii) to maximize sum(radii)\n    c_obj = -np.ones(n)\n\n    # Inequality constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    b_left = x\n    b_right = 1.0 - x\n    b_bottom = y\n    b_top = 1.0 - y\n\n    # Find which boundary is tightest for each circle\n    max_r_boundary = np.minimum.reduce([b_left, b_right, b_bottom, b_top])\n    bounds_lp = [(0, r) for r in max_r_boundary]\n\n    try:\n        # Highs is efficient and provides marginals (duals)\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, max_r_boundary\n\n\ndef run_packing():\n    \"\"\"\n    Runs the circle packing optimization and returns the best found configuration.\n    \"\"\"\n    n_circles = 26\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Define several starting configurations\n    initial_configs = []\n\n    # Init 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx.ravel(), gy.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # Init 2: Hexagonal-like staggered layers (5, 4, 5, 4, 5, 3) = 26 circles\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # Init 3: 6x4 Grid plus 2 extra circles\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx2.ravel(), gy2.ravel()])\n    c3 = np.vstack([c3, [[0.2, 0.5], [0.8, 0.5]]])\n    initial_configs.append(c3)\n\n    # Optimize each initial configuration\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        # Dual-gradient optimization iterations\n        for step in range(150):\n            res, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Update gradient based on pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        if d > 1e-8:\n                            grad[ii] += lam * diff / d\n                            grad[jj] -= lam * diff / d\n\n                # Update gradient based on boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0: grad[i, 0] += mu\n                        elif tightest == 1: grad[i, 0] -= mu\n                        elif tightest == 2: grad[i, 1] += mu\n                        elif tightest == 3: grad[i, 1] -= mu\n\n                # Normalize step for stability and apply update\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    # Decay the step size over time\n                    step_size = 0.006 * (0.99 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Keep centers within the unit square\n                cur_c = np.clip(cur_c, 1e-7, 1.0 - 1e-7)\n            else:\n                break\n\n    # Perform a final rigorous LP solve and validity correction\n    if best_c is None:\n        best_c = initial_configs[1]\n\n    res_final, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(best_c)\n    final_r = res_final.x\n    final_c = best_c\n\n    # Strict geometry enforcement (multi-pass) to ensure zero overlap or boundary violation\n    for _ in range(50):\n        for i in range(n_circles):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n\n    return final_c, final_r, np.sum(final_r)\n\n\ndef construct_packing():\n    \"\"\"Alias for run_packing to match expected constructor interface.\"\"\"\n    return run_packing()\n# EVOLVE-BLOCK-END\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii.\nThe dual variables of this LP provide the sensitivity of the sum of radii to the\ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and pairwise distances.\n    \"\"\"\n    n = 26\n    # Objective: maximize sum(radii) => minimize -sum(radii)\n    c_obj = -np.ones(n)\n\n    # Pairwise constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1.0 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    max_r_boundary = np.minimum.reduce([x, 1.0 - x, y, 1.0 - y])\n    bounds_lp = list(zip(np.zeros(n), np.maximum(max_r_boundary, 1e-10)))\n\n    try:\n        # Use HiGHS solver for efficiency and access to dual variables\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists\n\n\ndef construct_packing():\n    \"\"\"\n    Runs the circle packing optimization using dual-gradient ascent on center positions.\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Initial configurations to explore different topologies\n    initial_configs = []\n\n    # 1. Staggered layers (5, 5, 5, 5, 5, 1)\n    c1 = []\n    for r_idx in range(6):\n        num_row = 5 if r_idx < 5 else 1\n        for i_idx in range(num_row):\n            offset = 0.2 if r_idx % 2 == 1 else 0.0\n            x_coord = (i_idx + 0.5 + offset) / 5.5\n            y_coord = (r_idx + 0.5) / 6.0\n            c1.append([x_coord, y_coord])\n    initial_configs.append(np.array(c1)[:n])\n\n    # 2. Concentric rings (1 center, 8 middle, 17 outer)\n    c2 = [[0.5, 0.5]]\n    for rad, count in [(0.22, 8), (0.43, 17)]:\n        for i in range(count):\n            angle = 2 * np.pi * i / count\n            c2.append([0.5 + rad * np.cos(angle), 0.5 + rad * np.sin(angle)])\n    initial_configs.append(np.array(c2)[:n])\n\n    # 3. Standard 5x5 grid plus one circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c3 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]])\n    initial_configs.append(c3)\n\n    # Optimization Loop\n    for start_pts in initial_configs:\n        curr_pts = np.clip(start_pts, 0.01, 0.99)\n        \n        for step in range(160):\n            res, i_idx, j_idx, d_vals = solve_lp(curr_pts)\n            if not res or not res.success:\n                break\n\n            current_sum = -res.fun\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_c = curr_pts.copy()\n                best_r = res.x\n\n            try:\n                # Extract dual variables (marginals) to compute gradients\n                lambdas = getattr(res.ineqlin, 'marginals', None)\n                mus = getattr(res.upper, 'marginals', None)\n                if lambdas is None or mus is None:\n                    break\n                \n                grad = np.zeros((n, 2))\n                diffs = curr_pts[i_idx] - curr_pts[j_idx]\n                \n                # Pairwise sensitivity\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-8:\n                        ii, jj = i_idx[k], j_idx[k]\n                        vec = lam * diffs[k] / (d_vals[k] + 1e-10)\n                        grad[ii] += vec\n                        grad[jj] -= vec\n\n                # Boundary sensitivity\n                for k in range(n):\n                    mu = abs(mus[k])\n                    if mu > 1e-8:\n                        xk, yk = curr_pts[k]\n                        b_opts = [xk, 1.0 - xk, yk, 1.0 - yk]\n                        tightest = np.argmin(b_opts)\n                        if tightest == 0: grad[k, 0] += mu\n                        elif tightest == 1: grad[k, 0] -= mu\n                        elif tightest == 2: grad[k, 1] += mu\n                        elif tightest == 3: grad[k, 1] -= mu\n\n                # Normalize gradient step for stability\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-10:\n                    step_size = 0.009 * (0.99 ** step)\n                    curr_pts += step_size * grad / gnorm\n                    curr_pts = np.clip(curr_pts, 1e-8, 1.0 - 1e-8)\n                else:\n                    break\n            except Exception:\n                break\n\n    # Final geometric polish and LP solve to ensure perfect validity\n    res_final, _, _, _ = solve_lp(best_c)\n    final_c, final_r = best_c, res_final.x\n\n    # Strict multi-pass enforcement for zero overlap or boundary violations\n    for _ in range(100):\n        for i in range(n):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(final_c[i] - final_c[j])\n                if final_r[i] + final_r[j] > dist:\n                    overlap = (final_r[i] + final_r[j]) - dist\n                    final_r[i] -= overlap * 0.5\n                    final_r[j] -= overlap * 0.5\n\n    return final_c, final_r, np.sum(final_r)\n# EVOLVE-BLOCK-END\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.linalg.norm(diffs, axis=1)\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    # Use 1e-11 buffer to strictly avoid overlapping violations\n    b_ub[:num_pairs] = dists - 1e-11\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    x, y = pts[:, 0], pts[:, 1]\n    b_ub[num_pairs::4] = x - 1e-11\n    b_ub[num_pairs+1::4] = 1.0 - x - 1e-11\n    b_ub[num_pairs+2::4] = y - 1e-11\n    b_ub[num_pairs+3::4] = 1.0 - y - 1e-11\n    \n    # Ensure bounds are strictly non-negative to prevent LP infeasibility\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef optimize_layout(c_start, lr_init, max_steps, start_time, best_sum, best_centers, best_radii):\n    \"\"\"\n    Subgradient ascent using momentum and cosine annealing learning rate.\n    Uses the LP dual variables to find directions that increase the sum of radii.\n    \"\"\"\n    n = c_start.shape[0]\n    curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n    momentum = np.zeros((n, 2))\n    beta = 0.85\n    \n    for step in range(max_steps):\n        if time.time() - start_time > 540:\n            break\n            \n        radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n        if duals is None:\n            break\n            \n        current_sum = np.sum(radii)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = curr_c.copy()\n            best_radii = radii.copy()\n            \n        grad = np.zeros((n, 2))\n        num_pairs = len(i_idx)\n        lambdas = np.abs(duals)\n        \n        # Pull gradients from pairwise distance constraints\n        lams_p = lambdas[:num_pairs]\n        diffs = curr_c[i_idx] - curr_c[j_idx]\n        g_vals = lams_p[:, np.newaxis] * diffs / (dists[:, np.newaxis] + 1e-15)\n        np.add.at(grad, i_idx, g_vals)\n        np.add.at(grad, j_idx, -g_vals)\n        \n        # Pull gradients from boundary limit constraints\n        mus = lambdas[num_pairs:].reshape((n, 4))\n        grad[:, 0] += mus[:, 0] - mus[:, 1]\n        grad[:, 1] += mus[:, 2] - mus[:, 3]\n        \n        gnorm = np.linalg.norm(grad)\n        if gnorm > 1e-12:\n            grad_normed = grad / gnorm\n        else:\n            grad_normed = np.zeros_like(grad)\n            \n        # Apply momentum to smooth the objective's piecewise linear subgradients\n        momentum = beta * momentum + (1 - beta) * grad_normed\n        \n        # Cosine annealing learning rate for stable convergence\n        lr = lr_init * 0.5 * (1 + np.cos(np.pi * step / max_steps))\n        curr_c += lr * momentum\n        curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n        \n    return best_centers, best_radii, best_sum\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Explores heavily using diverse multi-start layouts and momentum optimization.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    inits = []\n    \n    # Structured Layout 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # Structured Layout 2: 5x5 Grid with one circle in the corner\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.05, 0.05]]))\n    \n    # Structured Layout 3: Staggered layers (5, 4, 5, 4, 5, 3)\n    c3 = []\n    for r_idx, n_row in enumerate([5, 4, 5, 4, 5, 3]):\n        for i_idx in range(n_row):\n            c3.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 6])\n    inits.append(np.array(c3))\n    \n    # Structured Layout 4: Staggered layers (6, 7, 6, 7)\n    c4 = []\n    for r_idx, n_row in enumerate([6, 7, 6, 7]):\n        for i_idx in range(n_row):\n            c4.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 4])\n    inits.append(np.array(c4))\n    \n    # Structured Layout 5: Staggered layers (5, 5, 5, 5, 6)\n    c5 = []\n    for r_idx, n_row in enumerate([5, 5, 5, 5, 6]):\n        for i_idx in range(n_row):\n            c5.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / 5])\n    inits.append(np.array(c5))\n\n    # Structured Layout 6: Ring distribution (1 center, 8 middle, 17 outer)\n    c6 = [[0.5, 0.5]]\n    for rad, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c6.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n    inits.append(np.array(c6))\n    \n    # Structured Layout 7: Fibonacci spiral pattern\n    c7 = []\n    phi = (1 + 5**0.5) / 2\n    for i in range(n):\n        r_spiral = 0.45 * np.sqrt((i + 0.5) / n)\n        theta = 2 * np.pi * i / (phi**2)\n        c7.append([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(np.array(c7))\n    \n    # Structured Layout 8: 6x4 Grid plus 2 extra focal circles\n    gx9, gy9 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx9.ravel(), gy9.ravel()]), [[0.5, 0.4], [0.5, 0.6]]]))\n\n    # Structured Layout 9: One huge center, 25 smaller circles around\n    c_large = [[0.5, 0.5]]\n    for i in range(25):\n        a = 2 * np.pi * i / 25\n        c_large.append([0.5 + 0.45 * np.cos(a), 0.5 + 0.45 * np.sin(a)])\n    inits.append(np.array(c_large))\n\n    # Structured Layout 10: Four large corners, 22 scattered circles\n    np.random.seed(42)\n    c_corners = [[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.85]]\n    for i in range(22):\n        c_corners.append([np.random.uniform(0.3, 0.7), np.random.uniform(0.3, 0.7)])\n    inits.append(np.array(c_corners))\n\n    # Add dense randomly perturbed versions of the structured layouts (20 configurations)\n    base_inits = list(inits)\n    for base in base_inits:\n        for _ in range(2):\n            inits.append(np.clip(base + np.random.normal(0, 0.015, (n, 2)), 0.05, 0.95))\n            \n    # Add completely random configurations for deep exploration (20 configurations)\n    for _ in range(20):\n        inits.append(np.random.uniform(0.05, 0.95, (n, 2)))\n\n    # Main exploratory optimization phase\n    for c_start in inits:\n        if time.time() - start_time > 520:\n            break\n        best_centers, best_radii, best_sum = optimize_layout(\n            c_start, 0.015, 800, start_time, best_sum, best_centers, best_radii\n        )\n            \n    # Final polishing on the overall best layout found with a lower learning rate\n    if best_centers is not None:\n        best_centers, best_radii, best\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0892, Type: Exploratory)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    Returns optimal radii, dual variables (marginals), and pairwise info.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes c^T * x, so we minimize -sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    dists = np.linalg.norm(pts[i_idx] - pts[j_idx], axis=1)\n    num_pairs = len(i_idx)\n    \n    # Total constraints: num_pairs + 4 * n (boundary constraints)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Vectorized assignment of pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - 1e-11\n    \n    # Vectorized assignment of boundary constraints\n    # r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    base = num_pairs\n    A_ub[base : base + n, np.arange(n)] = 1\n    b_ub[base : base + n] = x - 1e-11\n    \n    A_ub[base + n : base + 2*n, np.arange(n)] = 1\n    b_ub[base + n : base + 2*n] = 1.0 - x - 1e-11\n    \n    A_ub[base + 2*n : base + 3*n, np.arange(n)] = 1\n    b_ub[base + 2*n : base + 3*n] = y - 1e-11\n    \n    A_ub[base + 3*n : base + 4*n, np.arange(n)] = 1\n    b_ub[base + 3*n : base + 4*n] = 1.0 - y - 1e-11\n    \n    try:\n        # Using HiGHS solver for speed and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Utilizes multi-start configurations and dual-gradient descent.\n    \"\"\"\n    n = 26\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    start_time = time.time()\n    \n    # Diverse initial layouts for multi-start optimization\n    inits = []\n    \n    # 1. Perturbed 5x5 Grid with one extra circle\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.51, 0.49]])\n    inits.append(c1)\n    \n    # 2. Staggered layers (5, 4, 5, 4, 5, 3)\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        for i_idx in range(n_row):\n            c2.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n    inits.append(np.array(c2))\n    \n    # 3. Phyllotaxis Spiral\n    phi = (1 + np.sqrt(5)) / 2\n    indices = np.arange(n) + 0.5\n    r_spiral = np.sqrt(indices / n) * 0.47\n    theta = 2 * np.pi * indices / (phi**2)\n    c3 = np.column_stack([0.5 + r_spiral * np.cos(theta), 0.5 + r_spiral * np.sin(theta)])\n    inits.append(c3)\n    \n    # 4. Concentric Rings (1, 8, 17)\n    c4 = [[0.5, 0.5]]\n    for radius, count in [(0.23, 8), (0.45, 17)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c4.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c4))\n    \n    # 5. Concentric Rings (1, 7, 18)\n    c5 = [[0.5, 0.5]]\n    for radius, count in [(0.22, 7), (0.43, 18)]:\n        for i in range(count):\n            a = 2 * np.pi * i / count\n            c5.append([0.5 + radius * np.cos(a), 0.5 + radius * np.sin(a)])\n    inits.append(np.array(c5))\n\n    # Optimization Loop\n    for c_start in inits:\n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.009\n        \n        for step in range(350):\n            if time.time() - start_time > 580:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Construct gradient from dual variables (marginals)\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            \n            # Gradients from pairwise distances\n            lambdas = np.abs(duals[:num_pairs])\n            active_mask = lambdas > 1e-8\n            if np.any(active_mask):\n                ii, jj = i_idx[active_mask], j_idx[active_mask]\n                lams = lambdas[active_mask][:, np.newaxis]\n                diffs = curr_c[ii] - curr_c[jj]\n                ds = dists[active_mask][:, np.newaxis]\n                # Move centers apart to allow for larger radii\n                g_vals = lams * diffs / (ds + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity\n            # Indices correlate with the vectorized order in solve_max_radii\n            mu0 = np.abs(duals[num_pairs : num_pairs + n])\n            mu1 = np.abs(duals[num_pairs + n : num_pairs + 2*n])\n            mu2 = np.abs(duals[num_pairs + 2*n : num_pairs + 3*n])\n            mu3 = np.abs(duals[num_pairs + 3*n : num_pairs + 4*n])\n            grad[:, 0] += mu0 - mu1\n            grad[:, 1] += mu2 - mu3\n            \n            # Update step with normalization for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-10:\n                curr_c += lr * grad / gnorm\n            \n            # Boundary enforcement and learning rate decay\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.995\n            \n    # Final check and cleanup to ensure absolute validity\n    final_radii, _, i_idx, j_idx, _ = solve_max_radii(best_centers)\n    \n    # Geometric validity enforcement pass (eliminating floating point creep)\n    for _ in range(30):\n        for i in range(n):\n            final_radii[i] = min(final_radii[i], best_centers[i, 0], 1.0 - best_centers[i, 0],\n                                 best_centers[i, 1], 1.0 - best_centers[i, 1])\n        for i, j in zip(i_idx, j_idx):\n            d = np.linalg.norm(best_centers[i] - best_centers[j])\n            if final_radii[i] + final_radii[j] > d:\n                overlap = (final_radii[i] + final_radii[j]) - d\n                final_radii[i] -= overlap * 0.5\n                final_radii[j] -= overlap * 0.5\n                \n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Interface to match the evaluation expectations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = run_packing()\n    print(f\"Total sum of radii for n=26: {total_sum:.6f}\")\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"\nConstructor-based circle packing for n=26 circles maximizing the sum of their radii.\nThis implementation uses a dual-gradient optimization approach. For a fixed set of\ncenters, we solve a Linear Programming (LP) problem to find the optimal radii. \nThe dual variables of this LP provide the sensitivity of the sum of radii to the \ndistances between centers and to the distances from the centers to the boundaries.\nThe centers are then updated iteratively in the direction that increases the total sum.\n\"\"\"\n\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef solve_max_radii_lp(pts):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Returns the LP result, pairwise indices, and the tightest boundary constraints.\n    \"\"\"\n    n = pts.shape[0]\n    # Objective: minimize -sum(radii) to maximize sum(radii)\n    c_obj = -np.ones(n)\n\n    # Inequality constraints: r_i + r_j <= distance(P_i, P_j)\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n\n    # A_ub * r <= b_ub\n    a_ub = np.zeros((len(i_idx), n))\n    a_ub[np.arange(len(i_idx)), i_idx] = 1\n    a_ub[np.arange(len(i_idx)), j_idx] = 1\n    b_ub = dists\n\n    # Boundary constraints: r_i <= min(x, 1-x, y, 1-y)\n    # Ensure pts are within (0, 1) to avoid negative bounds\n    pts_clipped = np.clip(pts, 1e-9, 1 - 1e-9)\n    x = pts_clipped[:, 0]\n    y = pts_clipped[:, 1]\n    b_left = x\n    b_right = 1.0 - x\n    b_bottom = y\n    b_top = 1.0 - y\n\n    # Find which boundary is tightest for each circle\n    max_r_boundary = np.minimum.reduce([b_left, b_right, b_bottom, b_top])\n    bounds_lp = [(0, r) for r in max_r_boundary]\n\n    try:\n        # Highs is efficient and provides marginals (duals)\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp, method='highs')\n    except Exception:\n        # Fallback to default if 'highs' is unavailable\n        res = linprog(c_obj, A_ub=a_ub, b_ub=b_ub, bounds=bounds_lp)\n\n    return res, i_idx, j_idx, dists, max_r_boundary\n\n\ndef run_packing():\n    \"\"\"\n    Runs the circle packing optimization and returns the best found configuration.\n    \"\"\"\n    n_circles = 26\n    best_sum = -1.0\n    best_c = None\n    best_r = None\n\n    # Define several starting configurations\n    initial_configs = []\n\n    # Init 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    c1 = np.column_stack([gx.ravel(), gy.ravel()])\n    c1 = np.vstack([c1, [0.5, 0.5]])\n    initial_configs.append(c1)\n\n    # Init 2: Hexagonal-like staggered layers (5, 4, 5, 4, 5, 3) = 26 circles\n    c2 = []\n    layers = [5, 4, 5, 4, 5, 3]\n    for r_idx, n_row in enumerate(layers):\n        y_coord = (r_idx + 0.5) / len(layers)\n        for i_idx in range(n_row):\n            x_coord = (i_idx + 0.5) / n_row\n            c2.append([x_coord, y_coord])\n    initial_configs.append(np.array(c2))\n\n    # Init 3: 6x4 Grid plus 2 extra circles\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    c3 = np.column_stack([gx2.ravel(), gy2.ravel()])\n    c3 = np.vstack([c3, [[0.2, 0.5], [0.8, 0.5]]])\n    initial_configs.append(c3)\n\n    # Optimize each initial configuration\n    for start_c in initial_configs:\n        cur_c = start_c.copy()\n        \n        # Dual-gradient optimization iterations\n        for step in range(150):\n            res, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(cur_c)\n            if not res.success:\n                break\n\n            curr_sum = -res.fun\n            if curr_sum > best_sum:\n                best_sum = curr_sum\n                best_c = cur_c.copy()\n                best_r = res.x\n\n            # Extract dual variables (marginals)\n            lambdas = getattr(getattr(res, 'ineqlin', None), 'marginals', None)\n            mus = getattr(getattr(res, 'upper', None), 'marginals', None)\n\n            if lambdas is not None and mus is not None:\n                grad = np.zeros((n_circles, 2))\n                \n                # Update gradient based on pairwise distance constraints\n                for k in range(len(i_idx)):\n                    lam = abs(lambdas[k])\n                    if lam > 1e-7:\n                        ii, jj = i_idx[k], j_idx[k]\n                        diff = cur_c[ii] - cur_c[jj]\n                        d = dists[k]\n                        if d > 1e-8:\n                            grad[ii] += lam * diff / d\n                            grad[jj] -= lam * diff / d\n\n                # Update gradient based on boundary constraints\n                for i in range(n_circles):\n                    mu = abs(mus[i])\n                    if mu > 1e-7:\n                        xi, yi = cur_c[i]\n                        b_vals = [xi, 1.0 - xi, yi, 1.0 - yi]\n                        tightest = np.argmin(b_vals)\n                        if tightest == 0: grad[i, 0] += mu\n                        elif tightest == 1: grad[i, 0] -= mu\n                        elif tightest == 2: grad[i, 1] += mu\n                        elif tightest == 3: grad[i, 1] -= mu\n\n                # Normalize step for stability and apply update\n                gnorm = np.linalg.norm(grad)\n                if gnorm > 1e-9:\n                    # Decay the step size over time\n                    step_size = 0.006 * (0.99 ** step)\n                    cur_c += step_size * grad / gnorm\n                \n                # Keep centers within the unit square\n                cur_c = np.clip(cur_c, 1e-7, 1.0 - 1e-7)\n            else:\n                break\n\n    # Perform a final rigorous LP solve and validity correction\n    if best_c is None:\n        best_c = initial_configs[1]\n\n    res_final, i_idx, j_idx, dists, max_r_b = solve_max_radii_lp(best_c)\n    final_r = res_final.x\n    final_c = best_c\n\n    # Strict geometry enforcement (multi-pass) to ensure zero overlap or boundary violation\n    for _ in range(50):\n        for i in range(n_circles):\n            final_r[i] = min(final_r[i], final_c[i, 0], 1.0 - final_c[i, 0], \n                             final_c[i, 1], 1.0 - final_c[i, 1])\n            final_r[i] = max(0, final_r[i])\n        for k in range(len(i_idx)):\n            ii, jj = i_idx[k], j_idx[k]\n            d = np.hypot(final_c[ii, 0] - final_c[jj, 0], final_c[ii, 1] - final_c[jj, 1])\n            if final_r[ii] + final_r[jj] > d:\n                overlap = (final_r[ii] + final_r[jj]) - d\n                total_r = final_r[ii] + final_r[jj]\n                if total_r > 0:\n                    final_r[ii] -= overlap * (final_r[ii] / total_r)\n                    final_r[jj] -= overlap * (final_r[jj] / total_r)\n\n    return final_c, final_r, np.sum(final_r)\n\n\ndef construct_packing():\n    \"\"\"Alias for run_packing to match expected constructor interface.\"\"\"\n    return run_packing()\n# EVOLVE-BLOCK-END\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport numpy as np\nfrom scipy.optimize import linprog\nimport time\n\ndef solve_max_radii(pts, buffer=1e-11):\n    \"\"\"\n    Computes optimal radii for fixed centers using Linear Programming.\n    Maximizes sum(r_i) subject to r_i + r_j <= distance(P_i, P_j) and\n    boundary constraints r_i <= wall_distance.\n    \"\"\"\n    n = pts.shape[0]\n    # Scipy linprog minimizes -sum(r_i) to maximize sum(r_i)\n    c_lp = -np.ones(n)\n    \n    # Precompute indices for pairwise distance constraints\n    i_idx, j_idx = np.triu_indices(n, 1)\n    diffs = pts[i_idx] - pts[j_idx]\n    dists = np.hypot(diffs[:, 0], diffs[:, 1])\n    num_pairs = len(i_idx)\n    \n    # Combined pairwise and boundary constraints into one A_ub matrix\n    # Total constraints: num_pairs + 4 * n (boundary constraints per circle)\n    A_ub = np.zeros((num_pairs + 4 * n, n))\n    b_ub = np.zeros(num_pairs + 4 * n)\n    \n    # Pairwise constraints: r_i + r_j <= distance_ij\n    A_ub[np.arange(num_pairs), i_idx] = 1\n    A_ub[np.arange(num_pairs), j_idx] = 1\n    b_ub[:num_pairs] = dists - buffer\n        \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, r_i <= y_i, r_i <= 1-y_i\n    x, y = pts[:, 0], pts[:, 1]\n    row_idx_b = np.arange(num_pairs, num_pairs + 4 * n)\n    col_idx_b = np.repeat(np.arange(n), 4)\n    A_ub[row_idx_b, col_idx_b] = 1\n    \n    b_ub[num_pairs::4] = x - buffer\n    b_ub[num_pairs+1::4] = 1.0 - x - buffer\n    b_ub[num_pairs+2::4] = y - buffer\n    b_ub[num_pairs+3::4] = 1.0 - y - buffer\n    \n    # Ensure bounds are strictly non-negative\n    b_ub = np.maximum(b_ub, 0)\n        \n    try:\n        # Use HiGHS solver for efficiency and access to dual marginals\n        res = linprog(c_lp, A_ub=A_ub, b_ub=b_ub, bounds=(0, 1), method='highs')\n        if res.success and hasattr(res, 'ineqlin') and res.ineqlin is not None:\n            return res.x, res.ineqlin.marginals, i_idx, j_idx, dists\n    except Exception:\n        pass\n        \n    return np.zeros(n), None, i_idx, j_idx, dists\n\ndef construct_packing():\n    \"\"\"\n    Optimizes the arrangement of 26 circles to maximize the sum of their radii.\n    Employs a multi-start strategy with dual-gradient descent. The gradients\n    are derived from the sensitivity of the LP objective to center movements.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Generate diverse initial configurations to explore potential optimal topologies\n    inits = []\n    \n    # 1: 5x5 Grid with one circle in the center\n    gx, gy = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    inits.append(np.vstack([np.column_stack([gx.ravel(), gy.ravel()]), [0.5, 0.5]]))\n    \n    # 2: 6x4 Grid with two circles on the side\n    gx2, gy2 = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 4))\n    inits.append(np.vstack([np.column_stack([gx2.ravel(), gy2.ravel()]), [[0.2, 0.5], [0.8, 0.5]]]))\n    \n    # 3: Staggered layers to cover the square densely\n    for layers in [[5, 4, 5, 4, 5, 3], [6, 5, 6, 5, 4], [7, 6, 7, 6], [5, 5, 5, 5, 6]]:\n        c = []\n        for r_idx, n_row in enumerate(layers):\n            for i_idx in range(n_row):\n                c.append([(i_idx + 0.5) / n_row, (r_idx + 0.5) / len(layers)])\n        inits.append(np.array(c)[:n])\n        \n    # 4: Concentric Ring layouts (Phyllotaxis and manually defined)\n    for ring_counts in [[1, 8, 17], [1, 7, 18]]:\n        c_ring = [[0.5, 0.5]]\n        for rad, count in [(0.22, ring_counts[1]), (0.44, ring_counts[2])]:\n            for i in range(count):\n                a = 2 * np.pi * i / count\n                c_ring.append([0.5 + rad * np.cos(a), 0.5 + rad * np.sin(a)])\n        inits.append(np.array(c_ring)[:n])\n        \n    # 5: Fibonacci Spiral / Phyllotaxis\n    phi = (1 + 5**0.5) / 2\n    spir = np.array([[0.5 + 0.45 * np.sqrt((i + 0.5) / n) * np.cos(2 * np.pi * i / phi**2),\n                      0.5 + 0.45 * np.sqrt((i + 0.5) / n) * np.sin(2 * np.pi * i / phi**2)] \n                      for i in range(n)])\n    inits.append(spir)\n    \n    # 6: Pure random starts to cover less structured topologies\n    np.random.seed(1337)\n    for _ in range(4):\n        inits.append(np.random.uniform(0.1, 0.9, (n, 2)))\n\n    # Multi-start optimization loop\n    for c_start in inits:\n        # Time limit of 550 seconds for the entire process\n        if time.time() - start_time > 550:\n            break\n            \n        curr_c = np.clip(c_start.copy(), 1e-7, 1.0 - 1e-7)\n        lr = 0.018  # Learning rate for gradient ascent\n        \n        for step in range(400):\n            # Check for time limit inside the iteration loop\n            if step % 25 == 0 and time.time() - start_time > 550:\n                break\n                \n            radii, duals, i_idx, j_idx, dists = solve_max_radii(curr_c)\n            if duals is None:\n                break\n                \n            current_sum = np.sum(radii)\n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = curr_c.copy()\n                best_radii = radii.copy()\n            \n            # Use dual variables (marginal sensitivities) to compute gradient\n            grad = np.zeros((n, 2))\n            num_pairs = len(i_idx)\n            lambdas = np.abs(duals)\n            \n            # Gradients from pairwise distance sensitivity (pushing centers apart)\n            lams_p = lambdas[:num_pairs]\n            active_p = lams_p > 1e-9\n            if np.any(active_p):\n                ii, jj = i_idx[active_p], j_idx[active_p]\n                diffs = curr_c[ii] - curr_c[jj]\n                # Normalized directions scaled by sensitivity\n                g_vals = lams_p[active_p, np.newaxis] * diffs / (dists[active_p, np.newaxis] + 1e-15)\n                np.add.at(grad, ii, g_vals)\n                np.add.at(grad, jj, -g_vals)\n            \n            # Gradients from boundary sensitivity (pushing centers away from walls)\n            mus = lambdas[num_pairs:].reshape((n, 4))\n            grad[:, 0] += mus[:, 0] - mus[:, 1]\n            grad[:, 1] += mus[:, 2] - mus[:, 3]\n            \n            # Apply normalized gradient update for stability\n            gnorm = np.linalg.norm(grad)\n            if gnorm > 1e-11:\n                curr_c += lr * grad / gnorm\n            \n            # Keep centers within the square and decay the learning rate\n            curr_c = np.clip(curr_c, 1e-7, 1.0 - 1e-7)\n            lr *= 0.994\n            \n    # Re-calculate optimal radii for the best centers found across all starts\n    final_radii, _, _, _, _ = solve_max_radii(best_centers, buffer=1e-12)\n    return best_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Standard entry point for circle packing evaluations.\"\"\"\n    return construct_packing()\n\nif __name__ == \"__main__\":\n    centers, radii, total_sum = construct_packing()\n    print(f\"Total sum of radii: {total_sum:.6f}\")\n```"]}}, "artifacts_json": "{\"execution_time\": \"10.66s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.562579/2.635 = 0.9725\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 97.3% of target value\", \"radius_stats\": \"Min: 0.060700, Max: 0.173544, Avg: 0.098561\"}", "artifact_dir": null, "embedding": null}