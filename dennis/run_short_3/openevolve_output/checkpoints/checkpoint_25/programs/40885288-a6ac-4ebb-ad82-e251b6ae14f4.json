{"id": "40885288-a6ac-4ebb-ad82-e251b6ae14f4", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 160\n    N = 26\n    steps = 2800\n    \n    np.random.seed(42)\n    \n    B1 = 40\n    # 1: Pure random initialization strictly inside valid margins\n    X1 = np.random.uniform(0.1, 0.9, (B1, N))\n    Y1 = np.random.uniform(0.1, 0.9, (B1, N))\n    \n    B2 = 40\n    # 2: Grid-like initialized configuration with spatial variance naturally guiding alignments\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    B3 = 40\n    # 3: Edge-biased Beta distribution, forming a dense initial outer border to populate empty walls directly\n    X3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    \n    B4 = B - B1 - B2 - B3\n    # 4: Central \"big bang\" clustered center ensuring fully structurally organic outer migrations unlocking new patterns\n    X4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    Y4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    \n    X = np.vstack([X1, X2, X3, X4])\n    Y = np.vstack([Y1, Y2, Y3, Y4])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Advanced vectorized Multi-Agent Optimizer configuration setup handling batched environments continuously\n    lr = 0.035\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for symmetric geometric separation mapping interactions exclusively\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Progressively escalated constraint stiffness guaranteeing smooth expansion transitions dynamically avoiding collapses\n    start_pen = 10.0\n    end_pen = 30000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Soft Cosine Annealing dynamically tapering search strides establishing exact convergence settling limits ultimately\n        current_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        # Micro symmetry-breaking positional tremors shifting equilibria naturally enabling better secondary states discovery escapes \n        if step in (400, 800, 1200):\n            X += np.random.normal(0, 2e-4, X.shape)\n            Y += np.random.normal(0, 2e-4, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2)\n        dist = np.maximum(dist, 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Exact non-penetration logic targeting square boundary intersections dynamically pulling internally against expanding parameters safely \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Analyze entirely converged continuous physics limits sequentially transitioning reliably down rendering strictly unarguable verifications\n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Initial lock down bounding exactly ensuring valid float regions explicitly securing mathematics definitively inside margins consistently \n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Iteratively shrink overlaps maintaining exactly proportional interactions reliably fully passing tests completely symmetrically safely internally cleanly seamlessly reliably   \n        for _pass in range(2):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                    if r[i] + r[j] > dist_val:\n                        scale = (dist_val - 1e-12) / (r[i] + r[j])\n                        if scale < 0: \n                            scale = 0.0\n                        r[i] *= scale\n                        r[j] *= scale\n                        \n        r *= 0.999999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "0340a9e0-7c39-4c0e-bf75-fac389d53eaf", "generation": 2, "timestamp": 1771997374.4500482, "iteration_found": 18, "metrics": {"validity": 1.0, "sum_radii": 2.619421675221832, "target_ratio": 0.9940879222853253, "combined_score": 0.9940879222853253, "radius_variance": 0.004327819871759092, "spatial_spread": 0.19261630597746293, "eval_time": 6.189239740371704}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.408193615653468, "target_ratio": 0.9139254708362308, "combined_score": 0.9139254708362308, "radius_variance": 0.010155558292130128, "spatial_spread": 0.1871918404932837, "eval_time": 3.475430965423584}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9139\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.0000 \u2192 0.9139\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n3.48s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.408194/2.635 = 0.9139\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.4082, target_ratio: 0.9139, combined_score: 0.9139, radius_variance: 0.0102, spatial_spread: 0.1872, eval_time: 3.4754\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6282, target_ratio: 0.9974, combined_score: 0.9974, radius_variance: 0.0057, spatial_spread: 0.1927, eval_time: 1.7649\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9974)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 100\n    N = 26\n    steps = 1500\n    \n    np.random.seed(42)\n    \n    # 1: Pure random initialization strictly inside valid margins\n    B1 = B // 3\n    X1 = np.random.uniform(0.05, 0.95, (B1, N))\n    Y1 = np.random.uniform(0.05, 0.95, (B1, N))\n    \n    # 2: Grid-like initialized configuration (removes spatial cluttering risks)\n    B2 = B // 3\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    # 3: Edge-biased initialization (creates favorable layout patterns naturally)\n    B3 = B - B1 - B2\n    X3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    \n    X = np.vstack([X1, X2, X3])\n    Y = np.vstack([Y1, Y2, Y3])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Custom vectorized multi-agent Adam Optimizer setup\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for pairwise constraint calculations\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Exponential increasing penalty acts identically to a mathematical cooling regime\n    start_pen = 50.0\n    end_pen = 3000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Linearly decay learning rate completely\n        current_lr = lr * (1.0 - step / steps)\n        \n        # Gather full batch metric evaluations efficiently\n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        # Detect strict overlaps safely separated off exact pairs structurally\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Calculate wall overlap margins directly avoiding outer boundaries \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        # Composite spatial gradients and size pressure calculations\n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Objective expansion gradient pushes R continuously + weighted constraints pull \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        # Momentum & variance stabilization step integrations internally\n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    # Find fundamentally stable and correct instance safely mapping coordinates\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Hard lock mathematical conditions sequentially safely overriding variations\n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        # Trim off immediately exterior overlaps\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Scale back safely into fully acceptable layout ensuring valid overlap metric natively \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                if r[i] + r[j] > dist_val:\n                    scale = (dist_val - 1e-9) / (r[i] + r[j])\n                    if scale < 0: \n                        scale = 0.0\n                    r[i] *= scale\n                    r[j] *= scale\n                    \n        # Apply extremely soft padding preserving structure absolutely securely\n        r *= 0.99999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6282), Performs well on target_ratio (0.9974), Performs well on combined_score (0.9974), Performs well on radius_variance (0.0057), Performs well on spatial_spread (0.1927), Performs well on eval_time (1.7649)\n\n### Program 2 (Score: 0.9139)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(150):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 0:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-10:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef compute_loss_and_gradients(P, R, C):\n    n = P.shape[0]\n    grad_P = np.zeros_like(P)\n    grad_R = np.zeros_like(R)\n    \n    loss = -np.sum(R)\n    grad_R -= 1.0\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n    overlap = np.maximum(0, overlap)\n    \n    loss += C * np.sum(overlap**2) / 2.0\n    dL_dov = C * overlap \n    grad_R += np.sum(dL_dov, axis=1)\n    \n    mask = dist < np.inf\n    dist_safe = dist.copy()\n    dist_safe[dist_safe == 0] = 1e-8\n    \n    dE_dx = np.zeros_like(diff)\n    dE_dx[mask] = - dL_dov[mask, np.newaxis] * (diff[mask] / dist_safe[mask, np.newaxis])\n    grad_P += np.sum(dE_dx, axis=1)\n    \n    ov_xl = np.maximum(0, R - P[:, 0])\n    loss += C * np.sum(ov_xl**2)\n    dL_xl = 2 * C * ov_xl\n    grad_R += dL_xl\n    grad_P[:, 0] -= dL_xl\n    \n    ov_xu = np.maximum(0, R + P[:, 0] - 1.0)\n    loss += C * np.sum(ov_xu**2)\n    dL_xu = 2 * C * ov_xu\n    grad_R += dL_xu\n    grad_P[:, 0] += dL_xu\n    \n    ov_yl = np.maximum(0, R - P[:, 1])\n    loss += C * np.sum(ov_yl**2)\n    dL_yl = 2 * C * ov_yl\n    grad_R += dL_yl\n    grad_P[:, 1] -= dL_yl\n    \n    ov_yu = np.maximum(0, R + P[:, 1] - 1.0)\n    loss += C * np.sum(ov_yu**2)\n    dL_yu = 2 * C * ov_yu\n    grad_R += dL_yu\n    grad_P[:, 1] += dL_yu\n    \n    return loss, grad_P, grad_R\n\n\ndef adam_optimizer(P_init, R_init, iters=4000):\n    P = P_init.copy()\n    R = R_init.copy()\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.005\n    eps = 1e-8\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially scale up physics/penalty interaction multiplier smoothly\n        C = 10.0 * (10.0 ** (4.0 * progress))\n        # Simulated annealing concept adapted as gradually scaling down the LR step\n        lr = lr_start * (1.0 - 0.8 * progress)\n        \n        if progress < 0.3:\n            # Introduce slight random positional noise symmetrically shifting layouts out of soft equilibria\n            noise = 1e-4 * (0.3 - progress)\n            P += np.random.normal(0, noise, P.shape)\n            \n        loss, grad_P, grad_R = compute_loss_and_gradients(P, R, C)\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        P = np.clip(P, 0.01, 0.99)\n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef construct_packing():\n    n = 26\n    np.random.seed(42)\n    \n    # Establish deeply seeded initial heuristic start conditions across spatial diversities\n    states = []\n    radii_list = []\n    \n    # Strategy 1: Grid off-set structure placing \n    P_grid = []\n    for r in range(6):\n        for c in range(5):\n            x = (c + 0.5) / 5.0\n            y = (r + 0.5) / 6.0\n            if r % 2 == 1:\n                x += 0.02\n            P_grid.append([x, y])\n    P_grid = np.array(P_grid[:n])\n    states.append(P_grid)\n    radii_list.append(np.ones(n) * 0.05)\n    \n    # Strategy 2: Size oriented layout seeding large centrally & shrinking near peripheries\n    P_rings = np.zeros((n, 2))\n    R_rings = np.ones(n) * 0.05\n    P_rings[0] = [0.5, 0.5]\n    R_rings[0] = 0.15 \n    for i in range(8):\n        angle = 2 * np.pi * i / 8\n        P_rings[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        R_rings[i+1] = 0.1\n    for i in range(17):\n        angle = 2 * np.pi * i / 17\n        P_rings[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n        R_rings[i+9] = 0.05\n    P_rings = np.clip(P_rings, 0.05, 0.95)\n    states.append(P_rings)\n    radii_list.append(R_rings)\n    \n    # Strategy 3: Dense hexagonal gasket pack heavily mapping edges specifically\n    P_hex = [[0.5, 0.5]]\n    R_hex = [0.15]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        P_hex.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        R_hex.append(0.1)\n    for i in range(12):\n        a = 2 * np.pi * i / 12 + (np.pi/12)\n        P_hex.append([0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)])\n        R_hex.append(0.08)\n    corner_edges = [[0.08, 0.08], [0.08, 0.92], [0.92, 0.08], [0.92, 0.92], [0.5, 0.08], [0.5, 0.92], [0.08, 0.5]]\n    for p in corner_edges[:n-19]:\n        P_hex.append(p)\n        R_hex.append(0.04)\n    states.append(np.array(P_hex))\n    radii_list.append(np.array(R_hex))\n    \n    # Strategy 4 & 5: Heavily randomly driven configurations \n    for _ in range(2):\n        P_rand = np.random.uniform(0.1, 0.9, (n, 2))\n        states.append(P_rand)\n        radii_list.append(np.ones(n) * 0.02)\n        \n    best_P = None\n    best_R = None\n    best_sum = -1.0\n    \n    for P_init, R_init in zip(states, radii_list):\n        # Relax geometry structurally with physics gradients & bounds via optimization loop\n        P_opt, R_opt = adam_optimizer(P_init, R_init, iters=3000)\n        \n        # Enforce analytical extraction conditions eliminating marginal local overlapping\n        R_exact = extract_strict_radii(P_opt, R_opt)\n        current_sum = np.sum(R_exact)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_P = P_opt\n            best_R = R_exact\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.4082), Performs well on target_ratio (0.9139), Performs well on combined_score (0.9139), Performs well on radius_variance (0.0102), Performs well on spatial_spread (0.1872), Performs well on eval_time (3.4754)\n\n### Program 3 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    Designed safely without risk of infinite expansion, yielding perfectly constrained bounds.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints tightly limiting\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(500):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 1e-12:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-11:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef batched_adam_optimizer(P_init, R_init, iters=4500):\n    \"\"\"\n    Run vectorized gradient descent over numerous spatial initializations synchronously.\n    Calculates perfectly matched analytical Jacobians accurately handling symmetric gradients securely.\n    \"\"\"\n    B, n, _ = P_init.shape\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.006\n    eps = 1e-8\n    \n    # Masks diagonals implicitly gracefully stopping distance zero errors across entirely batched elements\n    diag_mask = np.eye(n)[np.newaxis, :, :] * 1e10\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially escalating penalty enforcement \n        C = 10.0 * (10.0 ** (4.0 * progress))\n        lr = lr_start * (1.0 - 0.85 * progress)\n        \n        if 0.1 < progress < 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (0.4 - progress)\n            P += np.random.normal(0, noise_scale, P.shape)\n            R += np.random.normal(0, noise_scale, R.shape)\n            \n        grad_P = np.zeros_like(P)\n        grad_R = -1.0 * np.ones_like(R)\n        \n        diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :] \n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + diag_mask\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        \n        # Fixing explicit scale handling symmetric derivative overlap summation cleanly matched\n        dL_dov = 2.0 * C * ov\n        grad_R += np.sum(dL_dov, axis=2)\n        \n        dist_safe = dist.copy()\n        dist_safe[dist_safe < 1e-10] = 1e-10\n        grad_P += np.sum(-dL_dov[:, :, :, np.newaxis] * (diff / dist_safe[:, :, :, np.newaxis]), axis=2)\n        \n        ov_xl = np.maximum(0, R - P[:, :, 0])\n        dL_xl = 2.0 * C * ov_xl\n        grad_R += dL_xl\n        grad_P[:, :, 0] -= dL_xl\n        \n        ov_xu = np.maximum(0, R + P[:, :, 0] - 1.0)\n        dL_xu = 2.0 * C * ov_xu\n        grad_R += dL_xu\n        grad_P[:, :, 0] += dL_xu\n        \n        ov_yl = np.maximum(0, R - P[:, :, 1])\n        dL_yl = 2.0 * C * ov_yl\n        grad_R += dL_yl\n        grad_P[:, :, 1] -= dL_yl\n        \n        ov_yu = np.maximum(0, R + P[:, :, 1] - 1.0)\n        dL_yu = 2.0 * C * ov_yu\n        grad_R += dL_yu\n        grad_P[:, :, 1] += dL_yu\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        # Smooth rigid constraints preventing unstable optimization excursions\n        P = np.clip(P, 0.005, 0.995)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef generate_batched_seeds(n, num_seeds):\n    \"\"\"\n    Produce extensively diverse arrays encompassing grid symmetries, central Apollonian\n    and natively varying random local permutations spanning wider basins inherently.\n    \"\"\"\n    np.random.seed(42)\n    seeds = []\n    \n    P_grid1 = []\n    for r in range(6):\n        for c in range(5):\n            P_grid1.append([(c + 0.5) / 5.0, (r + 0.5) / 6.0])\n    seeds.append(np.array(P_grid1[:n]))\n\n    P_grid2 = []\n    for r in range(5):\n        for c in range(6):\n            \n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    Designed safely without risk of infinite expansion, yielding perfectly constrained bounds.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints tightly limiting\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(500):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 1e-12:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-11:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef batched_adam_optimizer(P_init, R_init, iters=4500):\n    \"\"\"\n    Run vectorized gradient descent over numerous spatial initializations synchronously.\n    Calculates perfectly matched analytical Jacobians accurately handling symmetric gradients securely.\n    \"\"\"\n    B, n, _ = P_init.shape\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.006\n    eps = 1e-8\n    \n    # Masks diagonals implicitly gracefully stopping distance zero errors across entirely batched elements\n    diag_mask = np.eye(n)[np.newaxis, :, :] * 1e10\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially escalating penalty enforcement \n        C = 10.0 * (10.0 ** (4.0 * progress))\n        lr = lr_start * (1.0 - 0.85 * progress)\n        \n        if 0.1 < progress < 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (0.4 - progress)\n            P += np.random.normal(0, noise_scale, P.shape)\n            R += np.random.normal(0, noise_scale, R.shape)\n            \n        grad_P = np.zeros_like(P)\n        grad_R = -1.0 * np.ones_like(R)\n        \n        diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :] \n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + diag_mask\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        \n        # Fixing explicit scale handling symmetric derivative overlap summation cleanly matched\n        dL_dov = 2.0 * C * ov\n        grad_R += np.sum(dL_dov, axis=2)\n        \n        dist_safe = dist.copy()\n        dist_safe[dist_safe < 1e-10] = 1e-10\n        grad_P += np.sum(-dL_dov[:, :, :, np.newaxis] * (diff / dist_safe[:, :, :, np.newaxis]), axis=2)\n        \n        ov_xl = np.maximum(0, R - P[:, :, 0])\n        dL_xl = 2.0 * C * ov_xl\n        grad_R += dL_xl\n        grad_P[:, :, 0] -= dL_xl\n        \n        ov_xu = np.maximum(0, R + P[:, :, 0] - 1.0)\n        dL_xu = 2.0 * C * ov_xu\n        grad_R += dL_xu\n        grad_P[:, :, 0] += dL_xu\n        \n        ov_yl = np.maximum(0, R - P[:, :, 1])\n        dL_yl = 2.0 * C * ov_yl\n        grad_R += dL_yl\n        grad_P[:, :, 1] -= dL_yl\n        \n        ov_yu = np.maximum(0, R + P[:, :, 1] - 1.0)\n        dL_yu = 2.0 * C * ov_yu\n        grad_R += dL_yu\n        grad_P[:, :, 1] += dL_yu\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        # Smooth rigid constraints preventing unstable optimization excursions\n        P = np.clip(P, 0.005, 0.995)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef generate_batched_seeds(n, num_seeds):\n    \"\"\"\n    Produce extensively diverse arrays encompassing grid symmetries, central Apollonian\n    and natively varying random local permutations spanning wider basins inherently.\n    \"\"\"\n    np.random.seed(42)\n    seeds = []\n    \n    P_grid1 = []\n    for r in range(6):\n        for c in range(5):\n            P_grid1.append([(c + 0.5) / 5.0, (r + 0.5) / 6.0])\n    seeds.append(np.array(P_grid1[:n]))\n\n    P_grid2 = []\n    for r in range(5):\n        for c in range(6):\n            \n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9974, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 100\n    N = 26\n    steps = 1500\n    \n    np.random.seed(42)\n    \n    # 1: Pure random initialization strictly inside valid margins\n    B1 = B // 3\n    X1 = np.random.uniform(0.05, 0.95, (B1, N))\n    Y1 = np.random.uniform(0.05, 0.95, (B1, N))\n    \n    # 2: Grid-like initialized configuration (removes spatial cluttering risks)\n    B2 = B // 3\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    # 3: Edge-biased initialization (creates favorable layout patterns naturally)\n    B3 = B - B1 - B2\n    X3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    \n    X = np.vstack([X1, X2, X3])\n    Y = np.vstack([Y1, Y2, Y3])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Custom vectorized multi-agent Adam Optimizer setup\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for pairwise constraint calculations\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Exponential increasing penalty acts identically to a mathematical cooling regime\n    start_pen = 50.0\n    end_pen = 3000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Linearly decay learning rate completely\n        current_lr = lr * (1.0 - step / steps)\n        \n        # Gather full batch metric evaluations efficiently\n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        # Detect strict overlaps safely separated off exact pairs structurally\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Calculate wall overlap margins directly avoiding outer boundaries \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        # Composite spatial gradients and size pressure calculations\n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Objective expansion gradient pushes R continuously + weighted constraints pull \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        # Momentum & variance stabilization step integrations internally\n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    # Find fundamentally stable and correct instance safely mapping coordinates\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Hard lock mathematical conditions sequentially safely overriding variations\n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        # Trim off immediately exterior overlaps\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Scale back safely into fully acceptable layout ensuring valid overlap metric natively \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                if r[i] + r[j] > dist_val:\n                    scale = (dist_val - 1e-9) / (r[i] + r[j])\n                    if scale < 0: \n                        scale = 0.0\n                    r[i] *= scale\n                    r[j] *= scale\n                    \n        # Apply extremely soft padding preserving structure absolutely securely\n        r *= 0.99999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(150):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 0:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-10:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef compute_loss_and_gradients(P, R, C):\n    n = P.shape[0]\n    grad_P = np.zeros_like(P)\n    grad_R = np.zeros_like(R)\n    \n    loss = -np.sum(R)\n    grad_R -= 1.0\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n    overlap = np.maximum(0, overlap)\n    \n    loss += C * np.sum(overlap**2) / 2.0\n    dL_dov = C * overlap \n    grad_R += np.sum(dL_dov, axis=1)\n    \n    mask = dist < np.inf\n    dist_safe = dist.copy()\n    dist_safe[dist_safe == 0] = 1e-8\n    \n    dE_dx = np.zeros_like(diff)\n    dE_dx[mask] = - dL_dov[mask, np.newaxis] * (diff[mask] / dist_safe[mask, np.newaxis])\n    grad_P += np.sum(dE_dx, axis=1)\n    \n    ov_xl = np.maximum(0, R - P[:, 0])\n    loss += C * np.sum(ov_xl**2)\n    dL_xl = 2 * C * ov_xl\n    grad_R += dL_xl\n    grad_P[:, 0] -= dL_xl\n    \n    ov_xu = np.maximum(0, R + P[:, 0] - 1.0)\n    loss += C * np.sum(ov_xu**2)\n    dL_xu = 2 * C * ov_xu\n    grad_R += dL_xu\n    grad_P[:, 0] += dL_xu\n    \n    ov_yl = np.maximum(0, R - P[:, 1])\n    loss += C * np.sum(ov_yl**2)\n    dL_yl = 2 * C * ov_yl\n    grad_R += dL_yl\n    grad_P[:, 1] -= dL_yl\n    \n    ov_yu = np.maximum(0, R + P[:, 1] - 1.0)\n    loss += C * np.sum(ov_yu**2)\n    dL_yu = 2 * C * ov_yu\n    grad_R += dL_yu\n    grad_P[:, 1] += dL_yu\n    \n    return loss, grad_P, grad_R\n\n\ndef adam_optimizer(P_init, R_init, iters=4000):\n    P = P_init.copy()\n    R = R_init.copy()\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.005\n    eps = 1e-8\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially scale up physics/penalty interaction multiplier smoothly\n        C = 10.0 * (10.0 ** (4.0 * progress))\n        # Simulated annealing concept adapted as gradually scaling down the LR step\n        lr = lr_start * (1.0 - 0.8 * progress)\n        \n        if progress < 0.3:\n            # Introduce slight random positional noise symmetrically shifting layouts out of soft equilibria\n            noise = 1e-4 * (0.3 - progress)\n            P += np.random.normal(0, noise, P.shape)\n            \n        loss, grad_P, grad_R = compute_loss_and_gradients(P, R, C)\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        P = np.clip(P, 0.01, 0.99)\n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef construct_packing():\n    n = 26\n    np.random.seed(42)\n    \n    # Establish deeply seeded initial heuristic start conditions across spatial diversities\n    states = []\n    radii_list = []\n    \n    # Strategy 1: Grid off-set structure placing \n    P_grid = []\n    for r in range(6):\n        for c in range(5):\n            x = (c + 0.5) / 5.0\n            y = (r + 0.5) / 6.0\n            if r % 2 == 1:\n                x += 0.02\n            P_grid.append([x, y])\n    P_grid = np.array(P_grid[:n])\n    states.append(P_grid)\n    radii_list.append(np.ones(n) * 0.05)\n    \n    # Strategy 2: Size oriented layout seeding large centrally & shrinking near peripheries\n    P_rings = np.zeros((n, 2))\n    R_rings = np.ones(n) * 0.05\n    P_rings[0] = [0.5, 0.5]\n    R_rings[0] = 0.15 \n    for i in range(8):\n        angle = 2 * np.pi * i / 8\n        P_rings[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        R_rings[i+1] = 0.1\n    for i in range(17):\n        angle = 2 * np.pi * i / 17\n        P_rings[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n        R_rings[i+9] = 0.05\n    P_rings = np.clip(P_rings, 0.05, 0.95)\n    states.append(P_rings)\n    radii_list.append(R_rings)\n    \n    # Strategy 3: Dense hexagonal gasket pack heavily mapping edges specifically\n    P_hex = [[0.5, 0.5]]\n    R_hex = [0.15]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        P_hex.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        R_hex.append(0.1)\n    for i in range(12):\n        a = 2 * np.pi * i / 12 + (np.pi/12)\n        P_hex.append([0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)])\n        R_hex.append(0.08)\n    corner_edges = [[0.08, 0.08], [0.08, 0.92], [0.92, 0.08], [0.92, 0.92], [0.5, 0.08], [0.5, 0.92], [0.08, 0.5]]\n    for p in corner_edges[:n-19]:\n        P_hex.append(p)\n        R_hex.append(0.04)\n    states.append(np.array(P_hex))\n    radii_list.append(np.array(R_hex))\n    \n    # Strategy 4 & 5: Heavily randomly driven configurations \n    for _ in range(2):\n        P_rand = np.random.uniform(0.1, 0.9, (n, 2))\n        states.append(P_rand)\n        radii_list.append(np.ones(n) * 0.02)\n        \n    best_P = None\n    best_R = None\n    best_sum = -1.0\n    \n    for P_init, R_init in zip(states, radii_list):\n        # Relax geometry structurally with physics gradients & bounds via optimization loop\n        P_opt, R_opt = adam_optimizer(P_init, R_init, iters=3000)\n        \n        # Enforce analytical extraction conditions eliminating marginal local overlapping\n        R_exact = extract_strict_radii(P_opt, R_opt)\n        current_sum = np.sum(R_exact)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_P = P_opt\n            best_R = R_exact\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 160\n    N = 26\n    steps = 2800\n    \n    np.random.seed(42)\n    \n    B1 = 40\n    # 1: Pure random initialization strictly inside valid margins\n    X1 = np.random.uniform(0.1, 0.9, (B1, N))\n    Y1 = np.random.uniform(0.1, 0.9, (B1, N))\n    \n    B2 = 40\n    # 2: Grid-like initialized configuration with spatial variance naturally guiding alignments\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    B3 = 40\n    # 3: Edge-biased Beta distribution, forming a dense initial outer border to populate empty walls directly\n    X3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    \n    B4 = B - B1 - B2 - B3\n    # 4: Central \"big bang\" clustered center ensuring fully structurally organic outer migrations unlocking new patterns\n    X4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    Y4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    \n    X = np.vstack([X1, X2, X3, X4])\n    Y = np.vstack([Y1, Y2, Y3, Y4])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Advanced vectorized Multi-Agent Optimizer configuration setup handling batched environments continuously\n    lr = 0.035\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for symmetric geometric separation mapping interactions exclusively\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Progressively escalated constraint stiffness guaranteeing smooth expansion transitions dynamically avoiding collapses\n    start_pen = 10.0\n    end_pen = 30000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Soft Cosine Annealing dynamically tapering search strides establishing exact convergence settling limits ultimately\n        current_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        # Micro symmetry-breaking positional tremors shifting equilibria naturally enabling better secondary states discovery escapes \n        if step in (400, 800, 1200):\n            X += np.random.normal(0, 2e-4, X.shape)\n            Y += np.random.normal(0, 2e-4, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2)\n        dist = np.maximum(dist, 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Exact non-penetration logic targeting square boundary intersections dynamically pulling internally against expanding parameters safely \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Analyze entirely converged continuous physics limits sequentially transitioning reliably down rendering strictly unarguable verifications\n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Initial lock down bounding exactly ensuring valid float regions explicitly securing mathematics definitively inside margins consistently \n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Iteratively shrink overlaps maintaining exactly proportional interactions reliably fully passing tests completely symmetrically safely internally cleanly seamlessly reliably   \n        for _pass in range(2):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                    if r[i] + r[j] > dist_val:\n                        scale = (dist_val - 1e-12) / (r[i] + r[j])\n                        if scale < 0: \n                            scale = 0.0\n                        r[i] *= scale\n                        r[j] *= scale\n                        \n        r *= 0.999999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"6.19s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.619422/2.635 = 0.9941\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.4% of target value\", \"radius_stats\": \"Min: 0.066834, Max: 0.131369, Avg: 0.100747\"}", "artifact_dir": null, "embedding": null}