{"id": "57aadf93-89db-4517-9256-df33276593e6", "code": "```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    Designed safely without risk of infinite expansion, yielding perfectly constrained bounds.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints tightly limiting\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(500):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 1e-12:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-11:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef batched_adam_optimizer(P_init, R_init, iters=4500):\n    \"\"\"\n    Run vectorized gradient descent over numerous spatial initializations synchronously.\n    Calculates perfectly matched analytical Jacobians accurately handling symmetric gradients securely.\n    \"\"\"\n    B, n, _ = P_init.shape\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.006\n    eps = 1e-8\n    \n    # Masks diagonals implicitly gracefully stopping distance zero errors across entirely batched elements\n    diag_mask = np.eye(n)[np.newaxis, :, :] * 1e10\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially escalating penalty enforcement \n        C = 10.0 * (10.0 ** (4.0 * progress))\n        lr = lr_start * (1.0 - 0.85 * progress)\n        \n        if 0.1 < progress < 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (0.4 - progress)\n            P += np.random.normal(0, noise_scale, P.shape)\n            R += np.random.normal(0, noise_scale, R.shape)\n            \n        grad_P = np.zeros_like(P)\n        grad_R = -1.0 * np.ones_like(R)\n        \n        diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :] \n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + diag_mask\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        \n        # Fixing explicit scale handling symmetric derivative overlap summation cleanly matched\n        dL_dov = 2.0 * C * ov\n        grad_R += np.sum(dL_dov, axis=2)\n        \n        dist_safe = dist.copy()\n        dist_safe[dist_safe < 1e-10] = 1e-10\n        grad_P += np.sum(-dL_dov[:, :, :, np.newaxis] * (diff / dist_safe[:, :, :, np.newaxis]), axis=2)\n        \n        ov_xl = np.maximum(0, R - P[:, :, 0])\n        dL_xl = 2.0 * C * ov_xl\n        grad_R += dL_xl\n        grad_P[:, :, 0] -= dL_xl\n        \n        ov_xu = np.maximum(0, R + P[:, :, 0] - 1.0)\n        dL_xu = 2.0 * C * ov_xu\n        grad_R += dL_xu\n        grad_P[:, :, 0] += dL_xu\n        \n        ov_yl = np.maximum(0, R - P[:, :, 1])\n        dL_yl = 2.0 * C * ov_yl\n        grad_R += dL_yl\n        grad_P[:, :, 1] -= dL_yl\n        \n        ov_yu = np.maximum(0, R + P[:, :, 1] - 1.0)\n        dL_yu = 2.0 * C * ov_yu\n        grad_R += dL_yu\n        grad_P[:, :, 1] += dL_yu\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        # Smooth rigid constraints preventing unstable optimization excursions\n        P = np.clip(P, 0.005, 0.995)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef generate_batched_seeds(n, num_seeds):\n    \"\"\"\n    Produce extensively diverse arrays encompassing grid symmetries, central Apollonian\n    and natively varying random local permutations spanning wider basins inherently.\n    \"\"\"\n    np.random.seed(42)\n    seeds = []\n    \n    P_grid1 = []\n    for r in range(6):\n        for c in range(5):\n            P_grid1.append([(c + 0.5) / 5.0, (r + 0.5) / 6.0])\n    seeds.append(np.array(P_grid1[:n]))\n\n    P_grid2 = []\n    for r in range(5):\n        for c in range(6):\n            ", "changes_description": null, "language": "python", "parent_id": "0340a9e0-7c39-4c0e-bf75-fac389d53eaf", "generation": 2, "timestamp": 1771996871.0669932, "iteration_found": 10, "metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.408193615653468, "target_ratio": 0.9139254708362308, "combined_score": 0.9139254708362308, "radius_variance": 0.010155558292130128, "spatial_spread": 0.1871918404932837, "eval_time": 3.475430965423584}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9139\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.9139\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n3.48s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.408194/2.635 = 0.9139\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.4082, target_ratio: 0.9139, combined_score: 0.9139, radius_variance: 0.0102, spatial_spread: 0.1872, eval_time: 3.4754\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9139)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(150):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 0:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-10:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef compute_loss_and_gradients(P, R, C):\n    n = P.shape[0]\n    grad_P = np.zeros_like(P)\n    grad_R = np.zeros_like(R)\n    \n    loss = -np.sum(R)\n    grad_R -= 1.0\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n    overlap = np.maximum(0, overlap)\n    \n    loss += C * np.sum(overlap**2) / 2.0\n    dL_dov = C * overlap \n    grad_R += np.sum(dL_dov, axis=1)\n    \n    mask = dist < np.inf\n    dist_safe = dist.copy()\n    dist_safe[dist_safe == 0] = 1e-8\n    \n    dE_dx = np.zeros_like(diff)\n    dE_dx[mask] = - dL_dov[mask, np.newaxis] * (diff[mask] / dist_safe[mask, np.newaxis])\n    grad_P += np.sum(dE_dx, axis=1)\n    \n    ov_xl = np.maximum(0, R - P[:, 0])\n    loss += C * np.sum(ov_xl**2)\n    dL_xl = 2 * C * ov_xl\n    grad_R += dL_xl\n    grad_P[:, 0] -= dL_xl\n    \n    ov_xu = np.maximum(0, R + P[:, 0] - 1.0)\n    loss += C * np.sum(ov_xu**2)\n    dL_xu = 2 * C * ov_xu\n    grad_R += dL_xu\n    grad_P[:, 0] += dL_xu\n    \n    ov_yl = np.maximum(0, R - P[:, 1])\n    loss += C * np.sum(ov_yl**2)\n    dL_yl = 2 * C * ov_yl\n    grad_R += dL_yl\n    grad_P[:, 1] -= dL_yl\n    \n    ov_yu = np.maximum(0, R + P[:, 1] - 1.0)\n    loss += C * np.sum(ov_yu**2)\n    dL_yu = 2 * C * ov_yu\n    grad_R += dL_yu\n    grad_P[:, 1] += dL_yu\n    \n    return loss, grad_P, grad_R\n\n\ndef adam_optimizer(P_init, R_init, iters=4000):\n    P = P_init.copy()\n    R = R_init.copy()\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.005\n    eps = 1e-8\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially scale up physics/penalty interaction multiplier smoothly\n        C = 10.0 * (10.0 ** (4.0 * progress))\n        # Simulated annealing concept adapted as gradually scaling down the LR step\n        lr = lr_start * (1.0 - 0.8 * progress)\n        \n        if progress < 0.3:\n            # Introduce slight random positional noise symmetrically shifting layouts out of soft equilibria\n            noise = 1e-4 * (0.3 - progress)\n            P += np.random.normal(0, noise, P.shape)\n            \n        loss, grad_P, grad_R = compute_loss_and_gradients(P, R, C)\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        P = np.clip(P, 0.01, 0.99)\n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef construct_packing():\n    n = 26\n    np.random.seed(42)\n    \n    # Establish deeply seeded initial heuristic start conditions across spatial diversities\n    states = []\n    radii_list = []\n    \n    # Strategy 1: Grid off-set structure placing \n    P_grid = []\n    for r in range(6):\n        for c in range(5):\n            x = (c + 0.5) / 5.0\n            y = (r + 0.5) / 6.0\n            if r % 2 == 1:\n                x += 0.02\n            P_grid.append([x, y])\n    P_grid = np.array(P_grid[:n])\n    states.append(P_grid)\n    radii_list.append(np.ones(n) * 0.05)\n    \n    # Strategy 2: Size oriented layout seeding large centrally & shrinking near peripheries\n    P_rings = np.zeros((n, 2))\n    R_rings = np.ones(n) * 0.05\n    P_rings[0] = [0.5, 0.5]\n    R_rings[0] = 0.15 \n    for i in range(8):\n        angle = 2 * np.pi * i / 8\n        P_rings[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        R_rings[i+1] = 0.1\n    for i in range(17):\n        angle = 2 * np.pi * i / 17\n        P_rings[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n        R_rings[i+9] = 0.05\n    P_rings = np.clip(P_rings, 0.05, 0.95)\n    states.append(P_rings)\n    radii_list.append(R_rings)\n    \n    # Strategy 3: Dense hexagonal gasket pack heavily mapping edges specifically\n    P_hex = [[0.5, 0.5]]\n    R_hex = [0.15]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        P_hex.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        R_hex.append(0.1)\n    for i in range(12):\n        a = 2 * np.pi * i / 12 + (np.pi/12)\n        P_hex.append([0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)])\n        R_hex.append(0.08)\n    corner_edges = [[0.08, 0.08], [0.08, 0.92], [0.92, 0.08], [0.92, 0.92], [0.5, 0.08], [0.5, 0.92], [0.08, 0.5]]\n    for p in corner_edges[:n-19]:\n        P_hex.append(p)\n        R_hex.append(0.04)\n    states.append(np.array(P_hex))\n    radii_list.append(np.array(R_hex))\n    \n    # Strategy 4 & 5: Heavily randomly driven configurations \n    for _ in range(2):\n        P_rand = np.random.uniform(0.1, 0.9, (n, 2))\n        states.append(P_rand)\n        radii_list.append(np.ones(n) * 0.02)\n        \n    best_P = None\n    best_R = None\n    best_sum = -1.0\n    \n    for P_init, R_init in zip(states, radii_list):\n        # Relax geometry structurally with physics gradients & bounds via optimization loop\n        P_opt, R_opt = adam_optimizer(P_init, R_init, iters=3000)\n        \n        # Enforce analytical extraction conditions eliminating marginal local overlapping\n        R_exact = extract_strict_radii(P_opt, R_opt)\n        current_sum = np.sum(R_exact)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_P = P_opt\n            best_R = R_exact\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.4082), Performs well on target_ratio (0.9139), Performs well on combined_score (0.9139), Performs well on radius_variance (0.0102), Performs well on spatial_spread (0.1872), Performs well on eval_time (3.4754)\n\n\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(150):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 0:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-10:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef compute_loss_and_gradients(P, R, C):\n    n = P.shape[0]\n    grad_P = np.zeros_like(P)\n    grad_R = np.zeros_like(R)\n    \n    loss = -np.sum(R)\n    grad_R -= 1.0\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n    overlap = np.maximum(0, overlap)\n    \n    loss += C * np.sum(overlap**2) / 2.0\n    dL_dov = C * overlap \n    grad_R += np.sum(dL_dov, axis=1)\n    \n    mask = dist < np.inf\n    dist_safe = dist.copy()\n    dist_safe[dist_safe == 0] = 1e-8\n    \n    dE_dx = np.zeros_like(diff)\n    dE_dx[mask] = - dL_dov[mask, np.newaxis] * (diff[mask] / dist_safe[mask, np.newaxis])\n    grad_P += np.sum(dE_dx, axis=1)\n    \n    ov_xl = np.maximum(0, R - P[:, 0])\n    loss += C * np.sum(ov_xl**2)\n    dL_xl = 2 * C * ov_xl\n    grad_R += dL_xl\n    grad_P[:, 0] -= dL_xl\n    \n    ov_xu = np.maximum(0, R + P[:, 0] - 1.0)\n    loss += C * np.sum(ov_xu**2)\n    dL_xu = 2 * C * ov_xu\n    grad_R += dL_xu\n    grad_P[:, 0] += dL_xu\n    \n    ov_yl = np.maximum(0, R - P[:, 1])\n    loss += C * np.sum(ov_yl**2)\n    dL_yl = 2 * C * ov_yl\n    grad_R += dL_yl\n    grad_P[:, 1] -= dL_yl\n    \n    ov_yu = np.maximum(0, R + P[:, 1] - 1.0)\n    loss += C * np.sum(ov_yu**2)\n    dL_yu = 2 * C * ov_yu\n    grad_R += dL_yu\n    grad_P[:, 1] += dL_yu\n    \n    return loss, grad_P, grad_R\n\n\ndef adam_optimizer(P_init, R_init, iters=4000):\n    P = P_init.copy()\n    R = R_init.copy()\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.005\n    eps = 1e-8\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially scale up physics/penalty interaction multiplier smoothly\n        C = 10.0 * (10.0 ** (4.0 * progress))\n        # Simulated annealing concept adapted as gradually scaling down the LR step\n        lr = lr_start * (1.0 - 0.8 * progress)\n        \n        if progress < 0.3:\n            # Introduce slight random positional noise symmetrically shifting layouts out of soft equilibria\n            noise = 1e-4 * (0.3 - progress)\n            P += np.random.normal(0, noise, P.shape)\n            \n        loss, grad_P, grad_R = compute_loss_and_gradients(P, R, C)\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        P = np.clip(P, 0.01, 0.99)\n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef construct_packing():\n    n = 26\n    np.random.seed(42)\n    \n    # Establish deeply seeded initial heuristic start conditions across spatial diversities\n    states = []\n    radii_list = []\n    \n    # Strategy 1: Grid off-set structure placing \n    P_grid = []\n    for r in range(6):\n        for c in range(5):\n            x = (c + 0.5) / 5.0\n            y = (r + 0.5) / 6.0\n            if r % 2 == 1:\n                x += 0.02\n            P_grid.append([x, y])\n    P_grid = np.array(P_grid[:n])\n    states.append(P_grid)\n    radii_list.append(np.ones(n) * 0.05)\n    \n    # Strategy 2: Size oriented layout seeding large centrally & shrinking near peripheries\n    P_rings = np.zeros((n, 2))\n    R_rings = np.ones(n) * 0.05\n    P_rings[0] = [0.5, 0.5]\n    R_rings[0] = 0.15 \n    for i in range(8):\n        angle = 2 * np.pi * i / 8\n        P_rings[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        R_rings[i+1] = 0.1\n    for i in range(17):\n        angle = 2 * np.pi * i / 17\n        P_rings[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n        R_rings[i+9] = 0.05\n    P_rings = np.clip(P_rings, 0.05, 0.95)\n    states.append(P_rings)\n    radii_list.append(R_rings)\n    \n    # Strategy 3: Dense hexagonal gasket pack heavily mapping edges specifically\n    P_hex = [[0.5, 0.5]]\n    R_hex = [0.15]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        P_hex.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        R_hex.append(0.1)\n    for i in range(12):\n        a = 2 * np.pi * i / 12 + (np.pi/12)\n        P_hex.append([0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)])\n        R_hex.append(0.08)\n    corner_edges = [[0.08, 0.08], [0.08, 0.92], [0.92, 0.08], [0.92, 0.92], [0.5, 0.08], [0.5, 0.92], [0.08, 0.5]]\n    for p in corner_edges[:n-19]:\n        P_hex.append(p)\n        R_hex.append(0.04)\n    states.append(np.array(P_hex))\n    radii_list.append(np.array(R_hex))\n    \n    # Strategy 4 & 5: Heavily randomly driven configurations \n    for _ in range(2):\n        P_rand = np.random.uniform(0.1, 0.9, (n, 2))\n        states.append(P_rand)\n        radii_list.append(np.ones(n) * 0.02)\n        \n    best_P = None\n    best_R = None\n    best_sum = -1.0\n    \n    for P_init, R_init in zip(states, radii_list):\n        # Relax geometry structurally with physics gradients & bounds via optimization loop\n        P_opt, R_opt = adam_optimizer(P_init, R_init, iters=3000)\n        \n        # Enforce analytical extraction conditions eliminating marginal local overlapping\n        R_exact = extract_strict_radii(P_opt, R_opt)\n        current_sum = np.sum(R_exact)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_P = P_opt\n            best_R = R_exact\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    Designed safely without risk of infinite expansion, yielding perfectly constrained bounds.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints tightly limiting\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(500):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 1e-12:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-11:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef batched_adam_optimizer(P_init, R_init, iters=4500):\n    \"\"\"\n    Run vectorized gradient descent over numerous spatial initializations synchronously.\n    Calculates perfectly matched analytical Jacobians accurately handling symmetric gradients securely.\n    \"\"\"\n    B, n, _ = P_init.shape\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.006\n    eps = 1e-8\n    \n    # Masks diagonals implicitly gracefully stopping distance zero errors across entirely batched elements\n    diag_mask = np.eye(n)[np.newaxis, :, :] * 1e10\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially escalating penalty enforcement \n        C = 10.0 * (10.0 ** (4.0 * progress))\n        lr = lr_start * (1.0 - 0.85 * progress)\n        \n        if 0.1 < progress < 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (0.4 - progress)\n            P += np.random.normal(0, noise_scale, P.shape)\n            R += np.random.normal(0, noise_scale, R.shape)\n            \n        grad_P = np.zeros_like(P)\n        grad_R = -1.0 * np.ones_like(R)\n        \n        diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :] \n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + diag_mask\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        \n        # Fixing explicit scale handling symmetric derivative overlap summation cleanly matched\n        dL_dov = 2.0 * C * ov\n        grad_R += np.sum(dL_dov, axis=2)\n        \n        dist_safe = dist.copy()\n        dist_safe[dist_safe < 1e-10] = 1e-10\n        grad_P += np.sum(-dL_dov[:, :, :, np.newaxis] * (diff / dist_safe[:, :, :, np.newaxis]), axis=2)\n        \n        ov_xl = np.maximum(0, R - P[:, :, 0])\n        dL_xl = 2.0 * C * ov_xl\n        grad_R += dL_xl\n        grad_P[:, :, 0] -= dL_xl\n        \n        ov_xu = np.maximum(0, R + P[:, :, 0] - 1.0)\n        dL_xu = 2.0 * C * ov_xu\n        grad_R += dL_xu\n        grad_P[:, :, 0] += dL_xu\n        \n        ov_yl = np.maximum(0, R - P[:, :, 1])\n        dL_yl = 2.0 * C * ov_yl\n        grad_R += dL_yl\n        grad_P[:, :, 1] -= dL_yl\n        \n        ov_yu = np.maximum(0, R + P[:, :, 1] - 1.0)\n        dL_yu = 2.0 * C * ov_yu\n        grad_R += dL_yu\n        grad_P[:, :, 1] += dL_yu\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        # Smooth rigid constraints preventing unstable optimization excursions\n        P = np.clip(P, 0.005, 0.995)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef generate_batched_seeds(n, num_seeds):\n    \"\"\"\n    Produce extensively diverse arrays encompassing grid symmetries, central Apollonian\n    and natively varying random local permutations spanning wider basins inherently.\n    \"\"\"\n    np.random.seed(42)\n    seeds = []\n    \n    P_grid1 = []\n    for r in range(6):\n        for c in range(5):\n            P_grid1.append([(c + 0.5) / 5.0, (r + 0.5) / 6.0])\n    seeds.append(np.array(P_grid1[:n]))\n\n    P_grid2 = []\n    for r in range(5):\n        for c in range(6):\n            "]}}, "artifacts_json": "{\"stderr\": \"Stage 1 evaluation failed: Program execution failed: invalid syntax (tmp3stb3oes.py, line 1)\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/jupyter/Code/oe/dennis/run_short_3/evaluator.py\\\", line 384, in evaluate_stage1\\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\\n  File \\\"/home/jupyter/Code/oe/dennis/run_short_3/evaluator.py\\\", line 172, in run_with_timeout\\n    raise RuntimeError(f\\\"Program execution failed: {results['error']}\\\")\\nRuntimeError: Program execution failed: invalid syntax (tmp3stb3oes.py, line 1)\\n\", \"failure_stage\": \"stage1_execution\", \"suggestion\": \"Check basic syntax and imports before attempting full evaluation\"}", "artifact_dir": null, "embedding": null}