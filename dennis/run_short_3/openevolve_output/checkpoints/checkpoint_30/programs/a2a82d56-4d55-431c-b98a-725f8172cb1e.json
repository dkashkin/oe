{"id": "a2a82d56-4d55-431c-b98a-725f8172cb1e", "code": "# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    diverse multi-start configurations. The solver effectively evaluates broad\n    geometries dynamically explicitly handling spatial constraints iteratively.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 300\n    N = 26\n    steps = 2500\n\n    np.random.seed(42)\n\n    X = np.zeros((B, N))\n    Y = np.zeros((B, N))\n    \n    # 1. Random uniform initialization\n    b1 = 60\n    X[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    Y[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n\n    # 2. Concentric circle distributions ensuring structural density\n    b2 = 60\n    for i in range(b1, b1 + b2):\n        n_outer = 16\n        n_inner = 9\n        n_center = 1\n        \n        a_out = np.linspace(0, 2 * np.pi, n_outer, endpoint=False) + np.random.rand()\n        a_in = np.linspace(0, 2 * np.pi, n_inner, endpoint=False) + np.random.rand()\n        \n        X[i, 0] = 0.5\n        Y[i, 0] = 0.5\n        \n        r_in = 0.22 + np.random.normal(0, 0.01)\n        X[i, 1:n_inner+1] = 0.5 + r_in * np.cos(a_in)\n        Y[i, 1:n_inner+1] = 0.5 + r_in * np.sin(a_in)\n        \n        r_out = 0.45 + np.random.normal(0, 0.01)\n        X[i, n_inner+1:] = 0.5 + r_out * np.cos(a_out)\n        Y[i, n_inner+1:] = 0.5 + r_out * np.sin(a_out)\n\n    # 3. Random Beta boundary preference \n    b3 = 60\n    X[b1+b2:b1+b2+b3] = np.random.beta(0.5, 0.5, (b3, N)) * 0.9 + 0.05\n    Y[b1+b2:b1+b2+b3] = np.random.beta(0.5, 0.5, (b3, N)) * 0.9 + 0.05\n\n    # 4. Dense Hexagonal Grid packing style layout \n    b4 = 60\n    grid_pts = []\n    for row in range(6):\n        for col in range(5):\n            offset = 0.04 if row % 2 == 1 else 0.0\n            x = 0.15 + col * 0.16 + offset\n            y = 0.15 + row * 0.14\n            grid_pts.append((x, y))\n            \n    grid_arr = np.array(grid_pts)\n    for i in range(b1+b2+b3, b1+b2+b3+b4):\n        indices = np.random.choice(len(grid_arr), N, replace=False)\n        pts = grid_arr[indices] + np.random.normal(0, 0.01, (N, 2))\n        X[i] = pts[:, 0]\n        Y[i] = pts[:, 1]\n        \n    # 5. Anchor configurations mapping directly into tight corners\n    b5 = B - (b1+b2+b3+b4)\n    for i in range(b1+b2+b3+b4, B):\n        X[i, :4] = [0.1, 0.9, 0.1, 0.9]\n        Y[i, :4] = [0.1, 0.1, 0.9, 0.9]\n        X[i, 4:8] = [0.5, 0.5, 0.1, 0.9]\n        Y[i, 4:8] = [0.1, 0.9, 0.5, 0.5]\n        \n        X[i, 8:] = np.random.uniform(0.2, 0.8, N - 8)\n        Y[i, 8:] = np.random.uniform(0.2, 0.8, N - 8)\n\n    # Diverse randomized radius pushing to favor asymmetric structures early\n    R_push = np.zeros((B, N))\n    for i in range(B):\n        order = np.random.permutation(N)\n        R_push[i, order] = np.linspace(0.8, 1.3, N)\n        \n    R = np.random.uniform(0.01, 0.04, (B, N))\n\n    # Optimization Configuration\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    m_X = np.zeros_like(X)\n    v_X = np.zeros_like(X)\n    m_Y = np.zeros_like(Y)\n    v_Y = np.zeros_like(Y)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n\n    mask = ~np.eye(N, dtype=bool)\n\n    pen_start = 20.0\n    pen_end = 25000.0\n    pen_factor = (pen_end / pen_start) ** (1.0 / steps)\n    pen = pen_start\n\n    # Batched multi-strategy physics iterations\n    for step in range(1, steps + 1):\n        cur_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        if step < steps * 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (1.0 - step / (steps * 0.4))\n            X += np.random.normal(0, noise_scale, X.shape)\n            Y += np.random.normal(0, noise_scale, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist) * mask[np.newaxis, :, :]\n        \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Decay the asymmetry structure back to uniform maximization continuously\n        target_scale = max(0.0, 1.0 - step / (steps * 0.5))\n        current_push = 1.0 + (R_push - 1.0) * target_scale\n        \n        grad_R = -current_push + pen * (grad_R_overlap + grad_R_bounds)\n        grad_X = pen * (grad_X_overlap + grad_X_bounds)\n        grad_Y = pen * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1 = 1.0 - beta1**step\n        bias2 = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= cur_lr * (m_X / bias1) / (np.sqrt(v_X / bias2) + eps)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= cur_lr * (m_Y / bias1) / (np.sqrt(v_Y / bias2) + eps)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= cur_lr * (m_R / bias1) / (np.sqrt(v_R / bias2) + eps)\n        \n        X = np.clip(X, 1e-6, 1.0 - 1e-6)\n        Y = np.clip(Y, 1e-6, 1.0 - 1e-6)\n        R = np.maximum(R, 1e-6)\n\n        pen *= pen_factor\n\n    # Cleanup validation logic maintaining structurally optimized limits seamlessly\n    R = np.clip(R, 0.0, 0.5)\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n\n    dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n    dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n    dist_mat = np.hypot(dX, dY)\n    dist_mat[:, np.arange(N), np.arange(N)] = np.inf\n    \n    # Symmetric continuous elimination of minor constraints organically properly\n    for _ in range(300):\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist_mat)\n        if np.max(overlap) < 1e-10:\n            break\n            \n        sum_r = R[:, :, np.newaxis] + R[:, np.newaxis, :] + 1e-12\n        drop = np.sum(overlap * (R[:, :, np.newaxis] / sum_r), axis=2)\n        R -= drop * 0.45 \n        R = np.maximum(R, 0.0)\n\n    # Fail-safe pairwise intersection down-scaling appropriately logically accurately \n    for b in range(B):\n        r_b = R[b]\n        d_b = dist_mat[b]\n        for i in range(N):\n            for j in range(i + 1, N):\n                ov_c = r_b[i] + r_b[j] - d_b[i, j]\n                if ov_c > 1e-12:\n                    scale = (d_b[i, j] - 1e-12) / (r_b[i] + r_b[j] + 1e-12)\n                    scale = np.clip(scale, 0.0, 1.0)\n                    r_b[i] *= scale\n                    r_b[j] *= scale\n\n    # Boundary padding securely precisely safely neatly appropriately rationally safely cleanly\n    for b in range(B):\n        x, y = X[b], Y[b]\n        r = R[b]\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        r *= 0.999999\n        R[b] = np.maximum(r, 0.0)\n\n    sums = np.sum(R, axis=1)\n    best_id = np.argmax(sums)\n    \n    return np.column_stack((X[best_id], Y[best_id])), R[best_id], sums[best_id]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "d38d01b9-fec2-4a28-b58f-39def79e0274", "generation": 4, "timestamp": 1771997864.3182468, "iteration_found": 26, "metrics": {"validity": 1.0, "sum_radii": 2.6185224388224673, "target_ratio": 0.9937466560996081, "combined_score": 0.9937466560996081, "radius_variance": 0.00414838434544678, "spatial_spread": 0.18586855240229444, "eval_time": 8.233768463134766}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6144517305925077, "target_ratio": 0.9922017952912744, "combined_score": 0.9922017952912744, "radius_variance": 0.005737990882525431, "spatial_spread": 0.19972286138020226, "eval_time": 6.171552896499634}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9922\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.9922\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n6.17s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.614452/2.635 = 0.9922\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.2% of target value\n```\n\n### radius_stats\n```\nMin: 0.067636, Max: 0.139034, Avg: 0.100556\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6145, target_ratio: 0.9922, combined_score: 0.9922, radius_variance: 0.0057, spatial_spread: 0.1997, eval_time: 6.1716\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6194, target_ratio: 0.9941, combined_score: 0.9941, radius_variance: 0.0043, spatial_spread: 0.1926, eval_time: 6.1892\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6282, target_ratio: 0.9974, combined_score: 0.9974, radius_variance: 0.0057, spatial_spread: 0.1927, eval_time: 1.7649\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9974)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 100\n    N = 26\n    steps = 1500\n    \n    np.random.seed(42)\n    \n    # 1: Pure random initialization strictly inside valid margins\n    B1 = B // 3\n    X1 = np.random.uniform(0.05, 0.95, (B1, N))\n    Y1 = np.random.uniform(0.05, 0.95, (B1, N))\n    \n    # 2: Grid-like initialized configuration (removes spatial cluttering risks)\n    B2 = B // 3\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    # 3: Edge-biased initialization (creates favorable layout patterns naturally)\n    B3 = B - B1 - B2\n    X3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    \n    X = np.vstack([X1, X2, X3])\n    Y = np.vstack([Y1, Y2, Y3])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Custom vectorized multi-agent Adam Optimizer setup\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for pairwise constraint calculations\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Exponential increasing penalty acts identically to a mathematical cooling regime\n    start_pen = 50.0\n    end_pen = 3000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Linearly decay learning rate completely\n        current_lr = lr * (1.0 - step / steps)\n        \n        # Gather full batch metric evaluations efficiently\n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        # Detect strict overlaps safely separated off exact pairs structurally\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Calculate wall overlap margins directly avoiding outer boundaries \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        # Composite spatial gradients and size pressure calculations\n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Objective expansion gradient pushes R continuously + weighted constraints pull \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        # Momentum & variance stabilization step integrations internally\n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    # Find fundamentally stable and correct instance safely mapping coordinates\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Hard lock mathematical conditions sequentially safely overriding variations\n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        # Trim off immediately exterior overlaps\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Scale back safely into fully acceptable layout ensuring valid overlap metric natively \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                if r[i] + r[j] > dist_val:\n                    scale = (dist_val - 1e-9) / (r[i] + r[j])\n                    if scale < 0: \n                        scale = 0.0\n                    r[i] *= scale\n                    r[j] *= scale\n                    \n        # Apply extremely soft padding preserving structure absolutely securely\n        r *= 0.99999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6282), Performs well on target_ratio (0.9974), Performs well on combined_score (0.9974), Performs well on radius_variance (0.0057), Performs well on spatial_spread (0.1927), Performs well on eval_time (1.7649)\n\n### Program 2 (Score: 0.9941)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 160\n    N = 26\n    steps = 2800\n    \n    np.random.seed(42)\n    \n    B1 = 40\n    # 1: Pure random initialization strictly inside valid margins\n    X1 = np.random.uniform(0.1, 0.9, (B1, N))\n    Y1 = np.random.uniform(0.1, 0.9, (B1, N))\n    \n    B2 = 40\n    # 2: Grid-like initialized configuration with spatial variance naturally guiding alignments\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    B3 = 40\n    # 3: Edge-biased Beta distribution, forming a dense initial outer border to populate empty walls directly\n    X3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    \n    B4 = B - B1 - B2 - B3\n    # 4: Central \"big bang\" clustered center ensuring fully structurally organic outer migrations unlocking new patterns\n    X4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    Y4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    \n    X = np.vstack([X1, X2, X3, X4])\n    Y = np.vstack([Y1, Y2, Y3, Y4])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Advanced vectorized Multi-Agent Optimizer configuration setup handling batched environments continuously\n    lr = 0.035\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for symmetric geometric separation mapping interactions exclusively\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Progressively escalated constraint stiffness guaranteeing smooth expansion transitions dynamically avoiding collapses\n    start_pen = 10.0\n    end_pen = 30000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Soft Cosine Annealing dynamically tapering search strides establishing exact convergence settling limits ultimately\n        current_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        # Micro symmetry-breaking positional tremors shifting equilibria naturally enabling better secondary states discovery escapes \n        if step in (400, 800, 1200):\n            X += np.random.normal(0, 2e-4, X.shape)\n            Y += np.random.normal(0, 2e-4, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2)\n        dist = np.maximum(dist, 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Exact non-penetration logic targeting square boundary intersections dynamically pulling internally against expanding parameters safely \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Analyze entirely converged continuous physics limits sequentially transitioning reliably down rendering strictly unarguable verifications\n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Initial lock down bounding exactly ensuring valid float regions explicitly securing mathematics definitively inside margins consistently \n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Iteratively shrink overlaps maintaining exactly proportional interactions reliably fully passing tests completely symmetrically safely internally cleanly seamlessly reliably   \n        for _pass in range(2):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                    if r[i] + r[j] > dist_val:\n                        scale = (dist_val - 1e-12) / (r[i] + r[j])\n                        if scale < 0: \n                            scale = 0.0\n                        r[i] *= scale\n                        r[j] *= scale\n                        \n        r *= 0.999999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6194), Performs well on target_ratio (0.9941), Performs well on combined_score (0.9941), Performs well on radius_variance (0.0043), Performs well on spatial_spread (0.1926), Performs well on eval_time (6.1892)\n\n### Program 3 (Score: 0.9922)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    diverse multi-start configurations. The solver effectively evaluates broad\n    geometries dynamically explicitly handling spatial constraints iteratively safely natively perfectly correctly correctly rationally correctly.\n\n    Returns:\n        best_centers: shape (26, 2) arrays securely accurately smartly exactly organically.\n        best_radii: shape (26,) robustly accurately structurally smoothly exactly securely properly rationally natively elegantly securely cleanly functionally stably appropriately.\n        best_sum: explicit exact properly appropriately correctly logically functionally stably smoothly intelligently optimally functionally gracefully conceptually seamlessly compactly elegantly cleanly optimally stably reliably efficiently robustly.\n    \"\"\"\n    B = 300\n    N = 26\n    steps = 2000\n\n    np.random.seed(42)\n\n    X = np.zeros((B, N))\n    Y = np.zeros((B, N))\n    R_push = np.random.uniform(0.7, 1.3, (B, N))\n\n    # Initial multi-strategy heuristics mapping perfectly cleanly robustly functionally precisely precisely safely smartly organically natively conceptually precisely structurally conceptually optimally flawlessly intuitively organically conceptually reliably efficiently cleanly robustly stably intelligently natively cleanly reliably intelligently smoothly intuitively rationally organically naturally flawlessly correctly efficiently smoothly precisely\n    b1 = 60\n    X[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    Y[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n\n    b2 = 60\n    X[b1 : b1+b2] = np.random.beta(0.5, 0.5, (b2, N)) * 0.8 + 0.1\n    Y[b1 : b1+b2] = np.random.beta(0.5, 0.5, (b2, N)) * 0.8 + 0.1\n\n    b3 = 60\n    for i in range(b1+b2, b1+b2+b3):\n        X[i, 0], Y[i, 0] = 0.5, 0.5\n        R_push[i, 0] = 2.0\n        \n        a8 = np.linspace(0, 2*np.pi, 8, endpoint=False) + np.random.uniform(0, 0.5)\n        r8 = 0.22 + np.random.normal(0, 0.02, 8)\n        X[i, 1:9] = 0.5 + r8 * np.cos(a8)\n        Y[i, 1:9] = 0.5 + r8 * np.sin(a8)\n        R_push[i, 1:9] = 1.5\n        \n        a17 = np.linspace(0, 2*np.pi, 17, endpoint=False) + np.random.uniform(0, 0.5)\n        r17 = 0.42 + np.random.normal(0, 0.02, 17)\n        X[i, 9:] = 0.5 + r17 * np.cos(a17)\n        Y[i, 9:] = 0.5 + r17 * np.sin(a17)\n        R_push[i, 9:] = 0.9\n\n    b4 = 60\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    for i in range(b1+b2+b3, b1+b2+b3+b4):\n        idx_grid = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx_grid] + np.random.normal(0, 0.015, (N, 2))\n        X[i] = pts[:, 0]\n        Y[i] = pts[:, 1]\n        \n    b5 = B - (b1+b2+b3+b4)\n    X[-b5:] = np.random.uniform(0.3, 0.7, (b5, N))\n    Y[-b5:] = np.random.uniform(0.3, 0.7, (b5, N))\n    R_push[-b5:] = np.random.uniform(0.9, 1.8, (b5, N))\n\n    R = np.random.uniform(0.01, 0.04, (B, N))\n\n    # Adam optimized dynamics correctly effectively flawlessly appropriately intuitively\n    lr = 0.04\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n\n    mask = ~np.eye(N, dtype=bool)\n\n    start_pen = 40.0\n    end_pen = 4000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    pen = start_pen\n\n    for step in range(1, steps + 1):\n        cur_lr = lr * (1.0 - step / steps)\n        \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist) * mask[np.newaxis, :, :]\n        \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R = -R_push + pen * 2.0 * (np.sum(overlap, axis=2) + v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X, dir_Y = dX / dist, dY / dist\n        grad_X = pen * 2.0 * (-np.sum(overlap * dir_X, axis=2) - v_x1 + v_x2)\n        grad_Y = pen * 2.0 * (-np.sum(overlap * dir_Y, axis=2) - v_y1 + v_y2)\n\n        if step < steps * 0.4 and step % 50 == 0:\n            noise_scale = 1e-3 * (1.0 - step / (steps * 0.4))\n            grad_X += np.random.normal(0, noise_scale, grad_X.shape)\n            grad_Y += np.random.normal(0, noise_scale, grad_Y.shape)\n            \n        bias1, bias2 = 1.0 - beta1**step, 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X**2)\n        X -= cur_lr * (m_X / bias1) / (np.sqrt(v_X / bias2) + eps)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * (grad_Y**2)\n        Y -= cur_lr * (m_Y / bias1) / (np.sqrt(v_Y / bias2) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        R -= cur_lr * (m_R / bias1) / (np.sqrt(v_R / bias2) + eps)\n        \n        X = np.clip(X, 1e-6, 1.0 - 1e-6)\n        Y = np.clip(Y, 1e-6, 1.0 - 1e-6)\n        R = np.maximum(R, 1e-6)\n\n        pen *= pen_factor\n\n    R = np.clip(R, 0.0, 0.5)\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n\n    dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n    dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n    dist_mat = np.hypot(dX, dY)\n    dist_mat[:, np.arange(N), np.arange(N)] = np.inf\n    \n    # Soft proportional multi-pass overlapping elimination strictly efficiently functionally seamlessly explicitly organically intuitively precisely functionally intuitively accurately smoothly rationally compactly reliably optimally intelligently organically flawlessly effectively effectively naturally cleanly gracefully natively\n    for _ in range(250):\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist_mat)\n        if np.max(overlap) < 1e-10:\n            break\n            \n        sum_r = R[:, :, np.newaxis] + R[:, np.newaxis, :] + 1e-12\n        drop = np.sum(overlap * (R[:, :, np.newaxis] / sum_r), axis=2)\n        R -= drop * 0.45 \n        R = np.maximum(R, 0.0)\n\n    # Assured fallback mapping conservatively securely smoothly compactly correctly reliably structurally organically explicitly correctly logically precisely compactly purely cleanly precisely securely correctly intuitively correctly elegantly rationally stably properly effectively cleanly properly explicitly organically functionally seamlessly properly correctly purely cleanly seamlessly gracefully logically perfectly reliably smoothly correctly stably optimally rationally robustly smoothly precisely seamlessly elegantly\n    for b in range(B):\n        r_b = R[b]\n        d_b = dist_mat[b]\n        for i in range(N):\n            for j in range(i + 1, N):\n                ov_c = r_b[i] + r_b[j] - d_b[i, j]\n                if ov_c > 1e-11:\n                    scale = (d_b[i, j] - 1e-11) / (r_b[i] + r_b[j] + 1e-12)\n                    r_b[i] *= scale\n                    r_b[j] *= scale\n\n    for b in range(B):\n        x, y = X[b], Y[b]\n        r = R[b]\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        r *= 0.999999\n        R[b] = np.maximum(r, 0.0)\n\n    sums = np.sum(R, axis=1)\n    best_id = np.argmax(sums)\n    \n    return np.column_stack((X[best_id], Y[best_id])), R[best_id], sums[best_id]\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6145), Performs well on target_ratio (0.9922), Performs well on combined_score (0.9922), Performs well on radius_variance (0.0057), Performs well on spatial_spread (0.1997), Performs well on eval_time (6.1716)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.9392)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs a highly optimized valid arrangement of n=26 circles.\n    Utilizes an advanced fully-vectorized iterative solver acting on 200 distinct \n    candidate layouts seeded dynamically precisely smartly elegantly safely correctly cleanly\n    to evaluate broad geometries exactly cleanly optimally reliably precisely smoothly seamlessly effectively smartly properly accurately safely elegantly correctly cleanly seamlessly efficiently perfectly rationally mathematically naturally smartly physically functionally explicitly explicitly conceptually safely purely reliably efficiently flawlessly robustly robustly organically appropriately seamlessly compactly stably organically rationally explicitly intelligently smartly correctly safely cleanly logically compactly precisely.\n\n    Returns:\n        best_centers: shape (26, 2) arrays cleanly organically reliably conceptually smoothly explicitly securely safely exactly structurally.\n        best_radii: shape (26,) precise reliably safely efficiently neatly naturally accurately intelligently exactly flawlessly stably seamlessly natively properly rationally accurately stably explicitly.\n        best_sum: absolute exact accurately exactly conceptually identically safely valid stably mathematically robustly conceptually securely smartly intuitively elegantly effectively reliably rationally compactly smoothly gracefully functionally gracefully securely cleanly compactly safely naturally natively compactly securely safely optimally correctly conceptually cleanly smartly securely intelligently cleanly appropriately.\n    \"\"\"\n    B_per_strat = 50\n    N = 26\n    steps = 2500\n    B = B_per_strat * 4  \n    \n    np.random.seed(42)\n    \n    X = np.zeros((B, N))\n    Y = np.zeros((B, N))\n    R_push = np.ones((B, N))\n    \n    idx = 0\n    # Strategy 1: Uniform pure multi-start\n    b1 = B_per_strat\n    X[idx:idx+b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    Y[idx:idx+b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    R_push[idx:idx+b1] = np.random.uniform(0.8, 1.5, (b1, N))\n    idx += b1\n    \n    # Strategy 2: Concentric circles heuristics specifically targeting structurally stable cores\n    b2 = B_per_strat\n    for b in range(idx, idx+b2):\n        n_large = np.random.randint(1, 4) \n        n_med = np.random.randint(7, 10) \n        n_small = N - n_large - n_med    \n        \n        C_x, C_y = 0.5 + np.random.randn(2) * 0.02\n        X[b, :n_large] = C_x + np.random.randn(n_large) * 0.04\n        Y[b, :n_large] = C_y + np.random.randn(n_large) * 0.04\n        R_push[b, :n_large] = np.random.uniform(1.4, 2.2, n_large)\n        \n        angles_med = np.random.uniform(0, 2 * np.pi) + np.linspace(0, 2 * np.pi, n_med, endpoint=False)\n        rad_med = np.random.uniform(0.15, 0.25)\n        X[b, n_large:n_large+n_med] = C_x + rad_med * np.cos(angles_med)\n        Y[b, n_large:n_large+n_med] = C_y + rad_med * np.sin(angles_med)\n        R_push[b, n_large:n_large+n_med] = np.random.uniform(1.0, 1.4, n_med)\n        \n        angles_sml = np.random.uniform(0, 2 * np.pi) + np.linspace(0, 2 * np.pi, n_small, endpoint=False)\n        rad_sml = np.random.uniform(0.35, 0.45)\n        X[b, n_large+n_med:] = C_x + rad_sml * np.cos(angles_sml)\n        Y[b, n_large+n_med:] = C_y + rad_sml * np.sin(angles_sml)\n        R_push[b, n_large+n_med:] = np.random.uniform(0.7, 1.0, n_small)\n    idx += b2\n    \n    # Strategy 3: Beta-corner/edge biases\n    b3 = B_per_strat\n    X[idx:idx+b3] = np.random.beta(0.3, 0.3, (b3, N)) * 0.8 + 0.1\n    Y[idx:idx+b3] = np.random.beta(0.3, 0.3, (b3, N)) * 0.8 + 0.1\n    R_push[idx:idx+b3] = np.random.uniform(0.8, 1.6, (b3, N))\n    idx += b3\n    \n    # Strategy 4: Displaced jitter grid\n    b4 = B_per_strat\n    grid_x, grid_y = np.meshgrid(np.linspace(0.15, 0.85, 6), np.linspace(0.15, 0.85, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    for b in range(idx, idx+b4):\n        choices = np.random.choice(30, N, replace=False)\n        X[b] = grid_pts[choices, 0] + np.random.normal(0, 0.02, N)\n        Y[b] = grid_pts[choices, 1] + np.random.normal(0, 0.02, N)\n        R_push[b] = np.random.uniform(0.8, 1.5, N)\n        \n    R = np.random.uniform(0.01, 0.03, (B, N))\n    \n    # Fully vectorized Adam properties safely initializing efficiently smoothly \n    lr = 0.05\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    mask = ~np.eye(N, dtype=bool)\n    start_pen, end_pen = 20.0, 25000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    pen = start_pen\n    \n    # High-performance physics relaxation accurately cleanly compactly reliably appropriately intuitively optimally\n    for step in range(1, steps + 1):\n        cur_lr = lr * (1.0 - step / steps)\n        if cur_lr <= 0.0:\n            cur_lr = 0.0\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist) * mask[np.newaxis, :, :]\n        \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        g_R = -R_push + pen * 2.0 * (np.sum(ov, axis=2) + v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X, dir_Y = dX / dist, dY / dist\n        g_X = pen * 2.0 * (-np.sum(ov * dir_X, axis=2) - v_x1 + v_x2)\n        g_Y = pen * 2.0 * (-np.sum(ov * dir_Y, axis=2) - v_y1 + v_y2)\n        \n        bias1, bias2 = 1.0 - beta1**step, 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * g_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (g_X**2)\n        X -= cur_lr * (m_X / bias1) / (np.sqrt(v_X / bias2) + eps)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * g_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (g_Y**2)\n        Y -= cur_lr * (m_Y / bias1) / (np.sqrt(v_Y / bias2) + eps)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * g_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (g_R**2)\n        R -= cur_lr * (m_R / bias1) / (np.sqrt(v_R / bias2) + eps)\n        \n        X = np.clip(X, 1e-6, 1.0 - 1e-6)\n        Y = np.clip(Y, 1e-6, 1.0 - 1e-6)\n        R = np.maximum(R, 1e-6)\n        \n        pen *= pen_factor\n\n    # Explicit post-relaxation natively safely purely cleanly elegantly robustly accurately correctly reliably smoothly effectively exactly stably naturally structurally physically flawlessly flawlessly correctly seamlessly elegantly organically dynamically compactly logically perfectly properly securely intelligently flawlessly dynamically precisely dynamically flawlessly appropriately perfectly mathematically elegantly optimally exactly logically optimally seamlessly intelligently.\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n    \n    dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n    dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n    dist_mat = np.hypot(dX, dY)\n    dist_mat[:, np.arange(N), np.arange(N)] = np.inf\n    \n    # Clean vector resolution cleanly securely safely smartly intuitively smartly accurately effectively properly securely logically dynamically intelligently naturally reliably intuitively dynamically dynamically seamlessly optimally natively stably smoothly correctly explicitly securely seamlessly flawlessly rationally dynamically logically cleanly cleanly logically naturally compactly conceptually cleanly.\n    for _ in range(250):\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist_mat)\n        max_ov = np.max(overlap)\n        if max_ov < 1e-10:\n            break\n            \n        sum_r = R[:, :, np.newaxis] + R[:, np.newaxis, :] + 1e-12\n        drop = np.sum(overlap * (R[:, :, np.newaxis] / sum_r), axis=2)\n        R -= drop * 0.45 \n        R = np.maximum(R, 0.0)\n\n    # Assured fallback correctly conservatively perfectly conceptually flawlessly securely intuitively dynamically natively intuitively perfectly natively optimally flawlessly efficiently appropriately purely flawlessly gracefully optimally effectively.\n    for i in range(N):\n        for j in range(i + 1, N):\n            p_dist = dist_mat[:, i, j]\n            c_ov = R[:, i] + R[:, j] - p_dist\n            mask_ov = c_ov > 1e-11\n            if np.any(mask_ov):\n                scale_d = (p_dist[mask_ov] - 1e-11) / (R[mask_ov, i] + R[mask_ov, j] + 1e-12)\n                scale_d = np.clip(scale_d, 0.0, 1.0)\n                R[mask_ov, i] *= scale_d\n                R[mask_ov, j] *= scale_d\n\n    R *= 0.999999\n    R = np.maximum(R, 0.0)\n    \n    sums = np.sum(R, axis=1)\n    best_id = np.argmax(sums)\n    \n    return np.column_stack((X[best_id], Y[best_id])), R[best_id], sums[best_id]\n\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n### Program D2 (Score: 0.9139)\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(150):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 0:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-10:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef compute_loss_and_gradients(P, R, C):\n    n = P.shape[0]\n    grad_P = np.zeros_like(P)\n    grad_R = np.zeros_like(R)\n    \n    loss = -np.sum(R)\n    grad_R -= 1.0\n    \n    diff = P[:, np.newaxis, :] - P[np.newaxis, :, :] \n    dist = np.sqrt(np.sum(diff**2, axis=-1))\n    np.fill_diagonal(dist, np.inf)\n    \n    overlap = R[:, np.newaxis] + R[np.newaxis, :] - dist\n    overlap = np.maximum(0, overlap)\n    \n    loss += C * np.sum(overlap**2) / 2.0\n    dL_dov = C * overlap \n    grad_R += np.sum(dL_dov, axis=1)\n    \n    mask = dist < np.inf\n    dist_safe = dist.copy()\n    dist_safe[dist_safe == 0] = 1e-8\n    \n    dE_dx = np.zeros_like(diff)\n    dE_dx[mask] = - dL_dov[mask, np.newaxis] * (diff[mask] / dist_safe[mask, np.newaxis])\n    grad_P += np.sum(dE_dx, axis=1)\n    \n    ov_xl = np.maximum(0, R - P[:, 0])\n    loss += C * np.sum(ov_xl**2)\n    dL_xl = 2 * C * ov_xl\n    grad_R += dL_xl\n    grad_P[:, 0] -= dL_xl\n    \n    ov_xu = np.maximum(0, R + P[:, 0] - 1.0)\n    loss += C * np.sum(ov_xu**2)\n    dL_xu = 2 * C * ov_xu\n    grad_R += dL_xu\n    grad_P[:, 0] += dL_xu\n    \n    ov_yl = np.maximum(0, R - P[:, 1])\n    loss += C * np.sum(ov_yl**2)\n    dL_yl = 2 * C * ov_yl\n    grad_R += dL_yl\n    grad_P[:, 1] -= dL_yl\n    \n    ov_yu = np.maximum(0, R + P[:, 1] - 1.0)\n    loss += C * np.sum(ov_yu**2)\n    dL_yu = 2 * C * ov_yu\n    grad_R += dL_yu\n    grad_P[:, 1] += dL_yu\n    \n    return loss, grad_P, grad_R\n\n\ndef adam_optimizer(P_init, R_init, iters=4000):\n    P = P_init.copy()\n    R = R_init.copy()\n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.005\n    eps = 1e-8\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially scale up physics/penalty interaction multiplier smoothly\n        C = 10.0 * (10.0 ** (4.0 * progress))\n        # Simulated annealing concept adapted as gradually scaling down the LR step\n        lr = lr_start * (1.0 - 0.8 * progress)\n        \n        if progress < 0.3:\n            # Introduce slight random positional noise symmetrically shifting layouts out of soft equilibria\n            noise = 1e-4 * (0.3 - progress)\n            P += np.random.normal(0, noise, P.shape)\n            \n        loss, grad_P, grad_R = compute_loss_and_gradients(P, R, C)\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        P = np.clip(P, 0.01, 0.99)\n        R = np.maximum(R, 0.001)\n        \n    return P, R\n\n\ndef construct_packing():\n    n = 26\n    np.random.seed(42)\n    \n    # Establish deeply seeded initial heuristic start conditions across spatial diversities\n    states = []\n    radii_list = []\n    \n    # Strategy 1: Grid off-set structure placing \n    P_grid = []\n    for r in range(6):\n        for c in range(5):\n            x = (c + 0.5) / 5.0\n            y = (r + 0.5) / 6.0\n            if r % 2 == 1:\n                x += 0.02\n            P_grid.append([x, y])\n    P_grid = np.array(P_grid[:n])\n    states.append(P_grid)\n    radii_list.append(np.ones(n) * 0.05)\n    \n    # Strategy 2: Size oriented layout seeding large centrally & shrinking near peripheries\n    P_rings = np.zeros((n, 2))\n    R_rings = np.ones(n) * 0.05\n    P_rings[0] = [0.5, 0.5]\n    R_rings[0] = 0.15 \n    for i in range(8):\n        angle = 2 * np.pi * i / 8\n        P_rings[i+1] = [0.5 + 0.25 * np.cos(angle), 0.5 + 0.25 * np.sin(angle)]\n        R_rings[i+1] = 0.1\n    for i in range(17):\n        angle = 2 * np.pi * i / 17\n        P_rings[i+9] = [0.5 + 0.45 * np.cos(angle), 0.5 + 0.45 * np.sin(angle)]\n        R_rings[i+9] = 0.05\n    P_rings = np.clip(P_rings, 0.05, 0.95)\n    states.append(P_rings)\n    radii_list.append(R_rings)\n    \n    # Strategy 3: Dense hexagonal gasket pack heavily mapping edges specifically\n    P_hex = [[0.5, 0.5]]\n    R_hex = [0.15]\n    for i in range(6):\n        a = 2 * np.pi * i / 6\n        P_hex.append([0.5 + 0.2 * np.cos(a), 0.5 + 0.2 * np.sin(a)])\n        R_hex.append(0.1)\n    for i in range(12):\n        a = 2 * np.pi * i / 12 + (np.pi/12)\n        P_hex.append([0.5 + 0.38 * np.cos(a), 0.5 + 0.38 * np.sin(a)])\n        R_hex.append(0.08)\n    corner_edges = [[0.08, 0.08], [0.08, 0.92], [0.92, 0.08], [0.92, 0.92], [0.5, 0.08], [0.5, 0.92], [0.08, 0.5]]\n    for p in corner_edges[:n-19]:\n        P_hex.append(p)\n        R_hex.append(0.04)\n    states.append(np.array(P_hex))\n    radii_list.append(np.array(R_hex))\n    \n    # Strategy 4 & 5: Heavily randomly driven configurations \n    for _ in range(2):\n        P_rand = np.random.uniform(0.1, 0.9, (n, 2))\n        states.append(P_rand)\n        radii_list.append(np.ones(n) * 0.02)\n        \n    best_P = None\n    best_R = None\n    best_sum = -1.0\n    \n    for P_init, R_init in zip(states, radii_list):\n        # Relax geometry structurally with physics gradients & bounds via optimization loop\n        P_opt, R_opt = adam_optimizer(P_init, R_init, iters=3000)\n        \n        # Enforce analytical extraction conditions eliminating marginal local overlapping\n        R_exact = extract_strict_radii(P_opt, R_opt)\n        current_sum = np.sum(R_exact)\n        \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_P = P_opt\n            best_R = R_exact\n            \n    return best_P, best_R, best_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nKey features: Alternative approach to validity, Alternative approach to sum_radii\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\n\n\ndef extract_strict_radii(centers, initial_radii):\n    \"\"\"\n    Iteratively resolve minor overlaps exactly to yield valid maximum possible radii.\n    Designed safely without risk of infinite expansion, yielding perfectly constrained bounds.\n    \"\"\"\n    n = centers.shape[0]\n    R = initial_radii.copy()\n    \n    # Pre-enforce domain boundary constraints tightly limiting\n    for i in range(n):\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    for _ in range(500):\n        max_ov = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = R[i] + R[j] - dist\n                if ov > 1e-12:\n                    max_ov = max(max_ov, ov)\n                    sum_r = R[i] + R[j] + 1e-12\n                    R[i] -= (ov + 1e-12) * (R[i] / sum_r)\n                    R[j] -= (ov + 1e-12) * (R[j] / sum_r)\n                    \n        if max_ov < 1e-11:\n            break\n            \n    # Proportional strict fail-safe downscale\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(centers[i] - centers[j])\n            if R[i] + R[j] > dist:\n                scale = dist / (R[i] + R[j])\n                R[i] *= scale * 0.999999\n                R[j] *= scale * 0.999999\n                \n    for i in range(n):\n        R[i] = max(0.0, R[i])\n        R[i] = min(R[i], centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1])\n        \n    return R\n\n\ndef batched_adam_optimizer(P_init, R_init, iters=4500):\n    \"\"\"\n    Run vectorized gradient descent over numerous spatial initializations synchronously.\n    Calculates perfectly matched analytical Jacobians accurately handling symmetric gradients securely.\n    \"\"\"\n    B, n, _ = P_init.shape\n    P = P_init.copy()\n    R = R_init.copy()\n    \n    m_P = np.zeros_like(P)\n    v_P = np.zeros_like(P)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_start = 0.006\n    eps = 1e-8\n    \n    # Masks diagonals implicitly gracefully stopping distance zero errors across entirely batched elements\n    diag_mask = np.eye(n)[np.newaxis, :, :] * 1e10\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Exponentially escalating penalty enforcement \n        C = 10.0 * (10.0 ** (4.0 * progress))\n        lr = lr_start * (1.0 - 0.85 * progress)\n        \n        if 0.1 < progress < 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (0.4 - progress)\n            P += np.random.normal(0, noise_scale, P.shape)\n            R += np.random.normal(0, noise_scale, R.shape)\n            \n        grad_P = np.zeros_like(P)\n        grad_R = -1.0 * np.ones_like(R)\n        \n        diff = P[:, :, np.newaxis, :] - P[:, np.newaxis, :, :] \n        dist = np.sqrt(np.sum(diff**2, axis=-1)) + diag_mask\n        \n        ov = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        \n        # Fixing explicit scale handling symmetric derivative overlap summation cleanly matched\n        dL_dov = 2.0 * C * ov\n        grad_R += np.sum(dL_dov, axis=2)\n        \n        dist_safe = dist.copy()\n        dist_safe[dist_safe < 1e-10] = 1e-10\n        grad_P += np.sum(-dL_dov[:, :, :, np.newaxis] * (diff / dist_safe[:, :, :, np.newaxis]), axis=2)\n        \n        ov_xl = np.maximum(0, R - P[:, :, 0])\n        dL_xl = 2.0 * C * ov_xl\n        grad_R += dL_xl\n        grad_P[:, :, 0] -= dL_xl\n        \n        ov_xu = np.maximum(0, R + P[:, :, 0] - 1.0)\n        dL_xu = 2.0 * C * ov_xu\n        grad_R += dL_xu\n        grad_P[:, :, 0] += dL_xu\n        \n        ov_yl = np.maximum(0, R - P[:, :, 1])\n        dL_yl = 2.0 * C * ov_yl\n        grad_R += dL_yl\n        grad_P[:, :, 1] -= dL_yl\n        \n        ov_yu = np.maximum(0, R + P[:, :, 1] - 1.0)\n        dL_yu = 2.0 * C * ov_yu\n        grad_R += dL_yu\n        grad_P[:, :, 1] += dL_yu\n        \n        m_P = beta1 * m_P + (1 - beta1) * grad_P\n        v_P = beta2 * v_P + (1 - beta2) * (grad_P**2)\n        m_P_hat = m_P / (1 - beta1**step)\n        v_P_hat = v_P / (1 - beta2**step)\n        P -= lr * m_P_hat / (np.sqrt(v_P_hat) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr * m_R_hat / (np.sqrt(v_R_hat) + eps)\n        \n        # Smooth rigid constraints preventing unstable optimization excursions\n        P = np.clip(P, 0.005, 0.995)\n        R = np.clip(R, 0.001, 0.5)\n        \n    return P, R\n\n\ndef generate_batched_seeds(n, num_seeds):\n    \"\"\"\n    Produce extensively diverse arrays encompassing grid symmetries, central Apollonian\n    and natively varying random local permutations spanning wider basins inherently.\n    \"\"\"\n    np.random.seed(42)\n    seeds = []\n    \n    P_grid1 = []\n    for r in range(6):\n        for c in range(5):\n            P_grid1.append([(c + 0.5) / 5.0, (r + 0.5) / 6.0])\n    seeds.append(np.array(P_grid1[:n]))\n\n    P_grid2 = []\n    for r in range(5):\n        for c in range(6):\n            \n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9941, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 160\n    N = 26\n    steps = 2800\n    \n    np.random.seed(42)\n    \n    B1 = 40\n    # 1: Pure random initialization strictly inside valid margins\n    X1 = np.random.uniform(0.1, 0.9, (B1, N))\n    Y1 = np.random.uniform(0.1, 0.9, (B1, N))\n    \n    B2 = 40\n    # 2: Grid-like initialized configuration with spatial variance naturally guiding alignments\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    B3 = 40\n    # 3: Edge-biased Beta distribution, forming a dense initial outer border to populate empty walls directly\n    X3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.4, 0.4, (B3, N)) * 0.9 + 0.05\n    \n    B4 = B - B1 - B2 - B3\n    # 4: Central \"big bang\" clustered center ensuring fully structurally organic outer migrations unlocking new patterns\n    X4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    Y4 = np.clip(np.random.normal(0.5, 0.1, (B4, N)), 0.1, 0.9)\n    \n    X = np.vstack([X1, X2, X3, X4])\n    Y = np.vstack([Y1, Y2, Y3, Y4])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Advanced vectorized Multi-Agent Optimizer configuration setup handling batched environments continuously\n    lr = 0.035\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for symmetric geometric separation mapping interactions exclusively\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Progressively escalated constraint stiffness guaranteeing smooth expansion transitions dynamically avoiding collapses\n    start_pen = 10.0\n    end_pen = 30000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Soft Cosine Annealing dynamically tapering search strides establishing exact convergence settling limits ultimately\n        current_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        # Micro symmetry-breaking positional tremors shifting equilibria naturally enabling better secondary states discovery escapes \n        if step in (400, 800, 1200):\n            X += np.random.normal(0, 2e-4, X.shape)\n            Y += np.random.normal(0, 2e-4, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2)\n        dist = np.maximum(dist, 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Exact non-penetration logic targeting square boundary intersections dynamically pulling internally against expanding parameters safely \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Analyze entirely converged continuous physics limits sequentially transitioning reliably down rendering strictly unarguable verifications\n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Initial lock down bounding exactly ensuring valid float regions explicitly securing mathematics definitively inside margins consistently \n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Iteratively shrink overlaps maintaining exactly proportional interactions reliably fully passing tests completely symmetrically safely internally cleanly seamlessly reliably   \n        for _pass in range(2):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                    if r[i] + r[j] > dist_val:\n                        scale = (dist_val - 1e-12) / (r[i] + r[j])\n                        if scale < 0: \n                            scale = 0.0\n                        r[i] *= scale\n                        r[j] *= scale\n                        \n        r *= 0.999999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.9974, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    a diverse multi-start technique. A sequence of Adam updates minimizes\n    constraint violations while maintaining outward expansion of radii.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 100\n    N = 26\n    steps = 1500\n    \n    np.random.seed(42)\n    \n    # 1: Pure random initialization strictly inside valid margins\n    B1 = B // 3\n    X1 = np.random.uniform(0.05, 0.95, (B1, N))\n    Y1 = np.random.uniform(0.05, 0.95, (B1, N))\n    \n    # 2: Grid-like initialized configuration (removes spatial cluttering risks)\n    B2 = B // 3\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    X2 = np.zeros((B2, N))\n    Y2 = np.zeros((B2, N))\n    for b in range(B2):\n        idx = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx] + np.random.normal(0, 0.015, (N, 2))\n        X2[b] = pts[:, 0]\n        Y2[b] = pts[:, 1]\n        \n    # 3: Edge-biased initialization (creates favorable layout patterns naturally)\n    B3 = B - B1 - B2\n    X3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    Y3 = np.random.beta(0.5, 0.5, (B3, N)) * 0.9 + 0.05\n    \n    X = np.vstack([X1, X2, X3])\n    Y = np.vstack([Y1, Y2, Y3])\n    R = np.random.uniform(0.01, 0.05, (B, N))\n    \n    # Custom vectorized multi-agent Adam Optimizer setup\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon = 1e-8\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    # Self-exclusion matrix mask for pairwise constraint calculations\n    mask = ~np.eye(N, dtype=bool)\n    \n    # Exponential increasing penalty acts identically to a mathematical cooling regime\n    start_pen = 50.0\n    end_pen = 3000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    penalty_weight = start_pen\n    \n    for step in range(1, steps + 1):\n        # Linearly decay learning rate completely\n        current_lr = lr * (1.0 - step / steps)\n        \n        # Gather full batch metric evaluations efficiently\n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        # Detect strict overlaps safely separated off exact pairs structurally\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist)\n        overlap = overlap * mask[np.newaxis, :, :]\n        \n        # Calculate wall overlap margins directly avoiding outer boundaries \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        # Composite spatial gradients and size pressure calculations\n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Objective expansion gradient pushes R continuously + weighted constraints pull \n        grad_R = -1.0 + penalty_weight * (grad_R_overlap + grad_R_bounds)\n        grad_X = penalty_weight * (grad_X_overlap + grad_X_bounds)\n        grad_Y = penalty_weight * (grad_Y_overlap + grad_Y_bounds)\n        \n        # Momentum & variance stabilization step integrations internally\n        bias1_corr = 1.0 - beta1**step\n        bias2_corr = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= current_lr * (m_X / bias1_corr) / (np.sqrt(v_X / bias2_corr) + epsilon)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= current_lr * (m_Y / bias1_corr) / (np.sqrt(v_Y / bias2_corr) + epsilon)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= current_lr * (m_R / bias1_corr) / (np.sqrt(v_R / bias2_corr) + epsilon)\n        \n        penalty_weight *= pen_factor\n\n    # Find fundamentally stable and correct instance safely mapping coordinates\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    for b in range(B):\n        x = np.copy(X[b])\n        y = np.copy(Y[b])\n        r = np.copy(R[b])\n        \n        # Hard lock mathematical conditions sequentially safely overriding variations\n        x = np.clip(x, 1e-6, 1.0 - 1e-6)\n        y = np.clip(y, 1e-6, 1.0 - 1e-6)\n        r = np.clip(r, 0.0, 0.5)\n        \n        # Trim off immediately exterior overlaps\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        \n        # Scale back safely into fully acceptable layout ensuring valid overlap metric natively \n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_val = np.hypot(x[i] - x[j], y[i] - y[j])\n                if r[i] + r[j] > dist_val:\n                    scale = (dist_val - 1e-9) / (r[i] + r[j])\n                    if scale < 0: \n                        scale = 0.0\n                    r[i] *= scale\n                    r[j] *= scale\n                    \n        # Apply extremely soft padding preserving structure absolutely securely\n        r *= 0.99999\n        r = np.maximum(r, 0.0)\n        \n        current_sum = np.sum(r)\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.column_stack((x, y))\n            best_radii = r\n            \n    return best_centers, best_radii, best_sum\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    diverse multi-start configurations. The solver effectively evaluates broad\n    geometries dynamically explicitly handling spatial constraints iteratively safely natively perfectly correctly correctly rationally correctly.\n\n    Returns:\n        best_centers: shape (26, 2) arrays securely accurately smartly exactly organically.\n        best_radii: shape (26,) robustly accurately structurally smoothly exactly securely properly rationally natively elegantly securely cleanly functionally stably appropriately.\n        best_sum: explicit exact properly appropriately correctly logically functionally stably smoothly intelligently optimally functionally gracefully conceptually seamlessly compactly elegantly cleanly optimally stably reliably efficiently robustly.\n    \"\"\"\n    B = 300\n    N = 26\n    steps = 2000\n\n    np.random.seed(42)\n\n    X = np.zeros((B, N))\n    Y = np.zeros((B, N))\n    R_push = np.random.uniform(0.7, 1.3, (B, N))\n\n    # Initial multi-strategy heuristics mapping perfectly cleanly robustly functionally precisely precisely safely smartly organically natively conceptually precisely structurally conceptually optimally flawlessly intuitively organically conceptually reliably efficiently cleanly robustly stably intelligently natively cleanly reliably intelligently smoothly intuitively rationally organically naturally flawlessly correctly efficiently smoothly precisely\n    b1 = 60\n    X[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    Y[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n\n    b2 = 60\n    X[b1 : b1+b2] = np.random.beta(0.5, 0.5, (b2, N)) * 0.8 + 0.1\n    Y[b1 : b1+b2] = np.random.beta(0.5, 0.5, (b2, N)) * 0.8 + 0.1\n\n    b3 = 60\n    for i in range(b1+b2, b1+b2+b3):\n        X[i, 0], Y[i, 0] = 0.5, 0.5\n        R_push[i, 0] = 2.0\n        \n        a8 = np.linspace(0, 2*np.pi, 8, endpoint=False) + np.random.uniform(0, 0.5)\n        r8 = 0.22 + np.random.normal(0, 0.02, 8)\n        X[i, 1:9] = 0.5 + r8 * np.cos(a8)\n        Y[i, 1:9] = 0.5 + r8 * np.sin(a8)\n        R_push[i, 1:9] = 1.5\n        \n        a17 = np.linspace(0, 2*np.pi, 17, endpoint=False) + np.random.uniform(0, 0.5)\n        r17 = 0.42 + np.random.normal(0, 0.02, 17)\n        X[i, 9:] = 0.5 + r17 * np.cos(a17)\n        Y[i, 9:] = 0.5 + r17 * np.sin(a17)\n        R_push[i, 9:] = 0.9\n\n    b4 = 60\n    grid_x, grid_y = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.c_[grid_x.ravel(), grid_y.ravel()] \n    for i in range(b1+b2+b3, b1+b2+b3+b4):\n        idx_grid = np.random.choice(30, N, replace=False)\n        pts = grid_pts[idx_grid] + np.random.normal(0, 0.015, (N, 2))\n        X[i] = pts[:, 0]\n        Y[i] = pts[:, 1]\n        \n    b5 = B - (b1+b2+b3+b4)\n    X[-b5:] = np.random.uniform(0.3, 0.7, (b5, N))\n    Y[-b5:] = np.random.uniform(0.3, 0.7, (b5, N))\n    R_push[-b5:] = np.random.uniform(0.9, 1.8, (b5, N))\n\n    R = np.random.uniform(0.01, 0.04, (B, N))\n\n    # Adam optimized dynamics correctly effectively flawlessly appropriately intuitively\n    lr = 0.04\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n\n    mask = ~np.eye(N, dtype=bool)\n\n    start_pen = 40.0\n    end_pen = 4000.0\n    pen_factor = (end_pen / start_pen) ** (1.0 / steps)\n    pen = start_pen\n\n    for step in range(1, steps + 1):\n        cur_lr = lr * (1.0 - step / steps)\n        \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist) * mask[np.newaxis, :, :]\n        \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R = -R_push + pen * 2.0 * (np.sum(overlap, axis=2) + v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X, dir_Y = dX / dist, dY / dist\n        grad_X = pen * 2.0 * (-np.sum(overlap * dir_X, axis=2) - v_x1 + v_x2)\n        grad_Y = pen * 2.0 * (-np.sum(overlap * dir_Y, axis=2) - v_y1 + v_y2)\n\n        if step < steps * 0.4 and step % 50 == 0:\n            noise_scale = 1e-3 * (1.0 - step / (steps * 0.4))\n            grad_X += np.random.normal(0, noise_scale, grad_X.shape)\n            grad_Y += np.random.normal(0, noise_scale, grad_Y.shape)\n            \n        bias1, bias2 = 1.0 - beta1**step, 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * (grad_X**2)\n        X -= cur_lr * (m_X / bias1) / (np.sqrt(v_X / bias2) + eps)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * (grad_Y**2)\n        Y -= cur_lr * (m_Y / bias1) / (np.sqrt(v_Y / bias2) + eps)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * (grad_R**2)\n        R -= cur_lr * (m_R / bias1) / (np.sqrt(v_R / bias2) + eps)\n        \n        X = np.clip(X, 1e-6, 1.0 - 1e-6)\n        Y = np.clip(Y, 1e-6, 1.0 - 1e-6)\n        R = np.maximum(R, 1e-6)\n\n        pen *= pen_factor\n\n    R = np.clip(R, 0.0, 0.5)\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n\n    dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n    dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n    dist_mat = np.hypot(dX, dY)\n    dist_mat[:, np.arange(N), np.arange(N)] = np.inf\n    \n    # Soft proportional multi-pass overlapping elimination strictly efficiently functionally seamlessly explicitly organically intuitively precisely functionally intuitively accurately smoothly rationally compactly reliably optimally intelligently organically flawlessly effectively effectively naturally cleanly gracefully natively\n    for _ in range(250):\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist_mat)\n        if np.max(overlap) < 1e-10:\n            break\n            \n        sum_r = R[:, :, np.newaxis] + R[:, np.newaxis, :] + 1e-12\n        drop = np.sum(overlap * (R[:, :, np.newaxis] / sum_r), axis=2)\n        R -= drop * 0.45 \n        R = np.maximum(R, 0.0)\n\n    # Assured fallback mapping conservatively securely smoothly compactly correctly reliably structurally organically explicitly correctly logically precisely compactly purely cleanly precisely securely correctly intuitively correctly elegantly rationally stably properly effectively cleanly properly explicitly organically functionally seamlessly properly correctly purely cleanly seamlessly gracefully logically perfectly reliably smoothly correctly stably optimally rationally robustly smoothly precisely seamlessly elegantly\n    for b in range(B):\n        r_b = R[b]\n        d_b = dist_mat[b]\n        for i in range(N):\n            for j in range(i + 1, N):\n                ov_c = r_b[i] + r_b[j] - d_b[i, j]\n                if ov_c > 1e-11:\n                    scale = (d_b[i, j] - 1e-11) / (r_b[i] + r_b[j] + 1e-12)\n                    r_b[i] *= scale\n                    r_b[j] *= scale\n\n    for b in range(B):\n        x, y = X[b], Y[b]\n        r = R[b]\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        r *= 0.999999\n        R[b] = np.maximum(r, 0.0)\n\n    sums = np.sum(R, axis=1)\n    best_id = np.argmax(sums)\n    \n    return np.column_stack((X[best_id], Y[best_id])), R[best_id], sums[best_id]\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    that attempts to maximize the sum of their radii without overlap.\n    \n    Uses an iterative constrained penalty optimization initialized via\n    diverse multi-start configurations. The solver effectively evaluates broad\n    geometries dynamically explicitly handling spatial constraints iteratively.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii strictly valid\n    \"\"\"\n    B = 300\n    N = 26\n    steps = 2500\n\n    np.random.seed(42)\n\n    X = np.zeros((B, N))\n    Y = np.zeros((B, N))\n    \n    # 1. Random uniform initialization\n    b1 = 60\n    X[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n    Y[:b1] = np.random.uniform(0.1, 0.9, (b1, N))\n\n    # 2. Concentric circle distributions ensuring structural density\n    b2 = 60\n    for i in range(b1, b1 + b2):\n        n_outer = 16\n        n_inner = 9\n        n_center = 1\n        \n        a_out = np.linspace(0, 2 * np.pi, n_outer, endpoint=False) + np.random.rand()\n        a_in = np.linspace(0, 2 * np.pi, n_inner, endpoint=False) + np.random.rand()\n        \n        X[i, 0] = 0.5\n        Y[i, 0] = 0.5\n        \n        r_in = 0.22 + np.random.normal(0, 0.01)\n        X[i, 1:n_inner+1] = 0.5 + r_in * np.cos(a_in)\n        Y[i, 1:n_inner+1] = 0.5 + r_in * np.sin(a_in)\n        \n        r_out = 0.45 + np.random.normal(0, 0.01)\n        X[i, n_inner+1:] = 0.5 + r_out * np.cos(a_out)\n        Y[i, n_inner+1:] = 0.5 + r_out * np.sin(a_out)\n\n    # 3. Random Beta boundary preference \n    b3 = 60\n    X[b1+b2:b1+b2+b3] = np.random.beta(0.5, 0.5, (b3, N)) * 0.9 + 0.05\n    Y[b1+b2:b1+b2+b3] = np.random.beta(0.5, 0.5, (b3, N)) * 0.9 + 0.05\n\n    # 4. Dense Hexagonal Grid packing style layout \n    b4 = 60\n    grid_pts = []\n    for row in range(6):\n        for col in range(5):\n            offset = 0.04 if row % 2 == 1 else 0.0\n            x = 0.15 + col * 0.16 + offset\n            y = 0.15 + row * 0.14\n            grid_pts.append((x, y))\n            \n    grid_arr = np.array(grid_pts)\n    for i in range(b1+b2+b3, b1+b2+b3+b4):\n        indices = np.random.choice(len(grid_arr), N, replace=False)\n        pts = grid_arr[indices] + np.random.normal(0, 0.01, (N, 2))\n        X[i] = pts[:, 0]\n        Y[i] = pts[:, 1]\n        \n    # 5. Anchor configurations mapping directly into tight corners\n    b5 = B - (b1+b2+b3+b4)\n    for i in range(b1+b2+b3+b4, B):\n        X[i, :4] = [0.1, 0.9, 0.1, 0.9]\n        Y[i, :4] = [0.1, 0.1, 0.9, 0.9]\n        X[i, 4:8] = [0.5, 0.5, 0.1, 0.9]\n        Y[i, 4:8] = [0.1, 0.9, 0.5, 0.5]\n        \n        X[i, 8:] = np.random.uniform(0.2, 0.8, N - 8)\n        Y[i, 8:] = np.random.uniform(0.2, 0.8, N - 8)\n\n    # Diverse randomized radius pushing to favor asymmetric structures early\n    R_push = np.zeros((B, N))\n    for i in range(B):\n        order = np.random.permutation(N)\n        R_push[i, order] = np.linspace(0.8, 1.3, N)\n        \n    R = np.random.uniform(0.01, 0.04, (B, N))\n\n    # Optimization Configuration\n    lr = 0.04\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    m_X = np.zeros_like(X)\n    v_X = np.zeros_like(X)\n    m_Y = np.zeros_like(Y)\n    v_Y = np.zeros_like(Y)\n    m_R = np.zeros_like(R)\n    v_R = np.zeros_like(R)\n\n    mask = ~np.eye(N, dtype=bool)\n\n    pen_start = 20.0\n    pen_end = 25000.0\n    pen_factor = (pen_end / pen_start) ** (1.0 / steps)\n    pen = pen_start\n\n    # Batched multi-strategy physics iterations\n    for step in range(1, steps + 1):\n        cur_lr = lr * 0.5 * (1.0 + np.cos(np.pi * step / steps))\n        \n        if step < steps * 0.4 and step % 200 == 0:\n            noise_scale = 1e-3 * (1.0 - step / (steps * 0.4))\n            X += np.random.normal(0, noise_scale, X.shape)\n            Y += np.random.normal(0, noise_scale, Y.shape)\n            \n        dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n        dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n        dist = np.sqrt(dX**2 + dY**2 + 1e-12)\n        \n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist) * mask[np.newaxis, :, :]\n        \n        v_x1 = np.maximum(0, R - X)\n        v_x2 = np.maximum(0, X + R - 1.0)\n        v_y1 = np.maximum(0, R - Y)\n        v_y2 = np.maximum(0, Y + R - 1.0)\n        \n        grad_R_overlap = 2.0 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2.0 * (v_x1 + v_x2 + v_y1 + v_y2)\n        \n        dir_X = dX / dist\n        dir_Y = dY / dist\n        grad_X_overlap = -2.0 * np.sum(overlap * dir_X, axis=2)\n        grad_Y_overlap = -2.0 * np.sum(overlap * dir_Y, axis=2)\n        \n        grad_X_bounds = 2.0 * (-v_x1 + v_x2)\n        grad_Y_bounds = 2.0 * (-v_y1 + v_y2)\n        \n        # Decay the asymmetry structure back to uniform maximization continuously\n        target_scale = max(0.0, 1.0 - step / (steps * 0.5))\n        current_push = 1.0 + (R_push - 1.0) * target_scale\n        \n        grad_R = -current_push + pen * (grad_R_overlap + grad_R_bounds)\n        grad_X = pen * (grad_X_overlap + grad_X_bounds)\n        grad_Y = pen * (grad_Y_overlap + grad_Y_bounds)\n        \n        bias1 = 1.0 - beta1**step\n        bias2 = 1.0 - beta2**step\n        \n        m_X = beta1 * m_X + (1.0 - beta1) * grad_X\n        v_X = beta2 * v_X + (1.0 - beta2) * (grad_X**2)\n        X -= cur_lr * (m_X / bias1) / (np.sqrt(v_X / bias2) + eps)\n        \n        m_Y = beta1 * m_Y + (1.0 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1.0 - beta2) * (grad_Y**2)\n        Y -= cur_lr * (m_Y / bias1) / (np.sqrt(v_Y / bias2) + eps)\n        \n        m_R = beta1 * m_R + (1.0 - beta1) * grad_R\n        v_R = beta2 * v_R + (1.0 - beta2) * (grad_R**2)\n        R -= cur_lr * (m_R / bias1) / (np.sqrt(v_R / bias2) + eps)\n        \n        X = np.clip(X, 1e-6, 1.0 - 1e-6)\n        Y = np.clip(Y, 1e-6, 1.0 - 1e-6)\n        R = np.maximum(R, 1e-6)\n\n        pen *= pen_factor\n\n    # Cleanup validation logic maintaining structurally optimized limits seamlessly\n    R = np.clip(R, 0.0, 0.5)\n    R = np.minimum.reduce([R, X, 1.0 - X, Y, 1.0 - Y])\n\n    dX = X[:, :, np.newaxis] - X[:, np.newaxis, :]\n    dY = Y[:, :, np.newaxis] - Y[:, np.newaxis, :]\n    dist_mat = np.hypot(dX, dY)\n    dist_mat[:, np.arange(N), np.arange(N)] = np.inf\n    \n    # Symmetric continuous elimination of minor constraints organically properly\n    for _ in range(300):\n        overlap = np.maximum(0, R[:, :, np.newaxis] + R[:, np.newaxis, :] - dist_mat)\n        if np.max(overlap) < 1e-10:\n            break\n            \n        sum_r = R[:, :, np.newaxis] + R[:, np.newaxis, :] + 1e-12\n        drop = np.sum(overlap * (R[:, :, np.newaxis] / sum_r), axis=2)\n        R -= drop * 0.45 \n        R = np.maximum(R, 0.0)\n\n    # Fail-safe pairwise intersection down-scaling appropriately logically accurately \n    for b in range(B):\n        r_b = R[b]\n        d_b = dist_mat[b]\n        for i in range(N):\n            for j in range(i + 1, N):\n                ov_c = r_b[i] + r_b[j] - d_b[i, j]\n                if ov_c > 1e-12:\n                    scale = (d_b[i, j] - 1e-12) / (r_b[i] + r_b[j] + 1e-12)\n                    scale = np.clip(scale, 0.0, 1.0)\n                    r_b[i] *= scale\n                    r_b[j] *= scale\n\n    # Boundary padding securely precisely safely neatly appropriately rationally safely cleanly\n    for b in range(B):\n        x, y = X[b], Y[b]\n        r = R[b]\n        r = np.minimum.reduce([r, x, 1.0 - x, y, 1.0 - y])\n        r *= 0.999999\n        R[b] = np.maximum(r, 0.0)\n\n    sums = np.sum(R, axis=1)\n    best_id = np.argmax(sums)\n    \n    return np.column_stack((X[best_id], Y[best_id])), R[best_id], sums[best_id]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"8.23s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.618522/2.635 = 0.9937\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.4% of target value\", \"radius_stats\": \"Min: 0.070122, Max: 0.132109, Avg: 0.100712\"}", "artifact_dir": null, "embedding": null}