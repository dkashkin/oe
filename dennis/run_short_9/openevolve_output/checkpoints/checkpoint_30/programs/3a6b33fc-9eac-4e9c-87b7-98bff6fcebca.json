{"id": "3a6b33fc-9eac-4e9c-87b7-98bff6fcebca", "code": "import numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Batched and iterative physics-based continuous optimization discovering \n    tight Apollonian dense-packing circle properties via batched simulated layouts.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii) perfectly enclosed strictly in 1x1.\n    \"\"\"\n    # Deterministic batched states uniformly evaluating structural variations  \n    np.random.seed(8482)\n    n = 26\n    B = 32\n    \n    centers_all = []\n    R_init = np.random.uniform(0.005, 0.015, (B, n))\n    \n    for b in range(B):\n        centers = []\n        corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n        edges = [[0.5, 0.05], [0.05, 0.5], [0.95, 0.5], [0.5, 0.95]]\n        \n        mode = b % 8\n        if mode == 0:\n            centers.extend(corners)\n            centers.extend(edges)\n            n_inner = n - 8\n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n_inner):\n                r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.35\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        elif mode == 1:\n            centers.extend(corners)\n            n_inner = n - 4\n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n_inner):\n                r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.40\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        elif mode == 2:\n            centers.extend(corners)\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 3:\n            centers.append([0.5, 0.5])\n            R_init[b, 0] = 0.05  # Force strong primary structure growth early \n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 4:\n            # 5x5 Subgrid explicit testing  \n            pts = np.linspace(0.1, 0.9, 5)\n            for px in pts:\n                for py in pts:\n                    if len(centers) < n:\n                        centers.append([px, py])\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 5:\n            # Concentric rigid placement limits exactly accommodating circles \n            centers.append([0.5, 0.5])\n            R_init[b, 0] = 0.05\n            ring1, ring2 = 8, 17\n            for i in range(ring1):\n                t = 2 * np.pi * i / ring1\n                centers.append([0.5 + 0.2 * np.cos(t), 0.5 + 0.2 * np.sin(t)])\n            for i in range(ring2):\n                t = 2 * np.pi * i / ring2\n                centers.append([0.5 + 0.4 * np.cos(t), 0.5 + 0.4 * np.sin(t)])\n                \n        elif mode == 6:\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 7:\n            # Outside sweeping strictly traversing internal density placement \n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n):\n                r = 0.45 * np.sqrt(1.0 - i / n)\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        centers_all.append(np.array(centers[:n]))\n        \n    X = np.array(centers_all)\n    X += (np.random.rand(B, n, 2) - 0.5) * 0.015\n    X = np.clip(X, 0.01, 0.99)\n    R = R_init.copy()\n    \n    # Broadcast constraints uniquely per batched physics sequence paths  \n    base_noise = np.linspace(0.01, 0.09, B).reshape(B, 1, 1)\n    \n    lr_start_X = 0.01\n    lr_end_X = 0.0001\n    lr_start_R = 0.01\n    lr_end_R = 0.0001\n    \n    lambda_start = 5.0\n    lambda_end = 85000.0\n    n_iters = 16000\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    beta1, beta2 = 0.9, 0.999\n    epsilon = 1e-8\n    rng = np.arange(n)\n    \n    # Batched Adam Gradient Kinematics Evaluation Processing Loop\n    for step in range(1, n_iters + 1):\n        progress = step / n_iters\n        \n        lr_X = lr_start_X * (1 - progress) + lr_end_X * progress\n        lr_R = lr_start_R * (1 - progress) + lr_end_R * progress\n        \n        current_lambda = lambda_start * (lambda_end / lambda_start) ** progress\n        \n        # High-performance parallel pairwise analysis\n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :] \n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        R_sum = R[:, :, np.newaxis] + R[:, np.newaxis, :]\n        overlap = np.maximum(0, R_sum - dist)\n        overlap[:, rng, rng] = 0\n        \n        # Bound penalty vectors maintaining geometric constraints \n        ox1 = np.maximum(0, R - X[:, :, 0])\n        ox2 = np.maximum(0, X[:, :, 0] + R - 1)\n        oy1 = np.maximum(0, R - X[:, :, 1])\n        oy2 = np.maximum(0, X[:, :, 1] + R - 1)\n        \n        # Growth bias forcing tight boundaries organically\n        grad_R_pairs = 2 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2 * (ox1 + ox2 + oy1 + oy2)\n        grad_R = -1.0 + current_lambda * (grad_R_pairs + grad_R_bounds)\n        \n        force_mag = -2 * overlap / dist\n        grad_X_pairs = np.sum(force_mag[:, :, :, np.newaxis] * diff, axis=2)\n        \n        grad_X_bounds_x = 2 * (ox2 - ox1)\n        grad_X_bounds_y = 2 * (oy2 - oy1)\n        grad_X_bounds = np.stack([grad_X_bounds_x, grad_X_bounds_y], axis=-1)\n        grad_X = current_lambda * (grad_X_pairs + grad_X_bounds)\n        \n        # Stochastic exploration temperature uniquely applied natively capturing symmetries uniformly\n        if progress < 0.7:\n            noise_std = base_noise * (1.0 - progress / 0.7)\n            grad_X += np.random.randn(*X.shape) * noise_std\n            \n        grad_X = np.clip(grad_X, -50.0, 50.0)\n        grad_R = np.clip(grad_R, -50.0, 50.0)\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_X_hat = m_X / (1 - beta1**step)\n        v_X_hat = v_X / (1 - beta2**step)\n        X -= lr_X * m_X_hat / (np.sqrt(v_X_hat) + epsilon)\n        X = np.clip(X, 0.001, 0.999)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr_R * m_R_hat / (np.sqrt(v_R_hat) + epsilon)\n        R = np.clip(R, 0.001, 0.5)\n\n    best_sum = -1.0\n    best_X = None\n    best_R = None\n    \n    # -------------------------------------------------------------\n    # Deep Exact Verification resolving boundaries rigorously utilizing purely\n    # mathematically unbiased strict parallel reduction loops scaling fairly seamlessly  \n    for b in range(B):\n        X_b = X[b].copy()\n        R_b = R[b].copy()\n        \n        for _ in range(2000):\n            changed = False\n            \n            for i in range(n):\n                max_r = min(X_b[i, 0], 1 - X_b[i, 0], X_b[i, 1], 1 - X_b[i, 1])\n                if R_b[i] > max_r:\n                    R_b[i] = max_r * 0.9999999\n                    changed = True\n                    \n            v_count = 0\n            scales = np.ones(n)\n            for i in range(n):\n                for j in range(i + 1, n):\n                    d = np.linalg.norm(X_b[i] - X_b[j])\n                    if R_b[i] + R_b[j] > d + 1e-12:\n                        v_count += 1\n                        # Apply safe mathematical reduction correctly avoiding limits  \n                        s = max(1e-12, d) / (R_b[i] + R_b[j])\n                        scales[i] = min(scales[i], s)\n                        scales[j] = min(scales[j], s)\n                        \n            if v_count > 0:\n                R_b *= (scales * 0.9999999)\n                changed = True\n                \n            if not changed:\n                break\n                \n        sum_val = float(np.sum(R_b))\n        if sum_val > best_sum:\n            best_sum = sum_val\n            best_X = X_b\n            best_R = R_b\n\n    return best_X, best_R, best_sum\n\n\ndef compute_max_radii(centers):\n    \"\"\"Fallback strictly scaling given placements seamlessly checking limit metrics\"\"\"\n    n = centers.shape[0]\n    radii = np.ones(n) * 0.5\n    for _ in range(500):\n        changed = False\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if radii[i] > max_r:\n                radii[i] = max_r * 0.9999999\n                changed = True\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n                if radii[i] + radii[j] > dist:\n                    scale = (dist / (radii[i] + radii[j])) * 0.9999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    changed = True\n        if not changed:\n            break\n            \n    return radii\n\n\ndef run_packing():\n    \"\"\"Run mathematically batched framework simulating 32 separate 26-circle limits perfectly!\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"Verify geometrical configurations smoothly processing visual displays successfully\"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Construct the base frame borders accurately bounded purely geometrically   \n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5, edgecolor=\"black\")\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\", fontsize=8)\n\n    plt.title(f\"Highly Optimized Pack | Circles={len(centers)} | Target \u03a3={sum(radii):.6f}\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Optimal Result Found! Sum of mathematically bounded radii: {sum_radii}\")\n    # uncomment conditionally locally enabling visual confirmation output bounds   \n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "72df8f71-4fed-46ea-abae-376158e71de6", "generation": 2, "timestamp": 1772011740.9315252, "iteration_found": 23, "metrics": {"validity": 1.0, "sum_radii": 2.6297831922871246, "target_ratio": 0.9980201868262334, "combined_score": 0.9980201868262334, "radius_variance": 0.005546863107121158, "spatial_spread": 0.200755418544719, "eval_time": 28.21514081954956}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.612058001716155, "target_ratio": 0.9912933592850683, "combined_score": 0.9912933592850683, "radius_variance": 0.007595783058635037, "spatial_spread": 0.19504634836574303, "eval_time": 2.7212491035461426}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9913\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.6557 \u2192 0.9913\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n2.72s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.612058/2.635 = 0.9913\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.1% of target value\n```\n\n### radius_stats\n```\nMin: 0.067562, Max: 0.135806, Avg: 0.100464\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 1.7277, target_ratio: 0.6557, combined_score: 0.6557, radius_variance: 0.0096, spatial_spread: 0.1890, eval_time: 8.0851\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6121, target_ratio: 0.9913, combined_score: 0.9913, radius_variance: 0.0076, spatial_spread: 0.1950, eval_time: 2.7212\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9913)\n```python\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Iterative physics-based optimization to arrange 26 circles in a unit square.\n    Optimizes both positions and radii simultaneously via a physics-engine to find \n    the tightest dense-packing Apollonian-like configuration.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    np.random.seed(1337)\n    n = 26\n    \n    # 1. Initialize placements strategically \n    # Bias towards corners and edges heavily first to trap space effectively\n    centers = []\n    \n    # Place at the 4 extremities/corners\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    centers.extend(corners)\n    \n    # Place 4 near midpoints of boundary edges\n    edges = [[0.5, 0.05], [0.05, 0.5], [0.95, 0.5], [0.5, 0.95]]\n    centers.extend(edges)\n    \n    # Remaining 18 interior points using Golden Spiral for maximum equitable spreading\n    n_inner = 18\n    theta = np.pi * (3 - np.sqrt(5))\n    for i in range(n_inner):\n        r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.35\n        t = i * theta\n        centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n        \n    X = np.array(centers)\n    # Slight continuous perturbation breaking initial hard symmetries to avoid local peaks\n    X += (np.random.rand(n, 2) - 0.5) * 0.01\n    X = np.clip(X, 0.01, 0.99)\n    \n    # Bubbles start tiny so they have maximum flow mechanics to organically pack gaps\n    R = np.ones(n) * 0.01\n    \n    # Parameters for continuous continuous SGLD Adam-based optimizer\n    lr_start_X = 0.01\n    lr_end_X = 0.0001\n    lr_start_R = 0.01\n    lr_end_R = 0.0001\n    \n    lambda_start = 5.0\n    lambda_end = 50000.0\n    \n    n_iters = 20000\n    \n    # Adam velocity trackers\n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    beta1, beta2 = 0.9, 0.999\n    epsilon = 1e-8\n    \n    for step in range(1, n_iters + 1):\n        progress = step / n_iters\n        \n        lr_X = lr_start_X * (1 - progress) + lr_end_X * progress\n        lr_R = lr_start_R * (1 - progress) + lr_end_R * progress\n        \n        # Exponential annealing to violently harden borders later but remain fluid early\n        current_lambda = lambda_start * (lambda_end / lambda_start) ** progress\n        \n        # Distance checks using vectorized broadcast matrix mathematics\n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :] \n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = np.maximum(0, R_sum - dist)\n        np.fill_diagonal(overlap, 0)\n        \n        # Extraneous boundary clipping conditions limiting radii sizes independently\n        ox1 = np.maximum(0, R - X[:, 0])\n        ox2 = np.maximum(0, X[:, 0] + R - 1)\n        oy1 = np.maximum(0, R - X[:, 1])\n        oy2 = np.maximum(0, X[:, 1] + R - 1)\n        \n        # Objective Gradients - Constantly applying a bias toward expansive Radius Sum Growth\n        grad_R_pairs = 2 * np.sum(overlap, axis=1)\n        grad_R_bounds = 2 * (ox1 + ox2 + oy1 + oy2)\n        grad_R = -1.0 + current_lambda * (grad_R_pairs + grad_R_bounds)\n        \n        # Relocation Gradients \n        force_mag = -2 * overlap / dist\n        grad_X_pairs = np.sum(force_mag[:, :, np.newaxis] * diff, axis=1)\n        \n        grad_X_bounds_x = 2 * (ox2 - ox1)\n        grad_X_bounds_y = 2 * (oy2 - oy1)\n        grad_X_bounds = np.stack([grad_X_bounds_x, grad_X_bounds_y], axis=1)\n        grad_X = current_lambda * (grad_X_pairs + grad_X_bounds)\n        \n        # Simulated temperature decay inducing randomness while malleable to unlock local minima\n        if progress < 0.7:\n            noise_std = 0.05 * (1.0 - progress / 0.7)\n            grad_X += np.random.randn(*X.shape) * noise_std\n            \n        grad_X = np.clip(grad_X, -50.0, 50.0)\n        grad_R = np.clip(grad_R, -50.0, 50.0)\n        \n        # Propagating descent mechanics for Location Features\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_X_hat = m_X / (1 - beta1**step)\n        v_X_hat = v_X / (1 - beta2**step)\n        X -= lr_X * m_X_hat / (np.sqrt(v_X_hat) + epsilon)\n        X = np.clip(X, 0.001, 0.999)\n        \n        # Propagating descent mechanics for Radius Expansion Dimensions\n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr_R * m_R_hat / (np.sqrt(v_R_hat) + epsilon)\n        R = np.clip(R, 0.001, 0.5)\n        \n    # --- Exact Safety Relaxation Passes ---\n    # Guarantee mathematically valid boundaries avoiding any sub-fraction overlap penalizations\n    for _ in range(500):\n        changed = False\n        \n        # Limit via hard frame boundaries explicitly \n        for i in range(n):\n            max_r = min(X[i, 0], 1 - X[i, 0], X[i, 1], 1 - X[i, 1])\n            if R[i] > max_r:\n                R[i] = max_r * 0.999999\n                changed = True\n                \n        # Limit via sequential hard contact dependencies gracefully maintaining symmetry balances\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((X[i] - X[j]) ** 2))\n                if R[i] + R[j] > dist:\n                    scale = (dist / (R[i] + R[j])) * 0.999999\n                    R[i] *= scale\n                    R[j] *= scale\n                    changed = True\n                    \n        if not changed:\n            break\n            \n    sum_radii = float(np.sum(R))\n    return X, R, sum_radii\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Fallback mathematical safety net dynamically evaluating exact non-overlapping radii configurations \n    if strictly requested by upstream validation checks natively bypassing constructor states.\n    \"\"\"\n    n = centers.shape[0]\n    radii = np.ones(n) * 0.5\n    for _ in range(500):\n        changed = False\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if radii[i] > max_r:\n                radii[i] = max_r * 0.999999\n                changed = True\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n                if radii[i] + radii[j] > dist:\n                    scale = (dist / (radii[i] + radii[j])) * 0.999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    changed = True\n        if not changed:\n            break\n            \n    return radii\n\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6121), Performs well on target_ratio (0.9913), Performs well on combined_score (0.9913), Performs well on radius_variance (0.0076), Performs well on spatial_spread (0.1950), Performs well on eval_time (2.7212)\n\n### Program 2 (Score: 0.6557)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative batched physics-based circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_gradients_batched(C, R, w_penalty):\n    \"\"\"\n    Analytically compute the batched gradients of the cost and penalty terms\n    with respect to circle centers and their radii over multiple initializations.\n    \"\"\"\n    B, n, _ = C.shape\n    grad_C = np.zeros_like(C)\n    grad_R = np.zeros_like(R)\n\n    # Cost constraint: strictly push for maximization of the sum of radii\n    grad_R -= 1.0\n\n    # 1. Evaluate independently strictly isolated boundaries\n    # left wall (x=0)\n    v = np.maximum(0, R - C[:, :, 0])\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 0] -= w_penalty * 2 * v\n\n    # right wall (x=1)\n    v = np.maximum(0, R - (1 - C[:, :, 0]))\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 0] += w_penalty * 2 * v\n\n    # bottom wall (y=0)\n    v = np.maximum(0, R - C[:, :, 1])\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 1] -= w_penalty * 2 * v\n\n    # top wall (y=1)\n    v = np.maximum(0, R - (1 - C[:, :, 1]))\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 1] += w_penalty * 2 * v\n\n    # 2. Vectorized pairwise overlap distance analysis uniformly across batches\n    diff = C[:, :, np.newaxis, :] - C[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1) + 1e-9\n\n    R_sum = R[:, :, np.newaxis] + R[:, np.newaxis, :]\n    \n    # Pre-emptively mask out entirely diagonal self-interactions symmetrically\n    rng = np.arange(n)\n    R_sum[:, rng, rng] = 0\n\n    v = np.maximum(0, R_sum - dist)\n\n    grad_R += w_penalty * 2 * np.sum(v, axis=2)\n\n    v_scaled = 2 * w_penalty * v / dist\n    grad_C -= np.sum(v_scaled[..., np.newaxis] * diff, axis=2)\n\n    return grad_C, grad_R\n\n\ndef optimize_batched(C_init, R_init, steps=1600):\n    \"\"\"\n    Runs batched gradient descent simultaneously evolving distinct structural\n    layouts. Combines deeply weighted penalty forces mapped mathematically.\n    \"\"\"\n    C = C_init.copy()\n    R = R_init.copy()\n    \n    B, n, _ = C.shape\n    m_C, v_C = np.zeros_like(C), np.zeros_like(C)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n\n    for t in range(1, steps + 1):\n        progress = t / steps\n        \n        # Super-linear steep slope isolates structural edge violations tightly\n        w_penalty = 1.0 + 50000.0 * (progress ** 4)\n        lr = 0.05 * (1.0 - progress * 0.95)\n\n        grad_C, grad_R = get_gradients_batched(C, R, w_penalty)\n\n        # Smooth synthetic stochastic symmetry breaking via temperature scheduling\n        if progress < 0.3:\n            C += np.random.randn(B, n, 2) * 0.003 * (1 - progress / 0.3)\n\n        # Native momentum optimizer update rule (Adam based kinematics loop)\n        m_C = 0.9 * m_C + 0.1 * grad_C\n        v_C = 0.999 * v_C + 0.001 * (grad_C**2)\n        m_c_hat = m_C / (1 - 0.9**t)\n        v_c_hat = v_C / (1 - 0.999**t)\n        C -= lr * m_c_hat / (np.sqrt(v_c_hat) + 1e-8)\n\n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R**2)\n        m_r_hat = m_R / (1 - 0.9**t)\n        v_r_hat = v_R / (1 - 0.999**t)\n        R -= lr * m_r_hat / (np.sqrt(v_r_hat) + 1e-8)\n\n        # Uniform strict clipping bounds directly capturing layout phase logic limits\n        C = np.clip(C, 0.001, 0.999)\n        R = np.clip(R, 0.001, 0.5)\n\n    return C, R\n\n\ndef make_valid_single(C, R):\n    \"\"\"\n    Executes deep constraint resolution specifically verifying exact zero\n    geometric intersections utilizing fully deterministic resolution.\n    \"\"\"\n    R = R.copy()\n    n = len(R)\n\n    for i in range(n):\n        R[i] = min(R[i], C[i, 0], 1 - C[i, 0], C[i, 1], 1 - C[i, 1])\n\n    for _ in range(40):\n        v_count = 0\n        scales = np.ones(n)\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(C[i] - C[j])\n                if R[i] + R[j] > d + 1e-12:\n                    v_count += 1\n                    s = max(1e-9, d) / (R[i] + R[j])\n                    scales[i] = min(scales[i], s)\n                    scales[j] = min(scales[j], s)\n        \n        if v_count == 0:\n            break\n            \n        R *= scales\n\n    for i in range(n):\n        R[i] = max(1e-7, min(R[i], C[i, 0], 1 - C[i, 0], C[i, 1], 1 - C[i, 1]))\n        for j in range(i + 1, n):\n            d = max(np.linalg.norm(C[i] - C[j]), 1e-9)\n            if R[i] + R[j] > d:\n                s = d / (R[i] + R[j])\n                R[i] *= s\n                R[j] *= s\n\n    return R\n\n\ndef construct_packing():\n    \"\"\"\n    High-capacity entry executing deeply generated batch matrices resolving broadly natively \n    simulated optimal packing properties mathematically uniformly completely automatically limits.\n    \"\"\"\n    n = 26\n    np.random.seed(1234)\n\n    B = 64\n    C_init = np.random.rand(B, n, 2) * 0.9 + 0.05\n    R_init = np.random.uniform(0.01, 0.08, (B, n))\n\n    for b in range(B):\n        mode = b % 10\n        if mode == 0:\n            C_init[b, 0] = [0.5, 0.5]\n            R_init[b, 0] = 0.25\n            for i in range(1, n):\n                ang, rad = np.random.rand() * 6.28, 0.2 + 0.25 * np.random.rand()\n                C_init[b, i] = [0.5 + rad * np.cos(ang), 0.5 + rad * np.sin(ang)]\n        elif mode == 1:\n            C_init[b, :4] = [[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]]\n            R_init[b, :4] = 0.1\n            C_init[b, 4] = [0.5, 0.5]\n            R_init[b, 4] = 0.25\n        elif mode == 2:\n            C_init[b, 0] = [0.5, 0.5]\n            R_init[b, 0] = np.random.uniform(0.15, 0.35)\n            dists = np.linalg.norm(C_init[b] - np.array([0.5, 0.5]), axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n        elif mode == 3:\n            C_init[b, 0] = [0.3, 0.3]\n            C_init[b, 1] = [0.7, 0.7]\n            R_init[b, :2] = 0.2\n        elif mode == 4:\n            angles = np.linspace(0, 2*np.pi, n, endpoint=False)\n            C_init[b, :, 0] = 0.5 + 0.45 * np.cos(angles)\n            C_init[b, :, 1] = 0.5 + 0.45 * np.sin(angles)\n            R_init[b, :] = 0.05\n        elif mode == 5:\n            C_init[b, 0] = [0.3, 0.5]\n            R_init[b, 0] = 0.3\n            C_init[b, 1] = [0.7, 0.5]\n            R_init[b, 1] = 0.15\n        elif mode == 6:\n            C_init[b, :3] = [[0.3, 0.3], [0.7, 0.3], [0.5, 0.7]]\n            R_init[b, :3] = 0.15\n        elif mode == 7:\n            dists = np.linalg.norm(C_init[b], axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n        elif mode == 8:\n            grid_side = int(np.ceil(np.sqrt(n)))\n            pts = np.linspace(0.1, 0.9, grid_side)\n            xx, yy = np.meshgrid(pts, pts)\n            coords = np.column_stack((xx.ravel(), yy.ravel()))\n            C_init[b, :n] = coords[:n]\n            R_init[b, :] = 0.05\n        else:\n            center = np.random.rand(2)\n            dists = np.linalg.norm(C_init[b] - center, axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n\n        C_init[b] = np.clip(C_init[b], 0.05, 0.95)\n\n    C_opt, R_opt = optimize_batched(C_init, R_init, steps=1600)\n    \n    best_sum = -1.0\n    best_C = None\n    best_R = None\n\n    for b in range(B):\n        R_v = make_valid_single(C_opt[b], R_opt[b])\n        score = np.sum(R_v)\n        \n        if score > best_sum:\n            best_sum = score\n            best_C = C_opt[b].copy()\n            best_R = R_v.copy()\n\n    return best_C, best_R, best_sum\n\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the optimized parallel physics simulator layout algorithm constructor\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the mathematically processed optimized boundaries layout internally cleanly safely completely limits.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (1.7277), Performs well on target_ratio (0.6557), Performs well on combined_score (0.6557), Performs well on radius_variance (0.0096), Performs well on spatial_spread (0.1890), Performs well on eval_time (8.0851)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.6557, Type: Alternative)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Iterative batched physics-based circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef get_gradients_batched(C, R, w_penalty):\n    \"\"\"\n    Analytically compute the batched gradients of the cost and penalty terms\n    with respect to circle centers and their radii over multiple initializations.\n    \"\"\"\n    B, n, _ = C.shape\n    grad_C = np.zeros_like(C)\n    grad_R = np.zeros_like(R)\n\n    # Cost constraint: strictly push for maximization of the sum of radii\n    grad_R -= 1.0\n\n    # 1. Evaluate independently strictly isolated boundaries\n    # left wall (x=0)\n    v = np.maximum(0, R - C[:, :, 0])\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 0] -= w_penalty * 2 * v\n\n    # right wall (x=1)\n    v = np.maximum(0, R - (1 - C[:, :, 0]))\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 0] += w_penalty * 2 * v\n\n    # bottom wall (y=0)\n    v = np.maximum(0, R - C[:, :, 1])\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 1] -= w_penalty * 2 * v\n\n    # top wall (y=1)\n    v = np.maximum(0, R - (1 - C[:, :, 1]))\n    grad_R += w_penalty * 2 * v\n    grad_C[:, :, 1] += w_penalty * 2 * v\n\n    # 2. Vectorized pairwise overlap distance analysis uniformly across batches\n    diff = C[:, :, np.newaxis, :] - C[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1) + 1e-9\n\n    R_sum = R[:, :, np.newaxis] + R[:, np.newaxis, :]\n    \n    # Pre-emptively mask out entirely diagonal self-interactions symmetrically\n    rng = np.arange(n)\n    R_sum[:, rng, rng] = 0\n\n    v = np.maximum(0, R_sum - dist)\n\n    grad_R += w_penalty * 2 * np.sum(v, axis=2)\n\n    v_scaled = 2 * w_penalty * v / dist\n    grad_C -= np.sum(v_scaled[..., np.newaxis] * diff, axis=2)\n\n    return grad_C, grad_R\n\n\ndef optimize_batched(C_init, R_init, steps=1600):\n    \"\"\"\n    Runs batched gradient descent simultaneously evolving distinct structural\n    layouts. Combines deeply weighted penalty forces mapped mathematically.\n    \"\"\"\n    C = C_init.copy()\n    R = R_init.copy()\n    \n    B, n, _ = C.shape\n    m_C, v_C = np.zeros_like(C), np.zeros_like(C)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n\n    for t in range(1, steps + 1):\n        progress = t / steps\n        \n        # Super-linear steep slope isolates structural edge violations tightly\n        w_penalty = 1.0 + 50000.0 * (progress ** 4)\n        lr = 0.05 * (1.0 - progress * 0.95)\n\n        grad_C, grad_R = get_gradients_batched(C, R, w_penalty)\n\n        # Smooth synthetic stochastic symmetry breaking via temperature scheduling\n        if progress < 0.3:\n            C += np.random.randn(B, n, 2) * 0.003 * (1 - progress / 0.3)\n\n        # Native momentum optimizer update rule (Adam based kinematics loop)\n        m_C = 0.9 * m_C + 0.1 * grad_C\n        v_C = 0.999 * v_C + 0.001 * (grad_C**2)\n        m_c_hat = m_C / (1 - 0.9**t)\n        v_c_hat = v_C / (1 - 0.999**t)\n        C -= lr * m_c_hat / (np.sqrt(v_c_hat) + 1e-8)\n\n        m_R = 0.9 * m_R + 0.1 * grad_R\n        v_R = 0.999 * v_R + 0.001 * (grad_R**2)\n        m_r_hat = m_R / (1 - 0.9**t)\n        v_r_hat = v_R / (1 - 0.999**t)\n        R -= lr * m_r_hat / (np.sqrt(v_r_hat) + 1e-8)\n\n        # Uniform strict clipping bounds directly capturing layout phase logic limits\n        C = np.clip(C, 0.001, 0.999)\n        R = np.clip(R, 0.001, 0.5)\n\n    return C, R\n\n\ndef make_valid_single(C, R):\n    \"\"\"\n    Executes deep constraint resolution specifically verifying exact zero\n    geometric intersections utilizing fully deterministic resolution.\n    \"\"\"\n    R = R.copy()\n    n = len(R)\n\n    for i in range(n):\n        R[i] = min(R[i], C[i, 0], 1 - C[i, 0], C[i, 1], 1 - C[i, 1])\n\n    for _ in range(40):\n        v_count = 0\n        scales = np.ones(n)\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(C[i] - C[j])\n                if R[i] + R[j] > d + 1e-12:\n                    v_count += 1\n                    s = max(1e-9, d) / (R[i] + R[j])\n                    scales[i] = min(scales[i], s)\n                    scales[j] = min(scales[j], s)\n        \n        if v_count == 0:\n            break\n            \n        R *= scales\n\n    for i in range(n):\n        R[i] = max(1e-7, min(R[i], C[i, 0], 1 - C[i, 0], C[i, 1], 1 - C[i, 1]))\n        for j in range(i + 1, n):\n            d = max(np.linalg.norm(C[i] - C[j]), 1e-9)\n            if R[i] + R[j] > d:\n                s = d / (R[i] + R[j])\n                R[i] *= s\n                R[j] *= s\n\n    return R\n\n\ndef construct_packing():\n    \"\"\"\n    High-capacity entry executing deeply generated batch matrices resolving broadly natively \n    simulated optimal packing properties mathematically uniformly completely automatically limits.\n    \"\"\"\n    n = 26\n    np.random.seed(1234)\n\n    B = 64\n    C_init = np.random.rand(B, n, 2) * 0.9 + 0.05\n    R_init = np.random.uniform(0.01, 0.08, (B, n))\n\n    for b in range(B):\n        mode = b % 10\n        if mode == 0:\n            C_init[b, 0] = [0.5, 0.5]\n            R_init[b, 0] = 0.25\n            for i in range(1, n):\n                ang, rad = np.random.rand() * 6.28, 0.2 + 0.25 * np.random.rand()\n                C_init[b, i] = [0.5 + rad * np.cos(ang), 0.5 + rad * np.sin(ang)]\n        elif mode == 1:\n            C_init[b, :4] = [[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]]\n            R_init[b, :4] = 0.1\n            C_init[b, 4] = [0.5, 0.5]\n            R_init[b, 4] = 0.25\n        elif mode == 2:\n            C_init[b, 0] = [0.5, 0.5]\n            R_init[b, 0] = np.random.uniform(0.15, 0.35)\n            dists = np.linalg.norm(C_init[b] - np.array([0.5, 0.5]), axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n        elif mode == 3:\n            C_init[b, 0] = [0.3, 0.3]\n            C_init[b, 1] = [0.7, 0.7]\n            R_init[b, :2] = 0.2\n        elif mode == 4:\n            angles = np.linspace(0, 2*np.pi, n, endpoint=False)\n            C_init[b, :, 0] = 0.5 + 0.45 * np.cos(angles)\n            C_init[b, :, 1] = 0.5 + 0.45 * np.sin(angles)\n            R_init[b, :] = 0.05\n        elif mode == 5:\n            C_init[b, 0] = [0.3, 0.5]\n            R_init[b, 0] = 0.3\n            C_init[b, 1] = [0.7, 0.5]\n            R_init[b, 1] = 0.15\n        elif mode == 6:\n            C_init[b, :3] = [[0.3, 0.3], [0.7, 0.3], [0.5, 0.7]]\n            R_init[b, :3] = 0.15\n        elif mode == 7:\n            dists = np.linalg.norm(C_init[b], axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n        elif mode == 8:\n            grid_side = int(np.ceil(np.sqrt(n)))\n            pts = np.linspace(0.1, 0.9, grid_side)\n            xx, yy = np.meshgrid(pts, pts)\n            coords = np.column_stack((xx.ravel(), yy.ravel()))\n            C_init[b, :n] = coords[:n]\n            R_init[b, :] = 0.05\n        else:\n            center = np.random.rand(2)\n            dists = np.linalg.norm(C_init[b] - center, axis=1)\n            R_init[b, np.argsort(dists)] = np.sort(R_init[b])[::-1]\n\n        C_init[b] = np.clip(C_init[b], 0.05, 0.95)\n\n    C_opt, R_opt = optimize_batched(C_init, R_init, steps=1600)\n    \n    best_sum = -1.0\n    best_C = None\n    best_R = None\n\n    for b in range(B):\n        R_v = make_valid_single(C_opt[b], R_opt[b])\n        score = np.sum(R_v)\n        \n        if score > best_sum:\n            best_sum = score\n            best_C = C_opt[b].copy()\n            best_R = R_v.copy()\n\n    return best_C, best_R, best_sum\n\n# EVOLVE-BLOCK-END\n\ndef run_packing():\n    \"\"\"Run the optimized parallel physics simulator layout algorithm constructor\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the mathematically processed optimized boundaries layout internally cleanly safely completely limits.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Iterative physics-based optimization to arrange 26 circles in a unit square.\n    Optimizes both positions and radii simultaneously via a physics-engine to find \n    the tightest dense-packing Apollonian-like configuration.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    np.random.seed(1337)\n    n = 26\n    \n    # 1. Initialize placements strategically \n    # Bias towards corners and edges heavily first to trap space effectively\n    centers = []\n    \n    # Place at the 4 extremities/corners\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    centers.extend(corners)\n    \n    # Place 4 near midpoints of boundary edges\n    edges = [[0.5, 0.05], [0.05, 0.5], [0.95, 0.5], [0.5, 0.95]]\n    centers.extend(edges)\n    \n    # Remaining 18 interior points using Golden Spiral for maximum equitable spreading\n    n_inner = 18\n    theta = np.pi * (3 - np.sqrt(5))\n    for i in range(n_inner):\n        r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.35\n        t = i * theta\n        centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n        \n    X = np.array(centers)\n    # Slight continuous perturbation breaking initial hard symmetries to avoid local peaks\n    X += (np.random.rand(n, 2) - 0.5) * 0.01\n    X = np.clip(X, 0.01, 0.99)\n    \n    # Bubbles start tiny so they have maximum flow mechanics to organically pack gaps\n    R = np.ones(n) * 0.01\n    \n    # Parameters for continuous continuous SGLD Adam-based optimizer\n    lr_start_X = 0.01\n    lr_end_X = 0.0001\n    lr_start_R = 0.01\n    lr_end_R = 0.0001\n    \n    lambda_start = 5.0\n    lambda_end = 50000.0\n    \n    n_iters = 20000\n    \n    # Adam velocity trackers\n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    beta1, beta2 = 0.9, 0.999\n    epsilon = 1e-8\n    \n    for step in range(1, n_iters + 1):\n        progress = step / n_iters\n        \n        lr_X = lr_start_X * (1 - progress) + lr_end_X * progress\n        lr_R = lr_start_R * (1 - progress) + lr_end_R * progress\n        \n        # Exponential annealing to violently harden borders later but remain fluid early\n        current_lambda = lambda_start * (lambda_end / lambda_start) ** progress\n        \n        # Distance checks using vectorized broadcast matrix mathematics\n        diff = X[:, np.newaxis, :] - X[np.newaxis, :, :] \n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        R_sum = R[:, np.newaxis] + R[np.newaxis, :]\n        overlap = np.maximum(0, R_sum - dist)\n        np.fill_diagonal(overlap, 0)\n        \n        # Extraneous boundary clipping conditions limiting radii sizes independently\n        ox1 = np.maximum(0, R - X[:, 0])\n        ox2 = np.maximum(0, X[:, 0] + R - 1)\n        oy1 = np.maximum(0, R - X[:, 1])\n        oy2 = np.maximum(0, X[:, 1] + R - 1)\n        \n        # Objective Gradients - Constantly applying a bias toward expansive Radius Sum Growth\n        grad_R_pairs = 2 * np.sum(overlap, axis=1)\n        grad_R_bounds = 2 * (ox1 + ox2 + oy1 + oy2)\n        grad_R = -1.0 + current_lambda * (grad_R_pairs + grad_R_bounds)\n        \n        # Relocation Gradients \n        force_mag = -2 * overlap / dist\n        grad_X_pairs = np.sum(force_mag[:, :, np.newaxis] * diff, axis=1)\n        \n        grad_X_bounds_x = 2 * (ox2 - ox1)\n        grad_X_bounds_y = 2 * (oy2 - oy1)\n        grad_X_bounds = np.stack([grad_X_bounds_x, grad_X_bounds_y], axis=1)\n        grad_X = current_lambda * (grad_X_pairs + grad_X_bounds)\n        \n        # Simulated temperature decay inducing randomness while malleable to unlock local minima\n        if progress < 0.7:\n            noise_std = 0.05 * (1.0 - progress / 0.7)\n            grad_X += np.random.randn(*X.shape) * noise_std\n            \n        grad_X = np.clip(grad_X, -50.0, 50.0)\n        grad_R = np.clip(grad_R, -50.0, 50.0)\n        \n        # Propagating descent mechanics for Location Features\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_X_hat = m_X / (1 - beta1**step)\n        v_X_hat = v_X / (1 - beta2**step)\n        X -= lr_X * m_X_hat / (np.sqrt(v_X_hat) + epsilon)\n        X = np.clip(X, 0.001, 0.999)\n        \n        # Propagating descent mechanics for Radius Expansion Dimensions\n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr_R * m_R_hat / (np.sqrt(v_R_hat) + epsilon)\n        R = np.clip(R, 0.001, 0.5)\n        \n    # --- Exact Safety Relaxation Passes ---\n    # Guarantee mathematically valid boundaries avoiding any sub-fraction overlap penalizations\n    for _ in range(500):\n        changed = False\n        \n        # Limit via hard frame boundaries explicitly \n        for i in range(n):\n            max_r = min(X[i, 0], 1 - X[i, 0], X[i, 1], 1 - X[i, 1])\n            if R[i] > max_r:\n                R[i] = max_r * 0.999999\n                changed = True\n                \n        # Limit via sequential hard contact dependencies gracefully maintaining symmetry balances\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((X[i] - X[j]) ** 2))\n                if R[i] + R[j] > dist:\n                    scale = (dist / (R[i] + R[j])) * 0.999999\n                    R[i] *= scale\n                    R[j] *= scale\n                    changed = True\n                    \n        if not changed:\n            break\n            \n    sum_radii = float(np.sum(R))\n    return X, R, sum_radii\n\n\ndef compute_max_radii(centers):\n    \"\"\"\n    Fallback mathematical safety net dynamically evaluating exact non-overlapping radii configurations \n    if strictly requested by upstream validation checks natively bypassing constructor states.\n    \"\"\"\n    n = centers.shape[0]\n    radii = np.ones(n) * 0.5\n    for _ in range(500):\n        changed = False\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if radii[i] > max_r:\n                radii[i] = max_r * 0.999999\n                changed = True\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n                if radii[i] + radii[j] > dist:\n                    scale = (dist / (radii[i] + radii[j])) * 0.999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    changed = True\n        if not changed:\n            break\n            \n    return radii\n\n\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["An elegant way to consistently uncover strictly superior arrangements with an iterative physics simulation is executing it comprehensively utilizing **Simultaneous Batched Execution**, effectively enabling you to discover deeper minimum-energy valleys simultaneously. By completely vectorizing the position, size, constraint-handling, and simulated annealing (SGLD) gradient updates, the optimization traverses over $B=32$ completely independent Apoolonian network paths\u2014using different random geometric start arrangements\u2014and automatically converges uniformly across all structural guesses seamlessly before selecting the undisputed absolute best layout.\n\nTo systematically escape symmetrical local traps, we explicitly seed diverse spatial patterns (such as layered phyllotaxis or discrete concentric circles) and broadcast randomized `learning_temperatures` differently upon each discrete batched simulation instance concurrently to induce deep symmetric fracturing.\n\nHere is the thoroughly enhanced mathematically strict physics-packing solver using concurrent vectorized SGLD principles:\n\n```python\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Batched and iterative physics-based continuous optimization discovering \n    tight Apollonian dense-packing circle properties via batched simulated layouts.\n    \n    Returns:\n        Tuple of (centers, radii, sum_of_radii) perfectly enclosed strictly in 1x1.\n    \"\"\"\n    # Deterministic batched states uniformly evaluating structural variations  \n    np.random.seed(8482)\n    n = 26\n    B = 32\n    \n    centers_all = []\n    R_init = np.random.uniform(0.005, 0.015, (B, n))\n    \n    for b in range(B):\n        centers = []\n        corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n        edges = [[0.5, 0.05], [0.05, 0.5], [0.95, 0.5], [0.5, 0.95]]\n        \n        mode = b % 8\n        if mode == 0:\n            centers.extend(corners)\n            centers.extend(edges)\n            n_inner = n - 8\n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n_inner):\n                r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.35\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        elif mode == 1:\n            centers.extend(corners)\n            n_inner = n - 4\n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n_inner):\n                r = np.sqrt(i + 0.5) / np.sqrt(n_inner) * 0.40\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        elif mode == 2:\n            centers.extend(corners)\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 3:\n            centers.append([0.5, 0.5])\n            R_init[b, 0] = 0.05  # Force strong primary structure growth early \n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 4:\n            # 5x5 Subgrid explicit testing  \n            pts = np.linspace(0.1, 0.9, 5)\n            for px in pts:\n                for py in pts:\n                    if len(centers) < n:\n                        centers.append([px, py])\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 5:\n            # Concentric rigid placement limits exactly accommodating circles \n            centers.append([0.5, 0.5])\n            R_init[b, 0] = 0.05\n            ring1, ring2 = 8, 17\n            for i in range(ring1):\n                t = 2 * np.pi * i / ring1\n                centers.append([0.5 + 0.2 * np.cos(t), 0.5 + 0.2 * np.sin(t)])\n            for i in range(ring2):\n                t = 2 * np.pi * i / ring2\n                centers.append([0.5 + 0.4 * np.cos(t), 0.5 + 0.4 * np.sin(t)])\n                \n        elif mode == 6:\n            while len(centers) < n:\n                centers.append(np.random.rand(2) * 0.9 + 0.05)\n                \n        elif mode == 7:\n            # Outside sweeping strictly traversing internal density placement \n            theta = np.pi * (3 - np.sqrt(5))\n            for i in range(n):\n                r = 0.45 * np.sqrt(1.0 - i / n)\n                t = i * theta\n                centers.append([0.5 + r * np.cos(t), 0.5 + r * np.sin(t)])\n                \n        centers_all.append(np.array(centers[:n]))\n        \n    X = np.array(centers_all)\n    X += (np.random.rand(B, n, 2) - 0.5) * 0.015\n    X = np.clip(X, 0.01, 0.99)\n    R = R_init.copy()\n    \n    # Broadcast constraints uniquely per batched physics sequence paths  \n    base_noise = np.linspace(0.01, 0.09, B).reshape(B, 1, 1)\n    \n    lr_start_X = 0.01\n    lr_end_X = 0.0001\n    lr_start_R = 0.01\n    lr_end_R = 0.0001\n    \n    lambda_start = 5.0\n    lambda_end = 85000.0\n    n_iters = 16000\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    beta1, beta2 = 0.9, 0.999\n    epsilon = 1e-8\n    rng = np.arange(n)\n    \n    # Batched Adam Gradient Kinematics Evaluation Processing Loop\n    for step in range(1, n_iters + 1):\n        progress = step / n_iters\n        \n        lr_X = lr_start_X * (1 - progress) + lr_end_X * progress\n        lr_R = lr_start_R * (1 - progress) + lr_end_R * progress\n        \n        current_lambda = lambda_start * (lambda_end / lambda_start) ** progress\n        \n        # High-performance parallel pairwise analysis\n        diff = X[:, :, np.newaxis, :] - X[:, np.newaxis, :, :] \n        dist_sq = np.sum(diff**2, axis=-1)\n        dist = np.sqrt(dist_sq + 1e-12)\n        \n        R_sum = R[:, :, np.newaxis] + R[:, np.newaxis, :]\n        overlap = np.maximum(0, R_sum - dist)\n        overlap[:, rng, rng] = 0\n        \n        # Bound penalty vectors maintaining geometric constraints \n        ox1 = np.maximum(0, R - X[:, :, 0])\n        ox2 = np.maximum(0, X[:, :, 0] + R - 1)\n        oy1 = np.maximum(0, R - X[:, :, 1])\n        oy2 = np.maximum(0, X[:, :, 1] + R - 1)\n        \n        # Growth bias forcing tight boundaries organically\n        grad_R_pairs = 2 * np.sum(overlap, axis=2)\n        grad_R_bounds = 2 * (ox1 + ox2 + oy1 + oy2)\n        grad_R = -1.0 + current_lambda * (grad_R_pairs + grad_R_bounds)\n        \n        force_mag = -2 * overlap / dist\n        grad_X_pairs = np.sum(force_mag[:, :, :, np.newaxis] * diff, axis=2)\n        \n        grad_X_bounds_x = 2 * (ox2 - ox1)\n        grad_X_bounds_y = 2 * (oy2 - oy1)\n        grad_X_bounds = np.stack([grad_X_bounds_x, grad_X_bounds_y], axis=-1)\n        grad_X = current_lambda * (grad_X_pairs + grad_X_bounds)\n        \n        # Stochastic exploration temperature uniquely applied natively capturing symmetries uniformly\n        if progress < 0.7:\n            noise_std = base_noise * (1.0 - progress / 0.7)\n            grad_X += np.random.randn(*X.shape) * noise_std\n            \n        grad_X = np.clip(grad_X, -50.0, 50.0)\n        grad_R = np.clip(grad_R, -50.0, 50.0)\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_X_hat = m_X / (1 - beta1**step)\n        v_X_hat = v_X / (1 - beta2**step)\n        X -= lr_X * m_X_hat / (np.sqrt(v_X_hat) + epsilon)\n        X = np.clip(X, 0.001, 0.999)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_R_hat = m_R / (1 - beta1**step)\n        v_R_hat = v_R / (1 - beta2**step)\n        R -= lr_R * m_R_hat / (np.sqrt(v_R_hat) + epsilon)\n        R = np.clip(R, 0.001, 0.5)\n\n    best_sum = -1.0\n    best_X = None\n    best_R = None\n    \n    # -------------------------------------------------------------\n    # Deep Exact Verification resolving boundaries rigorously utilizing purely\n    # mathematically unbiased strict parallel reduction loops scaling fairly seamlessly  \n    for b in range(B):\n        X_b = X[b].copy()\n        R_b = R[b].copy()\n        \n        for _ in range(2000):\n            changed = False\n            \n            for i in range(n):\n                max_r = min(X_b[i, 0], 1 - X_b[i, 0], X_b[i, 1], 1 - X_b[i, 1])\n                if R_b[i] > max_r:\n                    R_b[i] = max_r * 0.9999999\n                    changed = True\n                    \n            v_count = 0\n            scales = np.ones(n)\n            for i in range(n):\n                for j in range(i + 1, n):\n                    d = np.linalg.norm(X_b[i] - X_b[j])\n                    if R_b[i] + R_b[j] > d + 1e-12:\n                        v_count += 1\n                        # Apply safe mathematical reduction correctly avoiding limits  \n                        s = max(1e-12, d) / (R_b[i] + R_b[j])\n                        scales[i] = min(scales[i], s)\n                        scales[j] = min(scales[j], s)\n                        \n            if v_count > 0:\n                R_b *= (scales * 0.9999999)\n                changed = True\n                \n            if not changed:\n                break\n                \n        sum_val = float(np.sum(R_b))\n        if sum_val > best_sum:\n            best_sum = sum_val\n            best_X = X_b\n            best_R = R_b\n\n    return best_X, best_R, best_sum\n\n\ndef compute_max_radii(centers):\n    \"\"\"Fallback strictly scaling given placements seamlessly checking limit metrics\"\"\"\n    n = centers.shape[0]\n    radii = np.ones(n) * 0.5\n    for _ in range(500):\n        changed = False\n        for i in range(n):\n            x, y = centers[i]\n            max_r = min(x, y, 1 - x, 1 - y)\n            if radii[i] > max_r:\n                radii[i] = max_r * 0.9999999\n                changed = True\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n                if radii[i] + radii[j] > dist:\n                    scale = (dist / (radii[i] + radii[j])) * 0.9999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    changed = True\n        if not changed:\n            break\n            \n    return radii\n\n\ndef run_packing():\n    \"\"\"Run mathematically batched framework simulating 32 separate 26-circle limits perfectly!\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"Verify geometrical configurations smoothly processing visual displays successfully\"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Construct the base frame borders accurately bounded purely geometrically   \n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5, edgecolor=\"black\")\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\", fontsize=8)\n\n    plt.title(f\"Highly Optimized Pack | Circles={len(centers)} | Target \u03a3={sum(radii):.6f}\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Optimal Result Found! Sum of mathematically bounded radii: {sum_radii}\")\n    # uncomment conditionally locally enabling visual confirmation output bounds   \n    # visualize(centers, radii)\n```"]}}, "artifacts_json": "{\"execution_time\": \"28.22s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.629783/2.635 = 0.9980\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.8% of target value\", \"radius_stats\": \"Min: 0.069529, Max: 0.138599, Avg: 0.101146\"}", "artifact_dir": null, "embedding": null}