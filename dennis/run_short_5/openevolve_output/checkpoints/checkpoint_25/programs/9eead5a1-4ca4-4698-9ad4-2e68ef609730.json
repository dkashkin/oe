{"id": "9eead5a1-4ca4-4698-9ad4-2e68ef609730", "code": "# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\ndef init_heuristic(n):\n    \"\"\"Establish a deeply structured base heuristic layout targeting known dense topological forms.\"\"\"\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Primary central giant seed\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Symmetric inner interlocking ring\n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Asymmetric outer enveloping ring\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Exploitation points at extreme structural boundaries\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Vertical spatial gap filler points dynamically\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    return centers, radii\n\ndef generate_diverse_seed(n, attempt):\n    \"\"\"Procedurally emit robust and globally distributed configuration sets mathematically mapping bounds spaces extensively.\"\"\"\n    if attempt == 0:\n        return init_heuristic(n)\n        \n    centers = np.zeros((n, 2))\n    radii = np.full(n, 0.05)\n    \n    if attempt < 15:\n        # Vogel Golden-Spiral alignments expanding varied compactness metrics continuously\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        exponent = 0.40 + 0.02 * attempt\n        for i in range(n):\n            rad = np.sqrt(i + 0.5) / np.sqrt(n)\n            theta = 2.0 * np.pi * i / (phi ** 2.0) + attempt * 0.7\n            centers[i, 0] = 0.5 + 0.4 * (rad ** exponent) * np.cos(theta)\n            centers[i, 1] = 0.5 + 0.4 * (rad ** exponent) * np.sin(theta)\n            radii[i] = 0.03 + 0.06 * (1.0 - rad)\n            \n    elif attempt < 25:\n        # Concentric rigid ring systems establishing deep symmetries initially mapped\n        centers[0] = [0.5, 0.5]\n        radii[0] = 0.12\n        counts = [6, 11, 8]\n        idx = 1\n        for ring, count in enumerate(counts):\n            r_dist = 0.17 * (ring + 1)\n            for j in range(count):\n                if idx < n:\n                    angle = 2 * np.pi * j / count + attempt * 0.5\n                    centers[idx, 0] = 0.5 + r_dist * np.cos(angle)\n                    centers[idx, 1] = 0.5 + r_dist * np.sin(angle)\n                    radii[idx] = 0.09 - 0.02 * ring\n                    idx += 1\n                    \n    elif attempt < 35:\n        # Hex-lattice rectangular structural mappings completely fully evenly evenly dispersed efficiently\n        cols, rows = 5, 6\n        idx = 0\n        spacing_x = 0.8 / (cols - 0.5)\n        spacing_y = 0.8 / (rows - 1.0)\n        for r in range(rows):\n            for c in range(cols):\n                if idx < n:\n                    offset = (r % 2) * 0.5\n                    centers[idx, 0] = 0.1 + ((c + offset) * spacing_x)\n                    centers[idx, 1] = 0.1 + (r * spacing_y)\n                    radii[idx] = 0.06\n                    idx += 1\n    else:\n        # Full uniform thermal stochastic structural distributions spanning wide initial conditions reliably perfectly effectively safely\n        centers = np.random.uniform(0.05, 0.95, (n, 2))\n        radii[:6] = np.random.uniform(0.1, 0.14, 6)\n        radii[6:16] = np.random.uniform(0.06, 0.1, 10)\n        radii[16:] = np.random.uniform(0.03, 0.06, 10)\n        \n    return centers, radii\n\ndef optimize_layout(centers, radii, iters, max_c, start_lr, end_lr, add_noise):\n    \"\"\"\n    Deep constrained natively unrolled and physics dynamically optimizing Adam loop.\n    Re-written iteratively accelerating linear arrays strictly comprehensively bypassing numpy overhead dynamically natively comprehensively securely smoothly perfectly!\n    \"\"\"\n    n = len(radii)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    m_c_x, v_c_x = np.zeros(n), np.zeros(n)\n    m_c_y, v_c_y = np.zeros(n), np.zeros(n)\n    m_r, v_r = np.zeros(n), np.zeros(n)\n    \n    c_x = np.copy(centers[:, 0])\n    c_y = np.copy(centers[:, 1])\n    r = np.copy(radii)\n    \n    power = np.log10(max_c)\n    lr_ratio = end_lr / start_lr\n\n    for step in range(1, iters + 1):\n        progress = step / float(iters)\n        C = float(10 ** (power * progress))\n        C_2 = C * 2.0\n        \n        dx = c_x[:, None] - c_x[None, :]\n        dy = c_y[:, None] - c_y[None, :]\n        \n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, np.inf)\n        dist = np.sqrt(dist_sq)\n        \n        sum_r = r[:, None] + r[None, :]\n        O = sum_r - dist\n        O = np.maximum(0.0, O) \n        \n        bx_L = np.maximum(0.0, r - c_x)\n        bx_R = np.maximum(0.0, r - (1.0 - c_x))\n        by_B = np.maximum(0.0, r - c_y)\n        by_T = np.maximum(0.0, r - (1.0 - c_y))\n        \n        current_bias = 0.1 * (1.0 - progress)\n        dist_c = np.sqrt((c_x - 0.5)**2 + (c_y - 0.5)**2)\n        grad_r = -(1.0 + current_bias * np.maximum(0.0, 0.4 - dist_c))\n        grad_r += C_2 * np.sum(O, axis=1) + C_2 * (bx_L + bx_R + by_B + by_T)\n        \n        inv_dist = 1.0 / dist\n        O_scaled = (C_2 * O) * inv_dist\n        \n        grad_c_x = -np.sum(O_scaled * dx, axis=1)\n        grad_c_y = -np.sum(O_scaled * dy, axis=1)\n        \n        grad_c_x += C_2 * (-bx_L + bx_R)\n        grad_c_y += C_2 * (-by_B + by_T)\n        \n        if add_noise and step < iters // 2:\n            noise_scale = 40.0 * (1.0 - step / (iters // 2))\n            grad_c_x += np.random.normal(0.0, noise_scale, size=n)\n            grad_c_y += np.random.normal(0.0, noise_scale, size=n)\n            \n        grad_c_x = np.clip(grad_c_x, -1000.0, 1000.0)\n        grad_c_y = np.clip(grad_c_y, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n        \n        current_lr = start_lr * (lr_ratio ** progress)\n        \n        m_c_x = beta1 * m_c_x + (1 - beta1) * grad_c_x\n        v_c_x = beta2 * v_c_x + (1 - beta2) * (grad_c_x ** 2)\n        m_hat_c_x = m_c_x / (1 - beta1 ** step)\n        v_hat_c_x = v_c_x / (1 - beta2 ** step)\n        c_x -= current_lr * m_hat_c_x / (np.sqrt(v_hat_c_x) + eps)\n        \n        m_c_y = beta1 * m_c_y + (1 - beta1) * grad_c_y\n        v_c_y = beta2 * v_c_y + (1 - beta2) * (grad_c_y ** 2)\n        m_hat_c_y = m_c_y / (1 - beta1 ** step)\n        v_hat_c_y = v_c_y / (1 - beta2 ** step)\n        c_y -= current_lr * m_hat_c_y / (np.sqrt(v_hat_c_y) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        r -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        np.clip(c_x, 0.0, 1.0, out=c_x)\n        np.clip(c_y, 0.0, 1.0, out=c_y)\n        np.maximum(r, 0.002, out=r)\n        \n    final_centers = np.column_stack((c_x, c_y))\n    return final_centers, r\n\ndef finalize_radii_lp(centers, initial_radii=None):\n    \"\"\"\n    Absolutely deterministic structurally unconstrained mathematical rigorous radii scaling comprehensively smoothly optimizing directly \n    solving strict internal gaps cleanly natively fully using highly robust Linear Programming.\n    \"\"\"\n    import warnings\n    \n    n = len(centers)\n    bounds = np.zeros(n)\n    for i in range(n):\n        x, y = centers[i]\n        bounds[i] = min(x, y, 1.0 - x, 1.0 - y)\n        \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub, b_ub = [], []\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                dist_safe = max(0.0, dist - 1e-12)\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_safe)\n                \n        bounds_arr = [(0.0, b) for b in bounds]\n        \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds_arr, method='highs')\n            \n        if res.success:\n            r = np.clip(res.x, 0.0, bounds)\n            for _ in range(50):\n                max_ov = 0.0\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        d = np.linalg.norm(centers[i] - centers[j])\n                        sum_r = r[i] + r[j]\n                        if sum_r > d:\n                            max_ov = max(max_ov, sum_r - d)\n                            scale = (d / sum_r) * 0.99999999\n                            r[i] *= scale\n                            r[j] *= scale\n                if max_ov < 1e-13:\n                    break\n            return r * 0.99999999\n    except Exception:\n        pass\n        \n    r = np.copy(initial_radii) if initial_radii is not None else np.copy(bounds)\n    r = np.minimum(r, centers[:, 0])\n    r = np.minimum(r, 1 - centers[:, 0])\n    r = np.minimum(r, centers[:, 1])\n    r = np.minimum(r, 1 - centers[:, 1])\n    r = np.maximum(r, 0.0)\n    for _ in range(200):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = r[i] + r[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.99999999\n                    r[i] *= scale\n                    r[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    return r * 0.99999999\n\ndef run_packing():\n    \"\"\"\n    Executing accelerated rigorous structural physics iterations maximizing dense area arrays safely correctly seamlessly properly fully perfectly.\n    \"\"\"\n    n = 26\n    candidates = []\n    \n    # Exploration structural mappings rapidly assessing spatial wells perfectly cleanly effectively strictly efficiently\n    for attempt in range(50):\n        np.random.seed(attempt * 707)\n        centers, radii = generate_diverse_seed(n, attempt)\n        if attempt > 0:\n            centers += np.random.uniform(-0.015, 0.015, (n, 2))\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        centers, radii = optimize_layout(\n            centers, radii, iters=4500, max_c=1e4, \n            start_lr=0.015, end_lr=0.001, add_noise=True\n        )\n        radii_valid = finalize_radii_lp(centers, radii)\n        score = float(np.sum(radii_valid))\n        candidates.append({\n            'score': score,\n            'centers': centers,\n            'radii': radii_valid\n        })\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Strict top configuration exploitation securely mapping final equilibrium exactly organically continuously\n    for i in range(min(10, len(candidates))):\n        cand = candidates[i]\n        c_init = cand['centers'].copy()\n        r_init = cand['radii'].copy()\n        \n        centers, radii = optimize_layout(\n            c_init, r_init, iters=18000, max_c=2e6, \n            start_lr=0.006, end_lr=1e-5, add_noise=False\n        )\n        \n        radii_valid = finalize_radii_lp(centers, radii)\n        s = float(np.sum(radii_valid))\n        \n        if s > best_sum:\n            best_sum = s\n            best_centers = centers.copy()\n            best_radii = radii_valid.copy()\n\n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END", "changes_description": null, "language": "python", "parent_id": "249d6b8e-4b77-4f75-8535-c0737c6a5c8a", "generation": 3, "timestamp": 1772001939.0500686, "iteration_found": 22, "metrics": {"validity": 1.0, "sum_radii": 2.618006399540526, "target_ratio": 0.9935508157649056, "combined_score": 0.9935508157649056, "radius_variance": 0.0064970037853264205, "spatial_spread": 0.18994348822703108, "eval_time": 40.98403573036194}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.6226049409053265, "target_ratio": 0.9952959927534447, "combined_score": 0.9952959927534447, "radius_variance": 0.005954515426716173, "spatial_spread": 0.18788158034949498, "eval_time": 41.06313920021057}, "island": 3}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9953\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.0000 \u2192 0.9953\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n41.06s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.622605/2.635 = 0.9953\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.5% of target value\n```\n\n### radius_stats\n```\nMin: 0.071926, Max: 0.143045, Avg: 0.100869\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6128, target_ratio: 0.9916, combined_score: 0.9916, radius_variance: 0.0064, spatial_spread: 0.1824, eval_time: 1.8823\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6226, target_ratio: 0.9953, combined_score: 0.9953, radius_variance: 0.0060, spatial_spread: 0.1879, eval_time: 41.0631\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9953)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef init_heuristic(n):\n    \"\"\"\n    Establish a heavily optimized 26-circle base heuristic layout to guarantee \n    an immediate deep-packing topological structure initialization to combat local traps.\n    \"\"\"\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Primary giant central seed\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Symmetrical inner interlocking ring of 7 \n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Asymmetrical staggered outer encasing ring of 12\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Exploitation slots dynamically placed at 4 primary extremes\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Central vertically elongated interstices filling mechanism\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    return centers, radii\n\n\ndef optimize_layout(centers, radii, iters, max_c, start_lr, end_lr, add_noise):\n    \"\"\"\n    Executes deep penalty-constrained geometric dynamics over the arrays natively \n    simulating unconstrained area-expansion forces interacting dynamically with overlaps bounds.\n    Utilizes exponential multi-start adaptive scaling via Custom Adam mapping mechanics.\n    \"\"\"\n    n = len(radii)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Standard 1st and 2nd momentum states\n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Iterative logarithmic scaling ensuring gradual structure settling smoothly locking rigid arrays\n        power = np.log10(max_c)\n        C = 1.0 * (10 ** (power * progress))\n        \n        # Computing pair distances optimally without creating self-interactive null traps \n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        # Pairwise overlap violations calculation continuously ensuring valid spatial arrangements natively\n        sum_radii_mat = radii[:, np.newaxis] + radii[np.newaxis, :]\n        O = np.maximum(0, sum_radii_mat - dist)\n        np.fill_diagonal(O, 0)\n        \n        # Enforcing stringent 1x1 boundary envelope mathematically matching precise limits explicitly\n        bx_L = np.maximum(0, radii - centers[:, 0])\n        bx_R = np.maximum(0, radii - (1 - centers[:, 0]))\n        by_B = np.maximum(0, radii - centers[:, 1])\n        by_T = np.maximum(0, radii - (1 - centers[:, 1]))\n        \n        # Baseline homogeneous positive objective derivative enforcing relentless radii enlargement forces universally\n        grad_r = -1.0 * np.ones(n)\n        grad_r += C * 2 * np.sum(O, axis=1)\n        grad_r += C * 2 * (bx_L + bx_R + by_B + by_T)\n        \n        grad_c = np.zeros_like(centers)\n        mask = dist < np.inf\n        inv_dist = np.zeros_like(dist)\n        inv_dist[mask] = 1.0 / np.maximum(dist[mask], 1e-8)\n        \n        # Dispersive repulsive dynamics calculation strictly moving coordinates countering overlap infractions linearly correctly \n        dir_ij = diff * inv_dist[..., np.newaxis]\n        overlap_dir = 2 * O[..., np.newaxis] * dir_ij\n        grad_c -= C * np.sum(overlap_dir, axis=1)\n        \n        # Lateral translation adjustments directly maintaining boundaries mathematically avoiding edges continuously seamlessly  \n        grad_c[:, 0] -= C * 2 * bx_L\n        grad_c[:, 0] += C * 2 * bx_R\n        grad_c[:, 1] -= C * 2 * by_B\n        grad_c[:, 1] += C * 2 * by_T\n        \n        # Thermal decay structural noise mechanism dynamically allowing escape locally maximizing final states fully comprehensively \n        if add_noise and step < iters // 2:\n            noise_scale = 50.0 * (1.0 - step / (iters // 2))\n            grad_c += np.random.normal(0, noise_scale, (n, 2))\n        \n        # Stabilized boundary logic averting explosive non-linearity \n        grad_c = np.clip(grad_c, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n        \n        # Exp-smoothing translation mechanics seamlessly handling step precision over immense gradient variation inherently\n        lr_ratio = end_lr / start_lr\n        current_lr = start_lr * (lr_ratio ** progress)\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** step)\n        v_hat_c = v_c / (1 - beta2 ** step)\n        centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        radii -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Geometric parameter stabilization locking values inside envelope securely \n        centers = np.clip(centers, 0, 1)\n        radii = np.maximum(radii, 0.002)\n\n    return centers, radii\n\n\ndef make_valid(centers, radii):\n    \"\"\"\n    Absolutely deterministic post-processing protocol to stringently assert \n    infinitesimally flawless evaluation overlap characteristics seamlessly flawlessly without breaking shapes rigidly.\n    \"\"\"\n    radii = np.copy(radii)\n    n = len(radii)\n    \n    # Guarantee outer perimeter structural confinement fully flawlessly explicitly rigorously\n    radii = np.minimum(radii, centers[:, 0])\n    radii = np.minimum(radii, 1 - centers[:, 0])\n    radii = np.minimum(radii, centers[:, 1])\n    radii = np.minimum(radii, 1 - centers[:, 1])\n    radii = np.maximum(radii, 0.0)\n    \n    # Successive hierarchical scaling inherently preventing mathematically microscopic invalidities safely resolving pairwise comprehensively\n    for _ in range(200):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = radii[i] + radii[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.99999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    # Sub-float universal scaling preventing mathematical engine drift issues securely fully optimally continuously\n    return radii * 0.99999999\n\n\ndef run_packing():\n    \"\"\"\n    Executing comprehensive 2-Phase geometric maximization solving explicitly identifying \n    density limits strictly over high iterations returning centers, radii seamlessly optimally correctly.\n\n    Returns:\n        Tuple: (centers (N, 2), radii (N,), sum_of_radii (float))\n    \"\"\"\n    n = 26\n    candidates = []\n    \n    # Exploration phase rigorously probing vast geometric initializations ensuring no local maxima effectively locks limits prematurely seamlessly comprehensively\n    for attempt in range(40):\n        np.random.seed(attempt * 100)\n        \n        if attempt == 0:\n            centers, radii = init_heuristic(n)\n            centers += np.random.uniform(-0.015, 0.015, (n, 2))\n        else:\n            centers = np.random.uniform(0.05, 0.95, (n, 2))\n            radii = np.full(n, 0.02)\n            # Impart diverse sizing to effectively decouple equal-scale lock mechanisms initially\n            radii[:5] = 0.08\n            radii[5:15] = 0.05\n\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        # Accelerated multi-start candidate testing \n        centers, radii = optimize_layout(\n            centers, radii, iters=5000, max_c=1e4, \n            start_lr=0.01, end_lr=0.001, add_noise=True\n        )\n        radii_valid = make_valid(centers, radii)\n        score = float(np.sum(radii_valid))\n        candidates.append({\n            'score': score,\n            'centers': centers,\n            'radii': radii_valid, \n            'seed': attempt\n        })\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Exploitation Polish comprehensively tightening perfectly evaluated structures resolving precisely entirely \n    for i in range(min(5, len(candidates))):\n        cand = candidates[i]\n        c_init = cand['centers'].copy()\n        r_init = cand['radii'].copy()\n        \n        # Focused profound Adam depth descent ensuring highest fidelity configurations accurately rigorously perfectly successfully\n        centers, radii = optimize_layout(\n            c_init, r_init, iters=15000, max_c=1e6, \n            start_lr=0.005, end_lr=1e-5, add_noise=False\n        )\n        \n        radii_valid = make_valid(centers, radii)\n        s = float(np.sum(radii_valid))\n        \n        if s > best_sum:\n            best_sum = s\n            best_centers = centers.copy()\n            best_radii = radii_valid.copy()\n\n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6226), Performs well on target_ratio (0.9953), Performs well on combined_score (0.9953), Performs well on radius_variance (0.0060), Performs well on spatial_spread (0.1879), Performs well on eval_time (41.0631)\n\n### Program 2 (Score: 0.9916)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers, radii_init=None):\n    \"\"\"\n    Compute the maximum possible radii for each circle position\n    such that they don't overlap and stay within the unit square.\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii_init: optional np.array of shape (n) providing starting radii guesses\n\n    Returns:\n        np.array of shape (n) with mathematically rigorous radii\n    \"\"\"\n    n = centers.shape[0]\n    bounds = np.zeros(n)\n    for i in range(n):\n        x, y = centers[i]\n        bounds[i] = min(x, y, 1.0 - x, 1.0 - y)\n\n    best_radii = None\n\n    try:\n        from scipy.optimize import linprog\n        import warnings\n        \n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(d)\n        \n        bounds_arr = [(0.0, b) for b in bounds]\n        \n        # Method 'highs' efficiently provides rigorously bounds-aligned answers \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds_arr, method='highs')\n            if res.success:\n                # Epsilon clearance guaranteeing no sub-float representation breaches \n                best_radii = np.clip(res.x - 1e-9, 0.0, bounds)\n    except Exception:\n        pass\n\n    # Ensure robust, perfect constraints purely in NumPy\n    if best_radii is not None:\n        radii = np.copy(best_radii)\n    elif radii_init is not None:\n        radii = np.copy(radii_init)\n        for i in range(n):\n            radii[i] = min(radii[i], bounds[i])\n    else:\n        radii = np.copy(bounds)\n        \n    for _ in range(5000):\n        max_overlap = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = radii[i] + radii[j] - dist\n                if ov > 1e-10:\n                    max_overlap = max(max_overlap, ov)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 1e-12:\n                        # Proportionally distribute tiny structural push aparts\n                        shrink_i = ov * (radii[i] / sum_r) + 1e-11\n                        shrink_j = ov * (radii[j] / sum_r) + 1e-11\n                        radii[i] = max(0.0, radii[i] - shrink_i)\n                        radii[j] = max(0.0, radii[j] - shrink_j)\n                        \n        if max_overlap < 1e-9:\n            break\n            \n    for i in range(n):\n        radii[i] = np.clip(radii[i], 0.0, bounds[i])\n        \n    return radii\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimal arrangement of 26 circles in a unit square\n    maximizing total radius via multi-start constrained physics Adam.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    np.random.seed(42)  # Secure stable pseudo-random geometric seed discovery\n    n = 26\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Executing several simulated parallel trials rapidly avoids sub-optima local wells\n    for attempt in range(4):\n        # 1. Initialization (Vogel's adapted golden ratio mappings out towards corners)\n        centers = np.zeros((n, 2))\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        exponent = 0.55 + 0.1 * attempt  # Test expanding out varied radial depths\n        \n        for i in range(n):\n            rad = np.sqrt(i + 0.5) / np.sqrt(n)\n            theta = 2.0 * np.pi * i / (phi ** 2.0) + attempt * 1.5\n            x = 0.5 + 0.45 * (rad ** exponent) * np.cos(theta)\n            y = 0.5 + 0.45 * (rad ** exponent) * np.sin(theta)\n            centers[i] = [x, y]\n            \n        centers += np.random.randn(n, 2) * 0.015\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        r = np.ones(n) * 0.05\n        \n        # 2. Relax geometry and scale parameters harmonically over ~3500 generations\n        lr = 0.006\n        beta1, beta2 = 0.9, 0.999\n        eps = 1e-8\n        m_c, v_c = np.zeros((n, 2)), np.zeros((n, 2))\n        m_r, v_r = np.zeros(n), np.zeros(n)\n        \n        num_steps = 3500\n        for step in range(1, num_steps + 1):\n            x = centers[:, 0]\n            y = centers[:, 1]\n            \n            # Subtle bias letting centers cultivate thicker geometric gaps than peripheral regions\n            dist_to_center = np.sqrt((x - 0.5)**2 + (y - 0.5)**2)\n            grad_r = -(1.0 + 0.1 * (0.5 - dist_to_center))\n            grad_c = np.zeros((n, 2))\n            \n            prog = step / float(num_steps)\n            lam = 40.0 * (1.0 + 9.0 * prog)  # Progressively ramp up violation weight metrics\n            \n            # Boundaries calculations isolating exterior clipping issues\n            bx1 = np.maximum(0, r - x)\n            bx2 = np.maximum(0, r - (1.0 - x))\n            by1 = np.maximum(0, r - y)\n            by2 = np.maximum(0, r - (1.0 - y))\n            \n            grad_r += lam * (bx1 + bx2 + by1 + by2)\n            grad_c[:, 0] -= lam * bx1\n            grad_c[:, 0] += lam * bx2\n            grad_c[:, 1] -= lam * by1\n            grad_c[:, 1] += lam * by2\n            \n            # Interstitial dynamics mitigating inner overlapping thresholds safely\n            dx = x[:, None] - x[None, :]\n            dy = y[:, None] - y[None, :]\n            dist_sq = dx**2 + dy**2\n            np.fill_diagonal(dist_sq, 1.0)\n            dist = np.sqrt(np.maximum(dist_sq, 1e-12))\n            \n            rad_sum = r[:, None] + r[None, :]\n            overlap = np.maximum(0, rad_sum - dist)\n            np.fill_diagonal(overlap, 0.0)\n            \n            grad_r += lam * np.sum(overlap, axis=1)\n            \n            mask = overlap > 0\n            factor = np.zeros_like(overlap)\n            factor[mask] = -lam * overlap[mask] / dist[mask]\n            \n            grad_c[:, 0] += np.sum(factor * dx, axis=1)\n            grad_c[:, 1] += np.sum(factor * dy, axis=1)\n            \n            # Micro-disturbances shake apart nested symmetrical alignments gracefully\n            if prog < 0.6:\n                noise_scale = 0.002 * (1.0 - prog / 0.6)\n                centers += np.random.randn(n, 2) * noise_scale\n                \n            m_c = beta1 * m_c + (1.0 - beta1) * grad_c\n            v_c = beta2 * v_c + (1.0 - beta2) * (grad_c**2)\n            m_hat_c = m_c / (1.0 - beta1**step)\n            v_hat_c = v_c / (1.0 - beta2**step)\n            \n            m_r = beta1 * m_r + (1.0 - beta1) * grad_r\n            v_r = beta2 * v_r + (1.0 - beta2) * (grad_r**2)\n            m_hat_r = m_r / (1.0 - beta1**step)\n            v_hat_r = v_r / (1.0 - beta2**step)\n            \n            # Simulated annealing decay settles the tight arrangements uniformly \n            current_lr = lr * (0.01 if prog > 0.8 else (1.0 - prog))\n            if current_lr < lr * 0.05:\n                current_lr = lr * 0.05\n                \n            centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n            r -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n            \n            centers = np.clip(centers, 0.001, 0.999)\n            r = np.clip(r, 0.001, 0.5)\n            \n        # 3. Impose mathematical rigour stripping all outstanding tiny constraint failures exactly\n        strict_radii = compute_max_radii(centers, radii_init=r)\n        current_sum = np.sum(strict_radii)\n        \n        # Capture superior global configuration from tested arrangements \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.copy(centers)\n            best_radii = np.copy(strict_radii)\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6128), Performs well on target_ratio (0.9916), Performs well on combined_score (0.9916), Performs well on radius_variance (0.0064), Performs well on spatial_spread (0.1824), Performs well on eval_time (1.8823)\n\n### Program 3 (Score: 0.0000)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii, using a simulated physical model.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    np.random.seed(42)  # Seed for reproducible random symmetrical breaking\n    \n    # Initialize arrays\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Heuristic Initialization: Bias towards centers and edges\n    # Central large circle\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Inner ring (7 circles)\n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Outer ring (12 circles)\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2  # Slight angle offset\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Four corners to fill gaps maximally\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Two additional circles to exploit largest interstices\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    # Break symmetry slightly to avoid saddle points\n    centers += np.random.uniform(-0.015, 0.015, (n, 2))\n    centers = np.clip(centers, 0.02, 0.98)\n    radii = np.clip(radii, 0.01, 0.5)\n\n    # Optimization using custom Adam optimizer with Penalty Method\n    iters = 3500\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    for step in range(1, iters + 1):\n        # Penalty multiplier grows exponentially to rigorously enforce non-overlap\n        C = 2.0 * (10 ** (4.0 * step / iters))\n        \n        # Calculate pair-wise distances efficiently\n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        # Calculate overlaps: O = max(0, r_i + r_j - dist)\n        sum_radii_mat = radii[:, np.newaxis] + radii[np.newaxis, :]\n        O = np.maximum(0, sum_radii_mat - dist)\n        np.fill_diagonal(O, 0)\n        \n        # Boundary violations\n        bx_L = np.maximum(0, radii - centers[:, 0])\n        bx_R = np.maximum(0, radii - (1 - centers[:, 0]))\n        by_B = np.maximum(0, radii - centers[:, 1])\n        by_T = np.maximum(0, radii - (1 - centers[:, 1]))\n        \n        # Accumulate gradients for radii\n        # Unconstrained push for radius maximization (-1.0 gradient)\n        grad_r = -1.0 * np.ones(n)\n        \n        # Gradient of overlaps w.r.t radii\n        grad_r += C * 2 * np.sum(O, axis=1)\n        \n        # Gradient of boundaries w.r.t radii\n        grad_r += C * 2 * (bx_L + bx_R + by_B + by_T)\n        \n        # Accumulate gradients for centers\n        grad_c = np.zeros_like(centers)\n        \n        # Inverse distance for stable division, ignoring diagonals\n        mask = dist < np.inf\n        inv_dist = np.zeros_like(dist)\n        inv_dist[mask] = 1.0 / np.maximum(dist[mask], 1e-8)\n        \n        # Gradient of overlaps w.r.t centers\n        dir_ij = diff * inv_dist[..., np.newaxis]\n        overlap_dir = 2 * O[..., np.newaxis] * dir_ij\n        grad_c -= C * np.sum(overlap_dir, axis=1)\n        \n        # Gradient of boundaries w.r.t centers\n        grad_c[:, 0] -= C * 2 * bx_L\n        grad_c[:, 0] += C * 2 * bx_R\n        grad_c[:, 1] -= C * 2 * by_B\n        grad_c[:, 1] += C * 2 * by_T\n        \n        # Gradient clipping to stabilize initially wild penalty landscapes\n        grad_c = np.clip(grad_c, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n\n        # Decaying learning rate for fine-grained equilibrium discovery\n        current_lr = 0.01 * (0.1 ** (step / iters))\n        \n        # Adam step for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** step)\n        v_hat_c = v_c / (1 - beta2 ** step)\n        centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n        \n        # Adam step for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        radii -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Domain bounds safely handled during optimization\n        centers = np.clip(centers, 0, 1)\n        radii = np.maximum(radii, 0.001)\n\n    # Post-process for absolute rigorous mathematical validity\n    radii = make_valid(centers, radii)\n    sum_radii = float(np.sum(radii))\n    \n    return centers, radii, sum_radii\n\n\ndef make_valid(centers, radii):\n    \"\"\"\n    Ensure the configuration perfectly satisfies bounds and overlap rules \n    via iterative deterministic constraint resolution.\n\n    Args:\n        centers: np.array of shape (n, 2)\n        radii: np.array of shape (n)\n\n    Returns:\n        np.array of validated shape (n) with radii perfectly conforming\n    \"\"\"\n    n = len(radii)\n    # Shrink to boundaries securely\n    for i in range(n):\n        x, y = centers[i]\n        radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n    \n    # Resolve any microscopically scaled overlaps securely\n    # Since operations shrink items dynamically, it stabilizes efficiently \n    # without risk of newly generating broken overlaps on previously checked targets.\n    for _ in range(50):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = radii[i] + radii[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    return radii\n\n# EVOLVE-BLOCK-END\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct a highly optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii, using a simulated physical model.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    n = 26\n    np.random.seed(42)  # Seed for reproducible random symmetrical breaking\n    \n    # Initialize arrays\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Heuristic Initialization: Bias towards centers and edges\n    # Central large circle\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Inner ring (7 circles)\n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Outer ring (12 circles)\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2  # Slight angle offset\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Four corners to fill gaps maximally\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Two additional circles to exploit largest interstices\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    # Break symmetry slightly to avoid saddle points\n    centers += np.random.uniform(-0.015, 0.015, (n, 2))\n    centers = np.clip(centers, 0.02, 0.98)\n    radii = np.clip(radii, 0.01, 0.5)\n\n    # Optimization using custom Adam optimizer with Penalty Method\n    iters = 3500\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n    \n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    for step in range(1, iters + 1):\n        # Penalty multiplier grows exponentially to rigorously enforce non-overlap\n        C = 2.0 * (10 ** (4.0 * step / iters))\n        \n        # Calculate pair-wise distances efficiently\n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        # Calculate overlaps: O = max(0, r_i + r_j - dist)\n        sum_radii_mat = radii[:, np.newaxis] + radii[np.newaxis, :]\n        O = np.maximum(0, sum_radii_mat - dist)\n        np.fill_diagonal(O, 0)\n        \n        # Boundary violations\n        bx_L = np.maximum(0, radii - centers[:, 0])\n        bx_R = np.maximum(0, radii - (1 - centers[:, 0]))\n        by_B = np.maximum(0, radii - centers[:, 1])\n        by_T = np.maximum(0, radii - (1 - centers[:, 1]))\n        \n        # Accumulate gradients for radii\n        # Unconstrained push for radius maximization (-1.0 gradient)\n        grad_r = -1.0 * np.ones(n)\n        \n        # Gradient of overlaps w.r.t radii\n        grad_r += C * 2 * np.sum(O, axis=1)\n        \n        # Gradient of boundaries w.r.t radii\n        grad_r += C * 2 * (bx_L + bx_R + by_B + by_T)\n        \n        # Accumulate gradients for centers\n        grad_c = np.zeros_like(centers)\n        \n        # Inverse distance for stable division, ignoring diagonals\n        mask = dist < np.inf\n        inv_dist = np.zeros_like(dist)\n        inv_dist[mask] = 1.0 / np.maximum(dist[mask], 1e-8)\n        \n        # Gradient of overlaps w.r.t centers\n        dir_ij = diff * inv_dist[..., np.newaxis]\n        overlap_dir = 2 * O[..., np.newaxis] * dir_ij\n        grad_c -= C * np.sum(overlap_dir, axis=1)\n        \n        # Gradient of boundaries w.r.t centers\n        grad_c[:, 0] -= C * 2 * bx_L\n        grad_c[:, 0] += C * 2 * bx_R\n        grad_c[:, 1] -= C * 2 * by_B\n        grad_c[:, 1] += C * 2 * by_T\n        \n        # Gradient clipping to stabilize initially wild penalty landscapes\n        grad_c = np.clip(grad_c, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n\n        # Decaying learning rate for fine-grained equilibrium discovery\n        current_lr = 0.01 * (0.1 ** (step / iters))\n        \n        # Adam step for centers\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** step)\n        v_hat_c = v_c / (1 - beta2 ** step)\n        centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n        \n        # Adam step for radii\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        radii -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Domain bounds safely handled during optimization\n        centers = np.clip(centers, 0, 1)\n        radii = np.maximum(radii, 0.001)\n\n    # Post-process for absolute rigorous mathematical validity\n    radii = make_valid(centers, radii)\n    sum_radii = float(np.sum(radii))\n    \n    return centers, radii, sum_radii\n\n\ndef make_valid(centers, radii):\n    \"\"\"\n    Ensure the configuration perfectly satisfies bounds and overlap rules \n    via iterative deterministic constraint resolution.\n\n    Args:\n        centers: np.array of shape (n, 2)\n        radii: np.array of shape (n)\n\n    Returns:\n        np.array of validated shape (n) with radii perfectly conforming\n    \"\"\"\n    n = len(radii)\n    # Shrink to boundaries securely\n    for i in range(n):\n        x, y = centers[i]\n        radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n    \n    # Resolve any microscopically scaled overlaps securely\n    # Since operations shrink items dynamically, it stabilizes efficiently \n    # without risk of newly generating broken overlaps on previously checked targets.\n    for _ in range(50):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = radii[i] + radii[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    return radii\n\n# EVOLVE-BLOCK-END\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9916, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef compute_max_radii(centers, radii_init=None):\n    \"\"\"\n    Compute the maximum possible radii for each circle position\n    such that they don't overlap and stay within the unit square.\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii_init: optional np.array of shape (n) providing starting radii guesses\n\n    Returns:\n        np.array of shape (n) with mathematically rigorous radii\n    \"\"\"\n    n = centers.shape[0]\n    bounds = np.zeros(n)\n    for i in range(n):\n        x, y = centers[i]\n        bounds[i] = min(x, y, 1.0 - x, 1.0 - y)\n\n    best_radii = None\n\n    try:\n        from scipy.optimize import linprog\n        import warnings\n        \n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                d = np.linalg.norm(centers[i] - centers[j])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(d)\n        \n        bounds_arr = [(0.0, b) for b in bounds]\n        \n        # Method 'highs' efficiently provides rigorously bounds-aligned answers \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds_arr, method='highs')\n            if res.success:\n                # Epsilon clearance guaranteeing no sub-float representation breaches \n                best_radii = np.clip(res.x - 1e-9, 0.0, bounds)\n    except Exception:\n        pass\n\n    # Ensure robust, perfect constraints purely in NumPy\n    if best_radii is not None:\n        radii = np.copy(best_radii)\n    elif radii_init is not None:\n        radii = np.copy(radii_init)\n        for i in range(n):\n            radii[i] = min(radii[i], bounds[i])\n    else:\n        radii = np.copy(bounds)\n        \n    for _ in range(5000):\n        max_overlap = 0.0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                ov = radii[i] + radii[j] - dist\n                if ov > 1e-10:\n                    max_overlap = max(max_overlap, ov)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 1e-12:\n                        # Proportionally distribute tiny structural push aparts\n                        shrink_i = ov * (radii[i] / sum_r) + 1e-11\n                        shrink_j = ov * (radii[j] / sum_r) + 1e-11\n                        radii[i] = max(0.0, radii[i] - shrink_i)\n                        radii[j] = max(0.0, radii[j] - shrink_j)\n                        \n        if max_overlap < 1e-9:\n            break\n            \n    for i in range(n):\n        radii[i] = np.clip(radii[i], 0.0, bounds[i])\n        \n    return radii\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimal arrangement of 26 circles in a unit square\n    maximizing total radius via multi-start constrained physics Adam.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n    \"\"\"\n    np.random.seed(42)  # Secure stable pseudo-random geometric seed discovery\n    n = 26\n    \n    best_centers = None\n    best_radii = None\n    best_sum = -1.0\n    \n    # Executing several simulated parallel trials rapidly avoids sub-optima local wells\n    for attempt in range(4):\n        # 1. Initialization (Vogel's adapted golden ratio mappings out towards corners)\n        centers = np.zeros((n, 2))\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        exponent = 0.55 + 0.1 * attempt  # Test expanding out varied radial depths\n        \n        for i in range(n):\n            rad = np.sqrt(i + 0.5) / np.sqrt(n)\n            theta = 2.0 * np.pi * i / (phi ** 2.0) + attempt * 1.5\n            x = 0.5 + 0.45 * (rad ** exponent) * np.cos(theta)\n            y = 0.5 + 0.45 * (rad ** exponent) * np.sin(theta)\n            centers[i] = [x, y]\n            \n        centers += np.random.randn(n, 2) * 0.015\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        r = np.ones(n) * 0.05\n        \n        # 2. Relax geometry and scale parameters harmonically over ~3500 generations\n        lr = 0.006\n        beta1, beta2 = 0.9, 0.999\n        eps = 1e-8\n        m_c, v_c = np.zeros((n, 2)), np.zeros((n, 2))\n        m_r, v_r = np.zeros(n), np.zeros(n)\n        \n        num_steps = 3500\n        for step in range(1, num_steps + 1):\n            x = centers[:, 0]\n            y = centers[:, 1]\n            \n            # Subtle bias letting centers cultivate thicker geometric gaps than peripheral regions\n            dist_to_center = np.sqrt((x - 0.5)**2 + (y - 0.5)**2)\n            grad_r = -(1.0 + 0.1 * (0.5 - dist_to_center))\n            grad_c = np.zeros((n, 2))\n            \n            prog = step / float(num_steps)\n            lam = 40.0 * (1.0 + 9.0 * prog)  # Progressively ramp up violation weight metrics\n            \n            # Boundaries calculations isolating exterior clipping issues\n            bx1 = np.maximum(0, r - x)\n            bx2 = np.maximum(0, r - (1.0 - x))\n            by1 = np.maximum(0, r - y)\n            by2 = np.maximum(0, r - (1.0 - y))\n            \n            grad_r += lam * (bx1 + bx2 + by1 + by2)\n            grad_c[:, 0] -= lam * bx1\n            grad_c[:, 0] += lam * bx2\n            grad_c[:, 1] -= lam * by1\n            grad_c[:, 1] += lam * by2\n            \n            # Interstitial dynamics mitigating inner overlapping thresholds safely\n            dx = x[:, None] - x[None, :]\n            dy = y[:, None] - y[None, :]\n            dist_sq = dx**2 + dy**2\n            np.fill_diagonal(dist_sq, 1.0)\n            dist = np.sqrt(np.maximum(dist_sq, 1e-12))\n            \n            rad_sum = r[:, None] + r[None, :]\n            overlap = np.maximum(0, rad_sum - dist)\n            np.fill_diagonal(overlap, 0.0)\n            \n            grad_r += lam * np.sum(overlap, axis=1)\n            \n            mask = overlap > 0\n            factor = np.zeros_like(overlap)\n            factor[mask] = -lam * overlap[mask] / dist[mask]\n            \n            grad_c[:, 0] += np.sum(factor * dx, axis=1)\n            grad_c[:, 1] += np.sum(factor * dy, axis=1)\n            \n            # Micro-disturbances shake apart nested symmetrical alignments gracefully\n            if prog < 0.6:\n                noise_scale = 0.002 * (1.0 - prog / 0.6)\n                centers += np.random.randn(n, 2) * noise_scale\n                \n            m_c = beta1 * m_c + (1.0 - beta1) * grad_c\n            v_c = beta2 * v_c + (1.0 - beta2) * (grad_c**2)\n            m_hat_c = m_c / (1.0 - beta1**step)\n            v_hat_c = v_c / (1.0 - beta2**step)\n            \n            m_r = beta1 * m_r + (1.0 - beta1) * grad_r\n            v_r = beta2 * v_r + (1.0 - beta2) * (grad_r**2)\n            m_hat_r = m_r / (1.0 - beta1**step)\n            v_hat_r = v_r / (1.0 - beta2**step)\n            \n            # Simulated annealing decay settles the tight arrangements uniformly \n            current_lr = lr * (0.01 if prog > 0.8 else (1.0 - prog))\n            if current_lr < lr * 0.05:\n                current_lr = lr * 0.05\n                \n            centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n            r -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n            \n            centers = np.clip(centers, 0.001, 0.999)\n            r = np.clip(r, 0.001, 0.5)\n            \n        # 3. Impose mathematical rigour stripping all outstanding tiny constraint failures exactly\n        strict_radii = compute_max_radii(centers, radii_init=r)\n        current_sum = np.sum(strict_radii)\n        \n        # Capture superior global configuration from tested arrangements \n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = np.copy(centers)\n            best_radii = np.copy(strict_radii)\n            \n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef init_heuristic(n):\n    \"\"\"\n    Establish a heavily optimized 26-circle base heuristic layout to guarantee \n    an immediate deep-packing topological structure initialization to combat local traps.\n    \"\"\"\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Primary giant central seed\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Symmetrical inner interlocking ring of 7 \n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Asymmetrical staggered outer encasing ring of 12\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Exploitation slots dynamically placed at 4 primary extremes\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Central vertically elongated interstices filling mechanism\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    return centers, radii\n\n\ndef optimize_layout(centers, radii, iters, max_c, start_lr, end_lr, add_noise):\n    \"\"\"\n    Executes deep penalty-constrained geometric dynamics over the arrays natively \n    simulating unconstrained area-expansion forces interacting dynamically with overlaps bounds.\n    Utilizes exponential multi-start adaptive scaling via Custom Adam mapping mechanics.\n    \"\"\"\n    n = len(radii)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Standard 1st and 2nd momentum states\n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n    \n    for step in range(1, iters + 1):\n        progress = step / iters\n        \n        # Iterative logarithmic scaling ensuring gradual structure settling smoothly locking rigid arrays\n        power = np.log10(max_c)\n        C = 1.0 * (10 ** (power * progress))\n        \n        # Computing pair distances optimally without creating self-interactive null traps \n        diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        np.fill_diagonal(dist, np.inf)\n        \n        # Pairwise overlap violations calculation continuously ensuring valid spatial arrangements natively\n        sum_radii_mat = radii[:, np.newaxis] + radii[np.newaxis, :]\n        O = np.maximum(0, sum_radii_mat - dist)\n        np.fill_diagonal(O, 0)\n        \n        # Enforcing stringent 1x1 boundary envelope mathematically matching precise limits explicitly\n        bx_L = np.maximum(0, radii - centers[:, 0])\n        bx_R = np.maximum(0, radii - (1 - centers[:, 0]))\n        by_B = np.maximum(0, radii - centers[:, 1])\n        by_T = np.maximum(0, radii - (1 - centers[:, 1]))\n        \n        # Baseline homogeneous positive objective derivative enforcing relentless radii enlargement forces universally\n        grad_r = -1.0 * np.ones(n)\n        grad_r += C * 2 * np.sum(O, axis=1)\n        grad_r += C * 2 * (bx_L + bx_R + by_B + by_T)\n        \n        grad_c = np.zeros_like(centers)\n        mask = dist < np.inf\n        inv_dist = np.zeros_like(dist)\n        inv_dist[mask] = 1.0 / np.maximum(dist[mask], 1e-8)\n        \n        # Dispersive repulsive dynamics calculation strictly moving coordinates countering overlap infractions linearly correctly \n        dir_ij = diff * inv_dist[..., np.newaxis]\n        overlap_dir = 2 * O[..., np.newaxis] * dir_ij\n        grad_c -= C * np.sum(overlap_dir, axis=1)\n        \n        # Lateral translation adjustments directly maintaining boundaries mathematically avoiding edges continuously seamlessly  \n        grad_c[:, 0] -= C * 2 * bx_L\n        grad_c[:, 0] += C * 2 * bx_R\n        grad_c[:, 1] -= C * 2 * by_B\n        grad_c[:, 1] += C * 2 * by_T\n        \n        # Thermal decay structural noise mechanism dynamically allowing escape locally maximizing final states fully comprehensively \n        if add_noise and step < iters // 2:\n            noise_scale = 50.0 * (1.0 - step / (iters // 2))\n            grad_c += np.random.normal(0, noise_scale, (n, 2))\n        \n        # Stabilized boundary logic averting explosive non-linearity \n        grad_c = np.clip(grad_c, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n        \n        # Exp-smoothing translation mechanics seamlessly handling step precision over immense gradient variation inherently\n        lr_ratio = end_lr / start_lr\n        current_lr = start_lr * (lr_ratio ** progress)\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** step)\n        v_hat_c = v_c / (1 - beta2 ** step)\n        centers -= current_lr * m_hat_c / (np.sqrt(v_hat_c) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        radii -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        # Geometric parameter stabilization locking values inside envelope securely \n        centers = np.clip(centers, 0, 1)\n        radii = np.maximum(radii, 0.002)\n\n    return centers, radii\n\n\ndef make_valid(centers, radii):\n    \"\"\"\n    Absolutely deterministic post-processing protocol to stringently assert \n    infinitesimally flawless evaluation overlap characteristics seamlessly flawlessly without breaking shapes rigidly.\n    \"\"\"\n    radii = np.copy(radii)\n    n = len(radii)\n    \n    # Guarantee outer perimeter structural confinement fully flawlessly explicitly rigorously\n    radii = np.minimum(radii, centers[:, 0])\n    radii = np.minimum(radii, 1 - centers[:, 0])\n    radii = np.minimum(radii, centers[:, 1])\n    radii = np.minimum(radii, 1 - centers[:, 1])\n    radii = np.maximum(radii, 0.0)\n    \n    # Successive hierarchical scaling inherently preventing mathematically microscopic invalidities safely resolving pairwise comprehensively\n    for _ in range(200):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = radii[i] + radii[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.99999999\n                    radii[i] *= scale\n                    radii[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    # Sub-float universal scaling preventing mathematical engine drift issues securely fully optimally continuously\n    return radii * 0.99999999\n\n\ndef run_packing():\n    \"\"\"\n    Executing comprehensive 2-Phase geometric maximization solving explicitly identifying \n    density limits strictly over high iterations returning centers, radii seamlessly optimally correctly.\n\n    Returns:\n        Tuple: (centers (N, 2), radii (N,), sum_of_radii (float))\n    \"\"\"\n    n = 26\n    candidates = []\n    \n    # Exploration phase rigorously probing vast geometric initializations ensuring no local maxima effectively locks limits prematurely seamlessly comprehensively\n    for attempt in range(40):\n        np.random.seed(attempt * 100)\n        \n        if attempt == 0:\n            centers, radii = init_heuristic(n)\n            centers += np.random.uniform(-0.015, 0.015, (n, 2))\n        else:\n            centers = np.random.uniform(0.05, 0.95, (n, 2))\n            radii = np.full(n, 0.02)\n            # Impart diverse sizing to effectively decouple equal-scale lock mechanisms initially\n            radii[:5] = 0.08\n            radii[5:15] = 0.05\n\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        # Accelerated multi-start candidate testing \n        centers, radii = optimize_layout(\n            centers, radii, iters=5000, max_c=1e4, \n            start_lr=0.01, end_lr=0.001, add_noise=True\n        )\n        radii_valid = make_valid(centers, radii)\n        score = float(np.sum(radii_valid))\n        candidates.append({\n            'score': score,\n            'centers': centers,\n            'radii': radii_valid, \n            'seed': attempt\n        })\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Exploitation Polish comprehensively tightening perfectly evaluated structures resolving precisely entirely \n    for i in range(min(5, len(candidates))):\n        cand = candidates[i]\n        c_init = cand['centers'].copy()\n        r_init = cand['radii'].copy()\n        \n        # Focused profound Adam depth descent ensuring highest fidelity configurations accurately rigorously perfectly successfully\n        centers, radii = optimize_layout(\n            c_init, r_init, iters=15000, max_c=1e6, \n            start_lr=0.005, end_lr=1e-5, add_noise=False\n        )\n        \n        radii_valid = make_valid(centers, radii)\n        s = float(np.sum(radii_valid))\n        \n        if s > best_sum:\n            best_sum = s\n            best_centers = centers.copy()\n            best_radii = radii_valid.copy()\n\n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative circle packing optimization for n=26 circles\"\"\"\nimport numpy as np\n\ndef init_heuristic(n):\n    \"\"\"Establish a deeply structured base heuristic layout targeting known dense topological forms.\"\"\"\n    centers = np.zeros((n, 2))\n    radii = np.zeros(n)\n    \n    # Primary central giant seed\n    centers[0] = [0.5, 0.5]\n    radii[0] = 0.15\n    \n    # Symmetric inner interlocking ring\n    for i in range(7):\n        angle = 2 * np.pi * i / 7\n        centers[i + 1] = [0.5 + 0.22 * np.cos(angle), 0.5 + 0.22 * np.sin(angle)]\n        radii[i + 1] = 0.1\n        \n    # Asymmetric outer enveloping ring\n    for i in range(12):\n        angle = 2 * np.pi * i / 12 + 0.2\n        centers[i + 8] = [0.5 + 0.4 * np.cos(angle), 0.5 + 0.4 * np.sin(angle)]\n        radii[i + 8] = 0.07\n        \n    # Exploitation points at extreme structural boundaries\n    corners = [[0.05, 0.05], [0.05, 0.95], [0.95, 0.05], [0.95, 0.95]]\n    for i in range(4):\n        centers[i + 20] = corners[i]\n        radii[i + 20] = 0.05\n        \n    # Vertical spatial gap filler points dynamically\n    centers[24] = [0.5, 0.15]\n    radii[24] = 0.05\n    centers[25] = [0.5, 0.85]\n    radii[25] = 0.05\n    \n    return centers, radii\n\ndef generate_diverse_seed(n, attempt):\n    \"\"\"Procedurally emit robust and globally distributed configuration sets mathematically mapping bounds spaces extensively.\"\"\"\n    if attempt == 0:\n        return init_heuristic(n)\n        \n    centers = np.zeros((n, 2))\n    radii = np.full(n, 0.05)\n    \n    if attempt < 15:\n        # Vogel Golden-Spiral alignments expanding varied compactness metrics continuously\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        exponent = 0.40 + 0.02 * attempt\n        for i in range(n):\n            rad = np.sqrt(i + 0.5) / np.sqrt(n)\n            theta = 2.0 * np.pi * i / (phi ** 2.0) + attempt * 0.7\n            centers[i, 0] = 0.5 + 0.4 * (rad ** exponent) * np.cos(theta)\n            centers[i, 1] = 0.5 + 0.4 * (rad ** exponent) * np.sin(theta)\n            radii[i] = 0.03 + 0.06 * (1.0 - rad)\n            \n    elif attempt < 25:\n        # Concentric rigid ring systems establishing deep symmetries initially mapped\n        centers[0] = [0.5, 0.5]\n        radii[0] = 0.12\n        counts = [6, 11, 8]\n        idx = 1\n        for ring, count in enumerate(counts):\n            r_dist = 0.17 * (ring + 1)\n            for j in range(count):\n                if idx < n:\n                    angle = 2 * np.pi * j / count + attempt * 0.5\n                    centers[idx, 0] = 0.5 + r_dist * np.cos(angle)\n                    centers[idx, 1] = 0.5 + r_dist * np.sin(angle)\n                    radii[idx] = 0.09 - 0.02 * ring\n                    idx += 1\n                    \n    elif attempt < 35:\n        # Hex-lattice rectangular structural mappings completely fully evenly evenly dispersed efficiently\n        cols, rows = 5, 6\n        idx = 0\n        spacing_x = 0.8 / (cols - 0.5)\n        spacing_y = 0.8 / (rows - 1.0)\n        for r in range(rows):\n            for c in range(cols):\n                if idx < n:\n                    offset = (r % 2) * 0.5\n                    centers[idx, 0] = 0.1 + ((c + offset) * spacing_x)\n                    centers[idx, 1] = 0.1 + (r * spacing_y)\n                    radii[idx] = 0.06\n                    idx += 1\n    else:\n        # Full uniform thermal stochastic structural distributions spanning wide initial conditions reliably perfectly effectively safely\n        centers = np.random.uniform(0.05, 0.95, (n, 2))\n        radii[:6] = np.random.uniform(0.1, 0.14, 6)\n        radii[6:16] = np.random.uniform(0.06, 0.1, 10)\n        radii[16:] = np.random.uniform(0.03, 0.06, 10)\n        \n    return centers, radii\n\ndef optimize_layout(centers, radii, iters, max_c, start_lr, end_lr, add_noise):\n    \"\"\"\n    Deep constrained natively unrolled and physics dynamically optimizing Adam loop.\n    Re-written iteratively accelerating linear arrays strictly comprehensively bypassing numpy overhead dynamically natively comprehensively securely smoothly perfectly!\n    \"\"\"\n    n = len(radii)\n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    m_c_x, v_c_x = np.zeros(n), np.zeros(n)\n    m_c_y, v_c_y = np.zeros(n), np.zeros(n)\n    m_r, v_r = np.zeros(n), np.zeros(n)\n    \n    c_x = np.copy(centers[:, 0])\n    c_y = np.copy(centers[:, 1])\n    r = np.copy(radii)\n    \n    power = np.log10(max_c)\n    lr_ratio = end_lr / start_lr\n\n    for step in range(1, iters + 1):\n        progress = step / float(iters)\n        C = float(10 ** (power * progress))\n        C_2 = C * 2.0\n        \n        dx = c_x[:, None] - c_x[None, :]\n        dy = c_y[:, None] - c_y[None, :]\n        \n        dist_sq = dx**2 + dy**2\n        np.fill_diagonal(dist_sq, np.inf)\n        dist = np.sqrt(dist_sq)\n        \n        sum_r = r[:, None] + r[None, :]\n        O = sum_r - dist\n        O = np.maximum(0.0, O) \n        \n        bx_L = np.maximum(0.0, r - c_x)\n        bx_R = np.maximum(0.0, r - (1.0 - c_x))\n        by_B = np.maximum(0.0, r - c_y)\n        by_T = np.maximum(0.0, r - (1.0 - c_y))\n        \n        current_bias = 0.1 * (1.0 - progress)\n        dist_c = np.sqrt((c_x - 0.5)**2 + (c_y - 0.5)**2)\n        grad_r = -(1.0 + current_bias * np.maximum(0.0, 0.4 - dist_c))\n        grad_r += C_2 * np.sum(O, axis=1) + C_2 * (bx_L + bx_R + by_B + by_T)\n        \n        inv_dist = 1.0 / dist\n        O_scaled = (C_2 * O) * inv_dist\n        \n        grad_c_x = -np.sum(O_scaled * dx, axis=1)\n        grad_c_y = -np.sum(O_scaled * dy, axis=1)\n        \n        grad_c_x += C_2 * (-bx_L + bx_R)\n        grad_c_y += C_2 * (-by_B + by_T)\n        \n        if add_noise and step < iters // 2:\n            noise_scale = 40.0 * (1.0 - step / (iters // 2))\n            grad_c_x += np.random.normal(0.0, noise_scale, size=n)\n            grad_c_y += np.random.normal(0.0, noise_scale, size=n)\n            \n        grad_c_x = np.clip(grad_c_x, -1000.0, 1000.0)\n        grad_c_y = np.clip(grad_c_y, -1000.0, 1000.0)\n        grad_r = np.clip(grad_r, -1000.0, 1000.0)\n        \n        current_lr = start_lr * (lr_ratio ** progress)\n        \n        m_c_x = beta1 * m_c_x + (1 - beta1) * grad_c_x\n        v_c_x = beta2 * v_c_x + (1 - beta2) * (grad_c_x ** 2)\n        m_hat_c_x = m_c_x / (1 - beta1 ** step)\n        v_hat_c_x = v_c_x / (1 - beta2 ** step)\n        c_x -= current_lr * m_hat_c_x / (np.sqrt(v_hat_c_x) + eps)\n        \n        m_c_y = beta1 * m_c_y + (1 - beta1) * grad_c_y\n        v_c_y = beta2 * v_c_y + (1 - beta2) * (grad_c_y ** 2)\n        m_hat_c_y = m_c_y / (1 - beta1 ** step)\n        v_hat_c_y = v_c_y / (1 - beta2 ** step)\n        c_y -= current_lr * m_hat_c_y / (np.sqrt(v_hat_c_y) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** step)\n        v_hat_r = v_r / (1 - beta2 ** step)\n        r -= current_lr * m_hat_r / (np.sqrt(v_hat_r) + eps)\n        \n        np.clip(c_x, 0.0, 1.0, out=c_x)\n        np.clip(c_y, 0.0, 1.0, out=c_y)\n        np.maximum(r, 0.002, out=r)\n        \n    final_centers = np.column_stack((c_x, c_y))\n    return final_centers, r\n\ndef finalize_radii_lp(centers, initial_radii=None):\n    \"\"\"\n    Absolutely deterministic structurally unconstrained mathematical rigorous radii scaling comprehensively smoothly optimizing directly \n    solving strict internal gaps cleanly natively fully using highly robust Linear Programming.\n    \"\"\"\n    import warnings\n    \n    n = len(centers)\n    bounds = np.zeros(n)\n    for i in range(n):\n        x, y = centers[i]\n        bounds[i] = min(x, y, 1.0 - x, 1.0 - y)\n        \n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub, b_ub = [], []\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                dist_safe = max(0.0, dist - 1e-12)\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_safe)\n                \n        bounds_arr = [(0.0, b) for b in bounds]\n        \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds_arr, method='highs')\n            \n        if res.success:\n            r = np.clip(res.x, 0.0, bounds)\n            for _ in range(50):\n                max_ov = 0.0\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        d = np.linalg.norm(centers[i] - centers[j])\n                        sum_r = r[i] + r[j]\n                        if sum_r > d:\n                            max_ov = max(max_ov, sum_r - d)\n                            scale = (d / sum_r) * 0.99999999\n                            r[i] *= scale\n                            r[j] *= scale\n                if max_ov < 1e-13:\n                    break\n            return r * 0.99999999\n    except Exception:\n        pass\n        \n    r = np.copy(initial_radii) if initial_radii is not None else np.copy(bounds)\n    r = np.minimum(r, centers[:, 0])\n    r = np.minimum(r, 1 - centers[:, 0])\n    r = np.minimum(r, centers[:, 1])\n    r = np.minimum(r, 1 - centers[:, 1])\n    r = np.maximum(r, 0.0)\n    for _ in range(200):\n        overlaps = False\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                sum_r = r[i] + r[j]\n                if sum_r > dist:\n                    scale = (dist / sum_r) * 0.99999999\n                    r[i] *= scale\n                    r[j] *= scale\n                    overlaps = True\n        if not overlaps:\n            break\n            \n    return r * 0.99999999\n\ndef run_packing():\n    \"\"\"\n    Executing accelerated rigorous structural physics iterations maximizing dense area arrays safely correctly seamlessly properly fully perfectly.\n    \"\"\"\n    n = 26\n    candidates = []\n    \n    # Exploration structural mappings rapidly assessing spatial wells perfectly cleanly effectively strictly efficiently\n    for attempt in range(50):\n        np.random.seed(attempt * 707)\n        centers, radii = generate_diverse_seed(n, attempt)\n        if attempt > 0:\n            centers += np.random.uniform(-0.015, 0.015, (n, 2))\n        centers = np.clip(centers, 0.02, 0.98)\n        \n        centers, radii = optimize_layout(\n            centers, radii, iters=4500, max_c=1e4, \n            start_lr=0.015, end_lr=0.001, add_noise=True\n        )\n        radii_valid = finalize_radii_lp(centers, radii)\n        score = float(np.sum(radii_valid))\n        candidates.append({\n            'score': score,\n            'centers': centers,\n            'radii': radii_valid\n        })\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    \n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n    \n    # Strict top configuration exploitation securely mapping final equilibrium exactly organically continuously\n    for i in range(min(10, len(candidates))):\n        cand = candidates[i]\n        c_init = cand['centers'].copy()\n        r_init = cand['radii'].copy()\n        \n        centers, radii = optimize_layout(\n            c_init, r_init, iters=18000, max_c=2e6, \n            start_lr=0.006, end_lr=1e-5, add_noise=False\n        )\n        \n        radii_valid = finalize_radii_lp(centers, radii)\n        s = float(np.sum(radii_valid))\n        \n        if s > best_sum:\n            best_sum = s\n            best_centers = centers.copy()\n            best_radii = radii_valid.copy()\n\n    return best_centers, best_radii, best_sum\n# EVOLVE-BLOCK-END"]}}, "artifacts_json": "{\"execution_time\": \"40.98s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.618006/2.635 = 0.9936\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.4% of target value\", \"radius_stats\": \"Min: 0.070596, Max: 0.142053, Avg: 0.100693\"}", "artifact_dir": null, "embedding": null}