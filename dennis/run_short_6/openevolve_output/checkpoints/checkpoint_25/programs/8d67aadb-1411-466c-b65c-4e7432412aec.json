{"id": "8d67aadb-1411-466c-b65c-4e7432412aec", "code": "# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to maximize the summation of their radii by using batched Adam\n    optimization with physics-based overlapping constraints.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) fitting in the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    n = 26\n    B = 80  # Simulate 80 batched topological arrangements simultaneously\n    np.random.seed(42)  # Strict determinism\n\n    centers = np.zeros((B, n, 2))\n    radii = np.zeros((B, n))\n\n    for i in range(B):\n        mode = i % 5\n        if mode == 0:\n            # Vogel spiral distribution mapping\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for j in range(n):\n                r_spiral = np.sqrt((j + 0.5) / n) * 0.45\n                centers[i, j, 0] = 0.5 + r_spiral * np.cos(j * phi)\n                centers[i, j, 1] = 0.5 + r_spiral * np.sin(j * phi)\n                radii[i, j] = 0.15 * (1.0 - r_spiral)\n        elif mode == 1:\n            # Highly concentric structured shells targeting max geometric coverage\n            centers[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.15\n            angles_in = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            centers[i, 1:9, 0] = 0.5 + 0.25 * np.cos(angles_in)\n            centers[i, 1:9, 1] = 0.5 + 0.25 * np.sin(angles_in)\n            radii[i, 1:9] = 0.08\n            angles_out = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            centers[i, 9:26, 0] = 0.5 + 0.45 * np.cos(angles_out)\n            centers[i, 9:26, 1] = 0.5 + 0.45 * np.sin(angles_out)\n            radii[i, 9:26] = 0.05\n        elif mode == 2:\n            # Distribute over deterministic evenly spaced jitter grid \n            grid_size = 5\n            lx = np.linspace(0.12, 0.88, grid_size)\n            ly = np.linspace(0.12, 0.88, grid_size)\n            x_mesh, y_mesh = np.meshgrid(lx, ly)\n            pts = np.column_stack((x_mesh.ravel(), y_mesh.ravel()))\n            np.random.shuffle(pts)\n            centers[i, :25] = pts[:25]\n            centers[i, 25] = [0.5, 0.5]\n            centers[i] += np.random.normal(0, 0.015, size=(n, 2))\n            radii[i] = np.random.uniform(0.04, 0.08, n)\n        elif mode == 3:\n            # Pushing tightly explicitly towards interstitial square boundaries\n            x_b = np.where(np.random.rand(n) < 0.5, 0.05, 0.95)\n            y_b = np.where(np.random.rand(n) < 0.5, 0.05, 0.95)\n            mask_swap = np.random.rand(n) < 0.5\n            x_b[mask_swap] = np.random.uniform(0.1, 0.9, mask_swap.sum())\n            y_b[~mask_swap] = np.random.uniform(0.1, 0.9, (~mask_swap).sum())\n            centers[i, :, 0] = x_b\n            centers[i, :, 1] = y_b\n            radii[i] = np.random.uniform(0.03, 0.08, n)\n        else:\n            # Complete unstructured randomized continuous domain \n            centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            radii[i] = np.random.uniform(0.02, 0.1, n)\n\n    # State parameters initialized optimally for standard continuous gradient limits \n    lr = 0.015\n    beta1, beta2 = 0.9, 0.999\n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n\n    steps = 2000\n    idx_arr = np.arange(n)\n\n    # Perform strict scheduled optimization directly integrating spatial intersections \n    for t in range(1, steps + 1):\n        if t <= 500:\n            lambda_p, lr = 15.0, 0.012\n        elif t <= 1000:\n            lambda_p, lr = 50.0, 0.005\n        elif t <= 1500:\n            lambda_p, lr = 250.0, 0.002\n        else:\n            lambda_p, lr = 2000.0, 0.001\n\n        # Intentionally break exact grid locking occasionally to help gradients map organically \n        if t < 1500 and t % 150 == 0:\n            centers += np.random.normal(0, 0.002, size=centers.shape)\n\n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n\n        diff = centers[:, :, None, :] - centers[:, None, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        dist[:, idx_arr, idx_arr] = 1.0  \n\n        overlap = radii[:, :, None] + radii[:, None, :] - dist\n        overlap[:, idx_arr, idx_arr] = -1.0\n        mask_over = overlap > 0\n\n        if np.any(mask_over):\n            pen = overlap * mask_over\n            grad_r += np.sum(lambda_p * 2 * pen, axis=2)\n\n            dist_safe = np.maximum(dist, 1e-12)\n            inv_dist = 1.0 / dist_safe\n            force = lambda_p * 2 * pen * inv_dist\n\n            grad_c -= np.einsum('bij,bijk->bik', force, diff)\n\n        # Force penalties preventing intersections directly passing bounds geometry\n        x = centers[:, :, 0]\n        y = centers[:, :, 1]\n\n        d_lx = radii - x\n        m_lx = d_lx > 0\n        grad_r[m_lx] += lambda_p * 2 * d_lx[m_lx]\n        grad_c[m_lx, 0] -= lambda_p * 2 * d_lx[m_lx]\n\n        d_rx = x + radii - 1.0\n        m_rx = d_rx > 0\n        grad_r[m_rx] += lambda_p * 2 * d_rx[m_rx]\n        grad_c[m_rx, 0] += lambda_p * 2 * d_rx[m_rx]\n\n        d_by = radii - y\n        m_by = d_by > 0\n        grad_r[m_by] += lambda_p * 2 * d_by[m_by]\n        grad_c[m_by, 1] -= lambda_p * 2 * d_by[m_by]\n\n        d_ty = y + radii - 1.0\n        m_ty = d_ty > 0\n        grad_r[m_ty] += lambda_p * 2 * d_ty[m_ty]\n        grad_c[m_ty, 1] += lambda_p * 2 * d_ty[m_ty]\n\n        m_nr = radii < 1e-3\n        grad_r[m_nr] += lambda_p * 2 * (radii[m_nr] - 1e-3)\n\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** t)\n        v_hat_c = v_c / (1 - beta2 ** t)\n        centers -= lr * m_hat_c / (np.sqrt(v_hat_c) + 1e-8)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** t)\n        v_hat_r = v_r / (1 - beta2 ** t)\n        radii -= lr * m_hat_r / (np.sqrt(v_hat_r) + 1e-8)\n\n    # Safe deterministic resolution guaranteeing valid solutions globally structurally strict limits\n    for _ in range(150):\n        diff = centers[:, :, None, :] - centers[:, None, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        dist[:, idx_arr, idx_arr] = np.inf\n        overlap = radii[:, :, None] + radii[:, None, :] - dist\n        \n        if np.max(overlap) <= 0.0:\n            break\n\n        mask_over = overlap > 0\n        overlap[~mask_over] = 0.0\n        shrinkage = np.sum((overlap / 2.0) + 1e-9, axis=2)\n        radii -= shrinkage * 0.5\n        radii = np.maximum(radii, 1e-5)\n\n    # Ultimate exact scaling ensuring no intersections logically identical to precision parameters mathematically smoothly mapping flawlessly!\n    diff = centers[:, :, None, :] - centers[:, None, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, idx_arr, idx_arr] = np.inf\n    overlap = radii[:, :, None] + radii[:, None, :] - dist\n    mask_over = overlap > 0\n\n    sum_r = radii[:, :, None] + radii[:, None, :]\n    safe_sum_r = np.maximum(sum_r, 1e-12)\n    scales = dist / safe_sum_r\n    scales[~mask_over] = 1.0\n    radii *= np.min(scales, axis=2) * 0.9999999\n\n    x = centers[:, :, 0]\n    y = centers[:, :, 1]\n    radii = np.minimum(radii, x)\n    radii = np.minimum(radii, 1.0 - x)\n    radii = np.minimum(radii, y)\n    radii = np.minimum(radii, 1.0 - y)\n    radii = np.maximum(radii, 1e-5)\n\n    valid_radii_sum = np.sum(radii, axis=1)\n    best_idx = np.argmax(valid_radii_sum)\n\n    best_c = centers[best_idx].copy()\n    best_r = radii[best_idx].copy()\n\n    # Utilize linear programming identically correctly resolving bounds directly correctly smoothly identically optimal smoothly flawlessly\n    try:\n        from scipy.optimize import linprog\n        A_ub = []\n        b_ub = []\n\n        for i in range(n):\n            row_l = np.zeros(n); row_l[i] = 1.0\n            A_ub.append(row_l); b_ub.append(best_c[i, 0])\n\n            row_r = np.zeros(n); row_r[i] = 1.0\n            A_ub.append(row_r); b_ub.append(1.0 - best_c[i, 0])\n\n            row_b = np.zeros(n); row_b[i] = 1.0\n            A_ub.append(row_b); b_ub.append(best_c[i, 1])\n\n            row_t = np.zeros(n); row_t[i] = 1.0\n            A_ub.append(row_t); b_ub.append(1.0 - best_c[i, 1])\n\n            for j in range(i + 1, n):\n                dist_val = np.hypot(best_c[i, 0] - best_c[j, 0], best_c[i, 1] - best_c[j, 1])\n                row_ij = np.zeros(n)\n                row_ij[i] = 1.0\n                row_ij[j] = 1.0\n                A_ub.append(row_ij)\n                b_ub.append(dist_val)\n\n        c_obj = -np.ones(n)\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=(1e-5, None), method='highs')\n        if res.success:\n            best_r = res.x * 0.999999\n            valid_radii_sum[best_idx] = np.sum(best_r)\n    except Exception:\n        pass\n\n    return best_c, best_r, valid_radii_sum[best_idx]\n\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)", "changes_description": null, "language": "python", "parent_id": "714a3ec3-7cf6-428f-9d90-5f36eb96de8a", "generation": 3, "timestamp": 1772004064.0470092, "iteration_found": 22, "metrics": {"validity": 1.0, "sum_radii": 2.629327144304732, "target_ratio": 0.9978471135881337, "combined_score": 0.9978471135881337, "radius_variance": 0.005243199658727249, "spatial_spread": 0.2035433319669849, "eval_time": 6.574464559555054}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0000\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stderr\n```\nStage 1 evaluation failed: Program execution failed: invalid syntax (tmpw6s1aaoj.py, line 1)\n```\n\n### traceback\n```\nTraceback (most recent call last):\n  File \"/home/jupyter/Code/oe/dennis/run_short_6/evaluator.py\", line 384, in evaluate_stage1\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\n  File \"/home/jupyter/Code/oe/dennis/run_short_6/evaluator.py\", line 172, in run_with_timeout\n    raise RuntimeError(f\"Program execution failed: {results['error']}\")\nRuntimeError: Program execution failed: invalid syntax (tmpw6s1aaoj.py, line 1)\n\n```\n\n### failure_stage\n```\nstage1_execution\n```\n\n### suggestion\n```\nCheck basic syntax and imports before attempting full evaluation\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 0.0000, combined_score: 0.0000, radius_variance: 0.0000, spatial_spread: 0.0000\n- Outcome: Regression in all metrics\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.4860, target_ratio: 0.9435, combined_score: 0.9435, radius_variance: 0.0054, spatial_spread: 0.1927, eval_time: 2.0613\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6262, target_ratio: 0.9967, combined_score: 0.9967, radius_variance: 0.0043, spatial_spread: 0.1870, eval_time: 7.1213\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9967)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to mathematically maximize the summation of radii natively utilizing\n    an Adam-guided gradient physics continuous domain solver on structured parallel arrays.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) perfectly bounding into the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    np.random.seed(42)  # Secure consistent highest deterministic result \n    N = 26\n    M = 100  # Broadly simulate over vast chaotic starting layouts\n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Smart heuristics - Bias seeding structure variations dynamically\n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            # Tightly placed Vogel spiral (seed density organically spreads to margins)\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            # Highly concentric shell layout prioritizing massive inner radius\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                # Interstitial snapping heuristics placing to hard exterior boundings \n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                # Radial dispersion bias\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                # Centric dominant growth with tight marginal jiggling\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                # Jittered grid intersections scaling towards gaps\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Custom vectorized gradient constraint minimizer (Adam framework on physics domain)\n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        # Stepped learning adjustments akin to schedule decay routines\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        # Break perfect locking by invoking randomized infinitesimal space perturbations\n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0) # Derivative pulls directly outwards to organically scale bubble size\n        \n        # Boundary physics penalties handling\n        diff_x0 = R - X\n        mask = diff_x0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x0[mask]\n        grad_X[mask] -= lambda_p * 2 * diff_x0[mask]\n        \n        diff_x1 = X + R - 1.0\n        mask = diff_x1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x1[mask]\n        grad_X[mask] += lambda_p * 2 * diff_x1[mask]\n        \n        diff_y0 = R - Y\n        mask = diff_y0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y0[mask]\n        grad_Y[mask] -= lambda_p * 2 * diff_y0[mask]\n        \n        diff_y1 = Y + R - 1.0\n        mask = diff_y1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y1[mask]\n        grad_Y[mask] += lambda_p * 2 * diff_y1[mask]\n        \n        # Internal circular compression handling mathematically computed in simultaneous tensors\n        dx = X[:, :, None] - X[:, None, :] \n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            \n            np.add.at(grad_R, (sm, si), grad_pen)\n            np.add.at(grad_R, (sm, sj), grad_pen)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen * dx[mask_over] * inv_dist\n            grad_yi = -grad_pen * dy[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        # Bottom threshold clipping parameter natively forcing radii sizes positively stable \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_hat_X = m_X / (1 - beta1**adam_step)\n        v_hat_X = v_X / (1 - beta2**adam_step)\n        X -= lr * m_hat_X / (np.sqrt(v_hat_X) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        m_hat_Y = m_Y / (1 - beta1**adam_step)\n        v_hat_Y = v_Y / (1 - beta2**adam_step)\n        Y -= lr * m_hat_Y / (np.sqrt(v_hat_Y) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_hat_R = m_R / (1 - beta1**adam_step)\n        v_hat_R = v_R / (1 - beta2**adam_step)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n\n    # Clean deterministic loop securing valid 0-bound overlapping resolutions smoothly\n    valid_radii_sum = np.zeros(M)\n    for m in range(M):\n        r_m = R[m].copy()\n        x_m = X[m].copy()\n        y_m = Y[m].copy()\n        \n        # Soft iterations allowing fluid convergence without boundary distortions\n        for _ in range(200):\n            max_viol = 0.0\n            for i in range(N):\n                for j in range(i+1, N):\n                    d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                    viol = r_m[i] + r_m[j] - d\n                    if viol > 0.0:\n                        if viol > max_viol: \n                            max_viol = viol\n                        sub = (viol / 2.0) + 1e-9\n                        r_m[i] -= sub\n                        r_m[j] -= sub\n            if max_viol <= 0.0:\n                break\n                \n        # Defensive absolute fail-safe pass proportionally shrinking perfectly maintaining layout distances natively\n        for i in range(N):\n            for j in range(i+1, N):\n                d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                if r_m[i] + r_m[j] > d:\n                    scale = d / (r_m[i] + r_m[j]) * 0.999999\n                    if scale < 1.0:\n                        r_m[i] *= scale\n                        r_m[j] *= scale\n        \n        # Safely enforce bounding clips locking strict internal box adherence\n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        r_m = np.maximum(r_m, 1e-5)\n        \n        valid_radii_sum[m] = np.sum(r_m)\n        R[m] = r_m \n        \n    best_idx = np.argmax(valid_radii_sum)\n    final_centers = np.stack((X[best_idx], Y[best_idx]), axis=1)\n    final_radii = R[best_idx]\n    \n    return final_centers, final_radii, valid_radii_sum[best_idx]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6262), Performs well on target_ratio (0.9967), Performs well on combined_score (0.9967), Performs well on radius_variance (0.0043), Performs well on spatial_spread (0.1870), Performs well on eval_time (7.1213)\n\n### Program 2 (Score: 0.9435)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles using physics optimization and annealing\"\"\"\nimport numpy as np\n\n\ndef compute_gradients(centers, radii, C):\n    \"\"\"Compute exact vectorized gradients for the circles based on overlap penalty constraints\"\"\"\n    grad_c = np.zeros_like(centers)\n    grad_r = np.full_like(radii, -1.0)  # Optimize to maximize sum(r) -> derivative of -sum(r)\n    \n    diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    # Avoid zero-distance divide errors explicitly via float safety bounds\n    dist = np.maximum(dist, 1e-8)\n    np.fill_diagonal(dist, 1.0)\n    \n    # Compute intersection overlap bounds and pairwise force repulsion masks\n    rad_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n    overlap = rad_sum - dist\n    np.fill_diagonal(overlap, 0.0)\n    \n    mask = overlap > 0\n    grad_r += np.sum(2.0 * C * overlap * mask, axis=1)\n    \n    factor = np.zeros_like(overlap)\n    factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n    \n    # Efficient pairwise repulsion calculations resolving directly using eignsum accumulation\n    grad_c -= np.einsum('ij,ijk->ik', factor, diff)\n    \n    # Left wall bounds validation penalty mechanism \n    overlap_left = radii - centers[:, 0]\n    mask_l = overlap_left > 0\n    grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n    grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n    \n    # Right wall bounds validation penalty mechanism \n    overlap_right = centers[:, 0] + radii - 1.0\n    mask_r = overlap_right > 0\n    grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n    grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n    \n    # Bottom wall bounds validation penalty mechanism \n    overlap_bot = radii - centers[:, 1]\n    mask_b = overlap_bot > 0\n    grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n    grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n    \n    # Top wall bounds validation penalty mechanism \n    overlap_top = centers[:, 1] + radii - 1.0\n    mask_t = overlap_top > 0\n    grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n    grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n    \n    return grad_c, grad_r\n\n\ndef adam_optimizer(n, init_centers, init_radii, steps=3000):\n    \"\"\"Executes smooth continuous annealing simulation matching physics engine properties\"\"\"\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Fine-tuned exponential decay constraints (similar to annealing schedules)\n    lr_initial = 0.015\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 100000.0\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        # Break perfect symmetry to escape topological grid deadlocks\n        if t % 500 == 0 and t < steps * 0.5:\n            centers += np.random.normal(0, 0.005, size=(n, 2))\n        \n        grad_c, grad_r = compute_gradients(centers, radii, C)\n        \n        # Moment and bias accumulations mapping smoothly to topological surfaces\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-6, 1.0 - 1e-6)\n        radii = np.clip(radii, 1e-6, 1.0)\n        \n    return centers, radii\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Handles mathematically valid strictly constrained radius fallbacks completely independently\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict bounds mathematically identical to target thresholds checking valid sizes exactly\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Generates an exceptionally robust and rigorously checked completely valid packing radius constraint.\"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        # Enforce all geometric exterior mapping limits globally utilizing bounding offsets natively \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        # Internal space limits exactly matching pairwise non-overlapping definitions mapping completely natively\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef construct_packing():\n    \"\"\"\n    Construct iteratively improved packings deploying simulated physics gradients with dynamic bounding heuristics\n    to guarantee globally effective area occupancy while retaining maximum stability features smoothly fitting geometries\n    \"\"\"\n    n = 26\n    best_centers = None\n    best_radii = None\n    max_sum = -1.0\n    \n    # Explores topological search tree combinations comprehensively testing symmetric structures fully scaling to solutions \n    for seed in range(4):\n        np.random.seed(42 + seed)\n        centers = np.zeros((n, 2))\n        radii = np.ones(n) * 0.05\n        \n        if seed == 0:\n            # Seed positions heuristically mapping optimal interstitial gap combinations directly applying size constraints appropriately \n            centers[0] = [0.5, 0.5]\n            radii[0] = 0.15\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for i in range(4):\n                centers[i + 1] = corners[i]\n                radii[i + 1] = 0.08\n            edges = [[0.5, 0.1], [0.5, 0.9], [0.1, 0.5], [0.9, 0.5]]\n            for i in range(4):\n                centers[i + 5] = edges[i]\n                radii[i + 5] = 0.08\n            centers[9:] = np.random.uniform(0.1, 0.9, (17, 2))\n            radii[9:] = np.random.uniform(0.02, 0.08, 17)\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n        elif seed == 1:\n            centers = np.random.uniform(0.1, 0.9, (n, 2))\n            radii = np.random.uniform(0.01, 0.1, n)\n        elif seed == 2:\n            grid_x, grid_y = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 6))\n            centers[:25, 0] = grid_x.flatten()[:25]\n            centers[:25, 1] = grid_y.flatten()[:25]\n            centers[25] = [0.5, 0.5]\n            centers += np.random.normal(0, 0.02, size=(n, 2))\n        else:\n            centers[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                centers[i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n            for i in range(16):\n                angle = 2 * np.pi * i / 16\n                centers[i + 9] = [0.5 + 0.7 * np.cos(angle), 0.5 + 0.7 * np.sin(angle)]\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n            \n        centers = np.clip(centers, 0.01, 0.99)\n        radii = np.clip(radii, 0.01, 0.2)\n        \n        c_opt, r_opt = adam_optimizer(n, centers, radii, steps=3000)\n        \n        r_exact = get_exact_radii(c_opt, r_opt)\n        current_sum = np.sum(r_exact)\n        \n        if current_sum > max_sum:\n            max_sum = current_sum\n            best_centers = c_opt.copy()\n            best_radii = r_exact.copy()\n            \n    return best_centers, best_radii, max_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.4860), Performs well on target_ratio (0.9435), Performs well on combined_score (0.9435), Performs well on radius_variance (0.0054), Performs well on spatial_spread (0.1927), Performs well on eval_time (2.0613)\n\n### Program 3 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom scipy.optimize import minimize, linprog, LinearConstraint, NonlinearConstraint\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Fallback iteratively shrinking radii avoiding pairwise bound exceptions completely securely\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict scaling explicit limits identical natively limits bounds check completely correctly structurally natively!\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Exact mathematically verified linprog ensuring zero bound overlapping limits seamlessly optimally globally properly matching perfectly limits bounds completely securely matching flawlessly natively gracefully gracefully identical.\"\"\"\n    n = len(centers)\n    try:\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef optimize_slsqp(c, r, n=26):\n    \"\"\"Refine topological models gracefully appropriately scaling flawlessly completely strictly effectively correctly optimally identically constraints mathematically securely globally smoothly securely perfectly bounds smoothly limits properly!\"\"\"\n    X0 = np.concatenate([c[:, 0], c[:, 1], r])\n    \n    A_lin = np.zeros((4 * n, 3 * n))\n    lb_lin = np.zeros(4 * n)\n    ub_lin = np.zeros(4 * n)\n\n    for i in range(n):\n        # x_i - r_i >= 0\n        A_lin[4 * i, i] = 1\n        A_lin[4 * i, 2 * n + i] = -1\n        lb_lin[4 * i] = 0\n        ub_lin[4 * i] = np.inf\n        \n        # y_i - r_i >= 0\n        A_lin[4 * i + 1, n + i] = 1\n        A_lin[4 * i + 1, 2 * n + i] = -1\n        lb_lin[4 * i + 1] = 0\n        ub_lin[4 * i + 1] = np.inf\n        \n        # x_i + r_i <= 1\n        A_lin[4 * i + 2, i] = 1\n        A_lin[4 * i + 2, 2 * n + i] = 1\n        lb_lin[4 * i + 2] = -np.inf\n        ub_lin[4 * i + 2] = 1.0\n        \n        # y_i + r_i <= 1\n        A_lin[4 * i + 3, n + i] = 1\n        A_lin[4 * i + 3, 2 * n + i] = 1\n        lb_lin[4 * i + 3] = -np.inf\n        ub_lin[4 * i + 3] = 1.0\n\n    lin_cons = LinearConstraint(A_lin, lb_lin, ub_lin)\n\n    def pairwise_constraint(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        dist_sq = (x[idx_i] - x[idx_j])**2 + (y[idx_i] - y[idx_j])**2\n        rad_sq = (r[idx_i] + r[idx_j])**2\n        return dist_sq - rad_sq\n\n    def pairwise_jac(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        num_cons = n * (n - 1) // 2\n        J = np.zeros((num_cons, 3 * n))\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        \n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        dr = r[idx_i] + r[idx_j]\n        \n        J[np.arange(num_cons), idx_i] = 2 * dx\n        J[np.arange(num_cons), idx_j] = -2 * dx\n        J[np.arange(num_cons), n + idx_i] = 2 * dy\n        J[np.arange(num_cons), n + idx_j] = -2 * dy\n        J[np.arange(num_cons), 2 * n + idx_i] = -2 * dr\n        J[np.arange(num_cons), 2 * n + idx_j] = -2 * dr\n        \n        return J\n\n    nonlin_cons = NonlinearConstraint(\n        pairwise_constraint,\n        0.0, np.inf,\n        jac=pairwise_jac\n    )\n\n    def obj(X):\n        return -np.sum(X[2 * n:])\n        \n    def obj_jac(X):\n        grad = np.zeros_like(X)\n        grad[2 * n:] = -1.0\n        return grad\n        \n    bounds = [(0.0, 1.0)] * (2 * n) + [(1e-5, 1.0)] * n\n\n    try:\n        res = minimize(\n            obj, X0, \n            jac=obj_jac,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=[lin_cons, nonlin_cons],\n            options={'maxiter': 250, 'ftol': 1e-6}\n        )\n        X_opt = res.x\n    except Exception:\n        X_opt = X0\n        \n    c_opt = np.column_stack((X_opt[:n], X_opt[n:2 * n]))\n    r_opt = X_opt[2 * n:]\n    return c_opt, r_opt\n\n\ndef batched_adam_optimizer(n, init_centers, init_radii, steps=1000):\n    \"\"\"Leverage vectorized hardware explicitly optimally robustly valid matching identically cleanly scaling perfectly accurately smoothly flawlessly identically bounds appropriately globally precisely perfectly efficiently strictly smoothly structurally optimally natively identical explicitly identical checks cleanly identically securely valid gracefully limits securely accurately gracefully securely securely perfectly strictly!\"\"\"\n    B = init_centers.shape[0]\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    lr_initial = 0.018\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 80000.0\n    \n    idx = np.arange(n)\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        if t % 200 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1, 1) < 0.6\n            centers += np.random.normal(0, 0.005, size=(B, n, 2)) * mask\n        \n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n        \n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :] \n        dist = np.linalg.norm(diff, axis=-1)\n        \n        dist = np.maximum(dist, 1e-8)\n        dist[:, idx, idx] = 1.0 \n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, idx, idx] = 0.0 \n        \n        mask = overlap > 0\n        grad_r += np.sum(2.0 * C * overlap * mask, axis=2)\n        \n        factor = np.zeros_like(overlap)\n        factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n        \n        grad_c -= np.einsum('bij,bijk->bik', factor, diff)\n        \n        overlap_left = radii - centers[:, :, 0]\n        mask_l = overlap_left > 0\n        grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n        grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n        \n        overlap_right = centers[:, :, 0] + radii - 1.0\n        mask_r = overlap_right > 0\n        grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n        grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n        \n        overlap_bot = radii - centers[:, :, 1]\n        mask_b = overlap_bot > 0\n        grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n        grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n        \n        overlap_top = centers[:, :, 1] + radii - 1.0\n        mask_t = overlap_top > 0\n        grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n        grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-5, 1.0 - 1e-5)\n        radii = np.clip(radii, 1e-5, 1.0)\n        \n    return centers, radii\n\n\ndef batched_fallback_radii(centers, target_radii):\n    \"\"\"Vectorized rapid checking ensuring securely robust correctly mapping identically globally precisely efficiently rigorously flawless natively robust checks explicitly effectively constraints smoothly checks identically valid constraints properly gracefully limits identically identical.\"\"\"\n    n = centers.shape[1]\n    radii = target_radii.copy()\n    \n    for _ in range(40):\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n        \n        mask = overlap > 0\n        if not np.any(mask):\n            break\n            \n        correction = np.sum(overlap * mask, axis=2) * 0.35\n        radii -= correction\n        \n    radii = np.clip(radii, 0.0, None)\n    \n    radii = np.minimum(radii, centers[:, :, 0])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 0])\n    radii = np.minimum(radii, centers[:, :, 1])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 1])\n    \n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, np.arange(n), np.arange(n)] = np.inf\n    \n    rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n    rad_sum = np.maximum(rad_sum, 1e-12)\n    \n    scale_matrix = dist / rad_sum\n    min_scale_per_circle = np.min(scale_matrix, axis=-1)\n    final_scales = np.minimum(min_scale_per_circle, 1.0)\n    \n    radii *= final_scales * 0.999999\n    \n    return radii\n\n\ndef construct_packing():\n    \"\"\"Build highly structured topological arrangements robustly resolving strictly bounds successfully securely mapping safely smoothly structurally efficiently explicitly explicitly smoothly flawlessly effectively completely valid precisely smoothly logically.\"\"\"\n    n = 26\n    B = 100\n    init_centers = np.zeros((B, n, 2))\n    init_radii = np.full((B, n), 0.05)\n    \n    np.random.seed(42)\n    \n    for i in range(B):\n        seed_type = i % 5\n        if seed_type == 0:\n            init_centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            init_radii[i] = np.random.uniform(0.02, 0.12, n)\n        elif seed_type == 1:\n            init_centers[i, 0] = [0.5, 0.5]\n            init_radii[i, 0] = np.random.uniform(0.15, 0.25)\n            init_centers[i, 1:] = np.random.uniform(0.1, 0.9, (n - 1, 2))\n            init_radii[i, 1:] = np.random.uniform(0.02, 0.08, n - 1)\n        elif seed_type == 2:\n            nx, ny = 5, 5\n            x, y = np.meshgrid(np.linspace(0.12, 0.88, nx), np.linspace(0.12, 0.88, ny))\n            pts = np.column_stack((x.ravel(), y.ravel()))\n            pts = np.vstack([pts, [0.5, 0.5]])\n            pts += np.random.normal(0, 0.02, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.normal(0.09, 0.015, n)\n        elif seed_type == 3:\n            init_centers[i, 0] = [0.5, 0.5]\n            angles9 = np.linspace(0, 2 * np.pi, 9, endpoint=False)\n            pts9 = np.column_stack([0.5 + 0.25 * np.cos(angles9), 0.5 + 0.25 * np.sin(angles9)])\n            angles16 = np.linspace(0, 2 * np.pi, 16, endpoint=False)\n            pts16 = np.column_stack([0.5 + 0.45 * np.cos(angles16), 0.5 + 0.45 * np.sin(angles16)])\n            pts = np.vstack([[0.5, 0.5], pts9, pts16])\n            pts += np.random.normal(0, 0.015, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.uniform(0.05, 0.1, n)\n        else:\n            pts = []\n            pts.extend([[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.\n```\nKey features: Performs well on validity (0.0000), Performs well on combined_score (0.0000), Performs well on radius_variance (0.0000), Performs well on spatial_spread (0.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.9435, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles using physics optimization and annealing\"\"\"\nimport numpy as np\n\n\ndef compute_gradients(centers, radii, C):\n    \"\"\"Compute exact vectorized gradients for the circles based on overlap penalty constraints\"\"\"\n    grad_c = np.zeros_like(centers)\n    grad_r = np.full_like(radii, -1.0)  # Optimize to maximize sum(r) -> derivative of -sum(r)\n    \n    diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    # Avoid zero-distance divide errors explicitly via float safety bounds\n    dist = np.maximum(dist, 1e-8)\n    np.fill_diagonal(dist, 1.0)\n    \n    # Compute intersection overlap bounds and pairwise force repulsion masks\n    rad_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n    overlap = rad_sum - dist\n    np.fill_diagonal(overlap, 0.0)\n    \n    mask = overlap > 0\n    grad_r += np.sum(2.0 * C * overlap * mask, axis=1)\n    \n    factor = np.zeros_like(overlap)\n    factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n    \n    # Efficient pairwise repulsion calculations resolving directly using eignsum accumulation\n    grad_c -= np.einsum('ij,ijk->ik', factor, diff)\n    \n    # Left wall bounds validation penalty mechanism \n    overlap_left = radii - centers[:, 0]\n    mask_l = overlap_left > 0\n    grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n    grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n    \n    # Right wall bounds validation penalty mechanism \n    overlap_right = centers[:, 0] + radii - 1.0\n    mask_r = overlap_right > 0\n    grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n    grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n    \n    # Bottom wall bounds validation penalty mechanism \n    overlap_bot = radii - centers[:, 1]\n    mask_b = overlap_bot > 0\n    grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n    grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n    \n    # Top wall bounds validation penalty mechanism \n    overlap_top = centers[:, 1] + radii - 1.0\n    mask_t = overlap_top > 0\n    grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n    grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n    \n    return grad_c, grad_r\n\n\ndef adam_optimizer(n, init_centers, init_radii, steps=3000):\n    \"\"\"Executes smooth continuous annealing simulation matching physics engine properties\"\"\"\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Fine-tuned exponential decay constraints (similar to annealing schedules)\n    lr_initial = 0.015\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 100000.0\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        # Break perfect symmetry to escape topological grid deadlocks\n        if t % 500 == 0 and t < steps * 0.5:\n            centers += np.random.normal(0, 0.005, size=(n, 2))\n        \n        grad_c, grad_r = compute_gradients(centers, radii, C)\n        \n        # Moment and bias accumulations mapping smoothly to topological surfaces\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-6, 1.0 - 1e-6)\n        radii = np.clip(radii, 1e-6, 1.0)\n        \n    return centers, radii\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Handles mathematically valid strictly constrained radius fallbacks completely independently\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict bounds mathematically identical to target thresholds checking valid sizes exactly\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Generates an exceptionally robust and rigorously checked completely valid packing radius constraint.\"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        # Enforce all geometric exterior mapping limits globally utilizing bounding offsets natively \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        # Internal space limits exactly matching pairwise non-overlapping definitions mapping completely natively\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef construct_packing():\n    \"\"\"\n    Construct iteratively improved packings deploying simulated physics gradients with dynamic bounding heuristics\n    to guarantee globally effective area occupancy while retaining maximum stability features smoothly fitting geometries\n    \"\"\"\n    n = 26\n    best_centers = None\n    best_radii = None\n    max_sum = -1.0\n    \n    # Explores topological search tree combinations comprehensively testing symmetric structures fully scaling to solutions \n    for seed in range(4):\n        np.random.seed(42 + seed)\n        centers = np.zeros((n, 2))\n        radii = np.ones(n) * 0.05\n        \n        if seed == 0:\n            # Seed positions heuristically mapping optimal interstitial gap combinations directly applying size constraints appropriately \n            centers[0] = [0.5, 0.5]\n            radii[0] = 0.15\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for i in range(4):\n                centers[i + 1] = corners[i]\n                radii[i + 1] = 0.08\n            edges = [[0.5, 0.1], [0.5, 0.9], [0.1, 0.5], [0.9, 0.5]]\n            for i in range(4):\n                centers[i + 5] = edges[i]\n                radii[i + 5] = 0.08\n            centers[9:] = np.random.uniform(0.1, 0.9, (17, 2))\n            radii[9:] = np.random.uniform(0.02, 0.08, 17)\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n        elif seed == 1:\n            centers = np.random.uniform(0.1, 0.9, (n, 2))\n            radii = np.random.uniform(0.01, 0.1, n)\n        elif seed == 2:\n            grid_x, grid_y = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 6))\n            centers[:25, 0] = grid_x.flatten()[:25]\n            centers[:25, 1] = grid_y.flatten()[:25]\n            centers[25] = [0.5, 0.5]\n            centers += np.random.normal(0, 0.02, size=(n, 2))\n        else:\n            centers[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                centers[i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n            for i in range(16):\n                angle = 2 * np.pi * i / 16\n                centers[i + 9] = [0.5 + 0.7 * np.cos(angle), 0.5 + 0.7 * np.sin(angle)]\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n            \n        centers = np.clip(centers, 0.01, 0.99)\n        radii = np.clip(radii, 0.01, 0.2)\n        \n        c_opt, r_opt = adam_optimizer(n, centers, radii, steps=3000)\n        \n        r_exact = get_exact_radii(c_opt, r_opt)\n        current_sum = np.sum(r_exact)\n        \n        if current_sum > max_sum:\n            max_sum = current_sum\n            best_centers = c_opt.copy()\n            best_radii = r_exact.copy()\n            \n    return best_centers, best_radii, max_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9967, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to mathematically maximize the summation of radii natively utilizing\n    an Adam-guided gradient physics continuous domain solver on structured parallel arrays.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) perfectly bounding into the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    np.random.seed(42)  # Secure consistent highest deterministic result \n    N = 26\n    M = 100  # Broadly simulate over vast chaotic starting layouts\n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Smart heuristics - Bias seeding structure variations dynamically\n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            # Tightly placed Vogel spiral (seed density organically spreads to margins)\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            # Highly concentric shell layout prioritizing massive inner radius\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                # Interstitial snapping heuristics placing to hard exterior boundings \n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                # Radial dispersion bias\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                # Centric dominant growth with tight marginal jiggling\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                # Jittered grid intersections scaling towards gaps\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Custom vectorized gradient constraint minimizer (Adam framework on physics domain)\n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        # Stepped learning adjustments akin to schedule decay routines\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        # Break perfect locking by invoking randomized infinitesimal space perturbations\n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0) # Derivative pulls directly outwards to organically scale bubble size\n        \n        # Boundary physics penalties handling\n        diff_x0 = R - X\n        mask = diff_x0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x0[mask]\n        grad_X[mask] -= lambda_p * 2 * diff_x0[mask]\n        \n        diff_x1 = X + R - 1.0\n        mask = diff_x1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x1[mask]\n        grad_X[mask] += lambda_p * 2 * diff_x1[mask]\n        \n        diff_y0 = R - Y\n        mask = diff_y0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y0[mask]\n        grad_Y[mask] -= lambda_p * 2 * diff_y0[mask]\n        \n        diff_y1 = Y + R - 1.0\n        mask = diff_y1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y1[mask]\n        grad_Y[mask] += lambda_p * 2 * diff_y1[mask]\n        \n        # Internal circular compression handling mathematically computed in simultaneous tensors\n        dx = X[:, :, None] - X[:, None, :] \n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            \n            np.add.at(grad_R, (sm, si), grad_pen)\n            np.add.at(grad_R, (sm, sj), grad_pen)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen * dx[mask_over] * inv_dist\n            grad_yi = -grad_pen * dy[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        # Bottom threshold clipping parameter natively forcing radii sizes positively stable \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_hat_X = m_X / (1 - beta1**adam_step)\n        v_hat_X = v_X / (1 - beta2**adam_step)\n        X -= lr * m_hat_X / (np.sqrt(v_hat_X) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        m_hat_Y = m_Y / (1 - beta1**adam_step)\n        v_hat_Y = v_Y / (1 - beta2**adam_step)\n        Y -= lr * m_hat_Y / (np.sqrt(v_hat_Y) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_hat_R = m_R / (1 - beta1**adam_step)\n        v_hat_R = v_R / (1 - beta2**adam_step)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n\n    # Clean deterministic loop securing valid 0-bound overlapping resolutions smoothly\n    valid_radii_sum = np.zeros(M)\n    for m in range(M):\n        r_m = R[m].copy()\n        x_m = X[m].copy()\n        y_m = Y[m].copy()\n        \n        # Soft iterations allowing fluid convergence without boundary distortions\n        for _ in range(200):\n            max_viol = 0.0\n            for i in range(N):\n                for j in range(i+1, N):\n                    d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                    viol = r_m[i] + r_m[j] - d\n                    if viol > 0.0:\n                        if viol > max_viol: \n                            max_viol = viol\n                        sub = (viol / 2.0) + 1e-9\n                        r_m[i] -= sub\n                        r_m[j] -= sub\n            if max_viol <= 0.0:\n                break\n                \n        # Defensive absolute fail-safe pass proportionally shrinking perfectly maintaining layout distances natively\n        for i in range(N):\n            for j in range(i+1, N):\n                d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                if r_m[i] + r_m[j] > d:\n                    scale = d / (r_m[i] + r_m[j]) * 0.999999\n                    if scale < 1.0:\n                        r_m[i] *= scale\n                        r_m[j] *= scale\n        \n        # Safely enforce bounding clips locking strict internal box adherence\n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        r_m = np.maximum(r_m, 1e-5)\n        \n        valid_radii_sum[m] = np.sum(r_m)\n        R[m] = r_m \n        \n    best_idx = np.argmax(valid_radii_sum)\n    final_centers = np.stack((X[best_idx], Y[best_idx]), axis=1)\n    final_radii = R[best_idx]\n    \n    return final_centers, final_radii, valid_radii_sum[best_idx]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom scipy.optimize import minimize, linprog, LinearConstraint, NonlinearConstraint\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Fallback iteratively shrinking radii avoiding pairwise bound exceptions completely securely\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict scaling explicit limits identical natively limits bounds check completely correctly structurally natively!\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Exact mathematically verified linprog ensuring zero bound overlapping limits seamlessly optimally globally properly matching perfectly limits bounds completely securely matching flawlessly natively gracefully gracefully identical.\"\"\"\n    n = len(centers)\n    try:\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef optimize_slsqp(c, r, n=26):\n    \"\"\"Refine topological models gracefully appropriately scaling flawlessly completely strictly effectively correctly optimally identically constraints mathematically securely globally smoothly securely perfectly bounds smoothly limits properly!\"\"\"\n    X0 = np.concatenate([c[:, 0], c[:, 1], r])\n    \n    A_lin = np.zeros((4 * n, 3 * n))\n    lb_lin = np.zeros(4 * n)\n    ub_lin = np.zeros(4 * n)\n\n    for i in range(n):\n        # x_i - r_i >= 0\n        A_lin[4 * i, i] = 1\n        A_lin[4 * i, 2 * n + i] = -1\n        lb_lin[4 * i] = 0\n        ub_lin[4 * i] = np.inf\n        \n        # y_i - r_i >= 0\n        A_lin[4 * i + 1, n + i] = 1\n        A_lin[4 * i + 1, 2 * n + i] = -1\n        lb_lin[4 * i + 1] = 0\n        ub_lin[4 * i + 1] = np.inf\n        \n        # x_i + r_i <= 1\n        A_lin[4 * i + 2, i] = 1\n        A_lin[4 * i + 2, 2 * n + i] = 1\n        lb_lin[4 * i + 2] = -np.inf\n        ub_lin[4 * i + 2] = 1.0\n        \n        # y_i + r_i <= 1\n        A_lin[4 * i + 3, n + i] = 1\n        A_lin[4 * i + 3, 2 * n + i] = 1\n        lb_lin[4 * i + 3] = -np.inf\n        ub_lin[4 * i + 3] = 1.0\n\n    lin_cons = LinearConstraint(A_lin, lb_lin, ub_lin)\n\n    def pairwise_constraint(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        dist_sq = (x[idx_i] - x[idx_j])**2 + (y[idx_i] - y[idx_j])**2\n        rad_sq = (r[idx_i] + r[idx_j])**2\n        return dist_sq - rad_sq\n\n    def pairwise_jac(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        num_cons = n * (n - 1) // 2\n        J = np.zeros((num_cons, 3 * n))\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        \n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        dr = r[idx_i] + r[idx_j]\n        \n        J[np.arange(num_cons), idx_i] = 2 * dx\n        J[np.arange(num_cons), idx_j] = -2 * dx\n        J[np.arange(num_cons), n + idx_i] = 2 * dy\n        J[np.arange(num_cons), n + idx_j] = -2 * dy\n        J[np.arange(num_cons), 2 * n + idx_i] = -2 * dr\n        J[np.arange(num_cons), 2 * n + idx_j] = -2 * dr\n        \n        return J\n\n    nonlin_cons = NonlinearConstraint(\n        pairwise_constraint,\n        0.0, np.inf,\n        jac=pairwise_jac\n    )\n\n    def obj(X):\n        return -np.sum(X[2 * n:])\n        \n    def obj_jac(X):\n        grad = np.zeros_like(X)\n        grad[2 * n:] = -1.0\n        return grad\n        \n    bounds = [(0.0, 1.0)] * (2 * n) + [(1e-5, 1.0)] * n\n\n    try:\n        res = minimize(\n            obj, X0, \n            jac=obj_jac,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=[lin_cons, nonlin_cons],\n            options={'maxiter': 250, 'ftol': 1e-6}\n        )\n        X_opt = res.x\n    except Exception:\n        X_opt = X0\n        \n    c_opt = np.column_stack((X_opt[:n], X_opt[n:2 * n]))\n    r_opt = X_opt[2 * n:]\n    return c_opt, r_opt\n\n\ndef batched_adam_optimizer(n, init_centers, init_radii, steps=1000):\n    \"\"\"Leverage vectorized hardware explicitly optimally robustly valid matching identically cleanly scaling perfectly accurately smoothly flawlessly identically bounds appropriately globally precisely perfectly efficiently strictly smoothly structurally optimally natively identical explicitly identical checks cleanly identically securely valid gracefully limits securely accurately gracefully securely securely perfectly strictly!\"\"\"\n    B = init_centers.shape[0]\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    lr_initial = 0.018\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 80000.0\n    \n    idx = np.arange(n)\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        if t % 200 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1, 1) < 0.6\n            centers += np.random.normal(0, 0.005, size=(B, n, 2)) * mask\n        \n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n        \n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :] \n        dist = np.linalg.norm(diff, axis=-1)\n        \n        dist = np.maximum(dist, 1e-8)\n        dist[:, idx, idx] = 1.0 \n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, idx, idx] = 0.0 \n        \n        mask = overlap > 0\n        grad_r += np.sum(2.0 * C * overlap * mask, axis=2)\n        \n        factor = np.zeros_like(overlap)\n        factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n        \n        grad_c -= np.einsum('bij,bijk->bik', factor, diff)\n        \n        overlap_left = radii - centers[:, :, 0]\n        mask_l = overlap_left > 0\n        grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n        grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n        \n        overlap_right = centers[:, :, 0] + radii - 1.0\n        mask_r = overlap_right > 0\n        grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n        grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n        \n        overlap_bot = radii - centers[:, :, 1]\n        mask_b = overlap_bot > 0\n        grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n        grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n        \n        overlap_top = centers[:, :, 1] + radii - 1.0\n        mask_t = overlap_top > 0\n        grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n        grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-5, 1.0 - 1e-5)\n        radii = np.clip(radii, 1e-5, 1.0)\n        \n    return centers, radii\n\n\ndef batched_fallback_radii(centers, target_radii):\n    \"\"\"Vectorized rapid checking ensuring securely robust correctly mapping identically globally precisely efficiently rigorously flawless natively robust checks explicitly effectively constraints smoothly checks identically valid constraints properly gracefully limits identically identical.\"\"\"\n    n = centers.shape[1]\n    radii = target_radii.copy()\n    \n    for _ in range(40):\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n        \n        mask = overlap > 0\n        if not np.any(mask):\n            break\n            \n        correction = np.sum(overlap * mask, axis=2) * 0.35\n        radii -= correction\n        \n    radii = np.clip(radii, 0.0, None)\n    \n    radii = np.minimum(radii, centers[:, :, 0])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 0])\n    radii = np.minimum(radii, centers[:, :, 1])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 1])\n    \n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, np.arange(n), np.arange(n)] = np.inf\n    \n    rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n    rad_sum = np.maximum(rad_sum, 1e-12)\n    \n    scale_matrix = dist / rad_sum\n    min_scale_per_circle = np.min(scale_matrix, axis=-1)\n    final_scales = np.minimum(min_scale_per_circle, 1.0)\n    \n    radii *= final_scales * 0.999999\n    \n    return radii\n\n\ndef construct_packing():\n    \"\"\"Build highly structured topological arrangements robustly resolving strictly bounds successfully securely mapping safely smoothly structurally efficiently explicitly explicitly smoothly flawlessly effectively completely valid precisely smoothly logically.\"\"\"\n    n = 26\n    B = 100\n    init_centers = np.zeros((B, n, 2))\n    init_radii = np.full((B, n), 0.05)\n    \n    np.random.seed(42)\n    \n    for i in range(B):\n        seed_type = i % 5\n        if seed_type == 0:\n            init_centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            init_radii[i] = np.random.uniform(0.02, 0.12, n)\n        elif seed_type == 1:\n            init_centers[i, 0] = [0.5, 0.5]\n            init_radii[i, 0] = np.random.uniform(0.15, 0.25)\n            init_centers[i, 1:] = np.random.uniform(0.1, 0.9, (n - 1, 2))\n            init_radii[i, 1:] = np.random.uniform(0.02, 0.08, n - 1)\n        elif seed_type == 2:\n            nx, ny = 5, 5\n            x, y = np.meshgrid(np.linspace(0.12, 0.88, nx), np.linspace(0.12, 0.88, ny))\n            pts = np.column_stack((x.ravel(), y.ravel()))\n            pts = np.vstack([pts, [0.5, 0.5]])\n            pts += np.random.normal(0, 0.02, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.normal(0.09, 0.015, n)\n        elif seed_type == 3:\n            init_centers[i, 0] = [0.5, 0.5]\n            angles9 = np.linspace(0, 2 * np.pi, 9, endpoint=False)\n            pts9 = np.column_stack([0.5 + 0.25 * np.cos(angles9), 0.5 + 0.25 * np.sin(angles9)])\n            angles16 = np.linspace(0, 2 * np.pi, 16, endpoint=False)\n            pts16 = np.column_stack([0.5 + 0.45 * np.cos(angles16), 0.5 + 0.45 * np.sin(angles16)])\n            pts = np.vstack([[0.5, 0.5], pts9, pts16])\n            pts += np.random.normal(0, 0.015, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.uniform(0.05, 0.1, n)\n        else:\n            pts = []\n            pts.extend([[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to maximize the summation of their radii by using batched Adam\n    optimization with physics-based overlapping constraints.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) fitting in the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    n = 26\n    B = 80  # Simulate 80 batched topological arrangements simultaneously\n    np.random.seed(42)  # Strict determinism\n\n    centers = np.zeros((B, n, 2))\n    radii = np.zeros((B, n))\n\n    for i in range(B):\n        mode = i % 5\n        if mode == 0:\n            # Vogel spiral distribution mapping\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for j in range(n):\n                r_spiral = np.sqrt((j + 0.5) / n) * 0.45\n                centers[i, j, 0] = 0.5 + r_spiral * np.cos(j * phi)\n                centers[i, j, 1] = 0.5 + r_spiral * np.sin(j * phi)\n                radii[i, j] = 0.15 * (1.0 - r_spiral)\n        elif mode == 1:\n            # Highly concentric structured shells targeting max geometric coverage\n            centers[i, 0] = [0.5, 0.5]\n            radii[i, 0] = 0.15\n            angles_in = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            centers[i, 1:9, 0] = 0.5 + 0.25 * np.cos(angles_in)\n            centers[i, 1:9, 1] = 0.5 + 0.25 * np.sin(angles_in)\n            radii[i, 1:9] = 0.08\n            angles_out = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            centers[i, 9:26, 0] = 0.5 + 0.45 * np.cos(angles_out)\n            centers[i, 9:26, 1] = 0.5 + 0.45 * np.sin(angles_out)\n            radii[i, 9:26] = 0.05\n        elif mode == 2:\n            # Distribute over deterministic evenly spaced jitter grid \n            grid_size = 5\n            lx = np.linspace(0.12, 0.88, grid_size)\n            ly = np.linspace(0.12, 0.88, grid_size)\n            x_mesh, y_mesh = np.meshgrid(lx, ly)\n            pts = np.column_stack((x_mesh.ravel(), y_mesh.ravel()))\n            np.random.shuffle(pts)\n            centers[i, :25] = pts[:25]\n            centers[i, 25] = [0.5, 0.5]\n            centers[i] += np.random.normal(0, 0.015, size=(n, 2))\n            radii[i] = np.random.uniform(0.04, 0.08, n)\n        elif mode == 3:\n            # Pushing tightly explicitly towards interstitial square boundaries\n            x_b = np.where(np.random.rand(n) < 0.5, 0.05, 0.95)\n            y_b = np.where(np.random.rand(n) < 0.5, 0.05, 0.95)\n            mask_swap = np.random.rand(n) < 0.5\n            x_b[mask_swap] = np.random.uniform(0.1, 0.9, mask_swap.sum())\n            y_b[~mask_swap] = np.random.uniform(0.1, 0.9, (~mask_swap).sum())\n            centers[i, :, 0] = x_b\n            centers[i, :, 1] = y_b\n            radii[i] = np.random.uniform(0.03, 0.08, n)\n        else:\n            # Complete unstructured randomized continuous domain \n            centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            radii[i] = np.random.uniform(0.02, 0.1, n)\n\n    # State parameters initialized optimally for standard continuous gradient limits \n    lr = 0.015\n    beta1, beta2 = 0.9, 0.999\n    m_c, v_c = np.zeros_like(centers), np.zeros_like(centers)\n    m_r, v_r = np.zeros_like(radii), np.zeros_like(radii)\n\n    steps = 2000\n    idx_arr = np.arange(n)\n\n    # Perform strict scheduled optimization directly integrating spatial intersections \n    for t in range(1, steps + 1):\n        if t <= 500:\n            lambda_p, lr = 15.0, 0.012\n        elif t <= 1000:\n            lambda_p, lr = 50.0, 0.005\n        elif t <= 1500:\n            lambda_p, lr = 250.0, 0.002\n        else:\n            lambda_p, lr = 2000.0, 0.001\n\n        # Intentionally break exact grid locking occasionally to help gradients map organically \n        if t < 1500 and t % 150 == 0:\n            centers += np.random.normal(0, 0.002, size=centers.shape)\n\n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n\n        diff = centers[:, :, None, :] - centers[:, None, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        dist[:, idx_arr, idx_arr] = 1.0  \n\n        overlap = radii[:, :, None] + radii[:, None, :] - dist\n        overlap[:, idx_arr, idx_arr] = -1.0\n        mask_over = overlap > 0\n\n        if np.any(mask_over):\n            pen = overlap * mask_over\n            grad_r += np.sum(lambda_p * 2 * pen, axis=2)\n\n            dist_safe = np.maximum(dist, 1e-12)\n            inv_dist = 1.0 / dist_safe\n            force = lambda_p * 2 * pen * inv_dist\n\n            grad_c -= np.einsum('bij,bijk->bik', force, diff)\n\n        # Force penalties preventing intersections directly passing bounds geometry\n        x = centers[:, :, 0]\n        y = centers[:, :, 1]\n\n        d_lx = radii - x\n        m_lx = d_lx > 0\n        grad_r[m_lx] += lambda_p * 2 * d_lx[m_lx]\n        grad_c[m_lx, 0] -= lambda_p * 2 * d_lx[m_lx]\n\n        d_rx = x + radii - 1.0\n        m_rx = d_rx > 0\n        grad_r[m_rx] += lambda_p * 2 * d_rx[m_rx]\n        grad_c[m_rx, 0] += lambda_p * 2 * d_rx[m_rx]\n\n        d_by = radii - y\n        m_by = d_by > 0\n        grad_r[m_by] += lambda_p * 2 * d_by[m_by]\n        grad_c[m_by, 1] -= lambda_p * 2 * d_by[m_by]\n\n        d_ty = y + radii - 1.0\n        m_ty = d_ty > 0\n        grad_r[m_ty] += lambda_p * 2 * d_ty[m_ty]\n        grad_c[m_ty, 1] += lambda_p * 2 * d_ty[m_ty]\n\n        m_nr = radii < 1e-3\n        grad_r[m_nr] += lambda_p * 2 * (radii[m_nr] - 1e-3)\n\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_hat_c = m_c / (1 - beta1 ** t)\n        v_hat_c = v_c / (1 - beta2 ** t)\n        centers -= lr * m_hat_c / (np.sqrt(v_hat_c) + 1e-8)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_hat_r = m_r / (1 - beta1 ** t)\n        v_hat_r = v_r / (1 - beta2 ** t)\n        radii -= lr * m_hat_r / (np.sqrt(v_hat_r) + 1e-8)\n\n    # Safe deterministic resolution guaranteeing valid solutions globally structurally strict limits\n    for _ in range(150):\n        diff = centers[:, :, None, :] - centers[:, None, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        dist[:, idx_arr, idx_arr] = np.inf\n        overlap = radii[:, :, None] + radii[:, None, :] - dist\n        \n        if np.max(overlap) <= 0.0:\n            break\n\n        mask_over = overlap > 0\n        overlap[~mask_over] = 0.0\n        shrinkage = np.sum((overlap / 2.0) + 1e-9, axis=2)\n        radii -= shrinkage * 0.5\n        radii = np.maximum(radii, 1e-5)\n\n    # Ultimate exact scaling ensuring no intersections logically identical to precision parameters mathematically smoothly mapping flawlessly!\n    diff = centers[:, :, None, :] - centers[:, None, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, idx_arr, idx_arr] = np.inf\n    overlap = radii[:, :, None] + radii[:, None, :] - dist\n    mask_over = overlap > 0\n\n    sum_r = radii[:, :, None] + radii[:, None, :]\n    safe_sum_r = np.maximum(sum_r, 1e-12)\n    scales = dist / safe_sum_r\n    scales[~mask_over] = 1.0\n    radii *= np.min(scales, axis=2) * 0.9999999\n\n    x = centers[:, :, 0]\n    y = centers[:, :, 1]\n    radii = np.minimum(radii, x)\n    radii = np.minimum(radii, 1.0 - x)\n    radii = np.minimum(radii, y)\n    radii = np.minimum(radii, 1.0 - y)\n    radii = np.maximum(radii, 1e-5)\n\n    valid_radii_sum = np.sum(radii, axis=1)\n    best_idx = np.argmax(valid_radii_sum)\n\n    best_c = centers[best_idx].copy()\n    best_r = radii[best_idx].copy()\n\n    # Utilize linear programming identically correctly resolving bounds directly correctly smoothly identically optimal smoothly flawlessly\n    try:\n        from scipy.optimize import linprog\n        A_ub = []\n        b_ub = []\n\n        for i in range(n):\n            row_l = np.zeros(n); row_l[i] = 1.0\n            A_ub.append(row_l); b_ub.append(best_c[i, 0])\n\n            row_r = np.zeros(n); row_r[i] = 1.0\n            A_ub.append(row_r); b_ub.append(1.0 - best_c[i, 0])\n\n            row_b = np.zeros(n); row_b[i] = 1.0\n            A_ub.append(row_b); b_ub.append(best_c[i, 1])\n\n            row_t = np.zeros(n); row_t[i] = 1.0\n            A_ub.append(row_t); b_ub.append(1.0 - best_c[i, 1])\n\n            for j in range(i + 1, n):\n                dist_val = np.hypot(best_c[i, 0] - best_c[j, 0], best_c[i, 1] - best_c[j, 1])\n                row_ij = np.zeros(n)\n                row_ij[i] = 1.0\n                row_ij[j] = 1.0\n                A_ub.append(row_ij)\n                b_ub.append(dist_val)\n\n        c_obj = -np.ones(n)\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=(1e-5, None), method='highs')\n        if res.success:\n            best_r = res.x * 0.999999\n            valid_radii_sum[best_idx] = np.sum(best_r)\n    except Exception:\n        pass\n\n    return best_c, best_r, valid_radii_sum[best_idx]\n\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)"]}}, "artifacts_json": "{\"execution_time\": \"6.57s\", \"stage\": \"quick_validation\", \"packing_summary\": \"Sum of radii: 2.629327/2.635 = 0.9978\", \"validation_report\": \"Valid: True, Violations: 0 boundary, 0 overlaps\", \"stdout\": \"Excellent packing! Achieved 99.8% of target value\", \"radius_stats\": \"Min: 0.069768, Max: 0.135607, Avg: 0.101128\"}", "artifact_dir": null, "embedding": null}