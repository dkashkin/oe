{"id": "2829965c-fde2-48b0-9f65-8e589850f056", "code": "# EVOLVE-BLOCK-START\nimport numpy as np\nimport warnings\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimal arrangement of 26 circles using batched Adam \n    continuous physics simulation combined with varied topological layouts, \n    refined via strict LinProg evaluation to exactly bind boundaries.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    np.random.seed(42)  \n    \n    N = 26\n    B = 160\n    \n    X = np.zeros((B, N), dtype=float)\n    Y = np.zeros((B, N), dtype=float)\n    R = np.full((B, N), 0.05, dtype=float)\n\n    # Inject varied topological structures structurally into parallel branches\n    for idx in range(B):\n        mode = idx % 6\n        if mode == 0:\n            X[idx] = np.random.uniform(0.1, 0.9, N)\n            Y[idx] = np.random.uniform(0.1, 0.9, N)\n            R[idx] = np.random.uniform(0.01, 0.1, N)\n        elif mode == 1:\n            X[idx, 0], Y[idx, 0] = 0.5, 0.5\n            R[idx, 0] = 0.2\n            angles8 = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angles17 = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            X[idx, 1:9] = 0.5 + 0.22 * np.cos(angles8)\n            Y[idx, 1:9] = 0.5 + 0.22 * np.sin(angles8)\n            X[idx, 9:] = 0.5 + 0.44 * np.cos(angles17)\n            Y[idx, 9:] = 0.5 + 0.44 * np.sin(angles17)\n            X[idx] += np.random.normal(0, 0.015, N)\n            Y[idx] += np.random.normal(0, 0.015, N)\n        elif mode == 2:\n            gx, gy = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 5))\n            X[idx, :25] = gx.ravel()\n            Y[idx, :25] = gy.ravel()\n            X[idx, 25], Y[idx, 25] = np.random.uniform(0.3, 0.7), np.random.uniform(0.3, 0.7)\n            R[idx] = 0.08\n            X[idx] += np.random.normal(0, 0.02, N)\n            Y[idx] += np.random.normal(0, 0.02, N)\n        elif mode == 3:\n            pts = [[cx, cy] for cx in [0.08, 0.92] for cy in [0.08, 0.92]]\n            pts += [[cx, 0.5] for cx in [0.08, 0.92]] + [[0.5, cy] for cy in [0.08, 0.92]]\n            pts = np.array(pts)\n            num_pts = len(pts)\n            X[idx, :num_pts], Y[idx, :num_pts] = pts[:, 0], pts[:, 1]\n            R[idx, :num_pts] = 0.07\n            X[idx, num_pts:] = np.random.uniform(0.2, 0.8, N - num_pts)\n            Y[idx, num_pts:] = np.random.uniform(0.2, 0.8, N - num_pts)\n            R[idx, num_pts:] = np.random.uniform(0.02, 0.05, N - num_pts)\n        elif mode == 4:\n            X[idx, 0], Y[idx, 0] = 0.5, 0.5\n            for layer, count in enumerate([6, 12, 7], 1):\n                start = 1 if layer == 1 else (7 if layer == 2 else 19)\n                radius = 0.15 * layer\n                ang = np.linspace(0, 2 * np.pi, count, endpoint=False) + (0.1 * layer)\n                X[idx, start:start+count] = 0.5 + radius * np.cos(ang)\n                Y[idx, start:start+count] = 0.5 + radius * np.sin(ang)\n            X[idx] += np.random.normal(0, 0.02, N)\n            Y[idx] += np.random.normal(0, 0.02, N)\n        else:\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for k in range(N):\n                r_spr = np.sqrt((k + 0.5) / N) * 0.44\n                X[idx, k] = 0.5 + r_spr * np.cos(k * phi)\n                Y[idx, k] = 0.5 + r_spr * np.sin(k * phi)\n            X[idx] += np.random.normal(0, 0.015, N)\n            Y[idx] += np.random.normal(0, 0.015, N)\n            \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_initial, lr_final = 0.02, 0.001\n    C_initial, C_final = 10.0, 100000.0\n    steps = 3500\n    idx_diag = np.arange(N)\n\n    # Batched iterative simulated continuous optimization strictly mapping arrays locally\n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        lambda_p = C_initial * (C_final / C_initial) ** frac\n        \n        # Shake arrays directly introducing perturbation escapes randomly explicitly  \n        if t % 250 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1) < 0.6\n            X += np.random.normal(0, 0.003, (B, N)) * mask\n            Y += np.random.normal(0, 0.003, (B, N)) * mask\n            R += np.random.normal(0, 0.002, (B, N)) * mask\n            \n        dx = X[:, :, None] - X[:, None, :]\n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        dist = np.sqrt(dist_sq)\n        dist_nz = np.where(dist == 0, 1e-8, dist)\n        \n        overlap = R[:, :, None] + R[:, None, :] - dist\n        overlap = np.maximum(0, overlap)\n        overlap[:, idx_diag, idx_diag] = 0.0\n        \n        ol = np.maximum(0, R - X)\n        or_ = np.maximum(0, X + R - 1.0)\n        ob = np.maximum(0, R - Y)\n        ot = np.maximum(0, Y + R - 1.0)\n        \n        grad_R = -1.0 + 2.0 * lambda_p * (np.sum(overlap, axis=2) + ol + or_ + ob + ot)\n        \n        fx = overlap * dx / dist_nz\n        fy = overlap * dy / dist_nz\n        \n        grad_X = 2.0 * lambda_p * (-np.sum(fx, axis=2) - ol + or_)\n        grad_Y = 2.0 * lambda_p * (-np.sum(fy, axis=2) - ob + ot)\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        X -= lr * (m_X / (1 - beta1**t)) / (np.sqrt(v_X / (1 - beta2**t)) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        Y -= lr * (m_Y / (1 - beta1**t)) / (np.sqrt(v_Y / (1 - beta2**t)) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        R -= lr * (m_R / (1 - beta1**t)) / (np.sqrt(v_R / (1 - beta2**t)) + 1e-8)\n        \n        X = np.clip(X, 1e-4, 1.0 - 1e-4)\n        Y = np.clip(Y, 1e-4, 1.0 - 1e-4)\n        R = np.clip(R, 1e-5, 0.5)\n\n    approx_score = np.zeros(B)\n    for m in range(B):\n        r_m = R[m].copy()\n        x_m, y_m = X[m], Y[m]\n        \n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        \n        d = np.linalg.norm(np.stack([x_m, y_m], axis=-1)[:, None, :] - np.stack([x_m, y_m], axis=-1)[None, :, :], axis=-1)\n        np.fill_diagonal(d, np.inf)\n        \n        for _ in range(25):\n            viol = r_m[:, None] + r_m[None, :] - d\n            if not np.any(viol > 0): break\n            for i in range(N):\n                for j in range(i+1, N):\n                    if viol[i, j] > 0:\n                        s = (viol[i, j] / 2.0) + 1e-7\n                        r_m[i] -= s\n                        r_m[j] -= s\n        approx_score[m] = np.sum(np.maximum(r_m, 0.0))\n\n    top_idx = np.argsort(approx_score)[-45:]\n\n    c_vec = -np.ones(N)\n    num_constraints = 4 * N + N * (N - 1) // 2\n    A_ub = np.zeros((num_constraints, N), dtype=float)\n\n    idx_con = 0\n    for i in range(N):\n        A_ub[idx_con:idx_con+4, i] = 1.0\n        idx_con += 4\n\n    i_idx, j_idx = np.triu_indices(N, k=1)\n    for i, j in zip(i_idx, j_idx):\n        A_ub[idx_con, i] = 1.0\n        A_ub[idx_con, j] = 1.0\n        idx_con += 1\n\n    def get_exact_radii(c_arr):\n        \"\"\"Map strictly globally bounded layouts securely valid natively reliably.\"\"\"\n        b_ub = np.zeros(num_constraints, dtype=float)\n        b_ub[0:4*N:4] = c_arr[:, 0]\n        b_ub[1:4*N:4] = 1.0 - c_arr[:, 0]\n        b_ub[2:4*N:4] = c_arr[:, 1]\n        b_ub[3:4*N:4] = 1.0 - c_arr[:, 1]\n        \n        dx_val = c_arr[:, None, 0] - c_arr[None, :, 0]\n        dy_val = c_arr[:, None, 1] - c_arr[None, :, 1]\n        dist_mat = np.sqrt(dx_val**2 + dy_val**2)\n        b_ub[4*N:] = dist_mat[i_idx, j_idx]\n        \n        try:\n            res = linprog(c_vec, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n            if res.success:\n                return res.x * 0.999999, -res.fun * 0.999999\n        except Exception:\n            pass\n        return None, -1.0\n\n    best_m_sum = -1.0\n    best_m_c, best_m_r = None, None\n\n    for m in top_idx[::-1]:\n        c_m = np.column_stack((X[m], Y[m]))\n        r_exact, sum_exact = get_exact_radii(c_m)\n        if sum_exact > best_m_sum:\n            best_m_sum = sum_exact\n            best_m_c = c_m\n            best_m_r = r_exact\n\n    # Centralize steep coordinate adjustments securely maintaining completely identical parameters cleanly valid smoothly \n    if best_m_c is not None:\n        curr_c, curr_sum, curr_r = best_m_c.copy(), best_m_sum, best_m_r.copy()\n        \n        m_t, v_t = np.zeros_like(curr_c), np.zeros_like(curr_c)\n        beta1_ls, beta2_ls = 0.9, 0.999\n        \n        def compute_finite_diff(arr, base_s, eps=1e-5):\n            g = np.zeros_like(arr)\n            for i in range(N):\n                for d in range(2):\n                    tmp = arr.copy()\n                    tmp[i, d] += eps\n                    _, val = get_exact_radii(tmp)\n                    if val != -1.0:\n                        g[i, d] = (val - base_s) / eps\n            return g\n\n        for step in range(40):\n            g = compute_finite_diff(curr_c, curr_sum, eps=1e-5)\n            \n            m_t = beta1_ls * m_t + (1 - beta1_ls) * g\n            v_t = beta2_ls * v_t + (1 - beta2_ls) * g**2\n            m_hat = m_t / (1 - beta1_ls**(step + 1))\n            v_hat = v_t / (1 - beta2_ls**(step + 1))\n            \n            lr_ls = 0.003 * (1.0 - step / 40.0)\n            base_cand = curr_c + lr_ls * m_hat / (np.sqrt(v_hat) + 1e-8)\n            base_cand = np.clip(base_cand, 0.01, 0.99)\n            \n            improved = False\n            for alpha in [1.0, 0.5, 0.2]:\n                c_cand = curr_c + alpha * (base_cand - curr_c)\n                r_cand, s_cand = get_exact_radii(c_cand)\n                if s_cand > curr_sum:\n                    curr_sum = s_cand\n                    curr_c = c_cand\n                    curr_r = r_cand\n                    improved = True\n                    break\n                    \n            if not improved:\n                c_rand = curr_c + np.random.normal(0, 0.0003, size=curr_c.shape)\n                c_rand = np.clip(c_rand, 0.01, 0.99)\n                r_rand, s_rand = get_exact_radii(c_rand)\n                if s_rand > curr_sum:\n                    curr_sum, curr_c, curr_r = s_rand, c_rand, r_rand\n                    m_t.fill(0.0)\n                    v_t.fill(0.0)\n                    \n        return curr_c, curr_r, curr_sum\n\n    return np.column_stack((X[0], Y[0])), R[0], 0.0\n# EVOLVE-BLOCK-END", "changes_description": null, "language": "python", "parent_id": "6d8cd50e-f467-4fd8-97de-fddffa4aea74", "generation": 3, "timestamp": 1772004328.9995742, "iteration_found": 23, "metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"validity": 1.0, "sum_radii": 2.628055920133247, "target_ratio": 0.99736467557239, "combined_score": 0.99736467557239, "radius_variance": 0.004304962631760404, "spatial_spread": 0.18700663587118757, "eval_time": 9.191513061523438}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Placement by size: consider placing larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.9974\n- Feature coordinates: \n- Focus areas: - Fitness improved: 0.9435 \u2192 0.9974\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### execution_time\n```\n9.19s\n```\n\n### stage\n```\nquick_validation\n```\n\n### packing_summary\n```\nSum of radii: 2.628056/2.635 = 0.9974\n```\n\n### validation_report\n```\nValid: True, Violations: 0 boundary, 0 overlaps\n```\n\n### stdout\n```\nExcellent packing! Achieved 99.7% of target value\n```\n\n### radius_stats\n```\nMin: 0.072616, Max: 0.142638, Avg: 0.101079\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.4860, target_ratio: 0.9435, combined_score: 0.9435, radius_variance: 0.0054, spatial_spread: 0.1927, eval_time: 2.0613\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6262, target_ratio: 0.9967, combined_score: 0.9967, radius_variance: 0.0043, spatial_spread: 0.1870, eval_time: 7.1213\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: validity: 1.0000, sum_radii: 2.6281, target_ratio: 0.9974, combined_score: 0.9974, radius_variance: 0.0043, spatial_spread: 0.1870, eval_time: 9.1915\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9974)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Hybrid Adam optimization coupled with Highs Exact-LinProg GD Local Search for circular packing.\"\"\"\nimport numpy as np\nimport warnings\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged layout using an extensive parallel physics\n    tensor optimizer, followed by a local coordinate ascent solver on the true exact linear\n    radius-sum objective function map.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    np.random.seed(42)  \n    N = 26\n    M = 100 \n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Heuristically structured seed injection to navigate topology combinations intelligently \n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Batched vectorized tensor optimization on the soft physical relaxation properties \n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0)\n        \n        mask_x0 = R > X\n        grad_pen = lambda_p * 2 * (R[mask_x0] - X[mask_x0])\n        grad_R[mask_x0] += grad_pen\n        grad_X[mask_x0] -= grad_pen\n        \n        mask_x1 = (X + R) > 1.0\n        grad_pen = lambda_p * 2 * (X[mask_x1] + R[mask_x1] - 1.0)\n        grad_R[mask_x1] += grad_pen\n        grad_X[mask_x1] += grad_pen\n        \n        mask_y0 = R > Y\n        grad_pen = lambda_p * 2 * (R[mask_y0] - Y[mask_y0])\n        grad_R[mask_y0] += grad_pen\n        grad_Y[mask_y0] -= grad_pen\n        \n        mask_y1 = (Y + R) > 1.0\n        grad_pen = lambda_p * 2 * (Y[mask_y1] + R[mask_y1] - 1.0)\n        grad_R[mask_y1] += grad_pen\n        grad_Y[mask_y1] += grad_pen\n        \n        dx_val = X[:, :, None] - X[:, None, :] \n        dy_val = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx_val**2 + dy_val**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen_ov = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            np.add.at(grad_R, (sm, si), grad_pen_ov)\n            np.add.at(grad_R, (sm, sj), grad_pen_ov)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen_ov * dx_val[mask_over] * inv_dist\n            grad_yi = -grad_pen_ov * dy_val[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        X -= lr * (m_X / (1 - beta1**adam_step)) / (np.sqrt(v_X / (1 - beta2**adam_step)) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        Y -= lr * (m_Y / (1 - beta1**adam_step)) / (np.sqrt(v_Y / (1 - beta2**adam_step)) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        R -= lr * (m_R / (1 - beta1**adam_step)) / (np.sqrt(v_R / (1 - beta2**adam_step)) + 1e-8)\n\n    # Topological assessment efficiently resolving internal structural candidate qualities safely\n    approx_score = np.zeros(M)\n    for m in range(M):\n        r_m = np.clip(R[m], 0.0, None)\n        x_m = X[m]\n        y_m = Y[m]\n        \n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        \n        for _ in range(4):\n            sum_r = r_m[:, None] + r_m[None, :]\n            viol = sum_r - dist[m]\n            mask_viol = viol > 0\n            if not np.any(mask_viol & triu_mask[0]): \n                break\n            for i in range(N):\n                for j in range(i+1, N):\n                    if viol[i, j] > 0:\n                        s = (viol[i, j] / 2.0) + 1e-7\n                        r_m[i] -= s\n                        r_m[j] -= s\n        approx_score[m] = np.sum(r_m)\n\n    top_candidates = np.argsort(approx_score)[-35:]\n    \n    # Pre-allocate strict constraints mapped inherently for the Highs linear mathematical operations reliably  \n    c_vec = -np.ones(N)\n    num_constraints = 4 * N + N * (N - 1) // 2\n    A_ub = np.zeros((num_constraints, N), dtype=float)\n\n    idx_con = 0\n    for i in range(N):\n        A_ub[idx_con:idx_con+4, i] = 1.0\n        idx_con += 4\n\n    i_idx, j_idx = np.triu_indices(N, 1)\n    for i, j in zip(i_idx, j_idx):\n        A_ub[idx_con, i] = 1.0\n        A_ub[idx_con, j] = 1.0\n        idx_con += 1\n\n    def get_exact_radii(c_arr):\n        \"\"\"Solve exactly for globally guaranteed optimal radii arrays for arbitrary defined configurations natively\"\"\"\n        b_ub = np.zeros(num_constraints, dtype=float)\n        b_ub[0:4*N:4] = c_arr[:, 0]\n        b_ub[1:4*N:4] = 1.0 - c_arr[:, 0]\n        b_ub[2:4*N:4] = c_arr[:, 1]\n        b_ub[3:4*N:4] = 1.0 - c_arr[:, 1]\n        \n        dx = c_arr[:, None, 0] - c_arr[None, :, 0]\n        dy = c_arr[:, None, 1] - c_arr[None, :, 1]\n        dist_mat = np.sqrt(dx**2 + dy**2)\n        b_ub[4*N:] = dist_mat[i_idx, j_idx]\n        \n        try:\n            res = linprog(c_vec, A_ub=A_ub, b_ub=b_ub, bounds=(1e-6, None), method='highs')\n            if res.success:\n                return res.x * 0.999999, -res.fun * 0.999999\n        except Exception:\n            pass\n        return None, -1.0\n\n    best_m_sum = -1.0\n    best_m_c = None\n    best_m_r = None\n\n    for m in top_candidates[::-1]:\n        c_m = np.column_stack((X[m], Y[m]))\n        r_exact, sum_exact = get_exact_radii(c_m)\n        if sum_exact > best_m_sum:\n            best_m_sum = sum_exact\n            best_m_c = c_m\n            best_m_r = r_exact\n\n    # Exact function finite-difference localized mapping optimization gradient efficiently \n    if best_m_c is not None:\n        curr_c = best_m_c.copy()\n        curr_sum = best_m_sum\n        curr_r = best_m_r.copy()\n        \n        m_t = np.zeros_like(curr_c)\n        v_t = np.zeros_like(curr_c)\n        beta1_ls = 0.9\n        beta2_ls = 0.999\n        \n        def get_grad(arr, base_val, eps=1e-5):\n            grad = np.zeros_like(arr)\n            for i in range(N):\n                for d in range(2):\n                    tmp = arr.copy()\n                    tmp[i, d] += eps\n                    _, val_pert = get_exact_radii(tmp)\n                    if val_pert != -1.0:\n                        grad[i, d] = (val_pert - base_val) / eps\n            return grad\n\n        for step in range(35):\n            g = get_grad(curr_c, curr_sum, eps=1e-5)\n            m_t = beta1_ls * m_t + (1 - beta1_ls) * g\n            v_t = beta2_ls * v_t + (1 - beta2_ls) * g**2\n            \n            m_hat = m_t / (1 - beta1_ls**(step + 1))\n            v_hat = v_t / (1 - beta2_ls**(step + 1))\n            \n            lr_ls = 0.005 * (1.0 - step / 35.0)\n            c_cand = curr_c + lr_ls * m_hat / (np.sqrt(v_hat) + 1e-8)\n            c_cand = np.clip(c_cand, 0.01, 0.99)\n            \n            r_cand, s_cand = get_exact_radii(c_cand)\n            if s_cand > curr_sum:\n                curr_sum = s_cand\n                curr_c = c_cand\n                curr_r = r_cand\n            else:\n                c_rand = curr_c + np.random.normal(0, 0.0003, size=curr_c.shape)\n                c_rand = np.clip(c_rand, 0.01, 0.99)\n                r_rand, s_rand = get_exact_radii(c_rand)\n                if s_rand > curr_sum:\n                    curr_sum = s_rand\n                    curr_c = c_rand\n                    curr_r = r_rand\n                    m_t.fill(0.0)\n                    v_t.fill(0.0)\n                    \n        return curr_c, curr_r, curr_sum\n\n    return np.column_stack((X[0], Y[0])), R[0], 0.0\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6281), Performs well on target_ratio (0.9974), Performs well on combined_score (0.9974), Performs well on radius_variance (0.0043), Performs well on spatial_spread (0.1870), Performs well on eval_time (9.1915)\n\n### Program 2 (Score: 0.9967)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to mathematically maximize the summation of radii natively utilizing\n    an Adam-guided gradient physics continuous domain solver on structured parallel arrays.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) perfectly bounding into the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    np.random.seed(42)  # Secure consistent highest deterministic result \n    N = 26\n    M = 100  # Broadly simulate over vast chaotic starting layouts\n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Smart heuristics - Bias seeding structure variations dynamically\n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            # Tightly placed Vogel spiral (seed density organically spreads to margins)\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            # Highly concentric shell layout prioritizing massive inner radius\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                # Interstitial snapping heuristics placing to hard exterior boundings \n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                # Radial dispersion bias\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                # Centric dominant growth with tight marginal jiggling\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                # Jittered grid intersections scaling towards gaps\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Custom vectorized gradient constraint minimizer (Adam framework on physics domain)\n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        # Stepped learning adjustments akin to schedule decay routines\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        # Break perfect locking by invoking randomized infinitesimal space perturbations\n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0) # Derivative pulls directly outwards to organically scale bubble size\n        \n        # Boundary physics penalties handling\n        diff_x0 = R - X\n        mask = diff_x0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x0[mask]\n        grad_X[mask] -= lambda_p * 2 * diff_x0[mask]\n        \n        diff_x1 = X + R - 1.0\n        mask = diff_x1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x1[mask]\n        grad_X[mask] += lambda_p * 2 * diff_x1[mask]\n        \n        diff_y0 = R - Y\n        mask = diff_y0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y0[mask]\n        grad_Y[mask] -= lambda_p * 2 * diff_y0[mask]\n        \n        diff_y1 = Y + R - 1.0\n        mask = diff_y1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y1[mask]\n        grad_Y[mask] += lambda_p * 2 * diff_y1[mask]\n        \n        # Internal circular compression handling mathematically computed in simultaneous tensors\n        dx = X[:, :, None] - X[:, None, :] \n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            \n            np.add.at(grad_R, (sm, si), grad_pen)\n            np.add.at(grad_R, (sm, sj), grad_pen)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen * dx[mask_over] * inv_dist\n            grad_yi = -grad_pen * dy[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        # Bottom threshold clipping parameter natively forcing radii sizes positively stable \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_hat_X = m_X / (1 - beta1**adam_step)\n        v_hat_X = v_X / (1 - beta2**adam_step)\n        X -= lr * m_hat_X / (np.sqrt(v_hat_X) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        m_hat_Y = m_Y / (1 - beta1**adam_step)\n        v_hat_Y = v_Y / (1 - beta2**adam_step)\n        Y -= lr * m_hat_Y / (np.sqrt(v_hat_Y) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_hat_R = m_R / (1 - beta1**adam_step)\n        v_hat_R = v_R / (1 - beta2**adam_step)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n\n    # Clean deterministic loop securing valid 0-bound overlapping resolutions smoothly\n    valid_radii_sum = np.zeros(M)\n    for m in range(M):\n        r_m = R[m].copy()\n        x_m = X[m].copy()\n        y_m = Y[m].copy()\n        \n        # Soft iterations allowing fluid convergence without boundary distortions\n        for _ in range(200):\n            max_viol = 0.0\n            for i in range(N):\n                for j in range(i+1, N):\n                    d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                    viol = r_m[i] + r_m[j] - d\n                    if viol > 0.0:\n                        if viol > max_viol: \n                            max_viol = viol\n                        sub = (viol / 2.0) + 1e-9\n                        r_m[i] -= sub\n                        r_m[j] -= sub\n            if max_viol <= 0.0:\n                break\n                \n        # Defensive absolute fail-safe pass proportionally shrinking perfectly maintaining layout distances natively\n        for i in range(N):\n            for j in range(i+1, N):\n                d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                if r_m[i] + r_m[j] > d:\n                    scale = d / (r_m[i] + r_m[j]) * 0.999999\n                    if scale < 1.0:\n                        r_m[i] *= scale\n                        r_m[j] *= scale\n        \n        # Safely enforce bounding clips locking strict internal box adherence\n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        r_m = np.maximum(r_m, 1e-5)\n        \n        valid_radii_sum[m] = np.sum(r_m)\n        R[m] = r_m \n        \n    best_idx = np.argmax(valid_radii_sum)\n    final_centers = np.stack((X[best_idx], Y[best_idx]), axis=1)\n    final_radii = R[best_idx]\n    \n    return final_centers, final_radii, valid_radii_sum[best_idx]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.6262), Performs well on target_ratio (0.9967), Performs well on combined_score (0.9967), Performs well on radius_variance (0.0043), Performs well on spatial_spread (0.1870), Performs well on eval_time (7.1213)\n\n### Program 3 (Score: 0.9435)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles using physics optimization and annealing\"\"\"\nimport numpy as np\n\n\ndef compute_gradients(centers, radii, C):\n    \"\"\"Compute exact vectorized gradients for the circles based on overlap penalty constraints\"\"\"\n    grad_c = np.zeros_like(centers)\n    grad_r = np.full_like(radii, -1.0)  # Optimize to maximize sum(r) -> derivative of -sum(r)\n    \n    diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    # Avoid zero-distance divide errors explicitly via float safety bounds\n    dist = np.maximum(dist, 1e-8)\n    np.fill_diagonal(dist, 1.0)\n    \n    # Compute intersection overlap bounds and pairwise force repulsion masks\n    rad_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n    overlap = rad_sum - dist\n    np.fill_diagonal(overlap, 0.0)\n    \n    mask = overlap > 0\n    grad_r += np.sum(2.0 * C * overlap * mask, axis=1)\n    \n    factor = np.zeros_like(overlap)\n    factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n    \n    # Efficient pairwise repulsion calculations resolving directly using eignsum accumulation\n    grad_c -= np.einsum('ij,ijk->ik', factor, diff)\n    \n    # Left wall bounds validation penalty mechanism \n    overlap_left = radii - centers[:, 0]\n    mask_l = overlap_left > 0\n    grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n    grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n    \n    # Right wall bounds validation penalty mechanism \n    overlap_right = centers[:, 0] + radii - 1.0\n    mask_r = overlap_right > 0\n    grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n    grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n    \n    # Bottom wall bounds validation penalty mechanism \n    overlap_bot = radii - centers[:, 1]\n    mask_b = overlap_bot > 0\n    grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n    grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n    \n    # Top wall bounds validation penalty mechanism \n    overlap_top = centers[:, 1] + radii - 1.0\n    mask_t = overlap_top > 0\n    grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n    grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n    \n    return grad_c, grad_r\n\n\ndef adam_optimizer(n, init_centers, init_radii, steps=3000):\n    \"\"\"Executes smooth continuous annealing simulation matching physics engine properties\"\"\"\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Fine-tuned exponential decay constraints (similar to annealing schedules)\n    lr_initial = 0.015\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 100000.0\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        # Break perfect symmetry to escape topological grid deadlocks\n        if t % 500 == 0 and t < steps * 0.5:\n            centers += np.random.normal(0, 0.005, size=(n, 2))\n        \n        grad_c, grad_r = compute_gradients(centers, radii, C)\n        \n        # Moment and bias accumulations mapping smoothly to topological surfaces\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-6, 1.0 - 1e-6)\n        radii = np.clip(radii, 1e-6, 1.0)\n        \n    return centers, radii\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Handles mathematically valid strictly constrained radius fallbacks completely independently\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict bounds mathematically identical to target thresholds checking valid sizes exactly\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Generates an exceptionally robust and rigorously checked completely valid packing radius constraint.\"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        # Enforce all geometric exterior mapping limits globally utilizing bounding offsets natively \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        # Internal space limits exactly matching pairwise non-overlapping definitions mapping completely natively\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef construct_packing():\n    \"\"\"\n    Construct iteratively improved packings deploying simulated physics gradients with dynamic bounding heuristics\n    to guarantee globally effective area occupancy while retaining maximum stability features smoothly fitting geometries\n    \"\"\"\n    n = 26\n    best_centers = None\n    best_radii = None\n    max_sum = -1.0\n    \n    # Explores topological search tree combinations comprehensively testing symmetric structures fully scaling to solutions \n    for seed in range(4):\n        np.random.seed(42 + seed)\n        centers = np.zeros((n, 2))\n        radii = np.ones(n) * 0.05\n        \n        if seed == 0:\n            # Seed positions heuristically mapping optimal interstitial gap combinations directly applying size constraints appropriately \n            centers[0] = [0.5, 0.5]\n            radii[0] = 0.15\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for i in range(4):\n                centers[i + 1] = corners[i]\n                radii[i + 1] = 0.08\n            edges = [[0.5, 0.1], [0.5, 0.9], [0.1, 0.5], [0.9, 0.5]]\n            for i in range(4):\n                centers[i + 5] = edges[i]\n                radii[i + 5] = 0.08\n            centers[9:] = np.random.uniform(0.1, 0.9, (17, 2))\n            radii[9:] = np.random.uniform(0.02, 0.08, 17)\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n        elif seed == 1:\n            centers = np.random.uniform(0.1, 0.9, (n, 2))\n            radii = np.random.uniform(0.01, 0.1, n)\n        elif seed == 2:\n            grid_x, grid_y = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 6))\n            centers[:25, 0] = grid_x.flatten()[:25]\n            centers[:25, 1] = grid_y.flatten()[:25]\n            centers[25] = [0.5, 0.5]\n            centers += np.random.normal(0, 0.02, size=(n, 2))\n        else:\n            centers[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                centers[i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n            for i in range(16):\n                angle = 2 * np.pi * i / 16\n                centers[i + 9] = [0.5 + 0.7 * np.cos(angle), 0.5 + 0.7 * np.sin(angle)]\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n            \n        centers = np.clip(centers, 0.01, 0.99)\n        radii = np.clip(radii, 0.01, 0.2)\n        \n        c_opt, r_opt = adam_optimizer(n, centers, radii, steps=3000)\n        \n        r_exact = get_exact_radii(c_opt, r_opt)\n        current_sum = np.sum(r_exact)\n        \n        if current_sum > max_sum:\n            max_sum = current_sum\n            best_centers = c_opt.copy()\n            best_radii = r_exact.copy()\n            \n    return best_centers, best_radii, max_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nKey features: Performs well on validity (1.0000), Performs well on sum_radii (2.4860), Performs well on target_ratio (0.9435), Performs well on combined_score (0.9435), Performs well on radius_variance (0.0054), Performs well on spatial_spread (0.1927), Performs well on eval_time (2.0613)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom scipy.optimize import minimize, linprog, LinearConstraint, NonlinearConstraint\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Fallback iteratively shrinking radii avoiding pairwise bound exceptions completely securely\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict scaling explicit limits identical natively limits bounds check completely correctly structurally natively!\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Exact mathematically verified linprog ensuring zero bound overlapping limits seamlessly optimally globally properly matching perfectly limits bounds completely securely matching flawlessly natively gracefully gracefully identical.\"\"\"\n    n = len(centers)\n    try:\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef optimize_slsqp(c, r, n=26):\n    \"\"\"Refine topological models gracefully appropriately scaling flawlessly completely strictly effectively correctly optimally identically constraints mathematically securely globally smoothly securely perfectly bounds smoothly limits properly!\"\"\"\n    X0 = np.concatenate([c[:, 0], c[:, 1], r])\n    \n    A_lin = np.zeros((4 * n, 3 * n))\n    lb_lin = np.zeros(4 * n)\n    ub_lin = np.zeros(4 * n)\n\n    for i in range(n):\n        # x_i - r_i >= 0\n        A_lin[4 * i, i] = 1\n        A_lin[4 * i, 2 * n + i] = -1\n        lb_lin[4 * i] = 0\n        ub_lin[4 * i] = np.inf\n        \n        # y_i - r_i >= 0\n        A_lin[4 * i + 1, n + i] = 1\n        A_lin[4 * i + 1, 2 * n + i] = -1\n        lb_lin[4 * i + 1] = 0\n        ub_lin[4 * i + 1] = np.inf\n        \n        # x_i + r_i <= 1\n        A_lin[4 * i + 2, i] = 1\n        A_lin[4 * i + 2, 2 * n + i] = 1\n        lb_lin[4 * i + 2] = -np.inf\n        ub_lin[4 * i + 2] = 1.0\n        \n        # y_i + r_i <= 1\n        A_lin[4 * i + 3, n + i] = 1\n        A_lin[4 * i + 3, 2 * n + i] = 1\n        lb_lin[4 * i + 3] = -np.inf\n        ub_lin[4 * i + 3] = 1.0\n\n    lin_cons = LinearConstraint(A_lin, lb_lin, ub_lin)\n\n    def pairwise_constraint(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        dist_sq = (x[idx_i] - x[idx_j])**2 + (y[idx_i] - y[idx_j])**2\n        rad_sq = (r[idx_i] + r[idx_j])**2\n        return dist_sq - rad_sq\n\n    def pairwise_jac(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        num_cons = n * (n - 1) // 2\n        J = np.zeros((num_cons, 3 * n))\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        \n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        dr = r[idx_i] + r[idx_j]\n        \n        J[np.arange(num_cons), idx_i] = 2 * dx\n        J[np.arange(num_cons), idx_j] = -2 * dx\n        J[np.arange(num_cons), n + idx_i] = 2 * dy\n        J[np.arange(num_cons), n + idx_j] = -2 * dy\n        J[np.arange(num_cons), 2 * n + idx_i] = -2 * dr\n        J[np.arange(num_cons), 2 * n + idx_j] = -2 * dr\n        \n        return J\n\n    nonlin_cons = NonlinearConstraint(\n        pairwise_constraint,\n        0.0, np.inf,\n        jac=pairwise_jac\n    )\n\n    def obj(X):\n        return -np.sum(X[2 * n:])\n        \n    def obj_jac(X):\n        grad = np.zeros_like(X)\n        grad[2 * n:] = -1.0\n        return grad\n        \n    bounds = [(0.0, 1.0)] * (2 * n) + [(1e-5, 1.0)] * n\n\n    try:\n        res = minimize(\n            obj, X0, \n            jac=obj_jac,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=[lin_cons, nonlin_cons],\n            options={'maxiter': 250, 'ftol': 1e-6}\n        )\n        X_opt = res.x\n    except Exception:\n        X_opt = X0\n        \n    c_opt = np.column_stack((X_opt[:n], X_opt[n:2 * n]))\n    r_opt = X_opt[2 * n:]\n    return c_opt, r_opt\n\n\ndef batched_adam_optimizer(n, init_centers, init_radii, steps=1000):\n    \"\"\"Leverage vectorized hardware explicitly optimally robustly valid matching identically cleanly scaling perfectly accurately smoothly flawlessly identically bounds appropriately globally precisely perfectly efficiently strictly smoothly structurally optimally natively identical explicitly identical checks cleanly identically securely valid gracefully limits securely accurately gracefully securely securely perfectly strictly!\"\"\"\n    B = init_centers.shape[0]\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    lr_initial = 0.018\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 80000.0\n    \n    idx = np.arange(n)\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        if t % 200 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1, 1) < 0.6\n            centers += np.random.normal(0, 0.005, size=(B, n, 2)) * mask\n        \n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n        \n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :] \n        dist = np.linalg.norm(diff, axis=-1)\n        \n        dist = np.maximum(dist, 1e-8)\n        dist[:, idx, idx] = 1.0 \n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, idx, idx] = 0.0 \n        \n        mask = overlap > 0\n        grad_r += np.sum(2.0 * C * overlap * mask, axis=2)\n        \n        factor = np.zeros_like(overlap)\n        factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n        \n        grad_c -= np.einsum('bij,bijk->bik', factor, diff)\n        \n        overlap_left = radii - centers[:, :, 0]\n        mask_l = overlap_left > 0\n        grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n        grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n        \n        overlap_right = centers[:, :, 0] + radii - 1.0\n        mask_r = overlap_right > 0\n        grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n        grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n        \n        overlap_bot = radii - centers[:, :, 1]\n        mask_b = overlap_bot > 0\n        grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n        grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n        \n        overlap_top = centers[:, :, 1] + radii - 1.0\n        mask_t = overlap_top > 0\n        grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n        grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-5, 1.0 - 1e-5)\n        radii = np.clip(radii, 1e-5, 1.0)\n        \n    return centers, radii\n\n\ndef batched_fallback_radii(centers, target_radii):\n    \"\"\"Vectorized rapid checking ensuring securely robust correctly mapping identically globally precisely efficiently rigorously flawless natively robust checks explicitly effectively constraints smoothly checks identically valid constraints properly gracefully limits identically identical.\"\"\"\n    n = centers.shape[1]\n    radii = target_radii.copy()\n    \n    for _ in range(40):\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n        \n        mask = overlap > 0\n        if not np.any(mask):\n            break\n            \n        correction = np.sum(overlap * mask, axis=2) * 0.35\n        radii -= correction\n        \n    radii = np.clip(radii, 0.0, None)\n    \n    radii = np.minimum(radii, centers[:, :, 0])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 0])\n    radii = np.minimum(radii, centers[:, :, 1])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 1])\n    \n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, np.arange(n), np.arange(n)] = np.inf\n    \n    rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n    rad_sum = np.maximum(rad_sum, 1e-12)\n    \n    scale_matrix = dist / rad_sum\n    min_scale_per_circle = np.min(scale_matrix, axis=-1)\n    final_scales = np.minimum(min_scale_per_circle, 1.0)\n    \n    radii *= final_scales * 0.999999\n    \n    return radii\n\n\ndef construct_packing():\n    \"\"\"Build highly structured topological arrangements robustly resolving strictly bounds successfully securely mapping safely smoothly structurally efficiently explicitly explicitly smoothly flawlessly effectively completely valid precisely smoothly logically.\"\"\"\n    n = 26\n    B = 100\n    init_centers = np.zeros((B, n, 2))\n    init_radii = np.full((B, n), 0.05)\n    \n    np.random.seed(42)\n    \n    for i in range(B):\n        seed_type = i % 5\n        if seed_type == 0:\n            init_centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            init_radii[i] = np.random.uniform(0.02, 0.12, n)\n        elif seed_type == 1:\n            init_centers[i, 0] = [0.5, 0.5]\n            init_radii[i, 0] = np.random.uniform(0.15, 0.25)\n            init_centers[i, 1:] = np.random.uniform(0.1, 0.9, (n - 1, 2))\n            init_radii[i, 1:] = np.random.uniform(0.02, 0.08, n - 1)\n        elif seed_type == 2:\n            nx, ny = 5, 5\n            x, y = np.meshgrid(np.linspace(0.12, 0.88, nx), np.linspace(0.12, 0.88, ny))\n            pts = np.column_stack((x.ravel(), y.ravel()))\n            pts = np.vstack([pts, [0.5, 0.5]])\n            pts += np.random.normal(0, 0.02, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.normal(0.09, 0.015, n)\n        elif seed_type == 3:\n            init_centers[i, 0] = [0.5, 0.5]\n            angles9 = np.linspace(0, 2 * np.pi, 9, endpoint=False)\n            pts9 = np.column_stack([0.5 + 0.25 * np.cos(angles9), 0.5 + 0.25 * np.sin(angles9)])\n            angles16 = np.linspace(0, 2 * np.pi, 16, endpoint=False)\n            pts16 = np.column_stack([0.5 + 0.45 * np.cos(angles16), 0.5 + 0.45 * np.sin(angles16)])\n            pts = np.vstack([[0.5, 0.5], pts9, pts16])\n            pts += np.random.normal(0, 0.015, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.uniform(0.05, 0.1, n)\n        else:\n            pts = []\n            pts.extend([[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nfrom scipy.optimize import minimize, linprog, LinearConstraint, NonlinearConstraint\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Fallback iteratively shrinking radii avoiding pairwise bound exceptions completely securely\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict scaling explicit limits identical natively limits bounds check completely correctly structurally natively!\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Exact mathematically verified linprog ensuring zero bound overlapping limits seamlessly optimally globally properly matching perfectly limits bounds completely securely matching flawlessly natively gracefully gracefully identical.\"\"\"\n    n = len(centers)\n    try:\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef optimize_slsqp(c, r, n=26):\n    \"\"\"Refine topological models gracefully appropriately scaling flawlessly completely strictly effectively correctly optimally identically constraints mathematically securely globally smoothly securely perfectly bounds smoothly limits properly!\"\"\"\n    X0 = np.concatenate([c[:, 0], c[:, 1], r])\n    \n    A_lin = np.zeros((4 * n, 3 * n))\n    lb_lin = np.zeros(4 * n)\n    ub_lin = np.zeros(4 * n)\n\n    for i in range(n):\n        # x_i - r_i >= 0\n        A_lin[4 * i, i] = 1\n        A_lin[4 * i, 2 * n + i] = -1\n        lb_lin[4 * i] = 0\n        ub_lin[4 * i] = np.inf\n        \n        # y_i - r_i >= 0\n        A_lin[4 * i + 1, n + i] = 1\n        A_lin[4 * i + 1, 2 * n + i] = -1\n        lb_lin[4 * i + 1] = 0\n        ub_lin[4 * i + 1] = np.inf\n        \n        # x_i + r_i <= 1\n        A_lin[4 * i + 2, i] = 1\n        A_lin[4 * i + 2, 2 * n + i] = 1\n        lb_lin[4 * i + 2] = -np.inf\n        ub_lin[4 * i + 2] = 1.0\n        \n        # y_i + r_i <= 1\n        A_lin[4 * i + 3, n + i] = 1\n        A_lin[4 * i + 3, 2 * n + i] = 1\n        lb_lin[4 * i + 3] = -np.inf\n        ub_lin[4 * i + 3] = 1.0\n\n    lin_cons = LinearConstraint(A_lin, lb_lin, ub_lin)\n\n    def pairwise_constraint(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        dist_sq = (x[idx_i] - x[idx_j])**2 + (y[idx_i] - y[idx_j])**2\n        rad_sq = (r[idx_i] + r[idx_j])**2\n        return dist_sq - rad_sq\n\n    def pairwise_jac(X):\n        x = X[:n]\n        y = X[n:2 * n]\n        r = X[2 * n:]\n        \n        num_cons = n * (n - 1) // 2\n        J = np.zeros((num_cons, 3 * n))\n        \n        idx_i, idx_j = np.triu_indices(n, k=1)\n        \n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        dr = r[idx_i] + r[idx_j]\n        \n        J[np.arange(num_cons), idx_i] = 2 * dx\n        J[np.arange(num_cons), idx_j] = -2 * dx\n        J[np.arange(num_cons), n + idx_i] = 2 * dy\n        J[np.arange(num_cons), n + idx_j] = -2 * dy\n        J[np.arange(num_cons), 2 * n + idx_i] = -2 * dr\n        J[np.arange(num_cons), 2 * n + idx_j] = -2 * dr\n        \n        return J\n\n    nonlin_cons = NonlinearConstraint(\n        pairwise_constraint,\n        0.0, np.inf,\n        jac=pairwise_jac\n    )\n\n    def obj(X):\n        return -np.sum(X[2 * n:])\n        \n    def obj_jac(X):\n        grad = np.zeros_like(X)\n        grad[2 * n:] = -1.0\n        return grad\n        \n    bounds = [(0.0, 1.0)] * (2 * n) + [(1e-5, 1.0)] * n\n\n    try:\n        res = minimize(\n            obj, X0, \n            jac=obj_jac,\n            method='SLSQP',\n            bounds=bounds,\n            constraints=[lin_cons, nonlin_cons],\n            options={'maxiter': 250, 'ftol': 1e-6}\n        )\n        X_opt = res.x\n    except Exception:\n        X_opt = X0\n        \n    c_opt = np.column_stack((X_opt[:n], X_opt[n:2 * n]))\n    r_opt = X_opt[2 * n:]\n    return c_opt, r_opt\n\n\ndef batched_adam_optimizer(n, init_centers, init_radii, steps=1000):\n    \"\"\"Leverage vectorized hardware explicitly optimally robustly valid matching identically cleanly scaling perfectly accurately smoothly flawlessly identically bounds appropriately globally precisely perfectly efficiently strictly smoothly structurally optimally natively identical explicitly identical checks cleanly identically securely valid gracefully limits securely accurately gracefully securely securely perfectly strictly!\"\"\"\n    B = init_centers.shape[0]\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    lr_initial = 0.018\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 80000.0\n    \n    idx = np.arange(n)\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        if t % 200 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1, 1) < 0.6\n            centers += np.random.normal(0, 0.005, size=(B, n, 2)) * mask\n        \n        grad_c = np.zeros_like(centers)\n        grad_r = np.full_like(radii, -1.0)\n        \n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :] \n        dist = np.linalg.norm(diff, axis=-1)\n        \n        dist = np.maximum(dist, 1e-8)\n        dist[:, idx, idx] = 1.0 \n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, idx, idx] = 0.0 \n        \n        mask = overlap > 0\n        grad_r += np.sum(2.0 * C * overlap * mask, axis=2)\n        \n        factor = np.zeros_like(overlap)\n        factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n        \n        grad_c -= np.einsum('bij,bijk->bik', factor, diff)\n        \n        overlap_left = radii - centers[:, :, 0]\n        mask_l = overlap_left > 0\n        grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n        grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n        \n        overlap_right = centers[:, :, 0] + radii - 1.0\n        mask_r = overlap_right > 0\n        grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n        grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n        \n        overlap_bot = radii - centers[:, :, 1]\n        mask_b = overlap_bot > 0\n        grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n        grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n        \n        overlap_top = centers[:, :, 1] + radii - 1.0\n        mask_t = overlap_top > 0\n        grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n        grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n        \n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-5, 1.0 - 1e-5)\n        radii = np.clip(radii, 1e-5, 1.0)\n        \n    return centers, radii\n\n\ndef batched_fallback_radii(centers, target_radii):\n    \"\"\"Vectorized rapid checking ensuring securely robust correctly mapping identically globally precisely efficiently rigorously flawless natively robust checks explicitly effectively constraints smoothly checks identically valid constraints properly gracefully limits identically identical.\"\"\"\n    n = centers.shape[1]\n    radii = target_radii.copy()\n    \n    for _ in range(40):\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n        \n        rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = rad_sum - dist\n        overlap[:, np.arange(n), np.arange(n)] = 0.0\n        \n        mask = overlap > 0\n        if not np.any(mask):\n            break\n            \n        correction = np.sum(overlap * mask, axis=2) * 0.35\n        radii -= correction\n        \n    radii = np.clip(radii, 0.0, None)\n    \n    radii = np.minimum(radii, centers[:, :, 0])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 0])\n    radii = np.minimum(radii, centers[:, :, 1])\n    radii = np.minimum(radii, 1.0 - centers[:, :, 1])\n    \n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    dist[:, np.arange(n), np.arange(n)] = np.inf\n    \n    rad_sum = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n    rad_sum = np.maximum(rad_sum, 1e-12)\n    \n    scale_matrix = dist / rad_sum\n    min_scale_per_circle = np.min(scale_matrix, axis=-1)\n    final_scales = np.minimum(min_scale_per_circle, 1.0)\n    \n    radii *= final_scales * 0.999999\n    \n    return radii\n\n\ndef construct_packing():\n    \"\"\"Build highly structured topological arrangements robustly resolving strictly bounds successfully securely mapping safely smoothly structurally efficiently explicitly explicitly smoothly flawlessly effectively completely valid precisely smoothly logically.\"\"\"\n    n = 26\n    B = 100\n    init_centers = np.zeros((B, n, 2))\n    init_radii = np.full((B, n), 0.05)\n    \n    np.random.seed(42)\n    \n    for i in range(B):\n        seed_type = i % 5\n        if seed_type == 0:\n            init_centers[i] = np.random.uniform(0.1, 0.9, (n, 2))\n            init_radii[i] = np.random.uniform(0.02, 0.12, n)\n        elif seed_type == 1:\n            init_centers[i, 0] = [0.5, 0.5]\n            init_radii[i, 0] = np.random.uniform(0.15, 0.25)\n            init_centers[i, 1:] = np.random.uniform(0.1, 0.9, (n - 1, 2))\n            init_radii[i, 1:] = np.random.uniform(0.02, 0.08, n - 1)\n        elif seed_type == 2:\n            nx, ny = 5, 5\n            x, y = np.meshgrid(np.linspace(0.12, 0.88, nx), np.linspace(0.12, 0.88, ny))\n            pts = np.column_stack((x.ravel(), y.ravel()))\n            pts = np.vstack([pts, [0.5, 0.5]])\n            pts += np.random.normal(0, 0.02, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.normal(0.09, 0.015, n)\n        elif seed_type == 3:\n            init_centers[i, 0] = [0.5, 0.5]\n            angles9 = np.linspace(0, 2 * np.pi, 9, endpoint=False)\n            pts9 = np.column_stack([0.5 + 0.25 * np.cos(angles9), 0.5 + 0.25 * np.sin(angles9)])\n            angles16 = np.linspace(0, 2 * np.pi, 16, endpoint=False)\n            pts16 = np.column_stack([0.5 + 0.45 * np.cos(angles16), 0.5 + 0.45 * np.sin(angles16)])\n            pts = np.vstack([[0.5, 0.5], pts9, pts16])\n            pts += np.random.normal(0, 0.015, size=(n, 2))\n            init_centers[i] = np.clip(pts, 0.05, 0.95)\n            init_radii[i] = np.random.uniform(0.05, 0.1, n)\n        else:\n            pts = []\n            pts.extend([[0.15, 0.15], [0.15, 0.85], [0.85, 0.15], [0.85, 0.\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.9967, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Physics-based iterative optimizer for circle packing n=26\"\"\"\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged packing of 26 circles inside a unit\n    square to mathematically maximize the summation of radii natively utilizing\n    an Adam-guided gradient physics continuous domain solver on structured parallel arrays.\n\n    Returns:\n        Tuple of (centers, radii, sum_radii) perfectly bounding into the 1x1 limits\n        without overlapping geometries.\n    \"\"\"\n    np.random.seed(42)  # Secure consistent highest deterministic result \n    N = 26\n    M = 100  # Broadly simulate over vast chaotic starting layouts\n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Smart heuristics - Bias seeding structure variations dynamically\n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            # Tightly placed Vogel spiral (seed density organically spreads to margins)\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            # Highly concentric shell layout prioritizing massive inner radius\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                # Interstitial snapping heuristics placing to hard exterior boundings \n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                # Radial dispersion bias\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                # Centric dominant growth with tight marginal jiggling\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                # Jittered grid intersections scaling towards gaps\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Custom vectorized gradient constraint minimizer (Adam framework on physics domain)\n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        # Stepped learning adjustments akin to schedule decay routines\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        # Break perfect locking by invoking randomized infinitesimal space perturbations\n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0) # Derivative pulls directly outwards to organically scale bubble size\n        \n        # Boundary physics penalties handling\n        diff_x0 = R - X\n        mask = diff_x0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x0[mask]\n        grad_X[mask] -= lambda_p * 2 * diff_x0[mask]\n        \n        diff_x1 = X + R - 1.0\n        mask = diff_x1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_x1[mask]\n        grad_X[mask] += lambda_p * 2 * diff_x1[mask]\n        \n        diff_y0 = R - Y\n        mask = diff_y0 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y0[mask]\n        grad_Y[mask] -= lambda_p * 2 * diff_y0[mask]\n        \n        diff_y1 = Y + R - 1.0\n        mask = diff_y1 > 0\n        grad_R[mask] += lambda_p * 2 * diff_y1[mask]\n        grad_Y[mask] += lambda_p * 2 * diff_y1[mask]\n        \n        # Internal circular compression handling mathematically computed in simultaneous tensors\n        dx = X[:, :, None] - X[:, None, :] \n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            \n            np.add.at(grad_R, (sm, si), grad_pen)\n            np.add.at(grad_R, (sm, sj), grad_pen)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen * dx[mask_over] * inv_dist\n            grad_yi = -grad_pen * dy[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        # Bottom threshold clipping parameter natively forcing radii sizes positively stable \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        m_hat_X = m_X / (1 - beta1**adam_step)\n        v_hat_X = v_X / (1 - beta2**adam_step)\n        X -= lr * m_hat_X / (np.sqrt(v_hat_X) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        m_hat_Y = m_Y / (1 - beta1**adam_step)\n        v_hat_Y = v_Y / (1 - beta2**adam_step)\n        Y -= lr * m_hat_Y / (np.sqrt(v_hat_Y) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        m_hat_R = m_R / (1 - beta1**adam_step)\n        v_hat_R = v_R / (1 - beta2**adam_step)\n        R -= lr * m_hat_R / (np.sqrt(v_hat_R) + 1e-8)\n\n    # Clean deterministic loop securing valid 0-bound overlapping resolutions smoothly\n    valid_radii_sum = np.zeros(M)\n    for m in range(M):\n        r_m = R[m].copy()\n        x_m = X[m].copy()\n        y_m = Y[m].copy()\n        \n        # Soft iterations allowing fluid convergence without boundary distortions\n        for _ in range(200):\n            max_viol = 0.0\n            for i in range(N):\n                for j in range(i+1, N):\n                    d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                    viol = r_m[i] + r_m[j] - d\n                    if viol > 0.0:\n                        if viol > max_viol: \n                            max_viol = viol\n                        sub = (viol / 2.0) + 1e-9\n                        r_m[i] -= sub\n                        r_m[j] -= sub\n            if max_viol <= 0.0:\n                break\n                \n        # Defensive absolute fail-safe pass proportionally shrinking perfectly maintaining layout distances natively\n        for i in range(N):\n            for j in range(i+1, N):\n                d = np.hypot(x_m[i]-x_m[j], y_m[i]-y_m[j])\n                if r_m[i] + r_m[j] > d:\n                    scale = d / (r_m[i] + r_m[j]) * 0.999999\n                    if scale < 1.0:\n                        r_m[i] *= scale\n                        r_m[j] *= scale\n        \n        # Safely enforce bounding clips locking strict internal box adherence\n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        r_m = np.maximum(r_m, 1e-5)\n        \n        valid_radii_sum[m] = np.sum(r_m)\n        R[m] = r_m \n        \n    best_idx = np.argmax(valid_radii_sum)\n    final_centers = np.stack((X[best_idx], Y[best_idx]), axis=1)\n    final_radii = R[best_idx]\n    \n    return final_centers, final_radii, valid_radii_sum[best_idx]\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.9435, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles using physics optimization and annealing\"\"\"\nimport numpy as np\n\n\ndef compute_gradients(centers, radii, C):\n    \"\"\"Compute exact vectorized gradients for the circles based on overlap penalty constraints\"\"\"\n    grad_c = np.zeros_like(centers)\n    grad_r = np.full_like(radii, -1.0)  # Optimize to maximize sum(r) -> derivative of -sum(r)\n    \n    diff = centers[:, np.newaxis, :] - centers[np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    # Avoid zero-distance divide errors explicitly via float safety bounds\n    dist = np.maximum(dist, 1e-8)\n    np.fill_diagonal(dist, 1.0)\n    \n    # Compute intersection overlap bounds and pairwise force repulsion masks\n    rad_sum = radii[:, np.newaxis] + radii[np.newaxis, :]\n    overlap = rad_sum - dist\n    np.fill_diagonal(overlap, 0.0)\n    \n    mask = overlap > 0\n    grad_r += np.sum(2.0 * C * overlap * mask, axis=1)\n    \n    factor = np.zeros_like(overlap)\n    factor[mask] = (2.0 * C * overlap[mask]) / dist[mask]\n    \n    # Efficient pairwise repulsion calculations resolving directly using eignsum accumulation\n    grad_c -= np.einsum('ij,ijk->ik', factor, diff)\n    \n    # Left wall bounds validation penalty mechanism \n    overlap_left = radii - centers[:, 0]\n    mask_l = overlap_left > 0\n    grad_r[mask_l] += 2.0 * C * overlap_left[mask_l]\n    grad_c[mask_l, 0] -= 2.0 * C * overlap_left[mask_l]\n    \n    # Right wall bounds validation penalty mechanism \n    overlap_right = centers[:, 0] + radii - 1.0\n    mask_r = overlap_right > 0\n    grad_r[mask_r] += 2.0 * C * overlap_right[mask_r]\n    grad_c[mask_r, 0] += 2.0 * C * overlap_right[mask_r]\n    \n    # Bottom wall bounds validation penalty mechanism \n    overlap_bot = radii - centers[:, 1]\n    mask_b = overlap_bot > 0\n    grad_r[mask_b] += 2.0 * C * overlap_bot[mask_b]\n    grad_c[mask_b, 1] -= 2.0 * C * overlap_bot[mask_b]\n    \n    # Top wall bounds validation penalty mechanism \n    overlap_top = centers[:, 1] + radii - 1.0\n    mask_t = overlap_top > 0\n    grad_r[mask_t] += 2.0 * C * overlap_top[mask_t]\n    grad_c[mask_t, 1] += 2.0 * C * overlap_top[mask_t]\n    \n    return grad_c, grad_r\n\n\ndef adam_optimizer(n, init_centers, init_radii, steps=3000):\n    \"\"\"Executes smooth continuous annealing simulation matching physics engine properties\"\"\"\n    centers = init_centers.copy()\n    radii = init_radii.copy()\n    \n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n    \n    beta1, beta2 = 0.9, 0.999\n    eps = 1e-8\n    \n    # Fine-tuned exponential decay constraints (similar to annealing schedules)\n    lr_initial = 0.015\n    lr_final = 0.001\n    C_initial = 10.0\n    C_final = 100000.0\n    \n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        C = C_initial * (C_final / C_initial) ** frac\n        \n        # Break perfect symmetry to escape topological grid deadlocks\n        if t % 500 == 0 and t < steps * 0.5:\n            centers += np.random.normal(0, 0.005, size=(n, 2))\n        \n        grad_c, grad_r = compute_gradients(centers, radii, C)\n        \n        # Moment and bias accumulations mapping smoothly to topological surfaces\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        m_c_hat = m_c / (1 - beta1 ** t)\n        v_c_hat = v_c / (1 - beta2 ** t)\n        centers -= lr * m_c_hat / (np.sqrt(v_c_hat) + eps)\n        \n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        m_r_hat = m_r / (1 - beta1 ** t)\n        v_r_hat = v_r / (1 - beta2 ** t)\n        radii -= lr * m_r_hat / (np.sqrt(v_r_hat) + eps)\n        \n        centers = np.clip(centers, 1e-6, 1.0 - 1e-6)\n        radii = np.clip(radii, 1e-6, 1.0)\n        \n    return centers, radii\n\n\ndef compute_exact_radii_fallback(centers, target_radii):\n    \"\"\"Handles mathematically valid strictly constrained radius fallbacks completely independently\"\"\"\n    radii = target_radii.copy()\n    \n    for _ in range(100):\n        max_violation = 0.0\n        for i in range(len(radii)):\n            for j in range(i + 1, len(radii)):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                overlap = radii[i] + radii[j] - dist\n                if overlap > 0:\n                    max_violation = max(max_violation, overlap)\n                    sum_r = radii[i] + radii[j]\n                    if sum_r > 0:\n                        correction = overlap * 0.51\n                        radii[i] -= correction\n                        radii[j] -= correction\n                        \n        radii = np.clip(radii, 0.0, None)\n        for i in range(len(radii)):\n            x, y = centers[i]\n            radii[i] = min(radii[i], x, 1 - x, y, 1 - y)\n            \n        if max_violation < 1e-8:\n            break\n            \n    # Guarantee strict bounds mathematically identical to target thresholds checking valid sizes exactly\n    for i in range(len(radii)):\n        for j in range(i + 1, len(radii)):\n            dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n            if radii[i] + radii[j] > dist:\n                scale = dist / (radii[i] + radii[j])\n                scale *= 0.999999\n                radii[i] *= scale\n                radii[j] *= scale\n                \n    return radii * 0.999999\n\n\ndef get_exact_radii(centers, target_radii):\n    \"\"\"Generates an exceptionally robust and rigorously checked completely valid packing radius constraint.\"\"\"\n    n = len(centers)\n    try:\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        \n        # Enforce all geometric exterior mapping limits globally utilizing bounding offsets natively \n        for i in range(n):\n            limits = [\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            ]\n            for lim in limits:\n                row = np.zeros(n)\n                row[i] = 1.0\n                A_ub.append(row)\n                b_ub.append(lim)\n                \n        # Internal space limits exactly matching pairwise non-overlapping definitions mapping completely natively\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.hypot(centers[i, 0] - centers[j, 0], centers[i, 1] - centers[j, 1])\n                row = np.zeros(n)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist)\n                \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n        if res.success:\n            return res.x * 0.999999\n    except Exception:\n        pass\n        \n    return compute_exact_radii_fallback(centers, target_radii)\n\n\ndef construct_packing():\n    \"\"\"\n    Construct iteratively improved packings deploying simulated physics gradients with dynamic bounding heuristics\n    to guarantee globally effective area occupancy while retaining maximum stability features smoothly fitting geometries\n    \"\"\"\n    n = 26\n    best_centers = None\n    best_radii = None\n    max_sum = -1.0\n    \n    # Explores topological search tree combinations comprehensively testing symmetric structures fully scaling to solutions \n    for seed in range(4):\n        np.random.seed(42 + seed)\n        centers = np.zeros((n, 2))\n        radii = np.ones(n) * 0.05\n        \n        if seed == 0:\n            # Seed positions heuristically mapping optimal interstitial gap combinations directly applying size constraints appropriately \n            centers[0] = [0.5, 0.5]\n            radii[0] = 0.15\n            corners = [[0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9]]\n            for i in range(4):\n                centers[i + 1] = corners[i]\n                radii[i + 1] = 0.08\n            edges = [[0.5, 0.1], [0.5, 0.9], [0.1, 0.5], [0.9, 0.5]]\n            for i in range(4):\n                centers[i + 5] = edges[i]\n                radii[i + 5] = 0.08\n            centers[9:] = np.random.uniform(0.1, 0.9, (17, 2))\n            radii[9:] = np.random.uniform(0.02, 0.08, 17)\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n        elif seed == 1:\n            centers = np.random.uniform(0.1, 0.9, (n, 2))\n            radii = np.random.uniform(0.01, 0.1, n)\n        elif seed == 2:\n            grid_x, grid_y = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 6))\n            centers[:25, 0] = grid_x.flatten()[:25]\n            centers[:25, 1] = grid_y.flatten()[:25]\n            centers[25] = [0.5, 0.5]\n            centers += np.random.normal(0, 0.02, size=(n, 2))\n        else:\n            centers[0] = [0.5, 0.5]\n            for i in range(8):\n                angle = 2 * np.pi * i / 8\n                centers[i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n            for i in range(16):\n                angle = 2 * np.pi * i / 16\n                centers[i + 9] = [0.5 + 0.7 * np.cos(angle), 0.5 + 0.7 * np.sin(angle)]\n            centers += np.random.normal(0, 0.01, size=(n, 2))\n            \n        centers = np.clip(centers, 0.01, 0.99)\n        radii = np.clip(radii, 0.01, 0.2)\n        \n        c_opt, r_opt = adam_optimizer(n, centers, radii, steps=3000)\n        \n        r_exact = get_exact_radii(c_opt, r_opt)\n        current_sum = np.sum(r_exact)\n        \n        if current_sum > max_sum:\n            max_sum = current_sum\n            best_centers = c_opt.copy()\n            best_radii = r_exact.copy()\n            \n    return best_centers, best_radii, max_sum\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    visualize(centers, radii)\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Hybrid Adam optimization coupled with Highs Exact-LinProg GD Local Search for circular packing.\"\"\"\nimport numpy as np\nimport warnings\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimally arranged layout using an extensive parallel physics\n    tensor optimizer, followed by a local coordinate ascent solver on the true exact linear\n    radius-sum objective function map.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    np.random.seed(42)  \n    N = 26\n    M = 100 \n\n    X = np.zeros((M, N), dtype=float)\n    Y = np.zeros((M, N), dtype=float)\n    R = np.zeros((M, N), dtype=float)\n\n    # Heuristically structured seed injection to navigate topology combinations intelligently \n    for idx in range(M):\n        x = np.random.uniform(0.01, 0.99, N)\n        y = np.random.uniform(0.01, 0.99, N)\n        r = np.random.uniform(0.01, 0.08, N)\n\n        if idx == 0:\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for i in range(N):\n                r_spiral = np.sqrt((i + 0.5) / N) * 0.45\n                x[i] = 0.5 + r_spiral * np.cos(i * phi)\n                y[i] = 0.5 + r_spiral * np.sin(i * phi)\n                r[i] = 0.15 * (1.0 - r_spiral)\n        elif idx == 1:\n            angle_inner = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angle_outer = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            x[0] = 0.5; y[0] = 0.5; r[0] = 0.15\n            x[1:9] = 0.5 + 0.25 * np.cos(angle_inner); y[1:9] = 0.5 + 0.25 * np.sin(angle_inner)\n            x[9:] = 0.5 + 0.45 * np.cos(angle_outer); y[9:] = 0.5 + 0.45 * np.sin(angle_outer)\n        else:\n            mode = idx % 4\n            if mode == 0:\n                mask = np.random.rand(N) < 0.6\n                x[mask] = np.where(np.random.rand(mask.sum()) < 0.5, 0.05, 0.95)\n                y[~mask] = np.where(np.random.rand((~mask).sum()) < 0.5, 0.05, 0.95)\n            elif mode == 1:\n                angles = np.random.uniform(0, 2 * np.pi, N)\n                radii_spr = np.random.uniform(0.2, 0.45, N)\n                x = np.clip(0.5 + radii_spr * np.cos(angles), 0.02, 0.98)\n                y = np.clip(0.5 + radii_spr * np.sin(angles), 0.02, 0.98)\n            elif mode == 2:\n                x[0] = 0.5; y[0] = 0.5; r[0] = 0.25\n                mask = np.arange(1, N) % 2 == 0\n                x[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n                y[1:][mask] = np.clip(np.random.normal(0.5, 0.15, mask.sum()), 0.1, 0.9)\n            else:\n                grid_n = int(np.ceil(np.sqrt(N)))\n                gx, gy = np.meshgrid(np.linspace(0.1, 0.9, grid_n), np.linspace(0.1, 0.9, grid_n))\n                px, py = gx.ravel(), gy.ravel()\n                pick = np.random.choice(len(px), N, replace=False)\n                x = np.clip(px[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n                y = np.clip(py[pick] + np.random.normal(0, 0.03, N), 0.05, 0.95)\n\n        X[idx, :] = x\n        Y[idx, :] = y\n        R[idx, :] = r\n\n    # Batched vectorized tensor optimization on the soft physical relaxation properties \n    lr = 0.01\n    beta1, beta2 = 0.9, 0.999\n    \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    lambda_p = 10.0\n    steps = 2500\n\n    idx_diag = np.arange(N)\n    triu_mask = np.triu(np.ones((N, N), dtype=bool), k=1)[None, :, :]\n    identity_matrix = np.eye(N)[None, :, :]\n\n    for step in range(1, steps + 1):\n        adam_step = (step - 1) % 500 + 1\n        \n        if adam_step == 1 and step > 1:\n            m_X.fill(0.0); v_X.fill(0.0)\n            m_Y.fill(0.0); v_Y.fill(0.0)\n            m_R.fill(0.0); v_R.fill(0.0)\n        \n        if step <= 500: lambda_p = 10.0; lr = 0.01\n        elif step <= 1000: lambda_p = 50.0; lr = 0.005\n        elif step <= 1500: lambda_p = 200.0; lr = 0.002\n        elif step <= 2000: lambda_p = 1000.0; lr = 0.001\n        else: lambda_p = 10000.0; lr = 0.0005\n        \n        if step < 1800 and step % 100 == 0:\n            X += np.random.normal(0, 0.001, X.shape)\n            Y += np.random.normal(0, 0.001, Y.shape)\n            \n        grad_X = np.zeros_like(X)\n        grad_Y = np.zeros_like(Y)\n        grad_R = np.full_like(R, -1.0)\n        \n        mask_x0 = R > X\n        grad_pen = lambda_p * 2 * (R[mask_x0] - X[mask_x0])\n        grad_R[mask_x0] += grad_pen\n        grad_X[mask_x0] -= grad_pen\n        \n        mask_x1 = (X + R) > 1.0\n        grad_pen = lambda_p * 2 * (X[mask_x1] + R[mask_x1] - 1.0)\n        grad_R[mask_x1] += grad_pen\n        grad_X[mask_x1] += grad_pen\n        \n        mask_y0 = R > Y\n        grad_pen = lambda_p * 2 * (R[mask_y0] - Y[mask_y0])\n        grad_R[mask_y0] += grad_pen\n        grad_Y[mask_y0] -= grad_pen\n        \n        mask_y1 = (Y + R) > 1.0\n        grad_pen = lambda_p * 2 * (Y[mask_y1] + R[mask_y1] - 1.0)\n        grad_R[mask_y1] += grad_pen\n        grad_Y[mask_y1] += grad_pen\n        \n        dx_val = X[:, :, None] - X[:, None, :] \n        dy_val = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx_val**2 + dy_val**2\n        \n        dist_sq += identity_matrix * 1.0\n        dist_sq = np.maximum(dist_sq, 1e-12)\n        dist = np.sqrt(dist_sq)\n        dist[:, idx_diag, idx_diag] = np.inf\n        \n        overlap = (R[:, :, None] + R[:, None, :]) - dist\n        mask_over = (overlap > 0) & triu_mask\n        \n        if np.any(mask_over):\n            pen = overlap[mask_over]\n            grad_pen_ov = lambda_p * 2 * pen \n            \n            sm, si, sj = np.nonzero(mask_over)\n            np.add.at(grad_R, (sm, si), grad_pen_ov)\n            np.add.at(grad_R, (sm, sj), grad_pen_ov)\n            \n            inv_dist = 1.0 / dist[mask_over]\n            grad_xi = -grad_pen_ov * dx_val[mask_over] * inv_dist\n            grad_yi = -grad_pen_ov * dy_val[mask_over] * inv_dist\n            \n            np.add.at(grad_X, (sm, si), grad_xi)\n            np.add.at(grad_X, (sm, sj), -grad_xi)\n            np.add.at(grad_Y, (sm, si), grad_yi)\n            np.add.at(grad_Y, (sm, sj), -grad_yi)\n        \n        mask_neg_r = R < 0.001\n        grad_R[mask_neg_r] += lambda_p * 2 * (R[mask_neg_r] - 0.001)\n\n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        X -= lr * (m_X / (1 - beta1**adam_step)) / (np.sqrt(v_X / (1 - beta2**adam_step)) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        Y -= lr * (m_Y / (1 - beta1**adam_step)) / (np.sqrt(v_Y / (1 - beta2**adam_step)) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        R -= lr * (m_R / (1 - beta1**adam_step)) / (np.sqrt(v_R / (1 - beta2**adam_step)) + 1e-8)\n\n    # Topological assessment efficiently resolving internal structural candidate qualities safely\n    approx_score = np.zeros(M)\n    for m in range(M):\n        r_m = np.clip(R[m], 0.0, None)\n        x_m = X[m]\n        y_m = Y[m]\n        \n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        \n        for _ in range(4):\n            sum_r = r_m[:, None] + r_m[None, :]\n            viol = sum_r - dist[m]\n            mask_viol = viol > 0\n            if not np.any(mask_viol & triu_mask[0]): \n                break\n            for i in range(N):\n                for j in range(i+1, N):\n                    if viol[i, j] > 0:\n                        s = (viol[i, j] / 2.0) + 1e-7\n                        r_m[i] -= s\n                        r_m[j] -= s\n        approx_score[m] = np.sum(r_m)\n\n    top_candidates = np.argsort(approx_score)[-35:]\n    \n    # Pre-allocate strict constraints mapped inherently for the Highs linear mathematical operations reliably  \n    c_vec = -np.ones(N)\n    num_constraints = 4 * N + N * (N - 1) // 2\n    A_ub = np.zeros((num_constraints, N), dtype=float)\n\n    idx_con = 0\n    for i in range(N):\n        A_ub[idx_con:idx_con+4, i] = 1.0\n        idx_con += 4\n\n    i_idx, j_idx = np.triu_indices(N, 1)\n    for i, j in zip(i_idx, j_idx):\n        A_ub[idx_con, i] = 1.0\n        A_ub[idx_con, j] = 1.0\n        idx_con += 1\n\n    def get_exact_radii(c_arr):\n        \"\"\"Solve exactly for globally guaranteed optimal radii arrays for arbitrary defined configurations natively\"\"\"\n        b_ub = np.zeros(num_constraints, dtype=float)\n        b_ub[0:4*N:4] = c_arr[:, 0]\n        b_ub[1:4*N:4] = 1.0 - c_arr[:, 0]\n        b_ub[2:4*N:4] = c_arr[:, 1]\n        b_ub[3:4*N:4] = 1.0 - c_arr[:, 1]\n        \n        dx = c_arr[:, None, 0] - c_arr[None, :, 0]\n        dy = c_arr[:, None, 1] - c_arr[None, :, 1]\n        dist_mat = np.sqrt(dx**2 + dy**2)\n        b_ub[4*N:] = dist_mat[i_idx, j_idx]\n        \n        try:\n            res = linprog(c_vec, A_ub=A_ub, b_ub=b_ub, bounds=(1e-6, None), method='highs')\n            if res.success:\n                return res.x * 0.999999, -res.fun * 0.999999\n        except Exception:\n            pass\n        return None, -1.0\n\n    best_m_sum = -1.0\n    best_m_c = None\n    best_m_r = None\n\n    for m in top_candidates[::-1]:\n        c_m = np.column_stack((X[m], Y[m]))\n        r_exact, sum_exact = get_exact_radii(c_m)\n        if sum_exact > best_m_sum:\n            best_m_sum = sum_exact\n            best_m_c = c_m\n            best_m_r = r_exact\n\n    # Exact function finite-difference localized mapping optimization gradient efficiently \n    if best_m_c is not None:\n        curr_c = best_m_c.copy()\n        curr_sum = best_m_sum\n        curr_r = best_m_r.copy()\n        \n        m_t = np.zeros_like(curr_c)\n        v_t = np.zeros_like(curr_c)\n        beta1_ls = 0.9\n        beta2_ls = 0.999\n        \n        def get_grad(arr, base_val, eps=1e-5):\n            grad = np.zeros_like(arr)\n            for i in range(N):\n                for d in range(2):\n                    tmp = arr.copy()\n                    tmp[i, d] += eps\n                    _, val_pert = get_exact_radii(tmp)\n                    if val_pert != -1.0:\n                        grad[i, d] = (val_pert - base_val) / eps\n            return grad\n\n        for step in range(35):\n            g = get_grad(curr_c, curr_sum, eps=1e-5)\n            m_t = beta1_ls * m_t + (1 - beta1_ls) * g\n            v_t = beta2_ls * v_t + (1 - beta2_ls) * g**2\n            \n            m_hat = m_t / (1 - beta1_ls**(step + 1))\n            v_hat = v_t / (1 - beta2_ls**(step + 1))\n            \n            lr_ls = 0.005 * (1.0 - step / 35.0)\n            c_cand = curr_c + lr_ls * m_hat / (np.sqrt(v_hat) + 1e-8)\n            c_cand = np.clip(c_cand, 0.01, 0.99)\n            \n            r_cand, s_cand = get_exact_radii(c_cand)\n            if s_cand > curr_sum:\n                curr_sum = s_cand\n                curr_c = c_cand\n                curr_r = r_cand\n            else:\n                c_rand = curr_c + np.random.normal(0, 0.0003, size=curr_c.shape)\n                c_rand = np.clip(c_rand, 0.01, 0.99)\n                r_rand, s_rand = get_exact_radii(c_rand)\n                if s_rand > curr_sum:\n                    curr_sum = s_rand\n                    curr_c = c_rand\n                    curr_r = r_rand\n                    m_t.fill(0.0)\n                    v_t.fill(0.0)\n                    \n        return curr_c, curr_r, curr_sum\n\n    return np.column_stack((X[0], Y[0])), R[0], 0.0\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_packing():\n    \"\"\"Run the circle packing constructor for n=26\"\"\"\n    centers, radii, sum_radii = construct_packing()\n    return centers, radii, sum_radii\n\n\ndef visualize(centers, radii):\n    \"\"\"\n    Visualize the circle packing\n\n    Args:\n        centers: np.array of shape (n, 2) with (x, y) coordinates\n        radii: np.array of shape (n) with radius of each circle\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Circle\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Draw unit square\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_aspect(\"equal\")\n    ax.grid(True)\n\n    # Draw circles\n    for i, (center, radius) in enumerate(zip(centers, radii)):\n        circle = Circle(center, radius, alpha=0.5)\n        ax.add_patch(circle)\n        ax.text(center[0], center[1], str(i), ha=\"center\", va=\"center\")\n\n    plt.title(f\"Circle Packing (n={len(centers)}, sum={sum(radii):.6f})\")\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    centers, radii, sum_radii = run_packing()\n    print(f\"Sum of radii: {sum_radii}\")\n    # AlphaEvolve improved this to 2.635\n\n    # Uncomment to visualize:\n    # visualize(centers, radii)\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["# EVOLVE-BLOCK-START\nimport numpy as np\nimport warnings\nfrom scipy.optimize import linprog\n\ndef construct_packing():\n    \"\"\"\n    Constructs an optimal arrangement of 26 circles using batched Adam \n    continuous physics simulation combined with varied topological layouts, \n    refined via strict LinProg evaluation to exactly bind boundaries.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\")\n    np.random.seed(42)  \n    \n    N = 26\n    B = 160\n    \n    X = np.zeros((B, N), dtype=float)\n    Y = np.zeros((B, N), dtype=float)\n    R = np.full((B, N), 0.05, dtype=float)\n\n    # Inject varied topological structures structurally into parallel branches\n    for idx in range(B):\n        mode = idx % 6\n        if mode == 0:\n            X[idx] = np.random.uniform(0.1, 0.9, N)\n            Y[idx] = np.random.uniform(0.1, 0.9, N)\n            R[idx] = np.random.uniform(0.01, 0.1, N)\n        elif mode == 1:\n            X[idx, 0], Y[idx, 0] = 0.5, 0.5\n            R[idx, 0] = 0.2\n            angles8 = np.linspace(0, 2 * np.pi, 8, endpoint=False)\n            angles17 = np.linspace(0, 2 * np.pi, 17, endpoint=False)\n            X[idx, 1:9] = 0.5 + 0.22 * np.cos(angles8)\n            Y[idx, 1:9] = 0.5 + 0.22 * np.sin(angles8)\n            X[idx, 9:] = 0.5 + 0.44 * np.cos(angles17)\n            Y[idx, 9:] = 0.5 + 0.44 * np.sin(angles17)\n            X[idx] += np.random.normal(0, 0.015, N)\n            Y[idx] += np.random.normal(0, 0.015, N)\n        elif mode == 2:\n            gx, gy = np.meshgrid(np.linspace(0.15, 0.85, 5), np.linspace(0.15, 0.85, 5))\n            X[idx, :25] = gx.ravel()\n            Y[idx, :25] = gy.ravel()\n            X[idx, 25], Y[idx, 25] = np.random.uniform(0.3, 0.7), np.random.uniform(0.3, 0.7)\n            R[idx] = 0.08\n            X[idx] += np.random.normal(0, 0.02, N)\n            Y[idx] += np.random.normal(0, 0.02, N)\n        elif mode == 3:\n            pts = [[cx, cy] for cx in [0.08, 0.92] for cy in [0.08, 0.92]]\n            pts += [[cx, 0.5] for cx in [0.08, 0.92]] + [[0.5, cy] for cy in [0.08, 0.92]]\n            pts = np.array(pts)\n            num_pts = len(pts)\n            X[idx, :num_pts], Y[idx, :num_pts] = pts[:, 0], pts[:, 1]\n            R[idx, :num_pts] = 0.07\n            X[idx, num_pts:] = np.random.uniform(0.2, 0.8, N - num_pts)\n            Y[idx, num_pts:] = np.random.uniform(0.2, 0.8, N - num_pts)\n            R[idx, num_pts:] = np.random.uniform(0.02, 0.05, N - num_pts)\n        elif mode == 4:\n            X[idx, 0], Y[idx, 0] = 0.5, 0.5\n            for layer, count in enumerate([6, 12, 7], 1):\n                start = 1 if layer == 1 else (7 if layer == 2 else 19)\n                radius = 0.15 * layer\n                ang = np.linspace(0, 2 * np.pi, count, endpoint=False) + (0.1 * layer)\n                X[idx, start:start+count] = 0.5 + radius * np.cos(ang)\n                Y[idx, start:start+count] = 0.5 + radius * np.sin(ang)\n            X[idx] += np.random.normal(0, 0.02, N)\n            Y[idx] += np.random.normal(0, 0.02, N)\n        else:\n            phi = np.pi * (3.0 - np.sqrt(5.0))\n            for k in range(N):\n                r_spr = np.sqrt((k + 0.5) / N) * 0.44\n                X[idx, k] = 0.5 + r_spr * np.cos(k * phi)\n                Y[idx, k] = 0.5 + r_spr * np.sin(k * phi)\n            X[idx] += np.random.normal(0, 0.015, N)\n            Y[idx] += np.random.normal(0, 0.015, N)\n            \n    m_X, v_X = np.zeros_like(X), np.zeros_like(X)\n    m_Y, v_Y = np.zeros_like(Y), np.zeros_like(Y)\n    m_R, v_R = np.zeros_like(R), np.zeros_like(R)\n    \n    beta1, beta2 = 0.9, 0.999\n    lr_initial, lr_final = 0.02, 0.001\n    C_initial, C_final = 10.0, 100000.0\n    steps = 3500\n    idx_diag = np.arange(N)\n\n    # Batched iterative simulated continuous optimization strictly mapping arrays locally\n    for t in range(1, steps + 1):\n        frac = t / steps\n        lr = lr_initial * (lr_final / lr_initial) ** frac\n        lambda_p = C_initial * (C_final / C_initial) ** frac\n        \n        # Shake arrays directly introducing perturbation escapes randomly explicitly  \n        if t % 250 == 0 and t < steps * 0.7:\n            mask = np.random.rand(B, 1) < 0.6\n            X += np.random.normal(0, 0.003, (B, N)) * mask\n            Y += np.random.normal(0, 0.003, (B, N)) * mask\n            R += np.random.normal(0, 0.002, (B, N)) * mask\n            \n        dx = X[:, :, None] - X[:, None, :]\n        dy = Y[:, :, None] - Y[:, None, :]\n        dist_sq = dx**2 + dy**2\n        dist = np.sqrt(dist_sq)\n        dist_nz = np.where(dist == 0, 1e-8, dist)\n        \n        overlap = R[:, :, None] + R[:, None, :] - dist\n        overlap = np.maximum(0, overlap)\n        overlap[:, idx_diag, idx_diag] = 0.0\n        \n        ol = np.maximum(0, R - X)\n        or_ = np.maximum(0, X + R - 1.0)\n        ob = np.maximum(0, R - Y)\n        ot = np.maximum(0, Y + R - 1.0)\n        \n        grad_R = -1.0 + 2.0 * lambda_p * (np.sum(overlap, axis=2) + ol + or_ + ob + ot)\n        \n        fx = overlap * dx / dist_nz\n        fy = overlap * dy / dist_nz\n        \n        grad_X = 2.0 * lambda_p * (-np.sum(fx, axis=2) - ol + or_)\n        grad_Y = 2.0 * lambda_p * (-np.sum(fy, axis=2) - ob + ot)\n        \n        m_X = beta1 * m_X + (1 - beta1) * grad_X\n        v_X = beta2 * v_X + (1 - beta2) * grad_X**2\n        X -= lr * (m_X / (1 - beta1**t)) / (np.sqrt(v_X / (1 - beta2**t)) + 1e-8)\n        \n        m_Y = beta1 * m_Y + (1 - beta1) * grad_Y\n        v_Y = beta2 * v_Y + (1 - beta2) * grad_Y**2\n        Y -= lr * (m_Y / (1 - beta1**t)) / (np.sqrt(v_Y / (1 - beta2**t)) + 1e-8)\n        \n        m_R = beta1 * m_R + (1 - beta1) * grad_R\n        v_R = beta2 * v_R + (1 - beta2) * grad_R**2\n        R -= lr * (m_R / (1 - beta1**t)) / (np.sqrt(v_R / (1 - beta2**t)) + 1e-8)\n        \n        X = np.clip(X, 1e-4, 1.0 - 1e-4)\n        Y = np.clip(Y, 1e-4, 1.0 - 1e-4)\n        R = np.clip(R, 1e-5, 0.5)\n\n    approx_score = np.zeros(B)\n    for m in range(B):\n        r_m = R[m].copy()\n        x_m, y_m = X[m], Y[m]\n        \n        r_m = np.minimum(r_m, x_m)\n        r_m = np.minimum(r_m, 1.0 - x_m)\n        r_m = np.minimum(r_m, y_m)\n        r_m = np.minimum(r_m, 1.0 - y_m)\n        \n        d = np.linalg.norm(np.stack([x_m, y_m], axis=-1)[:, None, :] - np.stack([x_m, y_m], axis=-1)[None, :, :], axis=-1)\n        np.fill_diagonal(d, np.inf)\n        \n        for _ in range(25):\n            viol = r_m[:, None] + r_m[None, :] - d\n            if not np.any(viol > 0): break\n            for i in range(N):\n                for j in range(i+1, N):\n                    if viol[i, j] > 0:\n                        s = (viol[i, j] / 2.0) + 1e-7\n                        r_m[i] -= s\n                        r_m[j] -= s\n        approx_score[m] = np.sum(np.maximum(r_m, 0.0))\n\n    top_idx = np.argsort(approx_score)[-45:]\n\n    c_vec = -np.ones(N)\n    num_constraints = 4 * N + N * (N - 1) // 2\n    A_ub = np.zeros((num_constraints, N), dtype=float)\n\n    idx_con = 0\n    for i in range(N):\n        A_ub[idx_con:idx_con+4, i] = 1.0\n        idx_con += 4\n\n    i_idx, j_idx = np.triu_indices(N, k=1)\n    for i, j in zip(i_idx, j_idx):\n        A_ub[idx_con, i] = 1.0\n        A_ub[idx_con, j] = 1.0\n        idx_con += 1\n\n    def get_exact_radii(c_arr):\n        \"\"\"Map strictly globally bounded layouts securely valid natively reliably.\"\"\"\n        b_ub = np.zeros(num_constraints, dtype=float)\n        b_ub[0:4*N:4] = c_arr[:, 0]\n        b_ub[1:4*N:4] = 1.0 - c_arr[:, 0]\n        b_ub[2:4*N:4] = c_arr[:, 1]\n        b_ub[3:4*N:4] = 1.0 - c_arr[:, 1]\n        \n        dx_val = c_arr[:, None, 0] - c_arr[None, :, 0]\n        dy_val = c_arr[:, None, 1] - c_arr[None, :, 1]\n        dist_mat = np.sqrt(dx_val**2 + dy_val**2)\n        b_ub[4*N:] = dist_mat[i_idx, j_idx]\n        \n        try:\n            res = linprog(c_vec, A_ub=A_ub, b_ub=b_ub, bounds=(0, None), method='highs')\n            if res.success:\n                return res.x * 0.999999, -res.fun * 0.999999\n        except Exception:\n            pass\n        return None, -1.0\n\n    best_m_sum = -1.0\n    best_m_c, best_m_r = None, None\n\n    for m in top_idx[::-1]:\n        c_m = np.column_stack((X[m], Y[m]))\n        r_exact, sum_exact = get_exact_radii(c_m)\n        if sum_exact > best_m_sum:\n            best_m_sum = sum_exact\n            best_m_c = c_m\n            best_m_r = r_exact\n\n    # Centralize steep coordinate adjustments securely maintaining completely identical parameters cleanly valid smoothly \n    if best_m_c is not None:\n        curr_c, curr_sum, curr_r = best_m_c.copy(), best_m_sum, best_m_r.copy()\n        \n        m_t, v_t = np.zeros_like(curr_c), np.zeros_like(curr_c)\n        beta1_ls, beta2_ls = 0.9, 0.999\n        \n        def compute_finite_diff(arr, base_s, eps=1e-5):\n            g = np.zeros_like(arr)\n            for i in range(N):\n                for d in range(2):\n                    tmp = arr.copy()\n                    tmp[i, d] += eps\n                    _, val = get_exact_radii(tmp)\n                    if val != -1.0:\n                        g[i, d] = (val - base_s) / eps\n            return g\n\n        for step in range(40):\n            g = compute_finite_diff(curr_c, curr_sum, eps=1e-5)\n            \n            m_t = beta1_ls * m_t + (1 - beta1_ls) * g\n            v_t = beta2_ls * v_t + (1 - beta2_ls) * g**2\n            m_hat = m_t / (1 - beta1_ls**(step + 1))\n            v_hat = v_t / (1 - beta2_ls**(step + 1))\n            \n            lr_ls = 0.003 * (1.0 - step / 40.0)\n            base_cand = curr_c + lr_ls * m_hat / (np.sqrt(v_hat) + 1e-8)\n            base_cand = np.clip(base_cand, 0.01, 0.99)\n            \n            improved = False\n            for alpha in [1.0, 0.5, 0.2]:\n                c_cand = curr_c + alpha * (base_cand - curr_c)\n                r_cand, s_cand = get_exact_radii(c_cand)\n                if s_cand > curr_sum:\n                    curr_sum = s_cand\n                    curr_c = c_cand\n                    curr_r = r_cand\n                    improved = True\n                    break\n                    \n            if not improved:\n                c_rand = curr_c + np.random.normal(0, 0.0003, size=curr_c.shape)\n                c_rand = np.clip(c_rand, 0.01, 0.99)\n                r_rand, s_rand = get_exact_radii(c_rand)\n                if s_rand > curr_sum:\n                    curr_sum, curr_c, curr_r = s_rand, c_rand, r_rand\n                    m_t.fill(0.0)\n                    v_t.fill(0.0)\n                    \n        return curr_c, curr_r, curr_sum\n\n    return np.column_stack((X[0], Y[0])), R[0], 0.0\n# EVOLVE-BLOCK-END"]}}, "artifacts_json": "{\"stderr\": \"Stage 1 evaluation failed: Program execution failed: module 'program' has no attribute 'run_packing'\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/jupyter/Code/oe/dennis/run_short_6/evaluator.py\\\", line 384, in evaluate_stage1\\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\\n  File \\\"/home/jupyter/Code/oe/dennis/run_short_6/evaluator.py\\\", line 172, in run_with_timeout\\n    raise RuntimeError(f\\\"Program execution failed: {results['error']}\\\")\\nRuntimeError: Program execution failed: module 'program' has no attribute 'run_packing'\\n\", \"failure_stage\": \"stage1_execution\", \"suggestion\": \"Check basic syntax and imports before attempting full evaluation\"}", "artifact_dir": null, "embedding": null}