{"id": "2db91d17-bb4f-44e5-bed5-73c5e3ae362c", "code": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 120  # Increased batch size for more diverse parallel exploration\n    N = 26   # Number of circles\n\n    # Initialization\n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # Pattern 1: Edge/Corner biased\n    centers[0:24] = np.random.beta(0.3, 0.3, size=(24, N, 2))\n\n    # Pattern 2: Uniform grid (5x5 + 1 interstitial point)\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    grid_pts = np.vstack([grid_pts, [0.4, 0.4]])\n    for b in range(24, 48):\n        centers[b] = grid_pts + np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 3: Concentric rings placement\n    for b in range(48, 72):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        angle_offset_1 = np.random.uniform(0, 2 * np.pi)\n        for i in range(7):\n            theta = 2.0 * np.pi * i / 7.0 + angle_offset_1\n            centers[b, idx] = [0.5 + 0.22 * np.cos(theta),\n                               0.5 + 0.22 * np.sin(theta)]\n            idx += 1\n        angle_offset_2 = np.random.uniform(0, 2 * np.pi)\n        for i in range(18):\n            theta = 2.0 * np.pi * i / 18.0 + angle_offset_2\n            centers[b, idx] = [0.5 + 0.44 * np.cos(theta),\n                               0.5 + 0.44 * np.sin(theta)]\n            idx += 1\n        centers[b] += np.random.normal(0, 0.005, size=(N, 2))\n\n    # Pattern 4: Golden ratio spiral (Fibonacci)\n    phi = (1.0 + np.sqrt(5.0)) / 2.0\n    for b in range(72, 96):\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45\n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 5: Random uniform with noise\n    centers[96:120] = np.random.uniform(0.05, 0.95, size=(24, N, 2))\n\n    # Keep all centers in a safe bounding box initially\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Size placement bias: larger radii in the center, smaller in corners/edges\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 15000\n    lam_start = 5.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    # Iterative physics-based optimization to push centers to optimal configurations\n    for step in range(max_steps):\n        # Simulated annealing for constraints: penalty weight grows exponentially\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap *= (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients w.r.t pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c =", "changes_description": null, "language": "python", "parent_id": "cc32adfb-8580-4237-8d3c-ca0c6a0fa9de", "generation": 3, "timestamp": 1771876415.966477, "iteration_found": 64, "metrics": {"validity": 0.0, "combined_score": 0.0, "radius_variance": 0.0, "spatial_spread": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"stage1_passed": 0.0, "error": 0.0, "timeout": true}, "island": 2}, "prompts": {"full_rewrite_user": {"system": "You are an expert mathematician and Python developer specializing in computational geometry and circle packing optimization.\nYour task is to improve the given Python algorithm for finding a highly optimized arrangement of 26 circles within a 1x1 unit square. The objective is to maximize the sum of their radii without any of the circles overlapping or extending outside the boundaries of the square.\nInstead of hardcoding a direct arrangement, implement an iterative optimization algorithm to find the solution.\nWhen designing the optimization routine, incorporate the following geometric heuristics:\n* Seed initial positions strategically: Bias initial placements toward corners and edges to maximize space utilization.\n* Break perfect symmetry: Introduce slight random perturbations during the optimization to escape local maxima caused by edge constraints.\n* Tune optimization parameters: Ensure your physics model uses a decaying learning rate or simulated annealing approach to smoothly settle into the tightest possible packing.\n* Size placement: Bias the initialization to push larger circles toward the center and smaller circles into the corners and interstitial gaps.\n\nCode Requirements:\n* Completeness: You MUST provide a fully runnable script. Do not use ellipses (`...`), comments-as-placeholders, or unclosed structures.\n* Style: Ensure the code is syntactically perfect and strictly adheres to PEP 8 formatting.\n* Code review: doublecheck your code to make sure it will not bump into any runtime exceptions.\n* Response Format: response in plain text, without wrapping the code into a Markdown codeblock.\n", "user": "# Current Program Information\n- Fitness: 0.3333\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.3333\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### timeout\n```\nTrue\n```\n\n### timeout_duration\n```\n60\n```\n\n### failure_stage\n```\nstage1\n```\n\n### error_type\n```\ntimeout\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: stage1_passed: 0.0000, error: 0.0000, timeout: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.3333)\n```python\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 150  # Batch size for parallel exploration\n    N = 26  # Number of circles\n    \n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # 1. Edge/Corner biased initialization (Beta distribution)\n    centers[0:30] = np.random.beta(0.2, 0.2, size=(30, N, 2))\n    centers[30:60] = np.random.beta(0.3, 0.3, size=(30, N, 2))\n    centers[60:90] = np.random.beta(0.4, 0.4, size=(30, N, 2))\n\n    # 2. Grid-based initialization with noise\n    grid_size = 6\n    xv, yv = np.meshgrid(\n        np.linspace(0.1, 0.9, grid_size),\n        np.linspace(0.1, 0.9, grid_size)\n    )\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(90, 110):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # 3. Concentric rings initialization\n    for b in range(110, 130):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.45\n            angle_offset = np.random.uniform(0, 2 * np.pi)\n            for i in range(count):\n                if idx < N:\n                    angle = 2.0 * np.pi * i / count + angle_offset\n                    centers[b, idx] = [\n                        0.5 + ring_radius * np.cos(angle),\n                        0.5 + ring_radius * np.sin(angle)\n                    ]\n                    idx += 1\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # 4. Golden spiral initialization\n    for b in range(130, 150):\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45 \n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Ensure everything remains in valid approximate bounds\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Initialize larger radii for central circles, smaller for corner/edge\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 20000\n    lam_start = 5.0\n    lam_end = 5e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Exponentially growing lambda for constraints (simulated annealing)\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c = np.clip(grad_c, -1e4, 1e4)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid ranges\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final strict cleanup pass: mathematically eliminate any residual overlaps\n    # Precompute distances since centers are locked\n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    for _ in range(10000):\n        # Trim boundaries strictly\n        radii = np.minimum(radii, centers[..., 0])\n        radii = np.minimum(radii, 1.0 - centers[..., 0])\n        radii = np.minimum(radii, centers[..., 1])\n        radii = np.minimum(radii, 1.0 - centers[..., 1])\n\n        # Trim pairwise overlaps\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)\n        \n        max_over = np.max(overlap, axis=2)\n        if np.max(max_over) < 1e-11:\n            break\n            \n        # Shrink by slightly more than half of the worst overlap to guarantee convergence\n        radii -= max_over * 0.505\n        radii = np.maximum(radii, 0.0)\n\n    # Return the best batch result\n    sum_radii = np.sum(radii, axis=1)\n    best_idx = int(np.argmax(sum_radii))\n\n    return centers[best_idx], radii[best_idx], float(sum_radii[best_idx])\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n### Program 2 (Score: 0.3333)\n```python\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 200  # Batch size for parallel exploration\n    N = 26  # Number of circles\n    \n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # 1. Edge/Corner biased initialization (Beta distribution)\n    centers[:15] = np.random.beta(0.2, 0.2, size=(15, N, 2))\n    centers[15:30] = np.random.beta(0.4, 0.4, size=(15, N, 2))\n    centers[30:45] = np.random.beta(0.5, 0.5, size=(15, N, 2))\n\n    # 2. Grid-based initialization with noise\n    grid_size = 6\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, grid_size), \n                         np.linspace(0.1, 0.9, grid_size))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(45, 80):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # 3. Concentric rings initialization\n    for b in range(80, 110):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.45\n            angle_offset = np.random.uniform(0, 2 * np.pi)\n            for i in range(count):\n                if idx < N:\n                    angle = 2.0 * np.pi * i / count + angle_offset\n                    centers[b, idx] = [0.5 + ring_radius * np.cos(angle), \n                                       0.5 + ring_radius * np.sin(angle)]\n                    idx += 1\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # 4. Golden spiral initialization\n    for b in range(110, 150):\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45 \n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # 5. Random\n    centers[150:] = np.random.uniform(0.05, 0.95, size=(B - 150, N, 2))\n\n    # Ensure everything remains in valid approximate bounds\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Initialize larger radii for central circles, smaller for corner/edge\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.015\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 25000\n    lam_start = 10.0\n    lam_end = 1e7\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Exponentially growing lambda for constraints\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c = np.clip(grad_c, -1e4, 1e4)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid ranges\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final strict cleanup pass: mathematically eliminate any residual overlaps\n    # Precompute distances since centers are locked\n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    for _ in range(10000):\n        # Trim boundaries strictly\n        radii = np.minimum(radii, centers[..., 0])\n        radii = np.minimum(radii, 1.0 - centers[..., 0])\n        radii = np.minimum(radii, centers[..., 1])\n        radii = np.minimum(radii, 1.0 - centers[..., 1])\n\n        # Trim pairwise overlaps\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)\n        \n        max_over = np.max(overlap, axis=2)\n        if np.max(max_over) < 1e-11:\n            break\n            \n        # Shrink by slightly more than half of the worst overlap to guarantee convergence\n        radii -= max_over * 0.505\n        radii = np.maximum(radii, 0.0)\n\n    # Return the best batch result\n    sum_radii = np.sum(radii, axis=1)\n    best_idx = int(np.argmax(sum_radii))\n\n    return centers[best_idx], radii[best_idx], float(sum_radii[best_idx])\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n### Program 3 (Score: 0.3333)\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 100\n    N = 26\n\n    # Initialization\n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # Pattern 1: Edge/Corner biased (Beta distribution)\n    centers[0:20] = np.random.beta(0.3, 0.3, size=(20, N, 2))\n\n    # Pattern 2: Uniform grid roughly tailored for square packing\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(20, 40):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 3: Concentric rings placement\n    for b in range(40, 60):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        angle_offset_1 = np.random.uniform(0, 2 * np.pi)\n        for i in range(7):\n            theta = 2.0 * np.pi * i / 7.0 + angle_offset_1\n            centers[b, idx] = [0.5 + 0.22 * np.cos(theta),\n                               0.5 + 0.22 * np.sin(theta)]\n            idx += 1\n        angle_offset_2 = np.random.uniform(0, 2 * np.pi)\n        for i in range(18):\n            theta = 2.0 * np.pi * i / 18.0 + angle_offset_2\n            centers[b, idx] = [0.5 + 0.44 * np.cos(theta),\n                               0.5 + 0.44 * np.sin(theta)]\n            idx += 1\n        centers[b] += np.random.normal(0, 0.005, size=(N, 2))\n\n    # Pattern 4: Golden ratio spiral (Fibonacci)\n    phi = (1.0 + np.sqrt(5.0)) / 2.0\n    for b in range(60, 80):\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45\n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 5: Random uniform with noise\n    centers[80:100] = np.random.uniform(0.05, 0.95, size=(20, N, 2))\n\n    # Keep all centers in a safe bounding box initially\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Size placement bias: larger radii in the center, smaller in corners/edges\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 20000\n    lam_start = 5.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Simulated annealing for constraints: penalty weight grows exponentially\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients w.r.t pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c = np.clip(grad_c, -1e4, 1e4)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid physical ranges to maintain optimizer stability\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final pass: Linear Programming for exact mathematical validity and maximization\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n\n    for b in range(B):\n        c = np.clip(centers[b], 0.0, 1.0)\n        c_obj = -np.ones(N)\n        A_ub = []\n        b_ub = []\n\n        # Bound constraints per circle\n        for i in range(N):\n            x_i, y_i = c[i]\n            \n            # Left bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(x_i)\n            \n            # Right bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(1.0 - x_i)\n            \n            # Bottom bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(y_i)\n            \n            # Top bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(1.0 - y_i)\n\n        # Pairwise distance constraints to ensure no circle overlaps\n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_ij = np.linalg.norm(c[i] - c[j])\n                row = np.zeros(N)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_ij)\n\n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub,\n                      bounds=(0.0, None), method='highs')\n\n        if res.success:\n            s_r = -res.fun\n            if s_r > best_sum:\n                best_sum = s_r\n                best_centers = c\n                best_radii = res.x\n\n    # Fallback to mathematically rigorous manual trimming if LP somehow fails\n    if best_centers is None:\n        best_centers = centers[0]\n        best_radii = radii[0]\n        for _ in range(1500):\n            best_radii = np.minimum(best_radii, best_centers[..., 0])\n            best_radii = np.minimum(best_radii, 1.0 - best_centers[..., 0])\n            best_radii = np.minimum(best_radii, best_centers[..., 1])\n            best_radii = np.minimum(best_radii, 1.0 - best_centers[..., 1])\n\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_ij = np.linalg.norm(best_centers[i] - best_centers[j])\n                    if best_radii[i] + best_radii[j] > dist_ij:\n                        overlap_ij = best_radii[i] + best_radii[j] - dist_ij\n                        # Reduce each radius symmetrically\n                        best_radii[i] -= overlap_ij * 0.505\n                        best_radii[j] -= overlap_ij * 0.505\n            best_radii = np.maximum(best_radii, 0.0)\n        best_sum = np.sum(best_radii)\n\n    return best_centers, best_radii, float(best_sum)\n\n\n# Create an alias to ensure maximum compatibility with the evaluator hook\nconstruct_packing = run_packing\n```\nKey features: Performs well on stage1_passed (0.0000), Performs well on error (0.0000), Performs well on timeout (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Constructor-based circle packing for n=26 circles\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    B = 30  # Batch size for parallel exploration\n    N = 26  # Number of circles\n    np.random.seed(42)\n\n    # 1. Seed initial positions strategically:\n    # Use Beta(0.5, 0.5) to heavily bias placements toward corners and edges.\n    centers = np.random.beta(0.5, 0.5, size=(B, N, 2))\n    \n    # Manually place one circle directly at the center and offset a few around it.\n    centers[:, 0, :] = 0.5\n    centers[:, 1:5, :] = 0.5 + 0.15 * np.random.randn(B, 4, 2)\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # 2. Size placement bias:\n    # Initialize larger radii for central circles, smaller for corner/edge circles.\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1, keepdims=True)\n    radii = 0.06 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.01, 0.06)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 4500\n\n    for step in range(max_steps):\n        # 3. Tune optimization parameters:\n        # Exponentially growing lambda acting as simulated annealing for constraints\n        lam = 30.0 * (1.0015 ** step)\n        \n        # Smoothly decaying learning rate to settle into tightest packing\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # 4. Break perfect symmetry:\n        # Inject small random perturbations early in the optimization run\n        if step < max_steps // 2 and step % 150 == 0:\n            centers += np.random.normal(0, 0.002, size=centers.shape)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii + np.transpose(radii, (0, 2, 1))\n        overlap = np.maximum(0, sum_r - dist)\n        \n        # Exclude self-intersections\n        mask = np.eye(N)[np.newaxis, :, :]\n        overlap = overlap * (1 - mask)\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = np.sum(overlap, axis=2, keepdims=True)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0:1]\n        y = centers[..., 1:2]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1)\n\n        grad_r_bounds = p_L + p_R + p_B + p_T\n        grad_x_bounds = -p_L + p_R\n        grad_y_bounds = -p_B + p_T\n        grad_c_bounds = np.concatenate([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii), so r grad base is -1.0\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * grad_c**2\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * grad_r**2\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce geometric validity constraints\n        radii = np.maximum(radii, 0.0)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Flatten the radii dimension for final cleanup\n    radii = radii[..., 0]\n\n    # Final pass: Ensure strictly zero mathematical overlap via iterative relaxation\n    for b in range(B):\n        for _ in range(150):\n            max_over = 0.0\n            \n            # Boundary trimming\n            radii[b] = np.minimum(radii[b], centers[b, :, 0])\n            radii[b] = np.minimum(radii[b], 1 - centers[b, :, 0])\n            radii[b] = np.minimum(radii[b], centers[b, :, 1])\n            radii[b] = np.minimum(radii[b], 1 - centers[b, :, 1])\n\n            # Pairwise trimming\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_ij = np.linalg.norm(centers[b, i] - centers[b, j])\n                    if radii[b, i] + radii[b, j] > dist_ij:\n                        overlap_ij = radii[b, i] + radii[b, j] - dist_ij\n                        max_over = max(max_over, overlap_ij)\n                        \n                        if radii[b, i] + radii[b, j] > 1e-9:\n                            \n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n### Program D2 (Score: 0.0000)\n```python\n\"\"\"Iterative physics-based circle packing optimization for n=26 circles.\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 36  # Batch size for parallel exploration\n    N = 26  # Number of circles\n    \n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # 1. Edge/Corner biased initialization (Beta distribution)\n    centers[:9] = np.random.beta(0.3, 0.3, size=(9, N, 2))\n\n    # 2. Grid-based initialization with noise\n    grid_size = 6\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, grid_size), \n                         np.linspace(0.1, 0.9, grid_size))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(9, 18):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # 3. Concentric rings initialization\n    for b in range(18, 27):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.45\n            angle_offset = np.random.uniform(0, 2 * np.pi)\n            for i in range(count):\n                if idx < N:\n                    angle = 2.0 * np.pi * i / count + angle_offset\n                    centers[b, idx] = [0.5 + ring_radius * np.cos(angle), \n                                       0.5 + ring_radius * np.sin(angle)]\n                    idx += 1\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # 4. Golden spiral initialization\n    for b in range(27, B):\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45 \n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Ensure everything remains in valid approximate bounds\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Initialize larger radii for central circles, smaller for corner/edge\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.015\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 10000\n    lam_start = 10.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Exponentially growing lambda for constraints\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 400 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid ranges\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final strict cleanup pass: mathematically eliminate any residual overlaps\n    # Precompute distances since centers are locked\n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    for _ in range(5000):\n        # Trim boundaries strictly\n        radii = np.minimum(radii, centers[..., 0])\n        radii = np.minimum(radii, 1.0 - centers[..., 0])\n        radii = np.minimum(radii, centers[..., 1])\n        radii = np.minimum(radii, 1.0 - centers[..., 1])\n\n        # Trim pairwise overlaps\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)\n        \n        max_over = np.max(overlap, axis=2)\n        if np.max(max_over) < 1e-11:\n            break\n            \n        # Shrink by slightly more than half of the worst overlap to guarantee convergence\n        radii -= max_over * 0.505\n        radii = np.maximum(radii, 0.0)\n\n    # Return the best batch result\n    sum_radii = np.sum(radii, axis=1)\n    best_idx = int(np.argmax(sum_radii))\n\n    return centers[best_idx], radii[best_idx], float(sum_radii[best_idx])\n```\nKey features: Alternative approach to validity, Alternative approach to combined_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n\"\"\"Iterative physics-based circle packing optimization for n=26 circles.\"\"\"\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef initialize_state(n, seed):\n    \"\"\"Seed initial positions strategically.\"\"\"\n    np.random.seed(42 + seed)\n    centers = np.zeros((n, 2))\n    \n    pattern = seed % 5\n    \n    if pattern == 0:\n        # Golden ratio spiral (Fibonacci)\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        for i in range(n):\n            r_dist = np.sqrt((i + 0.5) / n) * 0.45 \n            theta = 2.0 * np.pi * i / phi\n            centers[i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[i, 1] = 0.5 + r_dist * np.sin(theta)\n            \n    elif pattern == 1:\n        # Uniform grid roughly tailored for square packing\n        grid_size = int(np.ceil(np.sqrt(n)))\n        idx = 0\n        for i in range(grid_size):\n            for j in range(grid_size):\n                if idx < n:\n                    x = 0.05 + 0.9 * i / (grid_size - 1)\n                    y = 0.05 + 0.9 * j / (grid_size - 1)\n                    centers[idx] = [x, y]\n                    idx += 1\n                    \n    elif pattern == 2:\n        # Biased toward edges and corners to maximize space utilization\n        centers[:, 0] = np.random.beta(0.5, 0.5, size=n)\n        centers[:, 1] = np.random.beta(0.5, 0.5, size=n)\n        \n    elif pattern == 3:\n        # Concentric rings placement\n        centers[0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.42\n            for i in range(count):\n                if idx < n:\n                    angle = 2.0 * np.pi * i / count + (ring_idx * 0.5)\n                    centers[idx] = [0.5 + ring_radius * np.cos(angle), \n                                    0.5 + ring_radius * np.sin(angle)]\n                    idx += 1\n                    \n    elif pattern == 4:\n        # Approximate hexagonal grid\n        idx = 0\n        cols = 5\n        rows = int(np.ceil(n / cols))\n        for r in range(rows):\n            for c in range(cols):\n                if idx < n:\n                    x = 0.1 + 0.8 * c / (cols - 1)\n                    if r % 2 == 1:\n                        x += 0.4 / (cols - 1)\n                    y = 0.1 + 0.8 * r / (rows - 1)\n                    centers[idx] = [x, y]\n                    idx += 1\n                    \n    # Add random jitter scaled by the seed to break perfect symmetry\n    jitter_scale = 0.005 + \n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 2 (Score: 0.3333, Type: Exploratory)\n```python\nimport numpy as np\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 150  # Batch size for parallel exploration\n    N = 26  # Number of circles\n    \n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # 1. Edge/Corner biased initialization (Beta distribution)\n    centers[0:30] = np.random.beta(0.2, 0.2, size=(30, N, 2))\n    centers[30:60] = np.random.beta(0.3, 0.3, size=(30, N, 2))\n    centers[60:90] = np.random.beta(0.4, 0.4, size=(30, N, 2))\n\n    # 2. Grid-based initialization with noise\n    grid_size = 6\n    xv, yv = np.meshgrid(\n        np.linspace(0.1, 0.9, grid_size),\n        np.linspace(0.1, 0.9, grid_size)\n    )\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(90, 110):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # 3. Concentric rings initialization\n    for b in range(110, 130):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.45\n            angle_offset = np.random.uniform(0, 2 * np.pi)\n            for i in range(count):\n                if idx < N:\n                    angle = 2.0 * np.pi * i / count + angle_offset\n                    centers[b, idx] = [\n                        0.5 + ring_radius * np.cos(angle),\n                        0.5 + ring_radius * np.sin(angle)\n                    ]\n                    idx += 1\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # 4. Golden spiral initialization\n    for b in range(130, 150):\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45 \n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Ensure everything remains in valid approximate bounds\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Initialize larger radii for central circles, smaller for corner/edge\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 20000\n    lam_start = 5.0\n    lam_end = 5e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Exponentially growing lambda for constraints (simulated annealing)\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c = np.clip(grad_c, -1e4, 1e4)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid ranges\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final strict cleanup pass: mathematically eliminate any residual overlaps\n    # Precompute distances since centers are locked\n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    for _ in range(10000):\n        # Trim boundaries strictly\n        radii = np.minimum(radii, centers[..., 0])\n        radii = np.minimum(radii, 1.0 - centers[..., 0])\n        radii = np.minimum(radii, centers[..., 1])\n        radii = np.minimum(radii, 1.0 - centers[..., 1])\n\n        # Trim pairwise overlaps\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)\n        \n        max_over = np.max(overlap, axis=2)\n        if np.max(max_over) < 1e-11:\n            break\n            \n        # Shrink by slightly more than half of the worst overlap to guarantee convergence\n        radii -= max_over * 0.505\n        radii = np.maximum(radii, 0.0)\n\n    # Return the best batch result\n    sum_radii = np.sum(radii, axis=1)\n    best_idx = int(np.argmax(sum_radii))\n\n    return centers[best_idx], radii[best_idx], float(sum_radii[best_idx])\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n\"\"\"Iterative physics-based circle packing optimization for n=26 circles.\"\"\"\nimport numpy as np\n\n\ndef construct_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    b_size = 32  # Batch size for parallel exploration\n    n_circles = 26  # Number of circles\n    \n    centers = np.random.uniform(0.1, 0.9, size=(b_size, n_circles, 2))\n\n    # 1. Edge/Corner biased initialization (Beta distribution)\n    centers[:8] = np.random.beta(0.3, 0.3, size=(8, n_circles, 2))\n\n    # 2. Grid-based initialization with noise\n    grid_size = 6\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, grid_size), \n                         np.linspace(0.1, 0.9, grid_size))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(8, 16):\n        idx = np.random.choice(len(grid_pts), n_circles, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(n_circles, 2))\n\n    # 3. Concentric rings initialization\n    for b in range(16, 24):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        for ring_idx, count in enumerate([8, 17]):\n            ring_radius = 0.22 if ring_idx == 0 else 0.45\n            angle_offset = np.random.uniform(0, 2 * np.pi)\n            for i in range(count):\n                if idx < n_circles:\n                    angle = 2.0 * np.pi * i / count + angle_offset\n                    centers[b, idx] = [0.5 + ring_radius * np.cos(angle), \n                                       0.5 + ring_radius * np.sin(angle)]\n                    idx += 1\n        centers[b] += np.random.normal(0, 0.01, size=(n_circles, 2))\n\n    # 4. Golden spiral initialization\n    for b in range(24, b_size):\n        phi = (1.0 + np.sqrt(5.0)) / 2.0\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(n_circles):\n            r_dist = np.sqrt((i + 0.5) / n_circles) * 0.45 \n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(n_circles, 2))\n\n    # Ensure everything remains in valid approximate bounds\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Initialize larger radii for central circles, smaller for corner/edge\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.015\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 10000\n    lam_start = 10.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(n_circles)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Exponentially growing lambda for constraints\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 400 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients with respect to pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_l = np.maximum(0, r - x)\n        p_r = np.maximum(0, x + r - 1.0)\n        p_b = np.maximum(0, r - y)\n        p_t = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_l + p_r + p_b + p_t)\n        grad_x_bounds = -2.0 * p_l + 2.0 * p_r\n        grad_y_bounds = -2.0 * p_b + 2.0 * p_t\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1.0 - beta1) * grad_c\n        v_c = beta2 * v_c + (1.0 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1.0 - beta1) * grad_r\n        v_r = beta2 * v_r + (1.0 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid ranges\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final strict cleanup pass: mathematically eliminate any residual overlaps\n    # Precompute distances since centers are locked\n    diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n    dist = np.linalg.norm(diff, axis=-1)\n    \n    for _ in range(5000):\n        # Trim boundaries strictly\n        radii = np.minimum(radii, centers[..., 0])\n        radii = np.minimum(radii, 1.0 - centers[..., 0])\n        radii = np.minimum(radii, centers[..., 1])\n        radii = np.minimum(radii, 1.0 - centers[..., 1])\n\n        # Trim pairwise overlaps\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)\n        \n        max_over = np.max(overlap, axis=2)\n        if np.max(max_over) < 1e-11:\n            break\n            \n        # Shrink by slightly more than half of the worst overlap to guarantee convergence\n        radii -= max_over * 0.505\n        radii = np.maximum(radii, 0.0)\n\n    # Return the best batch result\n    sum_radii = np.sum(radii, axis=1)\n    best_idx = int(np.argmax(sum_radii))\n\n    return centers[best_idx], radii[best_idx], float(sum_radii[best_idx])\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], [Fragment formatting error: 'metric_name']\n\n# Current Program\n```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 100\n    N = 26\n\n    # Initialization\n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # Pattern 1: Edge/Corner biased (Beta distribution)\n    centers[0:20] = np.random.beta(0.3, 0.3, size=(20, N, 2))\n\n    # Pattern 2: Uniform grid roughly tailored for square packing\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 6), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    for b in range(20, 40):\n        idx = np.random.choice(len(grid_pts), N, replace=False)\n        centers[b] = grid_pts[idx] + np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 3: Concentric rings placement\n    for b in range(40, 60):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        angle_offset_1 = np.random.uniform(0, 2 * np.pi)\n        for i in range(7):\n            theta = 2.0 * np.pi * i / 7.0 + angle_offset_1\n            centers[b, idx] = [0.5 + 0.22 * np.cos(theta),\n                               0.5 + 0.22 * np.sin(theta)]\n            idx += 1\n        angle_offset_2 = np.random.uniform(0, 2 * np.pi)\n        for i in range(18):\n            theta = 2.0 * np.pi * i / 18.0 + angle_offset_2\n            centers[b, idx] = [0.5 + 0.44 * np.cos(theta),\n                               0.5 + 0.44 * np.sin(theta)]\n            idx += 1\n        centers[b] += np.random.normal(0, 0.005, size=(N, 2))\n\n    # Pattern 4: Golden ratio spiral (Fibonacci)\n    phi = (1.0 + np.sqrt(5.0)) / 2.0\n    for b in range(60, 80):\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45\n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 5: Random uniform with noise\n    centers[80:100] = np.random.uniform(0.05, 0.95, size=(20, N, 2))\n\n    # Keep all centers in a safe bounding box initially\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Size placement bias: larger radii in the center, smaller in corners/edges\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 20000\n    lam_start = 5.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    for step in range(max_steps):\n        # Simulated annealing for constraints: penalty weight grows exponentially\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap = overlap * (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients w.r.t pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c = np.clip(grad_c, -1e4, 1e4)\n\n        # Apply Adam updates\n        m_c = beta1 * m_c + (1 - beta1) * grad_c\n        v_c = beta2 * v_c + (1 - beta2) * (grad_c ** 2)\n        centers -= lr * m_c / (np.sqrt(v_c) + eps)\n\n        m_r = beta1 * m_r + (1 - beta1) * grad_r\n        v_r = beta2 * v_r + (1 - beta2) * (grad_r ** 2)\n        radii -= lr * m_r / (np.sqrt(v_r) + eps)\n\n        # Enforce valid physical ranges to maintain optimizer stability\n        radii = np.maximum(radii, 0.001)\n        centers = np.clip(centers, 0.0, 1.0)\n\n    # Final pass: Linear Programming for exact mathematical validity and maximization\n    best_sum = -1.0\n    best_centers = None\n    best_radii = None\n\n    for b in range(B):\n        c = np.clip(centers[b], 0.0, 1.0)\n        c_obj = -np.ones(N)\n        A_ub = []\n        b_ub = []\n\n        # Bound constraints per circle\n        for i in range(N):\n            x_i, y_i = c[i]\n            \n            # Left bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(x_i)\n            \n            # Right bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(1.0 - x_i)\n            \n            # Bottom bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(y_i)\n            \n            # Top bound\n            row = np.zeros(N)\n            row[i] = 1.0\n            A_ub.append(row)\n            b_ub.append(1.0 - y_i)\n\n        # Pairwise distance constraints to ensure no circle overlaps\n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_ij = np.linalg.norm(c[i] - c[j])\n                row = np.zeros(N)\n                row[i] = 1.0\n                row[j] = 1.0\n                A_ub.append(row)\n                b_ub.append(dist_ij)\n\n        A_ub = np.array(A_ub)\n        b_ub = np.array(b_ub)\n\n        res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub,\n                      bounds=(0.0, None), method='highs')\n\n        if res.success:\n            s_r = -res.fun\n            if s_r > best_sum:\n                best_sum = s_r\n                best_centers = c\n                best_radii = res.x\n\n    # Fallback to mathematically rigorous manual trimming if LP somehow fails\n    if best_centers is None:\n        best_centers = centers[0]\n        best_radii = radii[0]\n        for _ in range(1500):\n            best_radii = np.minimum(best_radii, best_centers[..., 0])\n            best_radii = np.minimum(best_radii, 1.0 - best_centers[..., 0])\n            best_radii = np.minimum(best_radii, best_centers[..., 1])\n            best_radii = np.minimum(best_radii, 1.0 - best_centers[..., 1])\n\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist_ij = np.linalg.norm(best_centers[i] - best_centers[j])\n                    if best_radii[i] + best_radii[j] > dist_ij:\n                        overlap_ij = best_radii[i] + best_radii[j] - dist_ij\n                        # Reduce each radius symmetrically\n                        best_radii[i] -= overlap_ij * 0.505\n                        best_radii[j] -= overlap_ij * 0.505\n            best_radii = np.maximum(best_radii, 0.0)\n        best_sum = np.sum(best_radii)\n\n    return best_centers, best_radii, float(best_sum)\n\n\n# Create an alias to ensure maximum compatibility with the evaluator hook\nconstruct_packing = run_packing\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\n\ndef run_packing():\n    \"\"\"\n    Construct an optimized arrangement of 26 circles in a unit square\n    to maximize the sum of their radii.\n\n    Returns:\n        Tuple of (centers, radii, sum_of_radii)\n        centers: np.array of shape (26, 2) with (x, y) coordinates\n        radii: np.array of shape (26) with radius of each circle\n        sum_of_radii: Sum of all radii\n    \"\"\"\n    np.random.seed(42)\n    B = 120  # Increased batch size for more diverse parallel exploration\n    N = 26   # Number of circles\n\n    # Initialization\n    centers = np.random.uniform(0.1, 0.9, size=(B, N, 2))\n\n    # Pattern 1: Edge/Corner biased\n    centers[0:24] = np.random.beta(0.3, 0.3, size=(24, N, 2))\n\n    # Pattern 2: Uniform grid (5x5 + 1 interstitial point)\n    xv, yv = np.meshgrid(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n    grid_pts = np.stack([xv.flatten(), yv.flatten()], axis=-1)\n    grid_pts = np.vstack([grid_pts, [0.4, 0.4]])\n    for b in range(24, 48):\n        centers[b] = grid_pts + np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 3: Concentric rings placement\n    for b in range(48, 72):\n        centers[b, 0] = [0.5, 0.5]\n        idx = 1\n        angle_offset_1 = np.random.uniform(0, 2 * np.pi)\n        for i in range(7):\n            theta = 2.0 * np.pi * i / 7.0 + angle_offset_1\n            centers[b, idx] = [0.5 + 0.22 * np.cos(theta),\n                               0.5 + 0.22 * np.sin(theta)]\n            idx += 1\n        angle_offset_2 = np.random.uniform(0, 2 * np.pi)\n        for i in range(18):\n            theta = 2.0 * np.pi * i / 18.0 + angle_offset_2\n            centers[b, idx] = [0.5 + 0.44 * np.cos(theta),\n                               0.5 + 0.44 * np.sin(theta)]\n            idx += 1\n        centers[b] += np.random.normal(0, 0.005, size=(N, 2))\n\n    # Pattern 4: Golden ratio spiral (Fibonacci)\n    phi = (1.0 + np.sqrt(5.0)) / 2.0\n    for b in range(72, 96):\n        angle_offset = np.random.uniform(0, 2 * np.pi)\n        for i in range(N):\n            r_dist = np.sqrt((i + 0.5) / N) * 0.45\n            theta = 2.0 * np.pi * i / phi + angle_offset\n            centers[b, i, 0] = 0.5 + r_dist * np.cos(theta)\n            centers[b, i, 1] = 0.5 + r_dist * np.sin(theta)\n        centers[b] += np.random.normal(0, 0.01, size=(N, 2))\n\n    # Pattern 5: Random uniform with noise\n    centers[96:120] = np.random.uniform(0.05, 0.95, size=(24, N, 2))\n\n    # Keep all centers in a safe bounding box initially\n    centers = np.clip(centers, 0.02, 0.98)\n\n    # Size placement bias: larger radii in the center, smaller in corners/edges\n    dist_to_center = np.linalg.norm(centers - 0.5, axis=-1)\n    radii = 0.08 - 0.05 * (dist_to_center / 0.707)\n    radii = np.clip(radii, 0.02, 0.1)\n\n    # Adam Optimizer states\n    lr_initial = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    eps = 1e-8\n\n    m_c = np.zeros_like(centers)\n    v_c = np.zeros_like(centers)\n    m_r = np.zeros_like(radii)\n    v_r = np.zeros_like(radii)\n\n    max_steps = 15000\n    lam_start = 5.0\n    lam_end = 2e6\n    lam_factor = (lam_end / lam_start) ** (1.0 / max_steps)\n\n    mask = np.eye(N)[np.newaxis, :, :]\n\n    # Iterative physics-based optimization to push centers to optimal configurations\n    for step in range(max_steps):\n        # Simulated annealing for constraints: penalty weight grows exponentially\n        lam = lam_start * (lam_factor ** step)\n        \n        # Smoothly decaying learning rate\n        lr = lr_initial * (0.01 ** (step / max_steps))\n\n        # Break perfect symmetry to escape local maxima\n        if step < max_steps // 2 and step % 500 == 0:\n            centers += np.random.normal(0, 0.001, size=centers.shape)\n            centers = np.clip(centers, 0.0, 1.0)\n\n        # Pairwise differences and distances\n        diff = centers[:, :, np.newaxis, :] - centers[:, np.newaxis, :, :]\n        dist = np.linalg.norm(diff, axis=-1)\n\n        # Calculate overlap magnitudes\n        sum_r = radii[:, :, np.newaxis] + radii[:, np.newaxis, :]\n        overlap = np.maximum(0, sum_r - dist)\n        overlap *= (1.0 - mask)  # Exclude self-intersections\n\n        # Gradients w.r.t pairwise overlaps\n        grad_r_overlap = 2.0 * np.sum(overlap, axis=2)\n\n        dist_safe = dist + mask + 1e-8\n        force_mag = 2.0 * overlap / dist_safe\n        grad_c_overlap = -np.sum(force_mag[..., np.newaxis] * diff, axis=2)\n\n        # Boundary constraints\n        x = centers[..., 0]\n        y = centers[..., 1]\n        r = radii\n\n        p_L = np.maximum(0, r - x)\n        p_R = np.maximum(0, x + r - 1.0)\n        p_B = np.maximum(0, r - y)\n        p_T = np.maximum(0, y + r - 1.0)\n\n        grad_r_bounds = 2.0 * (p_L + p_R + p_B + p_T)\n        grad_x_bounds = -2.0 * p_L + 2.0 * p_R\n        grad_y_bounds = -2.0 * p_B + 2.0 * p_T\n        grad_c_bounds = np.stack([grad_x_bounds, grad_y_bounds], axis=-1)\n\n        # Combine gradients. Objective is maximizing sum(radii) -> min -sum(r)\n        grad_r = -1.0 + lam * (grad_r_overlap + grad_r_bounds)\n        grad_c = lam * (grad_c_overlap + grad_c_bounds)\n\n        # Clip gradients to prevent numeric explosion\n        grad_r = np.clip(grad_r, -1e4, 1e4)\n        grad_c ="]}}, "artifacts_json": "{\"stderr\": \"Stage 1 evaluation failed: Program execution failed: invalid syntax (tmpu2zcd5hw.py, line 1)\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/jupyter/Code/oe/dennis/run2_improved_si/evaluator.py\\\", line 384, in evaluate_stage1\\n    centers, radii, sum_radii = run_with_timeout(program_path, timeout_seconds=600)\\n  File \\\"/home/jupyter/Code/oe/dennis/run2_improved_si/evaluator.py\\\", line 172, in run_with_timeout\\n    raise RuntimeError(f\\\"Program execution failed: {results['error']}\\\")\\nRuntimeError: Program execution failed: invalid syntax (tmpu2zcd5hw.py, line 1)\\n\", \"failure_stage\": \"stage1_execution\", \"suggestion\": \"Check basic syntax and imports before attempting full evaluation\"}", "artifact_dir": null, "embedding": null}